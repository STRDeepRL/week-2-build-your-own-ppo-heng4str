{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.3333333333333333, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.5, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.3333333333333333, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.5, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.3333333333333333, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.5, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2167829798728538, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 0.0010000000000000005, "total_loss": -0.04274532485069358, "policy_loss": -0.04814083935222394, "vf_loss": 0.006742091593696387, "vf_explained_var": 0.30631202006091673, "kl": 0.019753561539437314, "entropy": 1.9262433552493652, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.21951876828679814, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 0.0010000000000000005, "total_loss": -0.04743197501375107, "policy_loss": -0.05247522755914057, "vf_loss": 0.005832281756799299, "vf_explained_var": 0.34943950598438583, "kl": 0.020264817382391182, "entropy": 1.9258517810453972, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000}, "sampler_results": {"episode_reward_max": 0.9129999999999999, "episode_reward_min": -0.8980000000000001, "episode_reward_mean": -0.18866666666666668, "episode_len_mean": 204.33333333333334, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {"red_0": -1.027, "blue_0": -1.036}, "policy_reward_max": {"red_0": 0.651, "blue_0": 0.978}, "policy_reward_mean": {"red_0": -0.2795, "blue_0": 0.09083333333333332}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.3333333333333333, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.5, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.3333333333333333, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.5, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.3333333333333333, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.5, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.44300000000000006, -0.3450000000000001, -0.06900000000000006, -0.03500000000000003, 0.9129999999999999, -0.8980000000000001, -0.32499999999999996, -0.728, -0.04200000000000004, 0.4119999999999999, -0.366, -0.33799999999999986], "episode_lengths": [288, 257, 174, 164, 300, 273, 97, 221, 166, 300, 110, 102], "policy_red_0_reward": [0.09199999999999997, -0.537, -1.021, 0.484, 0.46299999999999997, 0.1379999999999999, -1.018, -1.027, -1.02, 0.45799999999999996, 0.651, -1.017], "policy_blue_0_reward": [-0.535, 0.19199999999999995, 0.952, -0.519, 0.44999999999999996, -1.036, 0.6930000000000001, 0.29899999999999993, 0.978, -0.046000000000000034, -1.017, 0.6789999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4410993008443145, "mean_inference_ms": 8.4284874467382, "mean_action_processing_ms": 0.5928193244553565, "mean_env_wait_ms": 0.5438191535962391, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.21806259950002035, "StateBufferConnector_ms": 0.011464953422546387, "ViewRequirementAgentConnector_ms": 0.25200943152109784}}, "episode_reward_max": 0.9129999999999999, "episode_reward_min": -0.8980000000000001, "episode_reward_mean": -0.18866666666666668, "episode_len_mean": 204.33333333333334, "episodes_this_iter": 12, "policy_reward_min": {"red_0": -1.027, "blue_0": -1.036}, "policy_reward_max": {"red_0": 0.651, "blue_0": 0.978}, "policy_reward_mean": {"red_0": -0.2795, "blue_0": 0.09083333333333332}, "hist_stats": {"episode_reward": [-0.44300000000000006, -0.3450000000000001, -0.06900000000000006, -0.03500000000000003, 0.9129999999999999, -0.8980000000000001, -0.32499999999999996, -0.728, -0.04200000000000004, 0.4119999999999999, -0.366, -0.33799999999999986], "episode_lengths": [288, 257, 174, 164, 300, 273, 97, 221, 166, 300, 110, 102], "policy_red_0_reward": [0.09199999999999997, -0.537, -1.021, 0.484, 0.46299999999999997, 0.1379999999999999, -1.018, -1.027, -1.02, 0.45799999999999996, 0.651, -1.017], "policy_blue_0_reward": [-0.535, 0.19199999999999995, 0.952, -0.519, 0.44999999999999996, -1.036, 0.6930000000000001, 0.29899999999999993, 0.978, -0.046000000000000034, -1.017, 0.6789999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4410993008443145, "mean_inference_ms": 8.4284874467382, "mean_action_processing_ms": 0.5928193244553565, "mean_env_wait_ms": 0.5438191535962391, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.21806259950002035, "StateBufferConnector_ms": 0.011464953422546387, "ViewRequirementAgentConnector_ms": 0.25200943152109784}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 146.91440335187852, "num_env_steps_trained_throughput_per_sec": 146.91440335187852, "timesteps_total": 4000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 8000, "timers": {"training_iteration_time_ms": 27226.697, "sample_time_ms": 4512.477, "learn_time_ms": 22686.857, "learn_throughput": 176.314, "synch_weights_time_ms": 25.798}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000}, "done": false, "episodes_total": 12, "training_iteration": 1, "trial_id": "fbd9b_00000", "date": "2023-09-15_23-57-04", "timestamp": 1694836624, "time_this_iter_s": 27.236225605010986, "time_total_s": 27.236225605010986, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80ec91b0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 27.236225605010986, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 27.042499999999997, "ram_util_percent": 56.395}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.29411764705882354, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.47058823529411764, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.29411764705882354, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.47058823529411764, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.29411764705882354, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.47058823529411764, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2811694419166694, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 0.0010000000000000005, "total_loss": -0.07926809321482627, "policy_loss": -0.0879254393177689, "vf_loss": 0.008616291616150799, "vf_explained_var": 0.4763003804410497, "kl": 0.03121369504328868, "entropy": 1.8935391213744879, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3046647164970636, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.0010000000000000005, "total_loss": -0.08949482340928322, "policy_loss": -0.10084474981752768, "vf_loss": 0.0064447980794890706, "vf_explained_var": 0.5500662152965864, "kl": 0.03338018905872338, "entropy": 1.8865292315681776, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "sampler_results": {"episode_reward_max": 0.9129999999999999, "episode_reward_min": -0.8980000000000001, "episode_reward_mean": -0.03923529411764708, "episode_len_mean": 197.41176470588235, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"red_0": -1.027, "blue_0": -1.036}, "policy_reward_max": {"red_0": 1.084, "blue_0": 1.123}, "policy_reward_mean": {"red_0": -0.16317647058823528, "blue_0": 0.12394117647058825}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.29411764705882354, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.47058823529411764, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.29411764705882354, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.47058823529411764, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.29411764705882354, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.47058823529411764, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.44300000000000006, -0.3450000000000001, -0.06900000000000006, -0.03500000000000003, 0.9129999999999999, -0.8980000000000001, -0.32499999999999996, -0.728, -0.04200000000000004, 0.4119999999999999, -0.366, -0.33799999999999986, 0.4089999999999999, -0.16600000000000004, 0.4149999999999999, 0.276, -0.03700000000000003, 0.10899999999999999, -0.18600000000000005, 0.06800000000000006, 0.2629999999999999, 0.17799999999999994, -0.42600000000000005, 0.45799999999999996, -0.383, -0.43400000000000005, -0.18899999999999995, -0.15600000000000003, -0.08100000000000006, 0.4179999999999999, 0.4069999999999999, 0.42399999999999993, 0.04299999999999993, -0.48], "episode_lengths": [288, 257, 174, 164, 300, 273, 97, 221, 166, 300, 110, 102, 300, 50, 300, 69, 163, 121, 209, 132, 72, 253, 288, 164, 115, 285, 58, 199, 300, 300, 300, 300, 137, 145], "policy_red_0_reward": [0.09199999999999997, -0.537, -1.021, 0.484, 0.46299999999999997, 0.1379999999999999, -1.018, -1.027, -1.02, 0.45799999999999996, 0.651, -1.017, -0.04100000000000003, -1.009, -0.03200000000000002, -0.5059999999999999, -1.024, -1.014, 0.844, 1.084, 0.775, -0.529, 0.10699999999999998, -0.519, 0.635, -0.543, 0.8180000000000001, -0.533, -0.046000000000000034, 0.46499999999999997, -0.04500000000000003, 0.46299999999999997, -0.524, -1.02], "policy_blue_0_reward": [-0.535, 0.19199999999999995, 0.952, -0.519, 0.44999999999999996, -1.036, 0.6930000000000001, 0.29899999999999993, 0.978, -0.046000000000000034, -1.017, 0.6789999999999999, 0.44999999999999996, 0.843, 0.44699999999999995, 0.7819999999999999, 0.987, 1.123, -1.03, -1.0159999999999998, -0.512, 0.707, -0.533, 0.977, -1.018, 0.10899999999999999, -1.007, 0.377, -0.035000000000000024, -0.047000000000000035, 0.45199999999999996, -0.03900000000000003, 0.567, 0.5399999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4379381607976987, "mean_inference_ms": 8.10199900536176, "mean_action_processing_ms": 0.558095622190795, "mean_env_wait_ms": 0.5503404197882802, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1948875539443072, "StateBufferConnector_ms": 0.010682905421537511, "ViewRequirementAgentConnector_ms": 0.21208524703979492}}, "episode_reward_max": 0.9129999999999999, "episode_reward_min": -0.8980000000000001, "episode_reward_mean": -0.03923529411764708, "episode_len_mean": 197.41176470588235, "episodes_this_iter": 22, "policy_reward_min": {"red_0": -1.027, "blue_0": -1.036}, "policy_reward_max": {"red_0": 1.084, "blue_0": 1.123}, "policy_reward_mean": {"red_0": -0.16317647058823528, "blue_0": 0.12394117647058825}, "hist_stats": {"episode_reward": [-0.44300000000000006, -0.3450000000000001, -0.06900000000000006, -0.03500000000000003, 0.9129999999999999, -0.8980000000000001, -0.32499999999999996, -0.728, -0.04200000000000004, 0.4119999999999999, -0.366, -0.33799999999999986, 0.4089999999999999, -0.16600000000000004, 0.4149999999999999, 0.276, -0.03700000000000003, 0.10899999999999999, -0.18600000000000005, 0.06800000000000006, 0.2629999999999999, 0.17799999999999994, -0.42600000000000005, 0.45799999999999996, -0.383, -0.43400000000000005, -0.18899999999999995, -0.15600000000000003, -0.08100000000000006, 0.4179999999999999, 0.4069999999999999, 0.42399999999999993, 0.04299999999999993, -0.48], "episode_lengths": [288, 257, 174, 164, 300, 273, 97, 221, 166, 300, 110, 102, 300, 50, 300, 69, 163, 121, 209, 132, 72, 253, 288, 164, 115, 285, 58, 199, 300, 300, 300, 300, 137, 145], "policy_red_0_reward": [0.09199999999999997, -0.537, -1.021, 0.484, 0.46299999999999997, 0.1379999999999999, -1.018, -1.027, -1.02, 0.45799999999999996, 0.651, -1.017, -0.04100000000000003, -1.009, -0.03200000000000002, -0.5059999999999999, -1.024, -1.014, 0.844, 1.084, 0.775, -0.529, 0.10699999999999998, -0.519, 0.635, -0.543, 0.8180000000000001, -0.533, -0.046000000000000034, 0.46499999999999997, -0.04500000000000003, 0.46299999999999997, -0.524, -1.02], "policy_blue_0_reward": [-0.535, 0.19199999999999995, 0.952, -0.519, 0.44999999999999996, -1.036, 0.6930000000000001, 0.29899999999999993, 0.978, -0.046000000000000034, -1.017, 0.6789999999999999, 0.44999999999999996, 0.843, 0.44699999999999995, 0.7819999999999999, 0.987, 1.123, -1.03, -1.0159999999999998, -0.512, 0.707, -0.533, 0.977, -1.018, 0.10899999999999999, -1.007, 0.377, -0.035000000000000024, -0.047000000000000035, 0.45199999999999996, -0.03900000000000003, 0.567, 0.5399999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4379381607976987, "mean_inference_ms": 8.10199900536176, "mean_action_processing_ms": 0.558095622190795, "mean_env_wait_ms": 0.5503404197882802, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1948875539443072, "StateBufferConnector_ms": 0.010682905421537511, "ViewRequirementAgentConnector_ms": 0.21208524703979492}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 150.31018805141937, "num_env_steps_trained_throughput_per_sec": 150.31018805141937, "timesteps_total": 8000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 26919.15, "sample_time_ms": 4278.105, "learn_time_ms": 22609.169, "learn_throughput": 176.919, "synch_weights_time_ms": 30.256}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "episodes_total": 34, "training_iteration": 2, "trial_id": "fbd9b_00000", "date": "2023-09-15_23-57-32", "timestamp": 1694836652, "time_this_iter_s": 26.6249418258667, "time_total_s": 53.861167430877686, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80edb0a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 53.861167430877686, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 27.928205128205125, "ram_util_percent": 56.39487179487181}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.2982456140350877, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.43859649122807015, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.2982456140350877, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.43859649122807015, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.2982456140350877, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.43859649122807015, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4174091026186943, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.0010000000000000005, "total_loss": -0.09190263078926364, "policy_loss": -0.1064263083387535, "vf_loss": 0.01034315018102158, "vf_explained_var": 0.45355093317727246, "kl": 0.037319235898666626, "entropy": 1.8436689477413892, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3815937533508986, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 0.0010000000000000005, "total_loss": -0.092894331367764, "policy_loss": -0.10910067502845777, "vf_loss": 0.00952838820873391, "vf_explained_var": 0.4560698893542091, "kl": 0.029560167488029143, "entropy": 1.8599259191503128, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000}, "sampler_results": {"episode_reward_max": 0.9169999999999999, "episode_reward_min": -0.8980000000000001, "episode_reward_mean": 0.1320175438596491, "episode_len_mean": 183.9298245614035, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"red_0": -1.027, "blue_0": -1.036}, "policy_reward_max": {"red_0": 1.384, "blue_0": 1.357}, "policy_reward_mean": {"red_0": -0.018701754385964907, "blue_0": 0.15071929824561406}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.2982456140350877, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.43859649122807015, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.2982456140350877, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.43859649122807015, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.2982456140350877, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.43859649122807015, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.44300000000000006, -0.3450000000000001, -0.06900000000000006, -0.03500000000000003, 0.9129999999999999, -0.8980000000000001, -0.32499999999999996, -0.728, -0.04200000000000004, 0.4119999999999999, -0.366, -0.33799999999999986, 0.4089999999999999, -0.16600000000000004, 0.4149999999999999, 0.276, -0.03700000000000003, 0.10899999999999999, -0.18600000000000005, 0.06800000000000006, 0.2629999999999999, 0.17799999999999994, -0.42600000000000005, 0.45799999999999996, -0.383, -0.43400000000000005, -0.18899999999999995, -0.15600000000000003, -0.08100000000000006, 0.4179999999999999, 0.4069999999999999, 0.42399999999999993, 0.04299999999999993, -0.48, 0.9099999999999999, 0.10899999999999999, 0.41899999999999993, 0.20899999999999996, 0.3780000000000001, 0.20199999999999996, 0.3979999999999999, 0.21300000000000008, -0.31099999999999994, -0.36499999999999977, 0.9169999999999999, 0.849, 0.43199999999999994, 0.9009999999999999, 0.34299999999999997, -0.31900000000000006, 0.21499999999999986, 0.582, 0.5230000000000001, 0.9059999999999999, 0.09799999999999998, 0.3360000000000001, 0.9139999999999999], "episode_lengths": [288, 257, 174, 164, 300, 273, 97, 221, 166, 300, 110, 102, 300, 50, 300, 69, 163, 121, 209, 132, 72, 253, 288, 164, 115, 285, 58, 199, 300, 300, 300, 300, 137, 145, 300, 118, 300, 88, 38, 88, 300, 89, 96, 113, 300, 45, 175, 300, 47, 94, 239, 129, 142, 300, 121, 50, 300], "policy_red_0_reward": [0.09199999999999997, -0.537, -1.021, 0.484, 0.46299999999999997, 0.1379999999999999, -1.018, -1.027, -1.02, 0.45799999999999996, 0.651, -1.017, -0.04100000000000003, -1.009, -0.03200000000000002, -0.5059999999999999, -1.024, -1.014, 0.844, 1.084, 0.775, -0.529, 0.10699999999999998, -0.519, 0.635, -0.543, 0.8180000000000001, -0.533, -0.046000000000000034, 0.46499999999999997, -0.04500000000000003, 0.46299999999999997, -0.524, -1.02, 0.45099999999999996, -0.514, 0.45999999999999996, -0.509, 1.384, 1.218, -0.05600000000000004, -0.5059999999999999, -1.014, -1.0119999999999998, 0.46499999999999997, -0.508, 0.955, 0.44899999999999995, -0.506, 0.698, 0.751, -0.512, 1.045, 0.46399999999999997, -0.521, 1.346, 0.45399999999999996], "policy_blue_0_reward": [-0.535, 0.19199999999999995, 0.952, -0.519, 0.44999999999999996, -1.036, 0.6930000000000001, 0.29899999999999993, 0.978, -0.046000000000000034, -1.017, 0.6789999999999999, 0.44999999999999996, 0.843, 0.44699999999999995, 0.7819999999999999, 0.987, 1.123, -1.03, -1.0159999999999998, -0.512, 0.707, -0.533, 0.977, -1.018, 0.10899999999999999, -1.007, 0.377, -0.035000000000000024, -0.047000000000000035, 0.45199999999999996, -0.03900000000000003, 0.567, 0.5399999999999999, 0.45899999999999996, 0.623, -0.04100000000000003, 0.718, -1.006, -1.016, 0.45399999999999996, 0.719, 0.703, 0.647, 0.45199999999999996, 1.357, -0.523, 0.45199999999999996, 0.849, -1.017, -0.536, 1.0939999999999999, -0.522, 0.44199999999999995, 0.619, -1.0099999999999998, 0.45999999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4050055175659895, "mean_inference_ms": 7.868129850075672, "mean_action_processing_ms": 0.5280395833969957, "mean_env_wait_ms": 0.5433516510713509, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.167741900996158, "StateBufferConnector_ms": 0.009773070352119311, "ViewRequirementAgentConnector_ms": 0.19849225094443873}}, "episode_reward_max": 0.9169999999999999, "episode_reward_min": -0.8980000000000001, "episode_reward_mean": 0.1320175438596491, "episode_len_mean": 183.9298245614035, "episodes_this_iter": 23, "policy_reward_min": {"red_0": -1.027, "blue_0": -1.036}, "policy_reward_max": {"red_0": 1.384, "blue_0": 1.357}, "policy_reward_mean": {"red_0": -0.018701754385964907, "blue_0": 0.15071929824561406}, "hist_stats": {"episode_reward": [-0.44300000000000006, -0.3450000000000001, -0.06900000000000006, -0.03500000000000003, 0.9129999999999999, -0.8980000000000001, -0.32499999999999996, -0.728, -0.04200000000000004, 0.4119999999999999, -0.366, -0.33799999999999986, 0.4089999999999999, -0.16600000000000004, 0.4149999999999999, 0.276, -0.03700000000000003, 0.10899999999999999, -0.18600000000000005, 0.06800000000000006, 0.2629999999999999, 0.17799999999999994, -0.42600000000000005, 0.45799999999999996, -0.383, -0.43400000000000005, -0.18899999999999995, -0.15600000000000003, -0.08100000000000006, 0.4179999999999999, 0.4069999999999999, 0.42399999999999993, 0.04299999999999993, -0.48, 0.9099999999999999, 0.10899999999999999, 0.41899999999999993, 0.20899999999999996, 0.3780000000000001, 0.20199999999999996, 0.3979999999999999, 0.21300000000000008, -0.31099999999999994, -0.36499999999999977, 0.9169999999999999, 0.849, 0.43199999999999994, 0.9009999999999999, 0.34299999999999997, -0.31900000000000006, 0.21499999999999986, 0.582, 0.5230000000000001, 0.9059999999999999, 0.09799999999999998, 0.3360000000000001, 0.9139999999999999], "episode_lengths": [288, 257, 174, 164, 300, 273, 97, 221, 166, 300, 110, 102, 300, 50, 300, 69, 163, 121, 209, 132, 72, 253, 288, 164, 115, 285, 58, 199, 300, 300, 300, 300, 137, 145, 300, 118, 300, 88, 38, 88, 300, 89, 96, 113, 300, 45, 175, 300, 47, 94, 239, 129, 142, 300, 121, 50, 300], "policy_red_0_reward": [0.09199999999999997, -0.537, -1.021, 0.484, 0.46299999999999997, 0.1379999999999999, -1.018, -1.027, -1.02, 0.45799999999999996, 0.651, -1.017, -0.04100000000000003, -1.009, -0.03200000000000002, -0.5059999999999999, -1.024, -1.014, 0.844, 1.084, 0.775, -0.529, 0.10699999999999998, -0.519, 0.635, -0.543, 0.8180000000000001, -0.533, -0.046000000000000034, 0.46499999999999997, -0.04500000000000003, 0.46299999999999997, -0.524, -1.02, 0.45099999999999996, -0.514, 0.45999999999999996, -0.509, 1.384, 1.218, -0.05600000000000004, -0.5059999999999999, -1.014, -1.0119999999999998, 0.46499999999999997, -0.508, 0.955, 0.44899999999999995, -0.506, 0.698, 0.751, -0.512, 1.045, 0.46399999999999997, -0.521, 1.346, 0.45399999999999996], "policy_blue_0_reward": [-0.535, 0.19199999999999995, 0.952, -0.519, 0.44999999999999996, -1.036, 0.6930000000000001, 0.29899999999999993, 0.978, -0.046000000000000034, -1.017, 0.6789999999999999, 0.44999999999999996, 0.843, 0.44699999999999995, 0.7819999999999999, 0.987, 1.123, -1.03, -1.0159999999999998, -0.512, 0.707, -0.533, 0.977, -1.018, 0.10899999999999999, -1.007, 0.377, -0.035000000000000024, -0.047000000000000035, 0.45199999999999996, -0.03900000000000003, 0.567, 0.5399999999999999, 0.45899999999999996, 0.623, -0.04100000000000003, 0.718, -1.006, -1.016, 0.45399999999999996, 0.719, 0.703, 0.647, 0.45199999999999996, 1.357, -0.523, 0.45199999999999996, 0.849, -1.017, -0.536, 1.0939999999999999, -0.522, 0.44199999999999995, 0.619, -1.0099999999999998, 0.45999999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4050055175659895, "mean_inference_ms": 7.868129850075672, "mean_action_processing_ms": 0.5280395833969957, "mean_env_wait_ms": 0.5433516510713509, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.167741900996158, "StateBufferConnector_ms": 0.009773070352119311, "ViewRequirementAgentConnector_ms": 0.19849225094443873}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 146.52761235251083, "num_env_steps_trained_throughput_per_sec": 146.52761235251083, "timesteps_total": 12000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 24000, "timers": {"training_iteration_time_ms": 27045.628, "sample_time_ms": 4047.918, "learn_time_ms": 22967.825, "learn_throughput": 174.157, "synch_weights_time_ms": 28.33}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000}, "done": false, "episodes_total": 57, "training_iteration": 3, "trial_id": "fbd9b_00000", "date": "2023-09-15_23-58-01", "timestamp": 1694836681, "time_this_iter_s": 27.31017231941223, "time_total_s": 81.17133975028992, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80eb8700>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 81.17133975028992, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 24.25238095238095, "ram_util_percent": 56.595238095238095}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0125, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.35, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.375, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.35, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.025, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.375, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.35, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.375, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4305150420560191, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 0.0010000000000000005, "total_loss": -0.09267473076567209, "policy_loss": -0.10881497235429076, "vf_loss": 0.007880709211167413, "vf_explained_var": 0.4232528207823634, "kl": 0.03117530076552234, "entropy": 1.8289988784740367, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 3360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43705847676222526, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 0.0010000000000000005, "total_loss": -0.09016850112432924, "policy_loss": -0.11116420916029407, "vf_loss": 0.008775511514007425, "vf_explained_var": 0.5631978491942088, "kl": 0.02732687313530293, "entropy": 1.8376877004901568, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 3360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "sampler_results": {"episode_reward_max": 1.188, "episode_reward_min": -0.8980000000000001, "episode_reward_mean": 0.17191249999999997, "episode_len_mean": 185.875, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.037}, "policy_reward_max": {"red_0": 1.384, "blue_0": 1.3639999999999999}, "policy_reward_mean": {"red_0": 0.07277499999999999, "blue_0": 0.09913749999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.0125, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.35, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.375, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.35, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.025, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.375, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.35, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.375, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.44300000000000006, -0.3450000000000001, -0.06900000000000006, -0.03500000000000003, 0.9129999999999999, -0.8980000000000001, -0.32499999999999996, -0.728, -0.04200000000000004, 0.4119999999999999, -0.366, -0.33799999999999986, 0.4089999999999999, -0.16600000000000004, 0.4149999999999999, 0.276, -0.03700000000000003, 0.10899999999999999, -0.18600000000000005, 0.06800000000000006, 0.2629999999999999, 0.17799999999999994, -0.42600000000000005, 0.45799999999999996, -0.383, -0.43400000000000005, -0.18899999999999995, -0.15600000000000003, -0.08100000000000006, 0.4179999999999999, 0.4069999999999999, 0.42399999999999993, 0.04299999999999993, -0.48, 0.9099999999999999, 0.10899999999999999, 0.41899999999999993, 0.20899999999999996, 0.3780000000000001, 0.20199999999999996, 0.3979999999999999, 0.21300000000000008, -0.31099999999999994, -0.36499999999999977, 0.9169999999999999, 0.849, 0.43199999999999994, 0.9009999999999999, 0.34299999999999997, -0.31900000000000006, 0.21499999999999986, 0.582, 0.5230000000000001, 0.9059999999999999, 0.09799999999999998, 0.3360000000000001, 0.9139999999999999, 0.009999999999999898, 0.6, 0.10999999999999988, 1.0979999999999999, 0.9179999999999999, -0.29300000000000004, 1.188, 0.33899999999999997, 0.4059999999999999, 0.358, 0.9259999999999999, 0.16799999999999993, 0.19700000000000006, -0.4880000000000001, 0.19999999999999973, -0.27400000000000013, -0.31199999999999994, 1.17, -0.45100000000000007, 0.9199999999999999, -0.384, 0.020000000000000018, -0.19799999999999995], "episode_lengths": [288, 257, 174, 164, 300, 273, 97, 221, 166, 300, 110, 102, 300, 50, 300, 69, 163, 121, 209, 132, 72, 253, 288, 164, 115, 285, 58, 199, 300, 300, 300, 300, 137, 145, 300, 118, 300, 88, 38, 88, 300, 89, 96, 113, 300, 45, 175, 300, 47, 94, 239, 129, 142, 300, 121, 50, 300, 146, 122, 120, 124, 300, 91, 245, 201, 300, 44, 300, 255, 92, 297, 243, 237, 95, 101, 295, 300, 275, 141, 62], "policy_red_0_reward": [0.09199999999999997, -0.537, -1.021, 0.484, 0.46299999999999997, 0.1379999999999999, -1.018, -1.027, -1.02, 0.45799999999999996, 0.651, -1.017, -0.04100000000000003, -1.009, -0.03200000000000002, -0.5059999999999999, -1.024, -1.014, 0.844, 1.084, 0.775, -0.529, 0.10699999999999998, -0.519, 0.635, -0.543, 0.8180000000000001, -0.533, -0.046000000000000034, 0.46499999999999997, -0.04500000000000003, 0.46299999999999997, -0.524, -1.02, 0.45099999999999996, -0.514, 0.45999999999999996, -0.509, 1.384, 1.218, -0.05600000000000004, -0.5059999999999999, -1.014, -1.0119999999999998, 0.46499999999999997, -0.508, 0.955, 0.44899999999999995, -0.506, 0.698, 0.751, -0.512, 1.045, 0.46399999999999997, -0.521, 1.346, 0.45399999999999996, -1.025, -0.516, 1.1189999999999998, 1.108, 0.45899999999999996, 0.718, 0.45999999999999996, 0.8739999999999999, -0.048000000000000036, -1.006, 0.45899999999999996, -0.535, 1.2069999999999999, 0.06099999999999995, 0.7449999999999999, 0.2559999999999999, 0.7000000000000001, -0.015000000000000006, 0.586, 0.45799999999999996, -1.034, 1.049, 0.808], "policy_blue_0_reward": [-0.535, 0.19199999999999995, 0.952, -0.519, 0.44999999999999996, -1.036, 0.6930000000000001, 0.29899999999999993, 0.978, -0.046000000000000034, -1.017, 0.6789999999999999, 0.44999999999999996, 0.843, 0.44699999999999995, 0.7819999999999999, 0.987, 1.123, -1.03, -1.0159999999999998, -0.512, 0.707, -0.533, 0.977, -1.018, 0.10899999999999999, -1.007, 0.377, -0.035000000000000024, -0.047000000000000035, 0.45199999999999996, -0.03900000000000003, 0.567, 0.5399999999999999, 0.45899999999999996, 0.623, -0.04100000000000003, 0.718, -1.006, -1.016, 0.45399999999999996, 0.719, 0.703, 0.647, 0.45199999999999996, 1.357, -0.523, 0.45199999999999996, 0.849, -1.017, -0.536, 1.0939999999999999, -0.522, 0.44199999999999995, 0.619, -1.0099999999999998, 0.45999999999999996, 1.035, 1.116, -1.009, -0.010000000000000002, 0.45899999999999996, -1.011, 0.728, -0.535, 0.45399999999999996, 1.3639999999999999, 0.46699999999999997, 0.703, -1.01, -0.549, -0.545, -0.53, -1.012, 1.185, -1.037, 0.46199999999999997, 0.65, -1.029, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3866617541868482, "mean_inference_ms": 7.737866398042743, "mean_action_processing_ms": 0.5034624670104146, "mean_env_wait_ms": 0.536077328008534, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15879318118095398, "StateBufferConnector_ms": 0.009447634220123291, "ViewRequirementAgentConnector_ms": 0.1920795440673828}}, "episode_reward_max": 1.188, "episode_reward_min": -0.8980000000000001, "episode_reward_mean": 0.17191249999999997, "episode_len_mean": 185.875, "episodes_this_iter": 23, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.037}, "policy_reward_max": {"red_0": 1.384, "blue_0": 1.3639999999999999}, "policy_reward_mean": {"red_0": 0.07277499999999999, "blue_0": 0.09913749999999999}, "hist_stats": {"episode_reward": [-0.44300000000000006, -0.3450000000000001, -0.06900000000000006, -0.03500000000000003, 0.9129999999999999, -0.8980000000000001, -0.32499999999999996, -0.728, -0.04200000000000004, 0.4119999999999999, -0.366, -0.33799999999999986, 0.4089999999999999, -0.16600000000000004, 0.4149999999999999, 0.276, -0.03700000000000003, 0.10899999999999999, -0.18600000000000005, 0.06800000000000006, 0.2629999999999999, 0.17799999999999994, -0.42600000000000005, 0.45799999999999996, -0.383, -0.43400000000000005, -0.18899999999999995, -0.15600000000000003, -0.08100000000000006, 0.4179999999999999, 0.4069999999999999, 0.42399999999999993, 0.04299999999999993, -0.48, 0.9099999999999999, 0.10899999999999999, 0.41899999999999993, 0.20899999999999996, 0.3780000000000001, 0.20199999999999996, 0.3979999999999999, 0.21300000000000008, -0.31099999999999994, -0.36499999999999977, 0.9169999999999999, 0.849, 0.43199999999999994, 0.9009999999999999, 0.34299999999999997, -0.31900000000000006, 0.21499999999999986, 0.582, 0.5230000000000001, 0.9059999999999999, 0.09799999999999998, 0.3360000000000001, 0.9139999999999999, 0.009999999999999898, 0.6, 0.10999999999999988, 1.0979999999999999, 0.9179999999999999, -0.29300000000000004, 1.188, 0.33899999999999997, 0.4059999999999999, 0.358, 0.9259999999999999, 0.16799999999999993, 0.19700000000000006, -0.4880000000000001, 0.19999999999999973, -0.27400000000000013, -0.31199999999999994, 1.17, -0.45100000000000007, 0.9199999999999999, -0.384, 0.020000000000000018, -0.19799999999999995], "episode_lengths": [288, 257, 174, 164, 300, 273, 97, 221, 166, 300, 110, 102, 300, 50, 300, 69, 163, 121, 209, 132, 72, 253, 288, 164, 115, 285, 58, 199, 300, 300, 300, 300, 137, 145, 300, 118, 300, 88, 38, 88, 300, 89, 96, 113, 300, 45, 175, 300, 47, 94, 239, 129, 142, 300, 121, 50, 300, 146, 122, 120, 124, 300, 91, 245, 201, 300, 44, 300, 255, 92, 297, 243, 237, 95, 101, 295, 300, 275, 141, 62], "policy_red_0_reward": [0.09199999999999997, -0.537, -1.021, 0.484, 0.46299999999999997, 0.1379999999999999, -1.018, -1.027, -1.02, 0.45799999999999996, 0.651, -1.017, -0.04100000000000003, -1.009, -0.03200000000000002, -0.5059999999999999, -1.024, -1.014, 0.844, 1.084, 0.775, -0.529, 0.10699999999999998, -0.519, 0.635, -0.543, 0.8180000000000001, -0.533, -0.046000000000000034, 0.46499999999999997, -0.04500000000000003, 0.46299999999999997, -0.524, -1.02, 0.45099999999999996, -0.514, 0.45999999999999996, -0.509, 1.384, 1.218, -0.05600000000000004, -0.5059999999999999, -1.014, -1.0119999999999998, 0.46499999999999997, -0.508, 0.955, 0.44899999999999995, -0.506, 0.698, 0.751, -0.512, 1.045, 0.46399999999999997, -0.521, 1.346, 0.45399999999999996, -1.025, -0.516, 1.1189999999999998, 1.108, 0.45899999999999996, 0.718, 0.45999999999999996, 0.8739999999999999, -0.048000000000000036, -1.006, 0.45899999999999996, -0.535, 1.2069999999999999, 0.06099999999999995, 0.7449999999999999, 0.2559999999999999, 0.7000000000000001, -0.015000000000000006, 0.586, 0.45799999999999996, -1.034, 1.049, 0.808], "policy_blue_0_reward": [-0.535, 0.19199999999999995, 0.952, -0.519, 0.44999999999999996, -1.036, 0.6930000000000001, 0.29899999999999993, 0.978, -0.046000000000000034, -1.017, 0.6789999999999999, 0.44999999999999996, 0.843, 0.44699999999999995, 0.7819999999999999, 0.987, 1.123, -1.03, -1.0159999999999998, -0.512, 0.707, -0.533, 0.977, -1.018, 0.10899999999999999, -1.007, 0.377, -0.035000000000000024, -0.047000000000000035, 0.45199999999999996, -0.03900000000000003, 0.567, 0.5399999999999999, 0.45899999999999996, 0.623, -0.04100000000000003, 0.718, -1.006, -1.016, 0.45399999999999996, 0.719, 0.703, 0.647, 0.45199999999999996, 1.357, -0.523, 0.45199999999999996, 0.849, -1.017, -0.536, 1.0939999999999999, -0.522, 0.44199999999999995, 0.619, -1.0099999999999998, 0.45999999999999996, 1.035, 1.116, -1.009, -0.010000000000000002, 0.45899999999999996, -1.011, 0.728, -0.535, 0.45399999999999996, 1.3639999999999999, 0.46699999999999997, 0.703, -1.01, -0.549, -0.545, -0.53, -1.012, 1.185, -1.037, 0.46199999999999997, 0.65, -1.029, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3866617541868482, "mean_inference_ms": 7.737866398042743, "mean_action_processing_ms": 0.5034624670104146, "mean_env_wait_ms": 0.536077328008534, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15879318118095398, "StateBufferConnector_ms": 0.009447634220123291, "ViewRequirementAgentConnector_ms": 0.1920795440673828}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 139.0278445064721, "num_env_steps_trained_throughput_per_sec": 139.0278445064721, "timesteps_total": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 27477.017, "sample_time_ms": 3984.135, "learn_time_ms": 23463.947, "learn_throughput": 170.474, "synch_weights_time_ms": 27.389}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "episodes_total": 80, "training_iteration": 4, "trial_id": "fbd9b_00000", "date": "2023-09-15_23-58-31", "timestamp": 1694836711, "time_this_iter_s": 28.78434991836548, "time_total_s": 109.9556896686554, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb418df640>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 109.9556896686554, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 24.24285714285714, "ram_util_percent": 56.56428571428571}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.35, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.38, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.35, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.38, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.35, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.38, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.44938241569325327, "cur_kl_coeff": 0.6750000000000002, "cur_lr": 0.0010000000000000005, "total_loss": -0.08023558472729443, "policy_loss": -0.09862680357133892, "vf_loss": 0.008857657642753718, "vf_explained_var": 0.4765578661113977, "kl": 0.023369630976959672, "entropy": 1.8121107534815868, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 4320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4623726643466701, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.07548708242441839, "policy_loss": -0.0978625684879565, "vf_loss": 0.0092564276529932, "vf_explained_var": 0.46230965908616783, "kl": 0.01934704917929148, "entropy": 1.8416159087171158, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 4320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000}, "sampler_results": {"episode_reward_max": 1.188, "episode_reward_min": -0.8980000000000001, "episode_reward_mean": 0.17062999999999998, "episode_len_mean": 186.03, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.037}, "policy_reward_max": {"red_0": 1.384, "blue_0": 1.3639999999999999}, "policy_reward_mean": {"red_0": 0.06727999999999998, "blue_0": 0.10334999999999997}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.35, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.38, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.35, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.38, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.35, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.38, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.06900000000000006, -0.03500000000000003, 0.9129999999999999, -0.8980000000000001, -0.32499999999999996, -0.728, -0.04200000000000004, 0.4119999999999999, -0.366, -0.33799999999999986, 0.4089999999999999, -0.16600000000000004, 0.4149999999999999, 0.276, -0.03700000000000003, 0.10899999999999999, -0.18600000000000005, 0.06800000000000006, 0.2629999999999999, 0.17799999999999994, -0.42600000000000005, 0.45799999999999996, -0.383, -0.43400000000000005, -0.18899999999999995, -0.15600000000000003, -0.08100000000000006, 0.4179999999999999, 0.4069999999999999, 0.42399999999999993, 0.04299999999999993, -0.48, 0.9099999999999999, 0.10899999999999999, 0.41899999999999993, 0.20899999999999996, 0.3780000000000001, 0.20199999999999996, 0.3979999999999999, 0.21300000000000008, -0.31099999999999994, -0.36499999999999977, 0.9169999999999999, 0.849, 0.43199999999999994, 0.9009999999999999, 0.34299999999999997, -0.31900000000000006, 0.21499999999999986, 0.582, 0.5230000000000001, 0.9059999999999999, 0.09799999999999998, 0.3360000000000001, 0.9139999999999999, 0.009999999999999898, 0.6, 0.10999999999999988, 1.0979999999999999, 0.9179999999999999, -0.29300000000000004, 1.188, 0.33899999999999997, 0.4059999999999999, 0.358, 0.9259999999999999, 0.16799999999999993, 0.19700000000000006, -0.4880000000000001, 0.19999999999999973, -0.27400000000000013, -0.31199999999999994, 1.17, -0.45100000000000007, 0.9199999999999999, -0.384, 0.020000000000000018, -0.19799999999999995, 0.9209999999999999, -0.2689999999999999, 0.9259999999999999, -0.09599999999999997, 0.262, 0.028999999999999915, 0.9289999999999999, -0.29900000000000004, -0.44000000000000017, -0.2819999999999998, 0.45799999999999985, 0.06899999999999995, -0.3700000000000001, -0.247, 0.05900000000000016, -0.07299999999999995, -0.13000000000000012, -0.2480000000000001, 0.9079999999999999, 0.43199999999999994, -0.17900000000000005, 0.16200000000000014], "episode_lengths": [174, 164, 300, 273, 97, 221, 166, 300, 110, 102, 300, 50, 300, 69, 163, 121, 209, 132, 72, 253, 288, 164, 115, 285, 58, 199, 300, 300, 300, 300, 137, 145, 300, 118, 300, 88, 38, 88, 300, 89, 96, 113, 300, 45, 175, 300, 47, 94, 239, 129, 142, 300, 121, 50, 300, 146, 122, 120, 124, 300, 91, 245, 201, 300, 44, 300, 255, 92, 297, 243, 237, 95, 101, 295, 300, 275, 141, 62, 300, 80, 300, 29, 226, 296, 300, 89, 289, 86, 165, 129, 267, 77, 285, 22, 191, 234, 300, 300, 208, 105], "policy_red_0_reward": [-1.021, 0.484, 0.46299999999999997, 0.1379999999999999, -1.018, -1.027, -1.02, 0.45799999999999996, 0.651, -1.017, -0.04100000000000003, -1.009, -0.03200000000000002, -0.5059999999999999, -1.024, -1.014, 0.844, 1.084, 0.775, -0.529, 0.10699999999999998, -0.519, 0.635, -0.543, 0.8180000000000001, -0.533, -0.046000000000000034, 0.46499999999999997, -0.04500000000000003, 0.46299999999999997, -0.524, -1.02, 0.45099999999999996, -0.514, 0.45999999999999996, -0.509, 1.384, 1.218, -0.05600000000000004, -0.5059999999999999, -1.014, -1.0119999999999998, 0.46499999999999997, -0.508, 0.955, 0.44899999999999995, -0.506, 0.698, 0.751, -0.512, 1.045, 0.46399999999999997, -0.521, 1.346, 0.45399999999999996, -1.025, -0.516, 1.1189999999999998, 1.108, 0.45899999999999996, 0.718, 0.45999999999999996, 0.8739999999999999, -0.048000000000000036, -1.006, 0.45899999999999996, -0.535, 1.2069999999999999, 0.06099999999999995, 0.7449999999999999, 0.2559999999999999, 0.7000000000000001, -0.015000000000000006, 0.586, 0.45799999999999996, -1.034, 1.049, 0.808, 0.46499999999999997, -1.013, 0.45599999999999996, 0.909, 0.795, -0.546, 0.478, 0.716, -0.539, -1.017, -0.522, 0.587, 0.16999999999999993, -1.008, 0.605, -1.004, 0.8909999999999999, -1.022, 0.45299999999999996, 0.46599999999999997, -1.033, 1.174], "policy_blue_0_reward": [0.952, -0.519, 0.44999999999999996, -1.036, 0.6930000000000001, 0.29899999999999993, 0.978, -0.046000000000000034, -1.017, 0.6789999999999999, 0.44999999999999996, 0.843, 0.44699999999999995, 0.7819999999999999, 0.987, 1.123, -1.03, -1.0159999999999998, -0.512, 0.707, -0.533, 0.977, -1.018, 0.10899999999999999, -1.007, 0.377, -0.035000000000000024, -0.047000000000000035, 0.45199999999999996, -0.03900000000000003, 0.567, 0.5399999999999999, 0.45899999999999996, 0.623, -0.04100000000000003, 0.718, -1.006, -1.016, 0.45399999999999996, 0.719, 0.703, 0.647, 0.45199999999999996, 1.357, -0.523, 0.45199999999999996, 0.849, -1.017, -0.536, 1.0939999999999999, -0.522, 0.44199999999999995, 0.619, -1.0099999999999998, 0.45999999999999996, 1.035, 1.116, -1.009, -0.010000000000000002, 0.45899999999999996, -1.011, 0.728, -0.535, 0.45399999999999996, 1.3639999999999999, 0.46699999999999997, 0.703, -1.01, -0.549, -0.545, -0.53, -1.012, 1.185, -1.037, 0.46199999999999997, 0.65, -1.029, -1.006, 0.45599999999999996, 0.744, 0.47, -1.005, -0.533, 0.575, 0.45099999999999996, -1.015, 0.09899999999999987, 0.735, 0.9799999999999999, -0.518, -0.54, 0.761, -0.5459999999999999, 0.9309999999999999, -1.021, 0.7739999999999999, 0.45499999999999996, -0.03400000000000002, 0.854, -1.0119999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.37417737336341, "mean_inference_ms": 7.652913026351236, "mean_action_processing_ms": 0.481901414311854, "mean_env_wait_ms": 0.5316201285709692, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15593719482421875, "StateBufferConnector_ms": 0.009392380714416504, "ViewRequirementAgentConnector_ms": 0.19096875190734863}}, "episode_reward_max": 1.188, "episode_reward_min": -0.8980000000000001, "episode_reward_mean": 0.17062999999999998, "episode_len_mean": 186.03, "episodes_this_iter": 22, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.037}, "policy_reward_max": {"red_0": 1.384, "blue_0": 1.3639999999999999}, "policy_reward_mean": {"red_0": 0.06727999999999998, "blue_0": 0.10334999999999997}, "hist_stats": {"episode_reward": [-0.06900000000000006, -0.03500000000000003, 0.9129999999999999, -0.8980000000000001, -0.32499999999999996, -0.728, -0.04200000000000004, 0.4119999999999999, -0.366, -0.33799999999999986, 0.4089999999999999, -0.16600000000000004, 0.4149999999999999, 0.276, -0.03700000000000003, 0.10899999999999999, -0.18600000000000005, 0.06800000000000006, 0.2629999999999999, 0.17799999999999994, -0.42600000000000005, 0.45799999999999996, -0.383, -0.43400000000000005, -0.18899999999999995, -0.15600000000000003, -0.08100000000000006, 0.4179999999999999, 0.4069999999999999, 0.42399999999999993, 0.04299999999999993, -0.48, 0.9099999999999999, 0.10899999999999999, 0.41899999999999993, 0.20899999999999996, 0.3780000000000001, 0.20199999999999996, 0.3979999999999999, 0.21300000000000008, -0.31099999999999994, -0.36499999999999977, 0.9169999999999999, 0.849, 0.43199999999999994, 0.9009999999999999, 0.34299999999999997, -0.31900000000000006, 0.21499999999999986, 0.582, 0.5230000000000001, 0.9059999999999999, 0.09799999999999998, 0.3360000000000001, 0.9139999999999999, 0.009999999999999898, 0.6, 0.10999999999999988, 1.0979999999999999, 0.9179999999999999, -0.29300000000000004, 1.188, 0.33899999999999997, 0.4059999999999999, 0.358, 0.9259999999999999, 0.16799999999999993, 0.19700000000000006, -0.4880000000000001, 0.19999999999999973, -0.27400000000000013, -0.31199999999999994, 1.17, -0.45100000000000007, 0.9199999999999999, -0.384, 0.020000000000000018, -0.19799999999999995, 0.9209999999999999, -0.2689999999999999, 0.9259999999999999, -0.09599999999999997, 0.262, 0.028999999999999915, 0.9289999999999999, -0.29900000000000004, -0.44000000000000017, -0.2819999999999998, 0.45799999999999985, 0.06899999999999995, -0.3700000000000001, -0.247, 0.05900000000000016, -0.07299999999999995, -0.13000000000000012, -0.2480000000000001, 0.9079999999999999, 0.43199999999999994, -0.17900000000000005, 0.16200000000000014], "episode_lengths": [174, 164, 300, 273, 97, 221, 166, 300, 110, 102, 300, 50, 300, 69, 163, 121, 209, 132, 72, 253, 288, 164, 115, 285, 58, 199, 300, 300, 300, 300, 137, 145, 300, 118, 300, 88, 38, 88, 300, 89, 96, 113, 300, 45, 175, 300, 47, 94, 239, 129, 142, 300, 121, 50, 300, 146, 122, 120, 124, 300, 91, 245, 201, 300, 44, 300, 255, 92, 297, 243, 237, 95, 101, 295, 300, 275, 141, 62, 300, 80, 300, 29, 226, 296, 300, 89, 289, 86, 165, 129, 267, 77, 285, 22, 191, 234, 300, 300, 208, 105], "policy_red_0_reward": [-1.021, 0.484, 0.46299999999999997, 0.1379999999999999, -1.018, -1.027, -1.02, 0.45799999999999996, 0.651, -1.017, -0.04100000000000003, -1.009, -0.03200000000000002, -0.5059999999999999, -1.024, -1.014, 0.844, 1.084, 0.775, -0.529, 0.10699999999999998, -0.519, 0.635, -0.543, 0.8180000000000001, -0.533, -0.046000000000000034, 0.46499999999999997, -0.04500000000000003, 0.46299999999999997, -0.524, -1.02, 0.45099999999999996, -0.514, 0.45999999999999996, -0.509, 1.384, 1.218, -0.05600000000000004, -0.5059999999999999, -1.014, -1.0119999999999998, 0.46499999999999997, -0.508, 0.955, 0.44899999999999995, -0.506, 0.698, 0.751, -0.512, 1.045, 0.46399999999999997, -0.521, 1.346, 0.45399999999999996, -1.025, -0.516, 1.1189999999999998, 1.108, 0.45899999999999996, 0.718, 0.45999999999999996, 0.8739999999999999, -0.048000000000000036, -1.006, 0.45899999999999996, -0.535, 1.2069999999999999, 0.06099999999999995, 0.7449999999999999, 0.2559999999999999, 0.7000000000000001, -0.015000000000000006, 0.586, 0.45799999999999996, -1.034, 1.049, 0.808, 0.46499999999999997, -1.013, 0.45599999999999996, 0.909, 0.795, -0.546, 0.478, 0.716, -0.539, -1.017, -0.522, 0.587, 0.16999999999999993, -1.008, 0.605, -1.004, 0.8909999999999999, -1.022, 0.45299999999999996, 0.46599999999999997, -1.033, 1.174], "policy_blue_0_reward": [0.952, -0.519, 0.44999999999999996, -1.036, 0.6930000000000001, 0.29899999999999993, 0.978, -0.046000000000000034, -1.017, 0.6789999999999999, 0.44999999999999996, 0.843, 0.44699999999999995, 0.7819999999999999, 0.987, 1.123, -1.03, -1.0159999999999998, -0.512, 0.707, -0.533, 0.977, -1.018, 0.10899999999999999, -1.007, 0.377, -0.035000000000000024, -0.047000000000000035, 0.45199999999999996, -0.03900000000000003, 0.567, 0.5399999999999999, 0.45899999999999996, 0.623, -0.04100000000000003, 0.718, -1.006, -1.016, 0.45399999999999996, 0.719, 0.703, 0.647, 0.45199999999999996, 1.357, -0.523, 0.45199999999999996, 0.849, -1.017, -0.536, 1.0939999999999999, -0.522, 0.44199999999999995, 0.619, -1.0099999999999998, 0.45999999999999996, 1.035, 1.116, -1.009, -0.010000000000000002, 0.45899999999999996, -1.011, 0.728, -0.535, 0.45399999999999996, 1.3639999999999999, 0.46699999999999997, 0.703, -1.01, -0.549, -0.545, -0.53, -1.012, 1.185, -1.037, 0.46199999999999997, 0.65, -1.029, -1.006, 0.45599999999999996, 0.744, 0.47, -1.005, -0.533, 0.575, 0.45099999999999996, -1.015, 0.09899999999999987, 0.735, 0.9799999999999999, -0.518, -0.54, 0.761, -0.5459999999999999, 0.9309999999999999, -1.021, 0.7739999999999999, 0.45499999999999996, -0.03400000000000002, 0.854, -1.0119999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.37417737336341, "mean_inference_ms": 7.652913026351236, "mean_action_processing_ms": 0.481901414311854, "mean_env_wait_ms": 0.5316201285709692, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15593719482421875, "StateBufferConnector_ms": 0.009392380714416504, "ViewRequirementAgentConnector_ms": 0.19096875190734863}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 139.18965484985742, "num_env_steps_trained_throughput_per_sec": 139.18965484985742, "timesteps_total": 20000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 40000, "timers": {"training_iteration_time_ms": 27729.161, "sample_time_ms": 3958.949, "learn_time_ms": 23742.054, "learn_throughput": 168.477, "synch_weights_time_ms": 26.581}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000}, "done": false, "episodes_total": 102, "training_iteration": 5, "trial_id": "fbd9b_00000", "date": "2023-09-15_23-59-01", "timestamp": 1694836741, "time_this_iter_s": 28.752727031707764, "time_total_s": 138.70841670036316, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80ec8dc0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 138.70841670036316, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 24.695238095238096, "ram_util_percent": 56.77380952380955}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.39, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.33, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.39, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.33, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.39, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.33, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49287625385137895, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.08123789438201735, "policy_loss": -0.10561470860945216, "vf_loss": 0.008128133530772175, "vf_explained_var": 0.47729188619802393, "kl": 0.021837991878196926, "entropy": 1.7982201074560484, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 5280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47154682433853545, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.07480533195096845, "policy_loss": -0.09782876714792413, "vf_loss": 0.009442413920623949, "vf_explained_var": 0.5288835487018029, "kl": 0.01987750782779282, "entropy": 1.8237491056323052, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 5280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "sampler_results": {"episode_reward_max": 1.188, "episode_reward_min": -0.4880000000000001, "episode_reward_mean": 0.23692999999999995, "episode_len_mean": 185.21, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.042}, "policy_reward_max": {"red_0": 1.384, "blue_0": 1.397}, "policy_reward_mean": {"red_0": 0.17623, "blue_0": 0.06070000000000001}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.39, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.33, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.39, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.33, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.39, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.33, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.383, -0.43400000000000005, -0.18899999999999995, -0.15600000000000003, -0.08100000000000006, 0.4179999999999999, 0.4069999999999999, 0.42399999999999993, 0.04299999999999993, -0.48, 0.9099999999999999, 0.10899999999999999, 0.41899999999999993, 0.20899999999999996, 0.3780000000000001, 0.20199999999999996, 0.3979999999999999, 0.21300000000000008, -0.31099999999999994, -0.36499999999999977, 0.9169999999999999, 0.849, 0.43199999999999994, 0.9009999999999999, 0.34299999999999997, -0.31900000000000006, 0.21499999999999986, 0.582, 0.5230000000000001, 0.9059999999999999, 0.09799999999999998, 0.3360000000000001, 0.9139999999999999, 0.009999999999999898, 0.6, 0.10999999999999988, 1.0979999999999999, 0.9179999999999999, -0.29300000000000004, 1.188, 0.33899999999999997, 0.4059999999999999, 0.358, 0.9259999999999999, 0.16799999999999993, 0.19700000000000006, -0.4880000000000001, 0.19999999999999973, -0.27400000000000013, -0.31199999999999994, 1.17, -0.45100000000000007, 0.9199999999999999, -0.384, 0.020000000000000018, -0.19799999999999995, 0.9209999999999999, -0.2689999999999999, 0.9259999999999999, -0.09599999999999997, 0.262, 0.028999999999999915, 0.9289999999999999, -0.29900000000000004, -0.44000000000000017, -0.2819999999999998, 0.45799999999999985, 0.06899999999999995, -0.3700000000000001, -0.247, 0.05900000000000016, -0.07299999999999995, -0.13000000000000012, -0.2480000000000001, 0.9079999999999999, 0.43199999999999994, -0.17900000000000005, 0.16200000000000014, -0.07300000000000006, 0.5159999999999999, -0.21400000000000008, 0.9149999999999999, -0.43600000000000017, 0.12199999999999989, 0.14500000000000002, -0.007000000000000006, -0.09399999999999997, 0.8949999999999999, -0.13000000000000012, 0.31999999999999984, 0.9159999999999999, -0.21200000000000008, 0.393, 0.1160000000000001, 0.3699999999999999, 0.08699999999999997, 0.611, 0.8939999999999999, 0.45799999999999974, 0.9229999999999999], "episode_lengths": [115, 285, 58, 199, 300, 300, 300, 300, 137, 145, 300, 118, 300, 88, 38, 88, 300, 89, 96, 113, 300, 45, 175, 300, 47, 94, 239, 129, 142, 300, 121, 50, 300, 146, 122, 120, 124, 300, 91, 245, 201, 300, 44, 300, 255, 92, 297, 243, 237, 95, 101, 295, 300, 275, 141, 62, 300, 80, 300, 29, 226, 296, 300, 89, 289, 86, 165, 129, 267, 77, 285, 22, 191, 234, 300, 300, 208, 105, 172, 145, 218, 300, 289, 115, 109, 156, 29, 300, 195, 56, 300, 215, 33, 118, 188, 124, 119, 300, 165, 300], "policy_red_0_reward": [0.635, -0.543, 0.8180000000000001, -0.533, -0.046000000000000034, 0.46499999999999997, -0.04500000000000003, 0.46299999999999997, -0.524, -1.02, 0.45099999999999996, -0.514, 0.45999999999999996, -0.509, 1.384, 1.218, -0.05600000000000004, -0.5059999999999999, -1.014, -1.0119999999999998, 0.46499999999999997, -0.508, 0.955, 0.44899999999999995, -0.506, 0.698, 0.751, -0.512, 1.045, 0.46399999999999997, -0.521, 1.346, 0.45399999999999996, -1.025, -0.516, 1.1189999999999998, 1.108, 0.45899999999999996, 0.718, 0.45999999999999996, 0.8739999999999999, -0.048000000000000036, -1.006, 0.45899999999999996, -0.535, 1.2069999999999999, 0.06099999999999995, 0.7449999999999999, 0.2559999999999999, 0.7000000000000001, -0.015000000000000006, 0.586, 0.45799999999999996, -1.034, 1.049, 0.808, 0.46499999999999997, -1.013, 0.45599999999999996, 0.909, 0.795, -0.546, 0.478, 0.716, -0.539, -1.017, -0.522, 0.587, 0.16999999999999993, -1.008, 0.605, -1.004, 0.8909999999999999, -1.022, 0.45299999999999996, 0.46599999999999997, -1.033, 1.174, -1.029, -0.527, 0.31699999999999995, 0.46199999999999997, 0.6059999999999999, 1.1400000000000001, 0.657, -0.516, 0.911, 0.44599999999999995, 0.8919999999999999, 0.823, 0.46299999999999997, -1.034, -1.004, -1.015, 0.8999999999999999, 0.608, 1.124, 0.44699999999999995, 0.9849999999999999, 0.46599999999999997], "policy_blue_0_reward": [-1.018, 0.10899999999999999, -1.007, 0.377, -0.035000000000000024, -0.047000000000000035, 0.45199999999999996, -0.03900000000000003, 0.567, 0.5399999999999999, 0.45899999999999996, 0.623, -0.04100000000000003, 0.718, -1.006, -1.016, 0.45399999999999996, 0.719, 0.703, 0.647, 0.45199999999999996, 1.357, -0.523, 0.45199999999999996, 0.849, -1.017, -0.536, 1.0939999999999999, -0.522, 0.44199999999999995, 0.619, -1.0099999999999998, 0.45999999999999996, 1.035, 1.116, -1.009, -0.010000000000000002, 0.45899999999999996, -1.011, 0.728, -0.535, 0.45399999999999996, 1.3639999999999999, 0.46699999999999997, 0.703, -1.01, -0.549, -0.545, -0.53, -1.012, 1.185, -1.037, 0.46199999999999997, 0.65, -1.029, -1.006, 0.45599999999999996, 0.744, 0.47, -1.005, -0.533, 0.575, 0.45099999999999996, -1.015, 0.09899999999999987, 0.735, 0.9799999999999999, -0.518, -0.54, 0.761, -0.5459999999999999, 0.9309999999999999, -1.021, 0.7739999999999999, 0.45499999999999996, -0.03400000000000002, 0.854, -1.0119999999999998, 0.956, 1.043, -0.531, 0.45299999999999996, -1.042, -1.018, -0.512, 0.509, -1.005, 0.44899999999999995, -1.022, -0.503, 0.45299999999999996, 0.822, 1.397, 1.131, -0.53, -0.521, -0.513, 0.44699999999999995, -0.527, 0.45699999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.353796774562855, "mean_inference_ms": 7.4659273866962135, "mean_action_processing_ms": 0.4500412340054645, "mean_env_wait_ms": 0.5240773289646643, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14583611488342285, "StateBufferConnector_ms": 0.008916258811950684, "ViewRequirementAgentConnector_ms": 0.1803114414215088}}, "episode_reward_max": 1.188, "episode_reward_min": -0.4880000000000001, "episode_reward_mean": 0.23692999999999995, "episode_len_mean": 185.21, "episodes_this_iter": 22, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.042}, "policy_reward_max": {"red_0": 1.384, "blue_0": 1.397}, "policy_reward_mean": {"red_0": 0.17623, "blue_0": 0.06070000000000001}, "hist_stats": {"episode_reward": [-0.383, -0.43400000000000005, -0.18899999999999995, -0.15600000000000003, -0.08100000000000006, 0.4179999999999999, 0.4069999999999999, 0.42399999999999993, 0.04299999999999993, -0.48, 0.9099999999999999, 0.10899999999999999, 0.41899999999999993, 0.20899999999999996, 0.3780000000000001, 0.20199999999999996, 0.3979999999999999, 0.21300000000000008, -0.31099999999999994, -0.36499999999999977, 0.9169999999999999, 0.849, 0.43199999999999994, 0.9009999999999999, 0.34299999999999997, -0.31900000000000006, 0.21499999999999986, 0.582, 0.5230000000000001, 0.9059999999999999, 0.09799999999999998, 0.3360000000000001, 0.9139999999999999, 0.009999999999999898, 0.6, 0.10999999999999988, 1.0979999999999999, 0.9179999999999999, -0.29300000000000004, 1.188, 0.33899999999999997, 0.4059999999999999, 0.358, 0.9259999999999999, 0.16799999999999993, 0.19700000000000006, -0.4880000000000001, 0.19999999999999973, -0.27400000000000013, -0.31199999999999994, 1.17, -0.45100000000000007, 0.9199999999999999, -0.384, 0.020000000000000018, -0.19799999999999995, 0.9209999999999999, -0.2689999999999999, 0.9259999999999999, -0.09599999999999997, 0.262, 0.028999999999999915, 0.9289999999999999, -0.29900000000000004, -0.44000000000000017, -0.2819999999999998, 0.45799999999999985, 0.06899999999999995, -0.3700000000000001, -0.247, 0.05900000000000016, -0.07299999999999995, -0.13000000000000012, -0.2480000000000001, 0.9079999999999999, 0.43199999999999994, -0.17900000000000005, 0.16200000000000014, -0.07300000000000006, 0.5159999999999999, -0.21400000000000008, 0.9149999999999999, -0.43600000000000017, 0.12199999999999989, 0.14500000000000002, -0.007000000000000006, -0.09399999999999997, 0.8949999999999999, -0.13000000000000012, 0.31999999999999984, 0.9159999999999999, -0.21200000000000008, 0.393, 0.1160000000000001, 0.3699999999999999, 0.08699999999999997, 0.611, 0.8939999999999999, 0.45799999999999974, 0.9229999999999999], "episode_lengths": [115, 285, 58, 199, 300, 300, 300, 300, 137, 145, 300, 118, 300, 88, 38, 88, 300, 89, 96, 113, 300, 45, 175, 300, 47, 94, 239, 129, 142, 300, 121, 50, 300, 146, 122, 120, 124, 300, 91, 245, 201, 300, 44, 300, 255, 92, 297, 243, 237, 95, 101, 295, 300, 275, 141, 62, 300, 80, 300, 29, 226, 296, 300, 89, 289, 86, 165, 129, 267, 77, 285, 22, 191, 234, 300, 300, 208, 105, 172, 145, 218, 300, 289, 115, 109, 156, 29, 300, 195, 56, 300, 215, 33, 118, 188, 124, 119, 300, 165, 300], "policy_red_0_reward": [0.635, -0.543, 0.8180000000000001, -0.533, -0.046000000000000034, 0.46499999999999997, -0.04500000000000003, 0.46299999999999997, -0.524, -1.02, 0.45099999999999996, -0.514, 0.45999999999999996, -0.509, 1.384, 1.218, -0.05600000000000004, -0.5059999999999999, -1.014, -1.0119999999999998, 0.46499999999999997, -0.508, 0.955, 0.44899999999999995, -0.506, 0.698, 0.751, -0.512, 1.045, 0.46399999999999997, -0.521, 1.346, 0.45399999999999996, -1.025, -0.516, 1.1189999999999998, 1.108, 0.45899999999999996, 0.718, 0.45999999999999996, 0.8739999999999999, -0.048000000000000036, -1.006, 0.45899999999999996, -0.535, 1.2069999999999999, 0.06099999999999995, 0.7449999999999999, 0.2559999999999999, 0.7000000000000001, -0.015000000000000006, 0.586, 0.45799999999999996, -1.034, 1.049, 0.808, 0.46499999999999997, -1.013, 0.45599999999999996, 0.909, 0.795, -0.546, 0.478, 0.716, -0.539, -1.017, -0.522, 0.587, 0.16999999999999993, -1.008, 0.605, -1.004, 0.8909999999999999, -1.022, 0.45299999999999996, 0.46599999999999997, -1.033, 1.174, -1.029, -0.527, 0.31699999999999995, 0.46199999999999997, 0.6059999999999999, 1.1400000000000001, 0.657, -0.516, 0.911, 0.44599999999999995, 0.8919999999999999, 0.823, 0.46299999999999997, -1.034, -1.004, -1.015, 0.8999999999999999, 0.608, 1.124, 0.44699999999999995, 0.9849999999999999, 0.46599999999999997], "policy_blue_0_reward": [-1.018, 0.10899999999999999, -1.007, 0.377, -0.035000000000000024, -0.047000000000000035, 0.45199999999999996, -0.03900000000000003, 0.567, 0.5399999999999999, 0.45899999999999996, 0.623, -0.04100000000000003, 0.718, -1.006, -1.016, 0.45399999999999996, 0.719, 0.703, 0.647, 0.45199999999999996, 1.357, -0.523, 0.45199999999999996, 0.849, -1.017, -0.536, 1.0939999999999999, -0.522, 0.44199999999999995, 0.619, -1.0099999999999998, 0.45999999999999996, 1.035, 1.116, -1.009, -0.010000000000000002, 0.45899999999999996, -1.011, 0.728, -0.535, 0.45399999999999996, 1.3639999999999999, 0.46699999999999997, 0.703, -1.01, -0.549, -0.545, -0.53, -1.012, 1.185, -1.037, 0.46199999999999997, 0.65, -1.029, -1.006, 0.45599999999999996, 0.744, 0.47, -1.005, -0.533, 0.575, 0.45099999999999996, -1.015, 0.09899999999999987, 0.735, 0.9799999999999999, -0.518, -0.54, 0.761, -0.5459999999999999, 0.9309999999999999, -1.021, 0.7739999999999999, 0.45499999999999996, -0.03400000000000002, 0.854, -1.0119999999999998, 0.956, 1.043, -0.531, 0.45299999999999996, -1.042, -1.018, -0.512, 0.509, -1.005, 0.44899999999999995, -1.022, -0.503, 0.45299999999999996, 0.822, 1.397, 1.131, -0.53, -0.521, -0.513, 0.44699999999999995, -0.527, 0.45699999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.353796774562855, "mean_inference_ms": 7.4659273866962135, "mean_action_processing_ms": 0.4500412340054645, "mean_env_wait_ms": 0.5240773289646643, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14583611488342285, "StateBufferConnector_ms": 0.008916258811950684, "ViewRequirementAgentConnector_ms": 0.1803114414215088}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 140.69496750132333, "num_env_steps_trained_throughput_per_sec": 140.69496750132333, "timesteps_total": 24000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 27846.012, "sample_time_ms": 3924.501, "learn_time_ms": 23894.601, "learn_throughput": 167.402, "synch_weights_time_ms": 25.359}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "episodes_total": 124, "training_iteration": 6, "trial_id": "fbd9b_00000", "date": "2023-09-15_23-59-30", "timestamp": 1694836770, "time_this_iter_s": 28.444574117660522, "time_total_s": 167.15299081802368, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb418df6d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 167.15299081802368, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 23.914285714285715, "ram_util_percent": 56.80476190476191}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.48, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.28, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.48, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.28, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.48, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.28, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4739189209106068, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07508140378631652, "policy_loss": -0.09947598442619589, "vf_loss": 0.007013105254857995, "vf_explained_var": 0.5724502128238479, "kl": 0.014946386044673366, "entropy": 1.8117944444219272, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 6240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5004580397314081, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.08122747575107496, "policy_loss": -0.10603948410231775, "vf_loss": 0.010253422606062183, "vf_explained_var": 0.5504237967853745, "kl": 0.021232674604478537, "entropy": 1.8127876125276088, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 6240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000}, "sampler_results": {"episode_reward_max": 1.188, "episode_reward_min": -0.765, "episode_reward_mean": 0.26117999999999997, "episode_len_mean": 180.72, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.042}, "policy_reward_max": {"red_0": 1.362, "blue_0": 1.397}, "policy_reward_mean": {"red_0": 0.26696999999999993, "blue_0": -0.0057900000000000095}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.48, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.28, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.48, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.28, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.48, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.28, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.43199999999999994, 0.9009999999999999, 0.34299999999999997, -0.31900000000000006, 0.21499999999999986, 0.582, 0.5230000000000001, 0.9059999999999999, 0.09799999999999998, 0.3360000000000001, 0.9139999999999999, 0.009999999999999898, 0.6, 0.10999999999999988, 1.0979999999999999, 0.9179999999999999, -0.29300000000000004, 1.188, 0.33899999999999997, 0.4059999999999999, 0.358, 0.9259999999999999, 0.16799999999999993, 0.19700000000000006, -0.4880000000000001, 0.19999999999999973, -0.27400000000000013, -0.31199999999999994, 1.17, -0.45100000000000007, 0.9199999999999999, -0.384, 0.020000000000000018, -0.19799999999999995, 0.9209999999999999, -0.2689999999999999, 0.9259999999999999, -0.09599999999999997, 0.262, 0.028999999999999915, 0.9289999999999999, -0.29900000000000004, -0.44000000000000017, -0.2819999999999998, 0.45799999999999985, 0.06899999999999995, -0.3700000000000001, -0.247, 0.05900000000000016, -0.07299999999999995, -0.13000000000000012, -0.2480000000000001, 0.9079999999999999, 0.43199999999999994, -0.17900000000000005, 0.16200000000000014, -0.07300000000000006, 0.5159999999999999, -0.21400000000000008, 0.9149999999999999, -0.43600000000000017, 0.12199999999999989, 0.14500000000000002, -0.007000000000000006, -0.09399999999999997, 0.8949999999999999, -0.13000000000000012, 0.31999999999999984, 0.9159999999999999, -0.21200000000000008, 0.393, 0.1160000000000001, 0.3699999999999999, 0.08699999999999997, 0.611, 0.8939999999999999, 0.45799999999999974, 0.9229999999999999, 0.9349999999999999, -0.765, 0.28, 0.41500000000000004, 0.31499999999999995, 0.264, -0.1529999999999999, 0.05999999999999983, -0.20800000000000007, 0.9129999999999999, 0.31099999999999994, -0.05800000000000005, -0.23099999999999998, 0.1259999999999999, 0.35599999999999987, 0.611, 0.6320000000000001, 0.9149999999999999, 0.19999999999999996, 0.9089999999999999, 0.029999999999999805, 0.06499999999999995], "episode_lengths": [175, 300, 47, 94, 239, 129, 142, 300, 121, 50, 300, 146, 122, 120, 124, 300, 91, 245, 201, 300, 44, 300, 255, 92, 297, 243, 237, 95, 101, 295, 300, 275, 141, 62, 300, 80, 300, 29, 226, 296, 300, 89, 289, 86, 165, 129, 267, 77, 285, 22, 191, 234, 300, 300, 208, 105, 172, 145, 218, 300, 289, 115, 109, 156, 29, 300, 195, 56, 300, 215, 33, 118, 188, 124, 119, 300, 165, 300, 300, 232, 68, 183, 55, 72, 46, 286, 61, 300, 210, 171, 225, 114, 45, 117, 115, 300, 91, 300, 143, 131], "policy_red_0_reward": [0.955, 0.44899999999999995, -0.506, 0.698, 0.751, -0.512, 1.045, 0.46399999999999997, -0.521, 1.346, 0.45399999999999996, -1.025, -0.516, 1.1189999999999998, 1.108, 0.45899999999999996, 0.718, 0.45999999999999996, 0.8739999999999999, -0.048000000000000036, -1.006, 0.45899999999999996, -0.535, 1.2069999999999999, 0.06099999999999995, 0.7449999999999999, 0.2559999999999999, 0.7000000000000001, -0.015000000000000006, 0.586, 0.45799999999999996, -1.034, 1.049, 0.808, 0.46499999999999997, -1.013, 0.45599999999999996, 0.909, 0.795, -0.546, 0.478, 0.716, -0.539, -1.017, -0.522, 0.587, 0.16999999999999993, -1.008, 0.605, -1.004, 0.8909999999999999, -1.022, 0.45299999999999996, 0.46599999999999997, -1.033, 1.174, -1.029, -0.527, 0.31699999999999995, 0.46199999999999997, 0.6059999999999999, 1.1400000000000001, 0.657, -0.516, 0.911, 0.44599999999999995, 0.8919999999999999, 0.823, 0.46299999999999997, -1.034, -1.004, -1.015, 0.8999999999999999, 0.608, 1.124, 0.44699999999999995, 0.9849999999999999, 0.46599999999999997, 0.46699999999999997, 0.274, 0.787, 0.938, -0.508, 1.2730000000000001, -1.006, 0.5969999999999999, 0.8039999999999999, 0.46399999999999997, 0.832, 0.46299999999999997, -1.027, -1.021, 1.362, -0.526, 1.145, 0.46499999999999997, 0.719, 0.45499999999999996, 0.5539999999999999, 1.092], "policy_blue_0_reward": [-0.523, 0.45199999999999996, 0.849, -1.017, -0.536, 1.0939999999999999, -0.522, 0.44199999999999995, 0.619, -1.0099999999999998, 0.45999999999999996, 1.035, 1.116, -1.009, -0.010000000000000002, 0.45899999999999996, -1.011, 0.728, -0.535, 0.45399999999999996, 1.3639999999999999, 0.46699999999999997, 0.703, -1.01, -0.549, -0.545, -0.53, -1.012, 1.185, -1.037, 0.46199999999999997, 0.65, -1.029, -1.006, 0.45599999999999996, 0.744, 0.47, -1.005, -0.533, 0.575, 0.45099999999999996, -1.015, 0.09899999999999987, 0.735, 0.9799999999999999, -0.518, -0.54, 0.761, -0.5459999999999999, 0.9309999999999999, -1.021, 0.7739999999999999, 0.45499999999999996, -0.03400000000000002, 0.854, -1.0119999999999998, 0.956, 1.043, -0.531, 0.45299999999999996, -1.042, -1.018, -0.512, 0.509, -1.005, 0.44899999999999995, -1.022, -0.503, 0.45299999999999996, 0.822, 1.397, 1.131, -0.53, -0.521, -0.513, 0.44699999999999995, -0.527, 0.45699999999999996, 0.46799999999999997, -1.039, -0.507, -0.523, 0.823, -1.009, 0.853, -0.537, -1.012, 0.44899999999999995, -0.521, -0.521, 0.7959999999999999, 1.1469999999999998, -1.006, 1.137, -0.513, 0.44999999999999996, -0.519, 0.45399999999999996, -0.524, -1.027]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.338039127535755, "mean_inference_ms": 7.37650495432369, "mean_action_processing_ms": 0.42932346362894447, "mean_env_wait_ms": 0.5157351419019506, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1385136842727661, "StateBufferConnector_ms": 0.008895397186279297, "ViewRequirementAgentConnector_ms": 0.18353474140167236}}, "episode_reward_max": 1.188, "episode_reward_min": -0.765, "episode_reward_mean": 0.26117999999999997, "episode_len_mean": 180.72, "episodes_this_iter": 22, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.042}, "policy_reward_max": {"red_0": 1.362, "blue_0": 1.397}, "policy_reward_mean": {"red_0": 0.26696999999999993, "blue_0": -0.0057900000000000095}, "hist_stats": {"episode_reward": [0.43199999999999994, 0.9009999999999999, 0.34299999999999997, -0.31900000000000006, 0.21499999999999986, 0.582, 0.5230000000000001, 0.9059999999999999, 0.09799999999999998, 0.3360000000000001, 0.9139999999999999, 0.009999999999999898, 0.6, 0.10999999999999988, 1.0979999999999999, 0.9179999999999999, -0.29300000000000004, 1.188, 0.33899999999999997, 0.4059999999999999, 0.358, 0.9259999999999999, 0.16799999999999993, 0.19700000000000006, -0.4880000000000001, 0.19999999999999973, -0.27400000000000013, -0.31199999999999994, 1.17, -0.45100000000000007, 0.9199999999999999, -0.384, 0.020000000000000018, -0.19799999999999995, 0.9209999999999999, -0.2689999999999999, 0.9259999999999999, -0.09599999999999997, 0.262, 0.028999999999999915, 0.9289999999999999, -0.29900000000000004, -0.44000000000000017, -0.2819999999999998, 0.45799999999999985, 0.06899999999999995, -0.3700000000000001, -0.247, 0.05900000000000016, -0.07299999999999995, -0.13000000000000012, -0.2480000000000001, 0.9079999999999999, 0.43199999999999994, -0.17900000000000005, 0.16200000000000014, -0.07300000000000006, 0.5159999999999999, -0.21400000000000008, 0.9149999999999999, -0.43600000000000017, 0.12199999999999989, 0.14500000000000002, -0.007000000000000006, -0.09399999999999997, 0.8949999999999999, -0.13000000000000012, 0.31999999999999984, 0.9159999999999999, -0.21200000000000008, 0.393, 0.1160000000000001, 0.3699999999999999, 0.08699999999999997, 0.611, 0.8939999999999999, 0.45799999999999974, 0.9229999999999999, 0.9349999999999999, -0.765, 0.28, 0.41500000000000004, 0.31499999999999995, 0.264, -0.1529999999999999, 0.05999999999999983, -0.20800000000000007, 0.9129999999999999, 0.31099999999999994, -0.05800000000000005, -0.23099999999999998, 0.1259999999999999, 0.35599999999999987, 0.611, 0.6320000000000001, 0.9149999999999999, 0.19999999999999996, 0.9089999999999999, 0.029999999999999805, 0.06499999999999995], "episode_lengths": [175, 300, 47, 94, 239, 129, 142, 300, 121, 50, 300, 146, 122, 120, 124, 300, 91, 245, 201, 300, 44, 300, 255, 92, 297, 243, 237, 95, 101, 295, 300, 275, 141, 62, 300, 80, 300, 29, 226, 296, 300, 89, 289, 86, 165, 129, 267, 77, 285, 22, 191, 234, 300, 300, 208, 105, 172, 145, 218, 300, 289, 115, 109, 156, 29, 300, 195, 56, 300, 215, 33, 118, 188, 124, 119, 300, 165, 300, 300, 232, 68, 183, 55, 72, 46, 286, 61, 300, 210, 171, 225, 114, 45, 117, 115, 300, 91, 300, 143, 131], "policy_red_0_reward": [0.955, 0.44899999999999995, -0.506, 0.698, 0.751, -0.512, 1.045, 0.46399999999999997, -0.521, 1.346, 0.45399999999999996, -1.025, -0.516, 1.1189999999999998, 1.108, 0.45899999999999996, 0.718, 0.45999999999999996, 0.8739999999999999, -0.048000000000000036, -1.006, 0.45899999999999996, -0.535, 1.2069999999999999, 0.06099999999999995, 0.7449999999999999, 0.2559999999999999, 0.7000000000000001, -0.015000000000000006, 0.586, 0.45799999999999996, -1.034, 1.049, 0.808, 0.46499999999999997, -1.013, 0.45599999999999996, 0.909, 0.795, -0.546, 0.478, 0.716, -0.539, -1.017, -0.522, 0.587, 0.16999999999999993, -1.008, 0.605, -1.004, 0.8909999999999999, -1.022, 0.45299999999999996, 0.46599999999999997, -1.033, 1.174, -1.029, -0.527, 0.31699999999999995, 0.46199999999999997, 0.6059999999999999, 1.1400000000000001, 0.657, -0.516, 0.911, 0.44599999999999995, 0.8919999999999999, 0.823, 0.46299999999999997, -1.034, -1.004, -1.015, 0.8999999999999999, 0.608, 1.124, 0.44699999999999995, 0.9849999999999999, 0.46599999999999997, 0.46699999999999997, 0.274, 0.787, 0.938, -0.508, 1.2730000000000001, -1.006, 0.5969999999999999, 0.8039999999999999, 0.46399999999999997, 0.832, 0.46299999999999997, -1.027, -1.021, 1.362, -0.526, 1.145, 0.46499999999999997, 0.719, 0.45499999999999996, 0.5539999999999999, 1.092], "policy_blue_0_reward": [-0.523, 0.45199999999999996, 0.849, -1.017, -0.536, 1.0939999999999999, -0.522, 0.44199999999999995, 0.619, -1.0099999999999998, 0.45999999999999996, 1.035, 1.116, -1.009, -0.010000000000000002, 0.45899999999999996, -1.011, 0.728, -0.535, 0.45399999999999996, 1.3639999999999999, 0.46699999999999997, 0.703, -1.01, -0.549, -0.545, -0.53, -1.012, 1.185, -1.037, 0.46199999999999997, 0.65, -1.029, -1.006, 0.45599999999999996, 0.744, 0.47, -1.005, -0.533, 0.575, 0.45099999999999996, -1.015, 0.09899999999999987, 0.735, 0.9799999999999999, -0.518, -0.54, 0.761, -0.5459999999999999, 0.9309999999999999, -1.021, 0.7739999999999999, 0.45499999999999996, -0.03400000000000002, 0.854, -1.0119999999999998, 0.956, 1.043, -0.531, 0.45299999999999996, -1.042, -1.018, -0.512, 0.509, -1.005, 0.44899999999999995, -1.022, -0.503, 0.45299999999999996, 0.822, 1.397, 1.131, -0.53, -0.521, -0.513, 0.44699999999999995, -0.527, 0.45699999999999996, 0.46799999999999997, -1.039, -0.507, -0.523, 0.823, -1.009, 0.853, -0.537, -1.012, 0.44899999999999995, -0.521, -0.521, 0.7959999999999999, 1.1469999999999998, -1.006, 1.137, -0.513, 0.44999999999999996, -0.519, 0.45399999999999996, -0.524, -1.027]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.338039127535755, "mean_inference_ms": 7.37650495432369, "mean_action_processing_ms": 0.42932346362894447, "mean_env_wait_ms": 0.5157351419019506, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1385136842727661, "StateBufferConnector_ms": 0.008895397186279297, "ViewRequirementAgentConnector_ms": 0.18353474140167236}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 133.62724204561567, "num_env_steps_trained_throughput_per_sec": 133.62724204561567, "timesteps_total": 28000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 56000, "timers": {"training_iteration_time_ms": 28144.293, "sample_time_ms": 3903.13, "learn_time_ms": 24213.913, "learn_throughput": 165.194, "synch_weights_time_ms": 25.694}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000}, "done": false, "episodes_total": 146, "training_iteration": 7, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-00-01", "timestamp": 1694836801, "time_this_iter_s": 29.949182987213135, "time_total_s": 197.10217380523682, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80eb8dc0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 197.10217380523682, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 26.159090909090914, "ram_util_percent": 56.849999999999994}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.47, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.28, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.47, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.01, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.28, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.47, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.28, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5154606289851169, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.06607731996725003, "policy_loss": -0.09194210133330974, "vf_loss": 0.007767889527167426, "vf_explained_var": 0.499559961942335, "kl": 0.015662234860872606, "entropy": 1.8061813186854123, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 7200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4970889446015159, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07275539643111793, "policy_loss": -0.09744954802372377, "vf_loss": 0.0077244543086029205, "vf_explained_var": 0.5396313309048613, "kl": 0.014912834255966604, "entropy": 1.8169419543196759, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 7200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "sampler_results": {"episode_reward_max": 1.17, "episode_reward_min": -0.765, "episode_reward_mean": 0.24475999999999995, "episode_len_mean": 184.9, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.051}, "policy_reward_max": {"red_0": 1.38, "blue_0": 1.397}, "policy_reward_mean": {"red_0": 0.24517999999999998, "blue_0": -0.000420000000000007}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.47, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.28, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.47, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.01, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.28, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.47, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.28, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9259999999999999, 0.16799999999999993, 0.19700000000000006, -0.4880000000000001, 0.19999999999999973, -0.27400000000000013, -0.31199999999999994, 1.17, -0.45100000000000007, 0.9199999999999999, -0.384, 0.020000000000000018, -0.19799999999999995, 0.9209999999999999, -0.2689999999999999, 0.9259999999999999, -0.09599999999999997, 0.262, 0.028999999999999915, 0.9289999999999999, -0.29900000000000004, -0.44000000000000017, -0.2819999999999998, 0.45799999999999985, 0.06899999999999995, -0.3700000000000001, -0.247, 0.05900000000000016, -0.07299999999999995, -0.13000000000000012, -0.2480000000000001, 0.9079999999999999, 0.43199999999999994, -0.17900000000000005, 0.16200000000000014, -0.07300000000000006, 0.5159999999999999, -0.21400000000000008, 0.9149999999999999, -0.43600000000000017, 0.12199999999999989, 0.14500000000000002, -0.007000000000000006, -0.09399999999999997, 0.8949999999999999, -0.13000000000000012, 0.31999999999999984, 0.9159999999999999, -0.21200000000000008, 0.393, 0.1160000000000001, 0.3699999999999999, 0.08699999999999997, 0.611, 0.8939999999999999, 0.45799999999999974, 0.9229999999999999, 0.9349999999999999, -0.765, 0.28, 0.41500000000000004, 0.31499999999999995, 0.264, -0.1529999999999999, 0.05999999999999983, -0.20800000000000007, 0.9129999999999999, 0.31099999999999994, -0.05800000000000005, -0.23099999999999998, 0.1259999999999999, 0.35599999999999987, 0.611, 0.6320000000000001, 0.9149999999999999, 0.19999999999999996, 0.9089999999999999, 0.029999999999999805, 0.06499999999999995, -0.10100000000000009, 0.2569999999999999, 0.6419999999999999, -0.47, -0.2819999999999998, 0.028000000000000025, 0.8979999999999999, -0.4870000000000001, 0.794, 0.1269999999999999, 0.9079999999999999, -0.14900000000000002, 0.42599999999999993, 0.3919999999999999, 0.6619999999999999, 0.817, 0.42999999999999994, 0.375, 0.939, 0.9269999999999999, 0.8899999999999999], "episode_lengths": [300, 255, 92, 297, 243, 237, 95, 101, 295, 300, 275, 141, 62, 300, 80, 300, 29, 226, 296, 300, 89, 289, 86, 165, 129, 267, 77, 285, 22, 191, 234, 300, 300, 208, 105, 172, 145, 218, 300, 289, 115, 109, 156, 29, 300, 195, 56, 300, 215, 33, 118, 188, 124, 119, 300, 165, 300, 300, 232, 68, 183, 55, 72, 46, 286, 61, 300, 210, 171, 225, 114, 45, 117, 115, 300, 91, 300, 143, 131, 185, 73, 104, 143, 88, 146, 300, 296, 64, 114, 300, 199, 300, 300, 104, 54, 300, 38, 300, 300, 300], "policy_red_0_reward": [0.45899999999999996, -0.535, 1.2069999999999999, 0.06099999999999995, 0.7449999999999999, 0.2559999999999999, 0.7000000000000001, -0.015000000000000006, 0.586, 0.45799999999999996, -1.034, 1.049, 0.808, 0.46499999999999997, -1.013, 0.45599999999999996, 0.909, 0.795, -0.546, 0.478, 0.716, -0.539, -1.017, -0.522, 0.587, 0.16999999999999993, -1.008, 0.605, -1.004, 0.8909999999999999, -1.022, 0.45299999999999996, 0.46599999999999997, -1.033, 1.174, -1.029, -0.527, 0.31699999999999995, 0.46199999999999997, 0.6059999999999999, 1.1400000000000001, 0.657, -0.516, 0.911, 0.44599999999999995, 0.8919999999999999, 0.823, 0.46299999999999997, -1.034, -1.004, -1.015, 0.8999999999999999, 0.608, 1.124, 0.44699999999999995, 0.9849999999999999, 0.46599999999999997, 0.46699999999999997, 0.274, 0.787, 0.938, -0.508, 1.2730000000000001, -1.006, 0.5969999999999999, 0.8039999999999999, 0.46399999999999997, 0.832, 0.46299999999999997, -1.027, -1.021, 1.362, -0.526, 1.145, 0.46499999999999997, 0.719, 0.45499999999999996, 0.5539999999999999, 1.092, 0.4159999999999999, 0.7679999999999999, 1.1629999999999998, -1.017, -1.0059999999999998, 0.5439999999999999, 0.43399999999999994, 0.564, -0.508, -0.513, 0.45799999999999996, -1.021, 0.45699999999999996, 0.44799999999999995, 1.1749999999999998, -0.511, -0.03400000000000002, 1.38, 0.471, 0.46499999999999997, 0.45399999999999996], "policy_blue_0_reward": [0.46699999999999997, 0.703, -1.01, -0.549, -0.545, -0.53, -1.012, 1.185, -1.037, 0.46199999999999997, 0.65, -1.029, -1.006, 0.45599999999999996, 0.744, 0.47, -1.005, -0.533, 0.575, 0.45099999999999996, -1.015, 0.09899999999999987, 0.735, 0.9799999999999999, -0.518, -0.54, 0.761, -0.5459999999999999, 0.9309999999999999, -1.021, 0.7739999999999999, 0.45499999999999996, -0.03400000000000002, 0.854, -1.0119999999999998, 0.956, 1.043, -0.531, 0.45299999999999996, -1.042, -1.018, -0.512, 0.509, -1.005, 0.44899999999999995, -1.022, -0.503, 0.45299999999999996, 0.822, 1.397, 1.131, -0.53, -0.521, -0.513, 0.44699999999999995, -0.527, 0.45699999999999996, 0.46799999999999997, -1.039, -0.507, -0.523, 0.823, -1.009, 0.853, -0.537, -1.012, 0.44899999999999995, -0.521, -0.521, 0.7959999999999999, 1.1469999999999998, -1.006, 1.137, -0.513, 0.44999999999999996, -0.519, 0.45399999999999996, -0.524, -1.027, -0.517, -0.511, -0.521, 0.5469999999999999, 0.724, -0.516, 0.46399999999999997, -1.051, 1.302, 0.6399999999999999, 0.44999999999999996, 0.872, -0.03100000000000002, -0.05600000000000004, -0.513, 1.3279999999999998, 0.46399999999999997, -1.005, 0.46799999999999997, 0.46199999999999997, 0.43599999999999994]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3301648808802864, "mean_inference_ms": 7.343695296836955, "mean_action_processing_ms": 0.41941737055088935, "mean_env_wait_ms": 0.5102832904922727, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13981389999389648, "StateBufferConnector_ms": 0.008996963500976562, "ViewRequirementAgentConnector_ms": 0.18782079219818115}}, "episode_reward_max": 1.17, "episode_reward_min": -0.765, "episode_reward_mean": 0.24475999999999995, "episode_len_mean": 184.9, "episodes_this_iter": 21, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.051}, "policy_reward_max": {"red_0": 1.38, "blue_0": 1.397}, "policy_reward_mean": {"red_0": 0.24517999999999998, "blue_0": -0.000420000000000007}, "hist_stats": {"episode_reward": [0.9259999999999999, 0.16799999999999993, 0.19700000000000006, -0.4880000000000001, 0.19999999999999973, -0.27400000000000013, -0.31199999999999994, 1.17, -0.45100000000000007, 0.9199999999999999, -0.384, 0.020000000000000018, -0.19799999999999995, 0.9209999999999999, -0.2689999999999999, 0.9259999999999999, -0.09599999999999997, 0.262, 0.028999999999999915, 0.9289999999999999, -0.29900000000000004, -0.44000000000000017, -0.2819999999999998, 0.45799999999999985, 0.06899999999999995, -0.3700000000000001, -0.247, 0.05900000000000016, -0.07299999999999995, -0.13000000000000012, -0.2480000000000001, 0.9079999999999999, 0.43199999999999994, -0.17900000000000005, 0.16200000000000014, -0.07300000000000006, 0.5159999999999999, -0.21400000000000008, 0.9149999999999999, -0.43600000000000017, 0.12199999999999989, 0.14500000000000002, -0.007000000000000006, -0.09399999999999997, 0.8949999999999999, -0.13000000000000012, 0.31999999999999984, 0.9159999999999999, -0.21200000000000008, 0.393, 0.1160000000000001, 0.3699999999999999, 0.08699999999999997, 0.611, 0.8939999999999999, 0.45799999999999974, 0.9229999999999999, 0.9349999999999999, -0.765, 0.28, 0.41500000000000004, 0.31499999999999995, 0.264, -0.1529999999999999, 0.05999999999999983, -0.20800000000000007, 0.9129999999999999, 0.31099999999999994, -0.05800000000000005, -0.23099999999999998, 0.1259999999999999, 0.35599999999999987, 0.611, 0.6320000000000001, 0.9149999999999999, 0.19999999999999996, 0.9089999999999999, 0.029999999999999805, 0.06499999999999995, -0.10100000000000009, 0.2569999999999999, 0.6419999999999999, -0.47, -0.2819999999999998, 0.028000000000000025, 0.8979999999999999, -0.4870000000000001, 0.794, 0.1269999999999999, 0.9079999999999999, -0.14900000000000002, 0.42599999999999993, 0.3919999999999999, 0.6619999999999999, 0.817, 0.42999999999999994, 0.375, 0.939, 0.9269999999999999, 0.8899999999999999], "episode_lengths": [300, 255, 92, 297, 243, 237, 95, 101, 295, 300, 275, 141, 62, 300, 80, 300, 29, 226, 296, 300, 89, 289, 86, 165, 129, 267, 77, 285, 22, 191, 234, 300, 300, 208, 105, 172, 145, 218, 300, 289, 115, 109, 156, 29, 300, 195, 56, 300, 215, 33, 118, 188, 124, 119, 300, 165, 300, 300, 232, 68, 183, 55, 72, 46, 286, 61, 300, 210, 171, 225, 114, 45, 117, 115, 300, 91, 300, 143, 131, 185, 73, 104, 143, 88, 146, 300, 296, 64, 114, 300, 199, 300, 300, 104, 54, 300, 38, 300, 300, 300], "policy_red_0_reward": [0.45899999999999996, -0.535, 1.2069999999999999, 0.06099999999999995, 0.7449999999999999, 0.2559999999999999, 0.7000000000000001, -0.015000000000000006, 0.586, 0.45799999999999996, -1.034, 1.049, 0.808, 0.46499999999999997, -1.013, 0.45599999999999996, 0.909, 0.795, -0.546, 0.478, 0.716, -0.539, -1.017, -0.522, 0.587, 0.16999999999999993, -1.008, 0.605, -1.004, 0.8909999999999999, -1.022, 0.45299999999999996, 0.46599999999999997, -1.033, 1.174, -1.029, -0.527, 0.31699999999999995, 0.46199999999999997, 0.6059999999999999, 1.1400000000000001, 0.657, -0.516, 0.911, 0.44599999999999995, 0.8919999999999999, 0.823, 0.46299999999999997, -1.034, -1.004, -1.015, 0.8999999999999999, 0.608, 1.124, 0.44699999999999995, 0.9849999999999999, 0.46599999999999997, 0.46699999999999997, 0.274, 0.787, 0.938, -0.508, 1.2730000000000001, -1.006, 0.5969999999999999, 0.8039999999999999, 0.46399999999999997, 0.832, 0.46299999999999997, -1.027, -1.021, 1.362, -0.526, 1.145, 0.46499999999999997, 0.719, 0.45499999999999996, 0.5539999999999999, 1.092, 0.4159999999999999, 0.7679999999999999, 1.1629999999999998, -1.017, -1.0059999999999998, 0.5439999999999999, 0.43399999999999994, 0.564, -0.508, -0.513, 0.45799999999999996, -1.021, 0.45699999999999996, 0.44799999999999995, 1.1749999999999998, -0.511, -0.03400000000000002, 1.38, 0.471, 0.46499999999999997, 0.45399999999999996], "policy_blue_0_reward": [0.46699999999999997, 0.703, -1.01, -0.549, -0.545, -0.53, -1.012, 1.185, -1.037, 0.46199999999999997, 0.65, -1.029, -1.006, 0.45599999999999996, 0.744, 0.47, -1.005, -0.533, 0.575, 0.45099999999999996, -1.015, 0.09899999999999987, 0.735, 0.9799999999999999, -0.518, -0.54, 0.761, -0.5459999999999999, 0.9309999999999999, -1.021, 0.7739999999999999, 0.45499999999999996, -0.03400000000000002, 0.854, -1.0119999999999998, 0.956, 1.043, -0.531, 0.45299999999999996, -1.042, -1.018, -0.512, 0.509, -1.005, 0.44899999999999995, -1.022, -0.503, 0.45299999999999996, 0.822, 1.397, 1.131, -0.53, -0.521, -0.513, 0.44699999999999995, -0.527, 0.45699999999999996, 0.46799999999999997, -1.039, -0.507, -0.523, 0.823, -1.009, 0.853, -0.537, -1.012, 0.44899999999999995, -0.521, -0.521, 0.7959999999999999, 1.1469999999999998, -1.006, 1.137, -0.513, 0.44999999999999996, -0.519, 0.45399999999999996, -0.524, -1.027, -0.517, -0.511, -0.521, 0.5469999999999999, 0.724, -0.516, 0.46399999999999997, -1.051, 1.302, 0.6399999999999999, 0.44999999999999996, 0.872, -0.03100000000000002, -0.05600000000000004, -0.513, 1.3279999999999998, 0.46399999999999997, -1.005, 0.46799999999999997, 0.46199999999999997, 0.43599999999999994]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3301648808802864, "mean_inference_ms": 7.343695296836955, "mean_action_processing_ms": 0.41941737055088935, "mean_env_wait_ms": 0.5102832904922727, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13981389999389648, "StateBufferConnector_ms": 0.008996963500976562, "ViewRequirementAgentConnector_ms": 0.18782079219818115}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 136.3864814536568, "num_env_steps_trained_throughput_per_sec": 136.3864814536568, "timesteps_total": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 28292.305, "sample_time_ms": 3896.465, "learn_time_ms": 24368.6, "learn_throughput": 164.146, "synch_weights_time_ms": 25.715}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "episodes_total": 167, "training_iteration": 8, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-00-31", "timestamp": 1694836831, "time_this_iter_s": 29.34227728843689, "time_total_s": 226.4444510936737, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb72348430>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 226.4444510936737, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 25.39302325581395, "ram_util_percent": 56.709302325581405}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.44, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.29, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.44, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.29, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.44, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.29, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4856900479334096, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07321514616099496, "policy_loss": -0.09877048961231291, "vf_loss": 0.007339011020546119, "vf_explained_var": 0.5754972401385506, "kl": 0.015599345283465937, "entropy": 1.805666299164295, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 8160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4738134789125373, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07125071276968811, "policy_loss": -0.09618237288183688, "vf_loss": 0.008751204269962424, "vf_explained_var": 0.569540563163658, "kl": 0.014729388237969232, "entropy": 1.8141993470489979, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 8160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000}, "sampler_results": {"episode_reward_max": 1.0430000000000001, "episode_reward_min": -0.765, "episode_reward_mean": 0.3071, "episode_len_mean": 178.61, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.051}, "policy_reward_max": {"red_0": 1.38, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.23687999999999995, "blue_0": 0.07021999999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.44, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.29, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.44, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.29, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.44, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.29, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.06899999999999995, -0.3700000000000001, -0.247, 0.05900000000000016, -0.07299999999999995, -0.13000000000000012, -0.2480000000000001, 0.9079999999999999, 0.43199999999999994, -0.17900000000000005, 0.16200000000000014, -0.07300000000000006, 0.5159999999999999, -0.21400000000000008, 0.9149999999999999, -0.43600000000000017, 0.12199999999999989, 0.14500000000000002, -0.007000000000000006, -0.09399999999999997, 0.8949999999999999, -0.13000000000000012, 0.31999999999999984, 0.9159999999999999, -0.21200000000000008, 0.393, 0.1160000000000001, 0.3699999999999999, 0.08699999999999997, 0.611, 0.8939999999999999, 0.45799999999999974, 0.9229999999999999, 0.9349999999999999, -0.765, 0.28, 0.41500000000000004, 0.31499999999999995, 0.264, -0.1529999999999999, 0.05999999999999983, -0.20800000000000007, 0.9129999999999999, 0.31099999999999994, -0.05800000000000005, -0.23099999999999998, 0.1259999999999999, 0.35599999999999987, 0.611, 0.6320000000000001, 0.9149999999999999, 0.19999999999999996, 0.9089999999999999, 0.029999999999999805, 0.06499999999999995, -0.10100000000000009, 0.2569999999999999, 0.6419999999999999, -0.47, -0.2819999999999998, 0.028000000000000025, 0.8979999999999999, -0.4870000000000001, 0.794, 0.1269999999999999, 0.9079999999999999, -0.14900000000000002, 0.42599999999999993, 0.3919999999999999, 0.6619999999999999, 0.817, 0.42999999999999994, 0.375, 0.939, 0.9269999999999999, 0.8899999999999999, -0.06700000000000006, 0.8270000000000001, 0.9079999999999999, 0.9139999999999999, 0.385, 0.029999999999999916, 0.9149999999999999, -0.14800000000000002, -0.17400000000000004, 0.4119999999999999, 0.39, 0.14700000000000002, -0.04400000000000015, -0.05900000000000005, 0.22999999999999998, 0.30400000000000005, 0.4159999999999999, 0.8879999999999999, 1.0430000000000001, 0.9229999999999999, 0.9099999999999999, -0.008000000000000007, 0.893, -0.16800000000000004], "episode_lengths": [129, 267, 77, 285, 22, 191, 234, 300, 300, 208, 105, 172, 145, 218, 300, 289, 115, 109, 156, 29, 300, 195, 56, 300, 215, 33, 118, 188, 124, 119, 300, 165, 300, 300, 232, 68, 183, 55, 72, 46, 286, 61, 300, 210, 171, 225, 114, 45, 117, 115, 300, 91, 300, 143, 131, 185, 73, 104, 143, 88, 146, 300, 296, 64, 114, 300, 199, 300, 300, 104, 54, 300, 38, 300, 300, 300, 172, 52, 300, 300, 36, 143, 300, 196, 52, 175, 35, 109, 165, 19, 231, 62, 300, 300, 290, 300, 300, 156, 31, 200], "policy_red_0_reward": [0.587, 0.16999999999999993, -1.008, 0.605, -1.004, 0.8909999999999999, -1.022, 0.45299999999999996, 0.46599999999999997, -1.033, 1.174, -1.029, -0.527, 0.31699999999999995, 0.46199999999999997, 0.6059999999999999, 1.1400000000000001, 0.657, -0.516, 0.911, 0.44599999999999995, 0.8919999999999999, 0.823, 0.46299999999999997, -1.034, -1.004, -1.015, 0.8999999999999999, 0.608, 1.124, 0.44699999999999995, 0.9849999999999999, 0.46599999999999997, 0.46699999999999997, 0.274, 0.787, 0.938, -0.508, 1.2730000000000001, -1.006, 0.5969999999999999, 0.8039999999999999, 0.46399999999999997, 0.832, 0.46299999999999997, -1.027, -1.021, 1.362, -0.526, 1.145, 0.46499999999999997, 0.719, 0.45499999999999996, 0.5539999999999999, 1.092, 0.4159999999999999, 0.7679999999999999, 1.1629999999999998, -1.017, -1.0059999999999998, 0.5439999999999999, 0.43399999999999994, 0.564, -0.508, -0.513, 0.45799999999999996, -1.021, 0.45699999999999996, 0.44799999999999995, 1.1749999999999998, -0.511, -0.03400000000000002, 1.38, 0.471, 0.46499999999999997, 0.45399999999999996, 0.46199999999999997, -0.5069999999999999, 0.44599999999999995, 0.45599999999999996, -1.002, -0.52, 0.44999999999999996, -1.031, 0.837, 0.94, -0.502, 1.155, 0.4819999999999999, -1.001, 0.7779999999999999, 0.808, 0.44799999999999995, 0.43799999999999994, 0.586, 0.46099999999999997, 0.45199999999999996, 0.508, -0.51, -0.537], "policy_blue_0_reward": [-0.518, -0.54, 0.761, -0.5459999999999999, 0.9309999999999999, -1.021, 0.7739999999999999, 0.45499999999999996, -0.03400000000000002, 0.854, -1.0119999999999998, 0.956, 1.043, -0.531, 0.45299999999999996, -1.042, -1.018, -0.512, 0.509, -1.005, 0.44899999999999995, -1.022, -0.503, 0.45299999999999996, 0.822, 1.397, 1.131, -0.53, -0.521, -0.513, 0.44699999999999995, -0.527, 0.45699999999999996, 0.46799999999999997, -1.039, -0.507, -0.523, 0.823, -1.009, 0.853, -0.537, -1.012, 0.44899999999999995, -0.521, -0.521, 0.7959999999999999, 1.1469999999999998, -1.006, 1.137, -0.513, 0.44999999999999996, -0.519, 0.45399999999999996, -0.524, -1.027, -0.517, -0.511, -0.521, 0.5469999999999999, 0.724, -0.516, 0.46399999999999997, -1.051, 1.302, 0.6399999999999999, 0.44999999999999996, 0.872, -0.03100000000000002, -0.05600000000000004, -0.513, 1.3279999999999998, 0.46399999999999997, -1.005, 0.46799999999999997, 0.46199999999999997, 0.43599999999999994, -0.529, 1.334, 0.46199999999999997, 0.45799999999999996, 1.387, 0.5499999999999999, 0.46499999999999997, 0.883, -1.011, -0.528, 0.892, -1.008, -0.526, 0.942, -0.548, -0.504, -0.03200000000000002, 0.44999999999999996, 0.45699999999999996, 0.46199999999999997, 0.45799999999999996, -0.516, 1.403, 0.369]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3257338308086446, "mean_inference_ms": 7.313144747933205, "mean_action_processing_ms": 0.4141766849032437, "mean_env_wait_ms": 0.5064423920481627, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1423509120941162, "StateBufferConnector_ms": 0.009084343910217285, "ViewRequirementAgentConnector_ms": 0.18883287906646729}}, "episode_reward_max": 1.0430000000000001, "episode_reward_min": -0.765, "episode_reward_mean": 0.3071, "episode_len_mean": 178.61, "episodes_this_iter": 24, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.051}, "policy_reward_max": {"red_0": 1.38, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.23687999999999995, "blue_0": 0.07021999999999999}, "hist_stats": {"episode_reward": [0.06899999999999995, -0.3700000000000001, -0.247, 0.05900000000000016, -0.07299999999999995, -0.13000000000000012, -0.2480000000000001, 0.9079999999999999, 0.43199999999999994, -0.17900000000000005, 0.16200000000000014, -0.07300000000000006, 0.5159999999999999, -0.21400000000000008, 0.9149999999999999, -0.43600000000000017, 0.12199999999999989, 0.14500000000000002, -0.007000000000000006, -0.09399999999999997, 0.8949999999999999, -0.13000000000000012, 0.31999999999999984, 0.9159999999999999, -0.21200000000000008, 0.393, 0.1160000000000001, 0.3699999999999999, 0.08699999999999997, 0.611, 0.8939999999999999, 0.45799999999999974, 0.9229999999999999, 0.9349999999999999, -0.765, 0.28, 0.41500000000000004, 0.31499999999999995, 0.264, -0.1529999999999999, 0.05999999999999983, -0.20800000000000007, 0.9129999999999999, 0.31099999999999994, -0.05800000000000005, -0.23099999999999998, 0.1259999999999999, 0.35599999999999987, 0.611, 0.6320000000000001, 0.9149999999999999, 0.19999999999999996, 0.9089999999999999, 0.029999999999999805, 0.06499999999999995, -0.10100000000000009, 0.2569999999999999, 0.6419999999999999, -0.47, -0.2819999999999998, 0.028000000000000025, 0.8979999999999999, -0.4870000000000001, 0.794, 0.1269999999999999, 0.9079999999999999, -0.14900000000000002, 0.42599999999999993, 0.3919999999999999, 0.6619999999999999, 0.817, 0.42999999999999994, 0.375, 0.939, 0.9269999999999999, 0.8899999999999999, -0.06700000000000006, 0.8270000000000001, 0.9079999999999999, 0.9139999999999999, 0.385, 0.029999999999999916, 0.9149999999999999, -0.14800000000000002, -0.17400000000000004, 0.4119999999999999, 0.39, 0.14700000000000002, -0.04400000000000015, -0.05900000000000005, 0.22999999999999998, 0.30400000000000005, 0.4159999999999999, 0.8879999999999999, 1.0430000000000001, 0.9229999999999999, 0.9099999999999999, -0.008000000000000007, 0.893, -0.16800000000000004], "episode_lengths": [129, 267, 77, 285, 22, 191, 234, 300, 300, 208, 105, 172, 145, 218, 300, 289, 115, 109, 156, 29, 300, 195, 56, 300, 215, 33, 118, 188, 124, 119, 300, 165, 300, 300, 232, 68, 183, 55, 72, 46, 286, 61, 300, 210, 171, 225, 114, 45, 117, 115, 300, 91, 300, 143, 131, 185, 73, 104, 143, 88, 146, 300, 296, 64, 114, 300, 199, 300, 300, 104, 54, 300, 38, 300, 300, 300, 172, 52, 300, 300, 36, 143, 300, 196, 52, 175, 35, 109, 165, 19, 231, 62, 300, 300, 290, 300, 300, 156, 31, 200], "policy_red_0_reward": [0.587, 0.16999999999999993, -1.008, 0.605, -1.004, 0.8909999999999999, -1.022, 0.45299999999999996, 0.46599999999999997, -1.033, 1.174, -1.029, -0.527, 0.31699999999999995, 0.46199999999999997, 0.6059999999999999, 1.1400000000000001, 0.657, -0.516, 0.911, 0.44599999999999995, 0.8919999999999999, 0.823, 0.46299999999999997, -1.034, -1.004, -1.015, 0.8999999999999999, 0.608, 1.124, 0.44699999999999995, 0.9849999999999999, 0.46599999999999997, 0.46699999999999997, 0.274, 0.787, 0.938, -0.508, 1.2730000000000001, -1.006, 0.5969999999999999, 0.8039999999999999, 0.46399999999999997, 0.832, 0.46299999999999997, -1.027, -1.021, 1.362, -0.526, 1.145, 0.46499999999999997, 0.719, 0.45499999999999996, 0.5539999999999999, 1.092, 0.4159999999999999, 0.7679999999999999, 1.1629999999999998, -1.017, -1.0059999999999998, 0.5439999999999999, 0.43399999999999994, 0.564, -0.508, -0.513, 0.45799999999999996, -1.021, 0.45699999999999996, 0.44799999999999995, 1.1749999999999998, -0.511, -0.03400000000000002, 1.38, 0.471, 0.46499999999999997, 0.45399999999999996, 0.46199999999999997, -0.5069999999999999, 0.44599999999999995, 0.45599999999999996, -1.002, -0.52, 0.44999999999999996, -1.031, 0.837, 0.94, -0.502, 1.155, 0.4819999999999999, -1.001, 0.7779999999999999, 0.808, 0.44799999999999995, 0.43799999999999994, 0.586, 0.46099999999999997, 0.45199999999999996, 0.508, -0.51, -0.537], "policy_blue_0_reward": [-0.518, -0.54, 0.761, -0.5459999999999999, 0.9309999999999999, -1.021, 0.7739999999999999, 0.45499999999999996, -0.03400000000000002, 0.854, -1.0119999999999998, 0.956, 1.043, -0.531, 0.45299999999999996, -1.042, -1.018, -0.512, 0.509, -1.005, 0.44899999999999995, -1.022, -0.503, 0.45299999999999996, 0.822, 1.397, 1.131, -0.53, -0.521, -0.513, 0.44699999999999995, -0.527, 0.45699999999999996, 0.46799999999999997, -1.039, -0.507, -0.523, 0.823, -1.009, 0.853, -0.537, -1.012, 0.44899999999999995, -0.521, -0.521, 0.7959999999999999, 1.1469999999999998, -1.006, 1.137, -0.513, 0.44999999999999996, -0.519, 0.45399999999999996, -0.524, -1.027, -0.517, -0.511, -0.521, 0.5469999999999999, 0.724, -0.516, 0.46399999999999997, -1.051, 1.302, 0.6399999999999999, 0.44999999999999996, 0.872, -0.03100000000000002, -0.05600000000000004, -0.513, 1.3279999999999998, 0.46399999999999997, -1.005, 0.46799999999999997, 0.46199999999999997, 0.43599999999999994, -0.529, 1.334, 0.46199999999999997, 0.45799999999999996, 1.387, 0.5499999999999999, 0.46499999999999997, 0.883, -1.011, -0.528, 0.892, -1.008, -0.526, 0.942, -0.548, -0.504, -0.03200000000000002, 0.44999999999999996, 0.45699999999999996, 0.46199999999999997, 0.45799999999999996, -0.516, 1.403, 0.369]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3257338308086446, "mean_inference_ms": 7.313144747933205, "mean_action_processing_ms": 0.4141766849032437, "mean_env_wait_ms": 0.5064423920481627, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1423509120941162, "StateBufferConnector_ms": 0.009084343910217285, "ViewRequirementAgentConnector_ms": 0.18883287906646729}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 133.91541021181533, "num_env_steps_trained_throughput_per_sec": 133.91541021181533, "timesteps_total": 36000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 72000, "timers": {"training_iteration_time_ms": 28467.557, "sample_time_ms": 3891.769, "learn_time_ms": 24548.509, "learn_throughput": 162.943, "synch_weights_time_ms": 25.778}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000}, "done": false, "episodes_total": 191, "training_iteration": 9, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-01-02", "timestamp": 1694836862, "time_this_iter_s": 29.884917974472046, "time_total_s": 256.32936906814575, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80ebbb50>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 256.32936906814575, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 24.89090909090909, "ram_util_percent": 56.777272727272745}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.41, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.3, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.41, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.3, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.41, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.3, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.46528261930992204, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07552362687711138, "policy_loss": -0.09999599288712488, "vf_loss": 0.007734484741498212, "vf_explained_var": 0.49992915683736405, "kl": 0.014754786353482057, "entropy": 1.8037073265761137, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 9120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4805495976780852, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.06744967020567856, "policy_loss": -0.09117015040198263, "vf_loss": 0.0072711658129264835, "vf_explained_var": 0.5479359042520324, "kl": 0.01441619654058572, "entropy": 1.8097004598627489, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 9120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "sampler_results": {"episode_reward_max": 1.0430000000000001, "episode_reward_min": -0.765, "episode_reward_mean": 0.36493999999999993, "episode_len_mean": 176.87, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.051}, "policy_reward_max": {"red_0": 1.38, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.23908000000000001, "blue_0": 0.12585999999999997}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.41, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.3, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.41, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.3, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.41, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.3, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.13000000000000012, 0.31999999999999984, 0.9159999999999999, -0.21200000000000008, 0.393, 0.1160000000000001, 0.3699999999999999, 0.08699999999999997, 0.611, 0.8939999999999999, 0.45799999999999974, 0.9229999999999999, 0.9349999999999999, -0.765, 0.28, 0.41500000000000004, 0.31499999999999995, 0.264, -0.1529999999999999, 0.05999999999999983, -0.20800000000000007, 0.9129999999999999, 0.31099999999999994, -0.05800000000000005, -0.23099999999999998, 0.1259999999999999, 0.35599999999999987, 0.611, 0.6320000000000001, 0.9149999999999999, 0.19999999999999996, 0.9089999999999999, 0.029999999999999805, 0.06499999999999995, -0.10100000000000009, 0.2569999999999999, 0.6419999999999999, -0.47, -0.2819999999999998, 0.028000000000000025, 0.8979999999999999, -0.4870000000000001, 0.794, 0.1269999999999999, 0.9079999999999999, -0.14900000000000002, 0.42599999999999993, 0.3919999999999999, 0.6619999999999999, 0.817, 0.42999999999999994, 0.375, 0.939, 0.9269999999999999, 0.8899999999999999, -0.06700000000000006, 0.8270000000000001, 0.9079999999999999, 0.9139999999999999, 0.385, 0.029999999999999916, 0.9149999999999999, -0.14800000000000002, -0.17400000000000004, 0.4119999999999999, 0.39, 0.14700000000000002, -0.04400000000000015, -0.05900000000000005, 0.22999999999999998, 0.30400000000000005, 0.4159999999999999, 0.8879999999999999, 1.0430000000000001, 0.9229999999999999, 0.9099999999999999, -0.008000000000000007, 0.893, -0.16800000000000004, 0.633, 0.17599999999999993, 0.9019999999999999, 0.31899999999999995, 0.3879999999999999, 0.18199999999999994, 0.9109999999999999, -0.24199999999999988, 0.8999999999999999, 0.05499999999999994, 0.9259999999999999, 0.10099999999999998, -0.355, 0.8979999999999999, 0.668, 0.3620000000000001, 0.40800000000000003, -0.06600000000000006, 0.31599999999999995, 0.3909999999999999, 0.06299999999999994], "episode_lengths": [195, 56, 300, 215, 33, 118, 188, 124, 119, 300, 165, 300, 300, 232, 68, 183, 55, 72, 46, 286, 61, 300, 210, 171, 225, 114, 45, 117, 115, 300, 91, 300, 143, 131, 185, 73, 104, 143, 88, 146, 300, 296, 64, 114, 300, 199, 300, 300, 104, 54, 300, 38, 300, 300, 300, 172, 52, 300, 300, 36, 143, 300, 196, 52, 175, 35, 109, 165, 19, 231, 62, 300, 300, 290, 300, 300, 156, 31, 200, 108, 99, 300, 206, 186, 251, 300, 75, 300, 135, 300, 273, 108, 300, 103, 43, 30, 20, 207, 300, 133], "policy_red_0_reward": [0.8919999999999999, 0.823, 0.46299999999999997, -1.034, -1.004, -1.015, 0.8999999999999999, 0.608, 1.124, 0.44699999999999995, 0.9849999999999999, 0.46599999999999997, 0.46699999999999997, 0.274, 0.787, 0.938, -0.508, 1.2730000000000001, -1.006, 0.5969999999999999, 0.8039999999999999, 0.46399999999999997, 0.832, 0.46299999999999997, -1.027, -1.021, 1.362, -0.526, 1.145, 0.46499999999999997, 0.719, 0.45499999999999996, 0.5539999999999999, 1.092, 0.4159999999999999, 0.7679999999999999, 1.1629999999999998, -1.017, -1.0059999999999998, 0.5439999999999999, 0.43399999999999994, 0.564, -0.508, -0.513, 0.45799999999999996, -1.021, 0.45699999999999996, 0.44799999999999995, 1.1749999999999998, -0.511, -0.03400000000000002, 1.38, 0.471, 0.46499999999999997, 0.45399999999999996, 0.46199999999999997, -0.5069999999999999, 0.44599999999999995, 0.45599999999999996, -1.002, -0.52, 0.44999999999999996, -1.031, 0.837, 0.94, -0.502, 1.155, 0.4819999999999999, -1.001, 0.7779999999999999, 0.808, 0.44799999999999995, 0.43799999999999994, 0.586, 0.46099999999999997, 0.45199999999999996, 0.508, -0.51, -0.537, 1.144, -0.513, 0.45199999999999996, 0.851, 0.9109999999999999, 0.715, 0.45999999999999996, 0.764, 0.45399999999999996, -1.019, 0.46099999999999997, -0.5449999999999999, -1.013, 0.45599999999999996, -0.509, -0.5029999999999999, 0.91, -1.005, -0.534, -0.05100000000000004, 1.08], "policy_blue_0_reward": [-1.022, -0.503, 0.45299999999999996, 0.822, 1.397, 1.131, -0.53, -0.521, -0.513, 0.44699999999999995, -0.527, 0.45699999999999996, 0.46799999999999997, -1.039, -0.507, -0.523, 0.823, -1.009, 0.853, -0.537, -1.012, 0.44899999999999995, -0.521, -0.521, 0.7959999999999999, 1.1469999999999998, -1.006, 1.137, -0.513, 0.44999999999999996, -0.519, 0.45399999999999996, -0.524, -1.027, -0.517, -0.511, -0.521, 0.5469999999999999, 0.724, -0.516, 0.46399999999999997, -1.051, 1.302, 0.6399999999999999, 0.44999999999999996, 0.872, -0.03100000000000002, -0.05600000000000004, -0.513, 1.3279999999999998, 0.46399999999999997, -1.005, 0.46799999999999997, 0.46199999999999997, 0.43599999999999994, -0.529, 1.334, 0.46199999999999997, 0.45799999999999996, 1.387, 0.5499999999999999, 0.46499999999999997, 0.883, -1.011, -0.528, 0.892, -1.008, -0.526, 0.942, -0.548, -0.504, -0.03200000000000002, 0.44999999999999996, 0.45699999999999996, 0.46199999999999997, 0.45799999999999996, -0.516, 1.403, 0.369, -0.511, 0.689, 0.44999999999999996, -0.532, -0.523, -0.533, 0.45099999999999996, -1.0059999999999998, 0.44599999999999995, 1.0739999999999998, 0.46499999999999997, 0.6459999999999999, 0.6579999999999999, 0.44199999999999995, 1.177, 0.865, -0.502, 0.939, 0.85, 0.44199999999999995, -1.017]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3218316670245298, "mean_inference_ms": 7.289066763092299, "mean_action_processing_ms": 0.40799809671717696, "mean_env_wait_ms": 0.5040495663973686, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14165306091308594, "StateBufferConnector_ms": 0.008954167366027832, "ViewRequirementAgentConnector_ms": 0.18738973140716553}}, "episode_reward_max": 1.0430000000000001, "episode_reward_min": -0.765, "episode_reward_mean": 0.36493999999999993, "episode_len_mean": 176.87, "episodes_this_iter": 21, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.051}, "policy_reward_max": {"red_0": 1.38, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.23908000000000001, "blue_0": 0.12585999999999997}, "hist_stats": {"episode_reward": [-0.13000000000000012, 0.31999999999999984, 0.9159999999999999, -0.21200000000000008, 0.393, 0.1160000000000001, 0.3699999999999999, 0.08699999999999997, 0.611, 0.8939999999999999, 0.45799999999999974, 0.9229999999999999, 0.9349999999999999, -0.765, 0.28, 0.41500000000000004, 0.31499999999999995, 0.264, -0.1529999999999999, 0.05999999999999983, -0.20800000000000007, 0.9129999999999999, 0.31099999999999994, -0.05800000000000005, -0.23099999999999998, 0.1259999999999999, 0.35599999999999987, 0.611, 0.6320000000000001, 0.9149999999999999, 0.19999999999999996, 0.9089999999999999, 0.029999999999999805, 0.06499999999999995, -0.10100000000000009, 0.2569999999999999, 0.6419999999999999, -0.47, -0.2819999999999998, 0.028000000000000025, 0.8979999999999999, -0.4870000000000001, 0.794, 0.1269999999999999, 0.9079999999999999, -0.14900000000000002, 0.42599999999999993, 0.3919999999999999, 0.6619999999999999, 0.817, 0.42999999999999994, 0.375, 0.939, 0.9269999999999999, 0.8899999999999999, -0.06700000000000006, 0.8270000000000001, 0.9079999999999999, 0.9139999999999999, 0.385, 0.029999999999999916, 0.9149999999999999, -0.14800000000000002, -0.17400000000000004, 0.4119999999999999, 0.39, 0.14700000000000002, -0.04400000000000015, -0.05900000000000005, 0.22999999999999998, 0.30400000000000005, 0.4159999999999999, 0.8879999999999999, 1.0430000000000001, 0.9229999999999999, 0.9099999999999999, -0.008000000000000007, 0.893, -0.16800000000000004, 0.633, 0.17599999999999993, 0.9019999999999999, 0.31899999999999995, 0.3879999999999999, 0.18199999999999994, 0.9109999999999999, -0.24199999999999988, 0.8999999999999999, 0.05499999999999994, 0.9259999999999999, 0.10099999999999998, -0.355, 0.8979999999999999, 0.668, 0.3620000000000001, 0.40800000000000003, -0.06600000000000006, 0.31599999999999995, 0.3909999999999999, 0.06299999999999994], "episode_lengths": [195, 56, 300, 215, 33, 118, 188, 124, 119, 300, 165, 300, 300, 232, 68, 183, 55, 72, 46, 286, 61, 300, 210, 171, 225, 114, 45, 117, 115, 300, 91, 300, 143, 131, 185, 73, 104, 143, 88, 146, 300, 296, 64, 114, 300, 199, 300, 300, 104, 54, 300, 38, 300, 300, 300, 172, 52, 300, 300, 36, 143, 300, 196, 52, 175, 35, 109, 165, 19, 231, 62, 300, 300, 290, 300, 300, 156, 31, 200, 108, 99, 300, 206, 186, 251, 300, 75, 300, 135, 300, 273, 108, 300, 103, 43, 30, 20, 207, 300, 133], "policy_red_0_reward": [0.8919999999999999, 0.823, 0.46299999999999997, -1.034, -1.004, -1.015, 0.8999999999999999, 0.608, 1.124, 0.44699999999999995, 0.9849999999999999, 0.46599999999999997, 0.46699999999999997, 0.274, 0.787, 0.938, -0.508, 1.2730000000000001, -1.006, 0.5969999999999999, 0.8039999999999999, 0.46399999999999997, 0.832, 0.46299999999999997, -1.027, -1.021, 1.362, -0.526, 1.145, 0.46499999999999997, 0.719, 0.45499999999999996, 0.5539999999999999, 1.092, 0.4159999999999999, 0.7679999999999999, 1.1629999999999998, -1.017, -1.0059999999999998, 0.5439999999999999, 0.43399999999999994, 0.564, -0.508, -0.513, 0.45799999999999996, -1.021, 0.45699999999999996, 0.44799999999999995, 1.1749999999999998, -0.511, -0.03400000000000002, 1.38, 0.471, 0.46499999999999997, 0.45399999999999996, 0.46199999999999997, -0.5069999999999999, 0.44599999999999995, 0.45599999999999996, -1.002, -0.52, 0.44999999999999996, -1.031, 0.837, 0.94, -0.502, 1.155, 0.4819999999999999, -1.001, 0.7779999999999999, 0.808, 0.44799999999999995, 0.43799999999999994, 0.586, 0.46099999999999997, 0.45199999999999996, 0.508, -0.51, -0.537, 1.144, -0.513, 0.45199999999999996, 0.851, 0.9109999999999999, 0.715, 0.45999999999999996, 0.764, 0.45399999999999996, -1.019, 0.46099999999999997, -0.5449999999999999, -1.013, 0.45599999999999996, -0.509, -0.5029999999999999, 0.91, -1.005, -0.534, -0.05100000000000004, 1.08], "policy_blue_0_reward": [-1.022, -0.503, 0.45299999999999996, 0.822, 1.397, 1.131, -0.53, -0.521, -0.513, 0.44699999999999995, -0.527, 0.45699999999999996, 0.46799999999999997, -1.039, -0.507, -0.523, 0.823, -1.009, 0.853, -0.537, -1.012, 0.44899999999999995, -0.521, -0.521, 0.7959999999999999, 1.1469999999999998, -1.006, 1.137, -0.513, 0.44999999999999996, -0.519, 0.45399999999999996, -0.524, -1.027, -0.517, -0.511, -0.521, 0.5469999999999999, 0.724, -0.516, 0.46399999999999997, -1.051, 1.302, 0.6399999999999999, 0.44999999999999996, 0.872, -0.03100000000000002, -0.05600000000000004, -0.513, 1.3279999999999998, 0.46399999999999997, -1.005, 0.46799999999999997, 0.46199999999999997, 0.43599999999999994, -0.529, 1.334, 0.46199999999999997, 0.45799999999999996, 1.387, 0.5499999999999999, 0.46499999999999997, 0.883, -1.011, -0.528, 0.892, -1.008, -0.526, 0.942, -0.548, -0.504, -0.03200000000000002, 0.44999999999999996, 0.45699999999999996, 0.46199999999999997, 0.45799999999999996, -0.516, 1.403, 0.369, -0.511, 0.689, 0.44999999999999996, -0.532, -0.523, -0.533, 0.45099999999999996, -1.0059999999999998, 0.44599999999999995, 1.0739999999999998, 0.46499999999999997, 0.6459999999999999, 0.6579999999999999, 0.44199999999999995, 1.177, 0.865, -0.502, 0.939, 0.85, 0.44199999999999995, -1.017]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3218316670245298, "mean_inference_ms": 7.289066763092299, "mean_action_processing_ms": 0.40799809671717696, "mean_env_wait_ms": 0.5040495663973686, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14165306091308594, "StateBufferConnector_ms": 0.008954167366027832, "ViewRequirementAgentConnector_ms": 0.18738973140716553}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 137.92558367268205, "num_env_steps_trained_throughput_per_sec": 137.92558367268205, "timesteps_total": 40000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 28520.913, "sample_time_ms": 3872.684, "learn_time_ms": 24620.988, "learn_throughput": 162.463, "synch_weights_time_ms": 25.755}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "episodes_total": 212, "training_iteration": 10, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-01-32", "timestamp": 1694836892, "time_this_iter_s": 29.01645517349243, "time_total_s": 285.3458242416382, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7234a710>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 285.3458242416382, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 23.77857142857143, "ram_util_percent": 56.7904761904762}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.37, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.32, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.37, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.01, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.32, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.37, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.32, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4946422164949278, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07652909707479315, "policy_loss": -0.10365564960763246, "vf_loss": 0.008122938313802782, "vf_explained_var": 0.49944561210771404, "kl": 0.01636702943816817, "entropy": 1.7923423934727907, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 10080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4879029431380332, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07698170367645313, "policy_loss": -0.10187832775118295, "vf_loss": 0.00838411166514561, "vf_explained_var": 0.5042078935851654, "kl": 0.014826818816180544, "entropy": 1.8136623083303371, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 10080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000}, "sampler_results": {"episode_reward_max": 1.279, "episode_reward_min": -0.4870000000000001, "episode_reward_mean": 0.39931999999999995, "episode_len_mean": 179.75, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"red_0": -1.031, "blue_0": -1.051}, "policy_reward_max": {"red_0": 1.38, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.21181000000000005, "blue_0": 0.18750999999999995}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.37, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.32, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.37, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.01, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.32, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.37, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.32, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.20800000000000007, 0.9129999999999999, 0.31099999999999994, -0.05800000000000005, -0.23099999999999998, 0.1259999999999999, 0.35599999999999987, 0.611, 0.6320000000000001, 0.9149999999999999, 0.19999999999999996, 0.9089999999999999, 0.029999999999999805, 0.06499999999999995, -0.10100000000000009, 0.2569999999999999, 0.6419999999999999, -0.47, -0.2819999999999998, 0.028000000000000025, 0.8979999999999999, -0.4870000000000001, 0.794, 0.1269999999999999, 0.9079999999999999, -0.14900000000000002, 0.42599999999999993, 0.3919999999999999, 0.6619999999999999, 0.817, 0.42999999999999994, 0.375, 0.939, 0.9269999999999999, 0.8899999999999999, -0.06700000000000006, 0.8270000000000001, 0.9079999999999999, 0.9139999999999999, 0.385, 0.029999999999999916, 0.9149999999999999, -0.14800000000000002, -0.17400000000000004, 0.4119999999999999, 0.39, 0.14700000000000002, -0.04400000000000015, -0.05900000000000005, 0.22999999999999998, 0.30400000000000005, 0.4159999999999999, 0.8879999999999999, 1.0430000000000001, 0.9229999999999999, 0.9099999999999999, -0.008000000000000007, 0.893, -0.16800000000000004, 0.633, 0.17599999999999993, 0.9019999999999999, 0.31899999999999995, 0.3879999999999999, 0.18199999999999994, 0.9109999999999999, -0.24199999999999988, 0.8999999999999999, 0.05499999999999994, 0.9259999999999999, 0.10099999999999998, -0.355, 0.8979999999999999, 0.668, 0.3620000000000001, 0.40800000000000003, -0.06600000000000006, 0.31599999999999995, 0.3909999999999999, 0.06299999999999994, 0.9019999999999999, -0.20299999999999985, 1.279, 0.45100000000000007, 0.42199999999999993, 0.34799999999999986, 0.4149999999999999, 0.9299999999999999, 0.4149999999999999, 0.02299999999999991, 0.819, 0.9219999999999999, 0.3500000000000001, 0.10400000000000009, 0.494, 0.30000000000000004, 0.32899999999999996, 0.32400000000000007, 0.509, 0.4019999999999999], "episode_lengths": [61, 300, 210, 171, 225, 114, 45, 117, 115, 300, 91, 300, 143, 131, 185, 73, 104, 143, 88, 146, 300, 296, 64, 114, 300, 199, 300, 300, 104, 54, 300, 38, 300, 300, 300, 172, 52, 300, 300, 36, 143, 300, 196, 52, 175, 35, 109, 165, 19, 231, 62, 300, 300, 290, 300, 300, 156, 31, 200, 108, 99, 300, 206, 186, 251, 300, 75, 300, 135, 300, 273, 108, 300, 103, 43, 30, 20, 207, 300, 133, 300, 63, 69, 166, 300, 191, 178, 300, 300, 298, 54, 300, 47, 121, 151, 62, 207, 206, 149, 181], "policy_red_0_reward": [0.8039999999999999, 0.46399999999999997, 0.832, 0.46299999999999997, -1.027, -1.021, 1.362, -0.526, 1.145, 0.46499999999999997, 0.719, 0.45499999999999996, 0.5539999999999999, 1.092, 0.4159999999999999, 0.7679999999999999, 1.1629999999999998, -1.017, -1.0059999999999998, 0.5439999999999999, 0.43399999999999994, 0.564, -0.508, -0.513, 0.45799999999999996, -1.021, 0.45699999999999996, 0.44799999999999995, 1.1749999999999998, -0.511, -0.03400000000000002, 1.38, 0.471, 0.46499999999999997, 0.45399999999999996, 0.46199999999999997, -0.5069999999999999, 0.44599999999999995, 0.45599999999999996, -1.002, -0.52, 0.44999999999999996, -1.031, 0.837, 0.94, -0.502, 1.155, 0.4819999999999999, -1.001, 0.7779999999999999, 0.808, 0.44799999999999995, 0.43799999999999994, 0.586, 0.46099999999999997, 0.45199999999999996, 0.508, -0.51, -0.537, 1.144, -0.513, 0.45199999999999996, 0.851, 0.9109999999999999, 0.715, 0.45999999999999996, 0.764, 0.45399999999999996, -1.019, 0.46099999999999997, -0.5449999999999999, -1.013, 0.45599999999999996, -0.509, -0.5029999999999999, 0.91, -1.005, -0.534, -0.05100000000000004, 1.08, 0.45699999999999996, -1.009, -0.006, 0.98, -0.03800000000000003, -0.553, -0.531, 0.46299999999999997, -0.04200000000000003, 0.5609999999999999, 1.325, 0.45699999999999996, 1.353, 1.119, -0.53, -1.007, -0.522, 0.859, -0.5199999999999999, 0.9339999999999999], "policy_blue_0_reward": [-1.012, 0.44899999999999995, -0.521, -0.521, 0.7959999999999999, 1.1469999999999998, -1.006, 1.137, -0.513, 0.44999999999999996, -0.519, 0.45399999999999996, -0.524, -1.027, -0.517, -0.511, -0.521, 0.5469999999999999, 0.724, -0.516, 0.46399999999999997, -1.051, 1.302, 0.6399999999999999, 0.44999999999999996, 0.872, -0.03100000000000002, -0.05600000000000004, -0.513, 1.3279999999999998, 0.46399999999999997, -1.005, 0.46799999999999997, 0.46199999999999997, 0.43599999999999994, -0.529, 1.334, 0.46199999999999997, 0.45799999999999996, 1.387, 0.5499999999999999, 0.46499999999999997, 0.883, -1.011, -0.528, 0.892, -1.008, -0.526, 0.942, -0.548, -0.504, -0.03200000000000002, 0.44999999999999996, 0.45699999999999996, 0.46199999999999997, 0.45799999999999996, -0.516, 1.403, 0.369, -0.511, 0.689, 0.44999999999999996, -0.532, -0.523, -0.533, 0.45099999999999996, -1.0059999999999998, 0.44599999999999995, 1.0739999999999998, 0.46499999999999997, 0.6459999999999999, 0.6579999999999999, 0.44199999999999995, 1.177, 0.865, -0.502, 0.939, 0.85, 0.44199999999999995, -1.017, 0.44499999999999995, 0.8059999999999999, 1.285, -0.529, 0.45999999999999996, 0.9009999999999999, 0.946, 0.46699999999999997, 0.45699999999999996, -0.538, -0.506, 0.46499999999999997, -1.003, -1.015, 1.024, 1.307, 0.851, -0.5349999999999999, 1.029, -0.532]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3220687717655495, "mean_inference_ms": 7.283707186282788, "mean_action_processing_ms": 0.4049918794161113, "mean_env_wait_ms": 0.5033824140074766, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14245617389678955, "StateBufferConnector_ms": 0.009130001068115234, "ViewRequirementAgentConnector_ms": 0.18762516975402832}}, "episode_reward_max": 1.279, "episode_reward_min": -0.4870000000000001, "episode_reward_mean": 0.39931999999999995, "episode_len_mean": 179.75, "episodes_this_iter": 20, "policy_reward_min": {"red_0": -1.031, "blue_0": -1.051}, "policy_reward_max": {"red_0": 1.38, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.21181000000000005, "blue_0": 0.18750999999999995}, "hist_stats": {"episode_reward": [-0.20800000000000007, 0.9129999999999999, 0.31099999999999994, -0.05800000000000005, -0.23099999999999998, 0.1259999999999999, 0.35599999999999987, 0.611, 0.6320000000000001, 0.9149999999999999, 0.19999999999999996, 0.9089999999999999, 0.029999999999999805, 0.06499999999999995, -0.10100000000000009, 0.2569999999999999, 0.6419999999999999, -0.47, -0.2819999999999998, 0.028000000000000025, 0.8979999999999999, -0.4870000000000001, 0.794, 0.1269999999999999, 0.9079999999999999, -0.14900000000000002, 0.42599999999999993, 0.3919999999999999, 0.6619999999999999, 0.817, 0.42999999999999994, 0.375, 0.939, 0.9269999999999999, 0.8899999999999999, -0.06700000000000006, 0.8270000000000001, 0.9079999999999999, 0.9139999999999999, 0.385, 0.029999999999999916, 0.9149999999999999, -0.14800000000000002, -0.17400000000000004, 0.4119999999999999, 0.39, 0.14700000000000002, -0.04400000000000015, -0.05900000000000005, 0.22999999999999998, 0.30400000000000005, 0.4159999999999999, 0.8879999999999999, 1.0430000000000001, 0.9229999999999999, 0.9099999999999999, -0.008000000000000007, 0.893, -0.16800000000000004, 0.633, 0.17599999999999993, 0.9019999999999999, 0.31899999999999995, 0.3879999999999999, 0.18199999999999994, 0.9109999999999999, -0.24199999999999988, 0.8999999999999999, 0.05499999999999994, 0.9259999999999999, 0.10099999999999998, -0.355, 0.8979999999999999, 0.668, 0.3620000000000001, 0.40800000000000003, -0.06600000000000006, 0.31599999999999995, 0.3909999999999999, 0.06299999999999994, 0.9019999999999999, -0.20299999999999985, 1.279, 0.45100000000000007, 0.42199999999999993, 0.34799999999999986, 0.4149999999999999, 0.9299999999999999, 0.4149999999999999, 0.02299999999999991, 0.819, 0.9219999999999999, 0.3500000000000001, 0.10400000000000009, 0.494, 0.30000000000000004, 0.32899999999999996, 0.32400000000000007, 0.509, 0.4019999999999999], "episode_lengths": [61, 300, 210, 171, 225, 114, 45, 117, 115, 300, 91, 300, 143, 131, 185, 73, 104, 143, 88, 146, 300, 296, 64, 114, 300, 199, 300, 300, 104, 54, 300, 38, 300, 300, 300, 172, 52, 300, 300, 36, 143, 300, 196, 52, 175, 35, 109, 165, 19, 231, 62, 300, 300, 290, 300, 300, 156, 31, 200, 108, 99, 300, 206, 186, 251, 300, 75, 300, 135, 300, 273, 108, 300, 103, 43, 30, 20, 207, 300, 133, 300, 63, 69, 166, 300, 191, 178, 300, 300, 298, 54, 300, 47, 121, 151, 62, 207, 206, 149, 181], "policy_red_0_reward": [0.8039999999999999, 0.46399999999999997, 0.832, 0.46299999999999997, -1.027, -1.021, 1.362, -0.526, 1.145, 0.46499999999999997, 0.719, 0.45499999999999996, 0.5539999999999999, 1.092, 0.4159999999999999, 0.7679999999999999, 1.1629999999999998, -1.017, -1.0059999999999998, 0.5439999999999999, 0.43399999999999994, 0.564, -0.508, -0.513, 0.45799999999999996, -1.021, 0.45699999999999996, 0.44799999999999995, 1.1749999999999998, -0.511, -0.03400000000000002, 1.38, 0.471, 0.46499999999999997, 0.45399999999999996, 0.46199999999999997, -0.5069999999999999, 0.44599999999999995, 0.45599999999999996, -1.002, -0.52, 0.44999999999999996, -1.031, 0.837, 0.94, -0.502, 1.155, 0.4819999999999999, -1.001, 0.7779999999999999, 0.808, 0.44799999999999995, 0.43799999999999994, 0.586, 0.46099999999999997, 0.45199999999999996, 0.508, -0.51, -0.537, 1.144, -0.513, 0.45199999999999996, 0.851, 0.9109999999999999, 0.715, 0.45999999999999996, 0.764, 0.45399999999999996, -1.019, 0.46099999999999997, -0.5449999999999999, -1.013, 0.45599999999999996, -0.509, -0.5029999999999999, 0.91, -1.005, -0.534, -0.05100000000000004, 1.08, 0.45699999999999996, -1.009, -0.006, 0.98, -0.03800000000000003, -0.553, -0.531, 0.46299999999999997, -0.04200000000000003, 0.5609999999999999, 1.325, 0.45699999999999996, 1.353, 1.119, -0.53, -1.007, -0.522, 0.859, -0.5199999999999999, 0.9339999999999999], "policy_blue_0_reward": [-1.012, 0.44899999999999995, -0.521, -0.521, 0.7959999999999999, 1.1469999999999998, -1.006, 1.137, -0.513, 0.44999999999999996, -0.519, 0.45399999999999996, -0.524, -1.027, -0.517, -0.511, -0.521, 0.5469999999999999, 0.724, -0.516, 0.46399999999999997, -1.051, 1.302, 0.6399999999999999, 0.44999999999999996, 0.872, -0.03100000000000002, -0.05600000000000004, -0.513, 1.3279999999999998, 0.46399999999999997, -1.005, 0.46799999999999997, 0.46199999999999997, 0.43599999999999994, -0.529, 1.334, 0.46199999999999997, 0.45799999999999996, 1.387, 0.5499999999999999, 0.46499999999999997, 0.883, -1.011, -0.528, 0.892, -1.008, -0.526, 0.942, -0.548, -0.504, -0.03200000000000002, 0.44999999999999996, 0.45699999999999996, 0.46199999999999997, 0.45799999999999996, -0.516, 1.403, 0.369, -0.511, 0.689, 0.44999999999999996, -0.532, -0.523, -0.533, 0.45099999999999996, -1.0059999999999998, 0.44599999999999995, 1.0739999999999998, 0.46499999999999997, 0.6459999999999999, 0.6579999999999999, 0.44199999999999995, 1.177, 0.865, -0.502, 0.939, 0.85, 0.44199999999999995, -1.017, 0.44499999999999995, 0.8059999999999999, 1.285, -0.529, 0.45999999999999996, 0.9009999999999999, 0.946, 0.46699999999999997, 0.45699999999999996, -0.538, -0.506, 0.46499999999999997, -1.003, -1.015, 1.024, 1.307, 0.851, -0.5349999999999999, 1.029, -0.532]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3220687717655495, "mean_inference_ms": 7.283707186282788, "mean_action_processing_ms": 0.4049918794161113, "mean_env_wait_ms": 0.5033824140074766, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14245617389678955, "StateBufferConnector_ms": 0.009130001068115234, "ViewRequirementAgentConnector_ms": 0.18762516975402832}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 120.89051924580102, "num_env_steps_trained_throughput_per_sec": 120.89051924580102, "timesteps_total": 44000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 88000, "timers": {"training_iteration_time_ms": 29107.019, "sample_time_ms": 3832.148, "learn_time_ms": 25247.608, "learn_throughput": 158.431, "synch_weights_time_ms": 25.754}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000}, "done": false, "episodes_total": 232, "training_iteration": 11, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-02-06", "timestamp": 1694836926, "time_this_iter_s": 33.10241198539734, "time_total_s": 318.4482362270355, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80ebb0a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 318.4482362270355, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 30.381250000000005, "ram_util_percent": 56.86249999999999}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.37, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.36, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.37, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.03, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.36, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.37, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.36, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48889122996479273, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07398728766517403, "policy_loss": -0.10321253748891952, "vf_loss": 0.015090308015351184, "vf_explained_var": 0.5507577315593759, "kl": 0.015452409462917179, "entropy": 1.7882505098978678, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 11040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49913000663121543, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07299820986518171, "policy_loss": -0.10258372648459044, "vf_loss": 0.014871183585880014, "vf_explained_var": 0.5894793054709832, "kl": 0.015767260254755132, "entropy": 1.7966007374227047, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 11040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "sampler_results": {"episode_reward_max": 1.279, "episode_reward_min": -0.43099999999999994, "episode_reward_mean": 0.40403, "episode_len_mean": 163.68, "episode_media": {}, "episodes_this_iter": 35, "policy_reward_min": {"red_0": -1.031, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.434, "blue_0": 1.447}, "policy_reward_mean": {"red_0": 0.18586, "blue_0": 0.21817}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.37, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.36, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.37, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.03, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.36, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.37, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.36, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.06700000000000006, 0.8270000000000001, 0.9079999999999999, 0.9139999999999999, 0.385, 0.029999999999999916, 0.9149999999999999, -0.14800000000000002, -0.17400000000000004, 0.4119999999999999, 0.39, 0.14700000000000002, -0.04400000000000015, -0.05900000000000005, 0.22999999999999998, 0.30400000000000005, 0.4159999999999999, 0.8879999999999999, 1.0430000000000001, 0.9229999999999999, 0.9099999999999999, -0.008000000000000007, 0.893, -0.16800000000000004, 0.633, 0.17599999999999993, 0.9019999999999999, 0.31899999999999995, 0.3879999999999999, 0.18199999999999994, 0.9109999999999999, -0.24199999999999988, 0.8999999999999999, 0.05499999999999994, 0.9259999999999999, 0.10099999999999998, -0.355, 0.8979999999999999, 0.668, 0.3620000000000001, 0.40800000000000003, -0.06600000000000006, 0.31599999999999995, 0.3909999999999999, 0.06299999999999994, 0.9019999999999999, -0.20299999999999985, 1.279, 0.45100000000000007, 0.42199999999999993, 0.34799999999999986, 0.4149999999999999, 0.9299999999999999, 0.4149999999999999, 0.02299999999999991, 0.819, 0.9219999999999999, 0.3500000000000001, 0.10400000000000009, 0.494, 0.30000000000000004, 0.32899999999999996, 0.32400000000000007, 0.509, 0.4019999999999999, 0.9219999999999999, 0.43299999999999983, 0.9139999999999999, -0.43099999999999994, 0.44399999999999995, 0.11399999999999988, 0.6240000000000001, 0.9319999999999999, 0.33999999999999997, 0.21599999999999997, -0.2400000000000001, 1.1549999999999998, 0.9069999999999999, -0.20600000000000007, 0.376, 0.735, -0.11399999999999999, 0.43699999999999983, 0.31499999999999995, 1.2650000000000001, 0.6219999999999999, -0.32000000000000006, 0.3700000000000001, 0.356, 0.815, -0.09600000000000007, 0.246, 0.747, -0.008000000000000007, -0.3879999999999999, 0.945, -0.1369999999999999, 0.9219999999999999, 0.252, -0.399], "episode_lengths": [172, 52, 300, 300, 36, 143, 300, 196, 52, 175, 35, 109, 165, 19, 231, 62, 300, 300, 290, 300, 300, 156, 31, 200, 108, 99, 300, 206, 186, 251, 300, 75, 300, 135, 300, 273, 108, 300, 103, 43, 30, 20, 207, 300, 133, 300, 63, 69, 166, 300, 191, 178, 300, 300, 298, 54, 300, 47, 121, 151, 62, 207, 206, 149, 181, 300, 174, 300, 136, 170, 273, 117, 21, 48, 86, 216, 258, 300, 63, 37, 85, 35, 171, 59, 74, 115, 256, 41, 43, 55, 300, 78, 79, 157, 119, 17, 42, 300, 76, 123], "policy_red_0_reward": [0.46199999999999997, -0.5069999999999999, 0.44599999999999995, 0.45599999999999996, -1.002, -0.52, 0.44999999999999996, -1.031, 0.837, 0.94, -0.502, 1.155, 0.4819999999999999, -1.001, 0.7779999999999999, 0.808, 0.44799999999999995, 0.43799999999999994, 0.586, 0.46099999999999997, 0.45199999999999996, 0.508, -0.51, -0.537, 1.144, -0.513, 0.45199999999999996, 0.851, 0.9109999999999999, 0.715, 0.45999999999999996, 0.764, 0.45399999999999996, -1.019, 0.46099999999999997, -0.5449999999999999, -1.013, 0.45599999999999996, -0.509, -0.5029999999999999, 0.91, -1.005, -0.534, -0.05100000000000004, 1.08, 0.45699999999999996, -1.009, -0.006, 0.98, -0.03800000000000003, -0.553, -0.531, 0.46299999999999997, -0.04200000000000003, 0.5609999999999999, 1.325, 0.45699999999999996, 1.353, 1.119, -0.53, -1.007, -0.522, 0.859, -0.5199999999999999, 0.9339999999999999, 0.45899999999999996, 0.955, 0.45299999999999996, 0.5790000000000001, 0.967, -0.547, 1.137, 1.434, -1.008, -0.511, -0.557, 0.46299999999999997, 0.45699999999999996, 0.7989999999999999, -0.503, -0.504, 0.89, 0.958, 1.319, -0.007, 1.1320000000000001, -1.028, 0.874, -1.01, 1.325, -0.047000000000000035, 1.256, -0.511, 0.51, -1.02, -0.502, -1.009, 0.46599999999999997, -0.512, 0.616], "policy_blue_0_reward": [-0.529, 1.334, 0.46199999999999997, 0.45799999999999996, 1.387, 0.5499999999999999, 0.46499999999999997, 0.883, -1.011, -0.528, 0.892, -1.008, -0.526, 0.942, -0.548, -0.504, -0.03200000000000002, 0.44999999999999996, 0.45699999999999996, 0.46199999999999997, 0.45799999999999996, -0.516, 1.403, 0.369, -0.511, 0.689, 0.44999999999999996, -0.532, -0.523, -0.533, 0.45099999999999996, -1.0059999999999998, 0.44599999999999995, 1.0739999999999998, 0.46499999999999997, 0.6459999999999999, 0.6579999999999999, 0.44199999999999995, 1.177, 0.865, -0.502, 0.939, 0.85, 0.44199999999999995, -1.017, 0.44499999999999995, 0.8059999999999999, 1.285, -0.529, 0.45999999999999996, 0.9009999999999999, 0.946, 0.46699999999999997, 0.45699999999999996, -0.538, -0.506, 0.46499999999999997, -1.003, -1.015, 1.024, 1.307, 0.851, -0.5349999999999999, 1.029, -0.532, 0.46299999999999997, -0.522, 0.46099999999999997, -1.01, -0.523, 0.6609999999999999, -0.513, -0.502, 1.3479999999999999, 0.727, 0.31699999999999995, 0.692, 0.44999999999999996, -1.005, 0.879, 1.2389999999999999, -1.004, -0.521, -1.004, 1.272, -0.51, 0.708, -0.504, 1.366, -0.5099999999999999, -0.04900000000000004, -1.01, 1.258, -0.518, 0.632, 1.447, 0.872, 0.45599999999999996, 0.764, -1.015]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.323331979390824, "mean_inference_ms": 7.291596271306672, "mean_action_processing_ms": 0.3998608899403198, "mean_env_wait_ms": 0.5029463832321084, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14359331130981445, "StateBufferConnector_ms": 0.009255647659301758, "ViewRequirementAgentConnector_ms": 0.18430614471435547}}, "episode_reward_max": 1.279, "episode_reward_min": -0.43099999999999994, "episode_reward_mean": 0.40403, "episode_len_mean": 163.68, "episodes_this_iter": 35, "policy_reward_min": {"red_0": -1.031, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.434, "blue_0": 1.447}, "policy_reward_mean": {"red_0": 0.18586, "blue_0": 0.21817}, "hist_stats": {"episode_reward": [-0.06700000000000006, 0.8270000000000001, 0.9079999999999999, 0.9139999999999999, 0.385, 0.029999999999999916, 0.9149999999999999, -0.14800000000000002, -0.17400000000000004, 0.4119999999999999, 0.39, 0.14700000000000002, -0.04400000000000015, -0.05900000000000005, 0.22999999999999998, 0.30400000000000005, 0.4159999999999999, 0.8879999999999999, 1.0430000000000001, 0.9229999999999999, 0.9099999999999999, -0.008000000000000007, 0.893, -0.16800000000000004, 0.633, 0.17599999999999993, 0.9019999999999999, 0.31899999999999995, 0.3879999999999999, 0.18199999999999994, 0.9109999999999999, -0.24199999999999988, 0.8999999999999999, 0.05499999999999994, 0.9259999999999999, 0.10099999999999998, -0.355, 0.8979999999999999, 0.668, 0.3620000000000001, 0.40800000000000003, -0.06600000000000006, 0.31599999999999995, 0.3909999999999999, 0.06299999999999994, 0.9019999999999999, -0.20299999999999985, 1.279, 0.45100000000000007, 0.42199999999999993, 0.34799999999999986, 0.4149999999999999, 0.9299999999999999, 0.4149999999999999, 0.02299999999999991, 0.819, 0.9219999999999999, 0.3500000000000001, 0.10400000000000009, 0.494, 0.30000000000000004, 0.32899999999999996, 0.32400000000000007, 0.509, 0.4019999999999999, 0.9219999999999999, 0.43299999999999983, 0.9139999999999999, -0.43099999999999994, 0.44399999999999995, 0.11399999999999988, 0.6240000000000001, 0.9319999999999999, 0.33999999999999997, 0.21599999999999997, -0.2400000000000001, 1.1549999999999998, 0.9069999999999999, -0.20600000000000007, 0.376, 0.735, -0.11399999999999999, 0.43699999999999983, 0.31499999999999995, 1.2650000000000001, 0.6219999999999999, -0.32000000000000006, 0.3700000000000001, 0.356, 0.815, -0.09600000000000007, 0.246, 0.747, -0.008000000000000007, -0.3879999999999999, 0.945, -0.1369999999999999, 0.9219999999999999, 0.252, -0.399], "episode_lengths": [172, 52, 300, 300, 36, 143, 300, 196, 52, 175, 35, 109, 165, 19, 231, 62, 300, 300, 290, 300, 300, 156, 31, 200, 108, 99, 300, 206, 186, 251, 300, 75, 300, 135, 300, 273, 108, 300, 103, 43, 30, 20, 207, 300, 133, 300, 63, 69, 166, 300, 191, 178, 300, 300, 298, 54, 300, 47, 121, 151, 62, 207, 206, 149, 181, 300, 174, 300, 136, 170, 273, 117, 21, 48, 86, 216, 258, 300, 63, 37, 85, 35, 171, 59, 74, 115, 256, 41, 43, 55, 300, 78, 79, 157, 119, 17, 42, 300, 76, 123], "policy_red_0_reward": [0.46199999999999997, -0.5069999999999999, 0.44599999999999995, 0.45599999999999996, -1.002, -0.52, 0.44999999999999996, -1.031, 0.837, 0.94, -0.502, 1.155, 0.4819999999999999, -1.001, 0.7779999999999999, 0.808, 0.44799999999999995, 0.43799999999999994, 0.586, 0.46099999999999997, 0.45199999999999996, 0.508, -0.51, -0.537, 1.144, -0.513, 0.45199999999999996, 0.851, 0.9109999999999999, 0.715, 0.45999999999999996, 0.764, 0.45399999999999996, -1.019, 0.46099999999999997, -0.5449999999999999, -1.013, 0.45599999999999996, -0.509, -0.5029999999999999, 0.91, -1.005, -0.534, -0.05100000000000004, 1.08, 0.45699999999999996, -1.009, -0.006, 0.98, -0.03800000000000003, -0.553, -0.531, 0.46299999999999997, -0.04200000000000003, 0.5609999999999999, 1.325, 0.45699999999999996, 1.353, 1.119, -0.53, -1.007, -0.522, 0.859, -0.5199999999999999, 0.9339999999999999, 0.45899999999999996, 0.955, 0.45299999999999996, 0.5790000000000001, 0.967, -0.547, 1.137, 1.434, -1.008, -0.511, -0.557, 0.46299999999999997, 0.45699999999999996, 0.7989999999999999, -0.503, -0.504, 0.89, 0.958, 1.319, -0.007, 1.1320000000000001, -1.028, 0.874, -1.01, 1.325, -0.047000000000000035, 1.256, -0.511, 0.51, -1.02, -0.502, -1.009, 0.46599999999999997, -0.512, 0.616], "policy_blue_0_reward": [-0.529, 1.334, 0.46199999999999997, 0.45799999999999996, 1.387, 0.5499999999999999, 0.46499999999999997, 0.883, -1.011, -0.528, 0.892, -1.008, -0.526, 0.942, -0.548, -0.504, -0.03200000000000002, 0.44999999999999996, 0.45699999999999996, 0.46199999999999997, 0.45799999999999996, -0.516, 1.403, 0.369, -0.511, 0.689, 0.44999999999999996, -0.532, -0.523, -0.533, 0.45099999999999996, -1.0059999999999998, 0.44599999999999995, 1.0739999999999998, 0.46499999999999997, 0.6459999999999999, 0.6579999999999999, 0.44199999999999995, 1.177, 0.865, -0.502, 0.939, 0.85, 0.44199999999999995, -1.017, 0.44499999999999995, 0.8059999999999999, 1.285, -0.529, 0.45999999999999996, 0.9009999999999999, 0.946, 0.46699999999999997, 0.45699999999999996, -0.538, -0.506, 0.46499999999999997, -1.003, -1.015, 1.024, 1.307, 0.851, -0.5349999999999999, 1.029, -0.532, 0.46299999999999997, -0.522, 0.46099999999999997, -1.01, -0.523, 0.6609999999999999, -0.513, -0.502, 1.3479999999999999, 0.727, 0.31699999999999995, 0.692, 0.44999999999999996, -1.005, 0.879, 1.2389999999999999, -1.004, -0.521, -1.004, 1.272, -0.51, 0.708, -0.504, 1.366, -0.5099999999999999, -0.04900000000000004, -1.01, 1.258, -0.518, 0.632, 1.447, 0.872, 0.45599999999999996, 0.764, -1.015]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.323331979390824, "mean_inference_ms": 7.291596271306672, "mean_action_processing_ms": 0.3998608899403198, "mean_env_wait_ms": 0.5029463832321084, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14359331130981445, "StateBufferConnector_ms": 0.009255647659301758, "ViewRequirementAgentConnector_ms": 0.18430614471435547}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.6341518727069, "num_env_steps_trained_throughput_per_sec": 131.6341518727069, "timesteps_total": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 29484.581, "sample_time_ms": 3827.107, "learn_time_ms": 25631.046, "learn_throughput": 156.061, "synch_weights_time_ms": 24.907}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "episodes_total": 267, "training_iteration": 12, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-02-37", "timestamp": 1694836957, "time_this_iter_s": 30.40199303627014, "time_total_s": 348.85022926330566, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7234b010>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 348.85022926330566, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 26.311363636363634, "ram_util_percent": 56.83636363636364}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.42, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.35, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.42, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.03, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.35, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.42, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.35, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5186466432176531, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08024082577079146, "policy_loss": -0.10852468620820825, "vf_loss": 0.008714522504487832, "vf_explained_var": 0.5917653817062577, "kl": 0.016924518903144604, "entropy": 1.7775131395707529, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5170453314358989, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.0813438589539146, "policy_loss": -0.1093528470567738, "vf_loss": 0.010747196729547189, "vf_explained_var": 0.5868725719551245, "kl": 0.016082898669163608, "entropy": 1.7905116315931082, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000}, "sampler_results": {"episode_reward_max": 1.279, "episode_reward_min": -0.43099999999999994, "episode_reward_mean": 0.4191599999999999, "episode_len_mean": 155.68, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"red_0": -1.028, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.434, "blue_0": 1.447}, "policy_reward_mean": {"red_0": 0.25003, "blue_0": 0.16912999999999997}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.42, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.35, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.42, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.03, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.35, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.42, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.35, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.633, 0.17599999999999993, 0.9019999999999999, 0.31899999999999995, 0.3879999999999999, 0.18199999999999994, 0.9109999999999999, -0.24199999999999988, 0.8999999999999999, 0.05499999999999994, 0.9259999999999999, 0.10099999999999998, -0.355, 0.8979999999999999, 0.668, 0.3620000000000001, 0.40800000000000003, -0.06600000000000006, 0.31599999999999995, 0.3909999999999999, 0.06299999999999994, 0.9019999999999999, -0.20299999999999985, 1.279, 0.45100000000000007, 0.42199999999999993, 0.34799999999999986, 0.4149999999999999, 0.9299999999999999, 0.4149999999999999, 0.02299999999999991, 0.819, 0.9219999999999999, 0.3500000000000001, 0.10400000000000009, 0.494, 0.30000000000000004, 0.32899999999999996, 0.32400000000000007, 0.509, 0.4019999999999999, 0.9219999999999999, 0.43299999999999983, 0.9139999999999999, -0.43099999999999994, 0.44399999999999995, 0.11399999999999988, 0.6240000000000001, 0.9319999999999999, 0.33999999999999997, 0.21599999999999997, -0.2400000000000001, 1.1549999999999998, 0.9069999999999999, -0.20600000000000007, 0.376, 0.735, -0.11399999999999999, 0.43699999999999983, 0.31499999999999995, 1.2650000000000001, 0.6219999999999999, -0.32000000000000006, 0.3700000000000001, 0.356, 0.815, -0.09600000000000007, 0.246, 0.747, -0.008000000000000007, -0.3879999999999999, 0.945, -0.1369999999999999, 0.9219999999999999, 0.252, -0.399, 0.08400000000000007, 0.31699999999999995, 0.664, 0.759, -0.1279999999999999, 0.31300000000000006, 0.35299999999999976, 0.9149999999999999, -0.10499999999999998, 0.48, 0.347, 0.356, 0.9359999999999999, 0.27300000000000013, 0.9169999999999999, -0.1180000000000001, 0.536, 0.6429999999999998, 0.7749999999999999, 0.699, 0.9149999999999999, 0.6779999999999999, 0.17700000000000005, 0.594], "episode_lengths": [108, 99, 300, 206, 186, 251, 300, 75, 300, 135, 300, 273, 108, 300, 103, 43, 30, 20, 207, 300, 133, 300, 63, 69, 166, 300, 191, 178, 300, 300, 298, 54, 300, 47, 121, 151, 62, 207, 206, 149, 181, 300, 174, 300, 136, 170, 273, 117, 21, 48, 86, 216, 258, 300, 63, 37, 85, 35, 171, 59, 74, 115, 256, 41, 43, 55, 300, 78, 79, 157, 119, 17, 42, 300, 76, 123, 278, 56, 102, 74, 39, 57, 195, 300, 34, 158, 197, 45, 300, 70, 300, 191, 141, 106, 70, 89, 300, 100, 98, 124], "policy_red_0_reward": [1.144, -0.513, 0.45199999999999996, 0.851, 0.9109999999999999, 0.715, 0.45999999999999996, 0.764, 0.45399999999999996, -1.019, 0.46099999999999997, -0.5449999999999999, -1.013, 0.45599999999999996, -0.509, -0.5029999999999999, 0.91, -1.005, -0.534, -0.05100000000000004, 1.08, 0.45699999999999996, -1.009, -0.006, 0.98, -0.03800000000000003, -0.553, -0.531, 0.46299999999999997, -0.04200000000000003, 0.5609999999999999, 1.325, 0.45699999999999996, 1.353, 1.119, -0.53, -1.007, -0.522, 0.859, -0.5199999999999999, 0.9339999999999999, 0.45899999999999996, 0.955, 0.45299999999999996, 0.5790000000000001, 0.967, -0.547, 1.137, 1.434, -1.008, -0.511, -0.557, 0.46299999999999997, 0.45699999999999996, 0.7989999999999999, -0.503, -0.504, 0.89, 0.958, 1.319, -0.007, 1.1320000000000001, -1.028, 0.874, -1.01, 1.325, -0.047000000000000035, 1.256, -0.511, 0.51, -1.02, -0.502, -1.009, 0.46599999999999997, -0.512, 0.616, 0.623, 1.327, -0.5169999999999999, -0.514, 0.88, -1.0119999999999998, 0.8829999999999999, 0.45599999999999996, 0.896, 0.999, 0.876, -0.502, 0.471, -0.5089999999999999, 0.45499999999999996, 0.3989999999999999, 1.0539999999999998, 1.168, 1.279, -0.517, 0.45899999999999996, 1.1869999999999998, 1.1949999999999998, -0.522], "policy_blue_0_reward": [-0.511, 0.689, 0.44999999999999996, -0.532, -0.523, -0.533, 0.45099999999999996, -1.0059999999999998, 0.44599999999999995, 1.0739999999999998, 0.46499999999999997, 0.6459999999999999, 0.6579999999999999, 0.44199999999999995, 1.177, 0.865, -0.502, 0.939, 0.85, 0.44199999999999995, -1.017, 0.44499999999999995, 0.8059999999999999, 1.285, -0.529, 0.45999999999999996, 0.9009999999999999, 0.946, 0.46699999999999997, 0.45699999999999996, -0.538, -0.506, 0.46499999999999997, -1.003, -1.015, 1.024, 1.307, 0.851, -0.5349999999999999, 1.029, -0.532, 0.46299999999999997, -0.522, 0.46099999999999997, -1.01, -0.523, 0.6609999999999999, -0.513, -0.502, 1.3479999999999999, 0.727, 0.31699999999999995, 0.692, 0.44999999999999996, -1.005, 0.879, 1.2389999999999999, -1.004, -0.521, -1.004, 1.272, -0.51, 0.708, -0.504, 1.366, -0.5099999999999999, -0.04900000000000004, -1.01, 1.258, -0.518, 0.632, 1.447, 0.872, 0.45599999999999996, 0.764, -1.015, -0.539, -1.01, 1.181, 1.2730000000000001, -1.0079999999999998, 1.325, -0.53, 0.45899999999999996, -1.001, -0.519, -0.529, 0.858, 0.46499999999999997, 0.782, 0.46199999999999997, -0.517, -0.518, -0.525, -0.504, 1.216, 0.45599999999999996, -0.509, -1.018, 1.116]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3253138804619127, "mean_inference_ms": 7.30027736336522, "mean_action_processing_ms": 0.398893791371237, "mean_env_wait_ms": 0.5032530257166714, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14196574687957764, "StateBufferConnector_ms": 0.009257912635803223, "ViewRequirementAgentConnector_ms": 0.1847609281539917}}, "episode_reward_max": 1.279, "episode_reward_min": -0.43099999999999994, "episode_reward_mean": 0.4191599999999999, "episode_len_mean": 155.68, "episodes_this_iter": 24, "policy_reward_min": {"red_0": -1.028, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.434, "blue_0": 1.447}, "policy_reward_mean": {"red_0": 0.25003, "blue_0": 0.16912999999999997}, "hist_stats": {"episode_reward": [0.633, 0.17599999999999993, 0.9019999999999999, 0.31899999999999995, 0.3879999999999999, 0.18199999999999994, 0.9109999999999999, -0.24199999999999988, 0.8999999999999999, 0.05499999999999994, 0.9259999999999999, 0.10099999999999998, -0.355, 0.8979999999999999, 0.668, 0.3620000000000001, 0.40800000000000003, -0.06600000000000006, 0.31599999999999995, 0.3909999999999999, 0.06299999999999994, 0.9019999999999999, -0.20299999999999985, 1.279, 0.45100000000000007, 0.42199999999999993, 0.34799999999999986, 0.4149999999999999, 0.9299999999999999, 0.4149999999999999, 0.02299999999999991, 0.819, 0.9219999999999999, 0.3500000000000001, 0.10400000000000009, 0.494, 0.30000000000000004, 0.32899999999999996, 0.32400000000000007, 0.509, 0.4019999999999999, 0.9219999999999999, 0.43299999999999983, 0.9139999999999999, -0.43099999999999994, 0.44399999999999995, 0.11399999999999988, 0.6240000000000001, 0.9319999999999999, 0.33999999999999997, 0.21599999999999997, -0.2400000000000001, 1.1549999999999998, 0.9069999999999999, -0.20600000000000007, 0.376, 0.735, -0.11399999999999999, 0.43699999999999983, 0.31499999999999995, 1.2650000000000001, 0.6219999999999999, -0.32000000000000006, 0.3700000000000001, 0.356, 0.815, -0.09600000000000007, 0.246, 0.747, -0.008000000000000007, -0.3879999999999999, 0.945, -0.1369999999999999, 0.9219999999999999, 0.252, -0.399, 0.08400000000000007, 0.31699999999999995, 0.664, 0.759, -0.1279999999999999, 0.31300000000000006, 0.35299999999999976, 0.9149999999999999, -0.10499999999999998, 0.48, 0.347, 0.356, 0.9359999999999999, 0.27300000000000013, 0.9169999999999999, -0.1180000000000001, 0.536, 0.6429999999999998, 0.7749999999999999, 0.699, 0.9149999999999999, 0.6779999999999999, 0.17700000000000005, 0.594], "episode_lengths": [108, 99, 300, 206, 186, 251, 300, 75, 300, 135, 300, 273, 108, 300, 103, 43, 30, 20, 207, 300, 133, 300, 63, 69, 166, 300, 191, 178, 300, 300, 298, 54, 300, 47, 121, 151, 62, 207, 206, 149, 181, 300, 174, 300, 136, 170, 273, 117, 21, 48, 86, 216, 258, 300, 63, 37, 85, 35, 171, 59, 74, 115, 256, 41, 43, 55, 300, 78, 79, 157, 119, 17, 42, 300, 76, 123, 278, 56, 102, 74, 39, 57, 195, 300, 34, 158, 197, 45, 300, 70, 300, 191, 141, 106, 70, 89, 300, 100, 98, 124], "policy_red_0_reward": [1.144, -0.513, 0.45199999999999996, 0.851, 0.9109999999999999, 0.715, 0.45999999999999996, 0.764, 0.45399999999999996, -1.019, 0.46099999999999997, -0.5449999999999999, -1.013, 0.45599999999999996, -0.509, -0.5029999999999999, 0.91, -1.005, -0.534, -0.05100000000000004, 1.08, 0.45699999999999996, -1.009, -0.006, 0.98, -0.03800000000000003, -0.553, -0.531, 0.46299999999999997, -0.04200000000000003, 0.5609999999999999, 1.325, 0.45699999999999996, 1.353, 1.119, -0.53, -1.007, -0.522, 0.859, -0.5199999999999999, 0.9339999999999999, 0.45899999999999996, 0.955, 0.45299999999999996, 0.5790000000000001, 0.967, -0.547, 1.137, 1.434, -1.008, -0.511, -0.557, 0.46299999999999997, 0.45699999999999996, 0.7989999999999999, -0.503, -0.504, 0.89, 0.958, 1.319, -0.007, 1.1320000000000001, -1.028, 0.874, -1.01, 1.325, -0.047000000000000035, 1.256, -0.511, 0.51, -1.02, -0.502, -1.009, 0.46599999999999997, -0.512, 0.616, 0.623, 1.327, -0.5169999999999999, -0.514, 0.88, -1.0119999999999998, 0.8829999999999999, 0.45599999999999996, 0.896, 0.999, 0.876, -0.502, 0.471, -0.5089999999999999, 0.45499999999999996, 0.3989999999999999, 1.0539999999999998, 1.168, 1.279, -0.517, 0.45899999999999996, 1.1869999999999998, 1.1949999999999998, -0.522], "policy_blue_0_reward": [-0.511, 0.689, 0.44999999999999996, -0.532, -0.523, -0.533, 0.45099999999999996, -1.0059999999999998, 0.44599999999999995, 1.0739999999999998, 0.46499999999999997, 0.6459999999999999, 0.6579999999999999, 0.44199999999999995, 1.177, 0.865, -0.502, 0.939, 0.85, 0.44199999999999995, -1.017, 0.44499999999999995, 0.8059999999999999, 1.285, -0.529, 0.45999999999999996, 0.9009999999999999, 0.946, 0.46699999999999997, 0.45699999999999996, -0.538, -0.506, 0.46499999999999997, -1.003, -1.015, 1.024, 1.307, 0.851, -0.5349999999999999, 1.029, -0.532, 0.46299999999999997, -0.522, 0.46099999999999997, -1.01, -0.523, 0.6609999999999999, -0.513, -0.502, 1.3479999999999999, 0.727, 0.31699999999999995, 0.692, 0.44999999999999996, -1.005, 0.879, 1.2389999999999999, -1.004, -0.521, -1.004, 1.272, -0.51, 0.708, -0.504, 1.366, -0.5099999999999999, -0.04900000000000004, -1.01, 1.258, -0.518, 0.632, 1.447, 0.872, 0.45599999999999996, 0.764, -1.015, -0.539, -1.01, 1.181, 1.2730000000000001, -1.0079999999999998, 1.325, -0.53, 0.45899999999999996, -1.001, -0.519, -0.529, 0.858, 0.46499999999999997, 0.782, 0.46199999999999997, -0.517, -0.518, -0.525, -0.504, 1.216, 0.45599999999999996, -0.509, -1.018, 1.116]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3253138804619127, "mean_inference_ms": 7.30027736336522, "mean_action_processing_ms": 0.398893791371237, "mean_env_wait_ms": 0.5032530257166714, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14196574687957764, "StateBufferConnector_ms": 0.009257912635803223, "ViewRequirementAgentConnector_ms": 0.1847609281539917}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.7258326491102, "num_env_steps_trained_throughput_per_sec": 127.7258326491102, "timesteps_total": 52000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 104000, "timers": {"training_iteration_time_ms": 29886.427, "sample_time_ms": 3867.611, "learn_time_ms": 25991.723, "learn_throughput": 153.895, "synch_weights_time_ms": 25.499}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000}, "done": false, "episodes_total": 291, "training_iteration": 13, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-03-10", "timestamp": 1694836990, "time_this_iter_s": 31.333882093429565, "time_total_s": 380.18411135673523, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80eba950>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 380.18411135673523, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 26.541304347826085, "ram_util_percent": 56.84347826086955}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.49, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.33, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.49, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.33, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.49, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.33, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4713423473915706, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.0673064053383617, "policy_loss": -0.09297257740909118, "vf_loss": 0.008734079787245719, "vf_explained_var": 0.6233325795580943, "kl": 0.015195303795500574, "entropy": 1.7787342006961504, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5003757862374186, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07772404875189144, "policy_loss": -0.10646225415791075, "vf_loss": 0.012107682649608856, "vf_explained_var": 0.6187504135072232, "kl": 0.016109157564872616, "entropy": 1.7814183274904887, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "sampler_results": {"episode_reward_max": 1.2650000000000001, "episode_reward_min": -0.43800000000000006, "episode_reward_mean": 0.3919499999999999, "episode_len_mean": 147.15, "episode_media": {}, "episodes_this_iter": 30, "policy_reward_min": {"red_0": -1.028, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.434, "blue_0": 1.447}, "policy_reward_mean": {"red_0": 0.3091299999999999, "blue_0": 0.08282000000000002}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.49, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.33, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.49, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.33, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.49, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.33, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.02299999999999991, 0.819, 0.9219999999999999, 0.3500000000000001, 0.10400000000000009, 0.494, 0.30000000000000004, 0.32899999999999996, 0.32400000000000007, 0.509, 0.4019999999999999, 0.9219999999999999, 0.43299999999999983, 0.9139999999999999, -0.43099999999999994, 0.44399999999999995, 0.11399999999999988, 0.6240000000000001, 0.9319999999999999, 0.33999999999999997, 0.21599999999999997, -0.2400000000000001, 1.1549999999999998, 0.9069999999999999, -0.20600000000000007, 0.376, 0.735, -0.11399999999999999, 0.43699999999999983, 0.31499999999999995, 1.2650000000000001, 0.6219999999999999, -0.32000000000000006, 0.3700000000000001, 0.356, 0.815, -0.09600000000000007, 0.246, 0.747, -0.008000000000000007, -0.3879999999999999, 0.945, -0.1369999999999999, 0.9219999999999999, 0.252, -0.399, 0.08400000000000007, 0.31699999999999995, 0.664, 0.759, -0.1279999999999999, 0.31300000000000006, 0.35299999999999976, 0.9149999999999999, -0.10499999999999998, 0.48, 0.347, 0.356, 0.9359999999999999, 0.27300000000000013, 0.9169999999999999, -0.1180000000000001, 0.536, 0.6429999999999998, 0.7749999999999999, 0.699, 0.9149999999999999, 0.6779999999999999, 0.17700000000000005, 0.594, 0.08099999999999996, 0.9249999999999999, -0.124, 0.9009999999999999, 0.252, 0.9219999999999999, 0.7429999999999999, -0.32499999999999996, -0.20199999999999996, 0.9249999999999999, 0.691, 0.911, 0.472, 0.0129999999999999, 0.29400000000000004, 0.2469999999999999, 0.08899999999999997, -0.15700000000000003, 0.19599999999999995, 0.598, 0.23099999999999998, 0.4969999999999999, -0.43800000000000006, 0.028999999999999915, 0.9149999999999999, -0.07599999999999985, 0.9109999999999999, -0.09799999999999998, 0.34999999999999987, 0.4009999999999998], "episode_lengths": [298, 54, 300, 47, 121, 151, 62, 207, 206, 149, 181, 300, 174, 300, 136, 170, 273, 117, 21, 48, 86, 216, 258, 300, 63, 37, 85, 35, 171, 59, 74, 115, 256, 41, 43, 55, 300, 78, 79, 157, 119, 17, 42, 300, 76, 123, 278, 56, 102, 74, 39, 57, 195, 300, 34, 158, 197, 45, 300, 70, 300, 191, 141, 106, 70, 89, 300, 100, 98, 124, 279, 300, 36, 300, 77, 300, 80, 101, 59, 300, 94, 28, 166, 147, 64, 78, 125, 49, 244, 124, 77, 152, 283, 294, 300, 23, 300, 31, 204, 176], "policy_red_0_reward": [0.5609999999999999, 1.325, 0.45699999999999996, 1.353, 1.119, -0.53, -1.007, -0.522, 0.859, -0.5199999999999999, 0.9339999999999999, 0.45899999999999996, 0.955, 0.45299999999999996, 0.5790000000000001, 0.967, -0.547, 1.137, 1.434, -1.008, -0.511, -0.557, 0.46299999999999997, 0.45699999999999996, 0.7989999999999999, -0.503, -0.504, 0.89, 0.958, 1.319, -0.007, 1.1320000000000001, -1.028, 0.874, -1.01, 1.325, -0.047000000000000035, 1.256, -0.511, 0.51, -1.02, -0.502, -1.009, 0.46599999999999997, -0.512, 0.616, 0.623, 1.327, -0.5169999999999999, -0.514, 0.88, -1.0119999999999998, 0.8829999999999999, 0.45599999999999996, 0.896, 0.999, 0.876, -0.502, 0.471, -0.5089999999999999, 0.45499999999999996, 0.3989999999999999, 1.0539999999999998, 1.168, 1.279, -0.517, 0.45899999999999996, 1.1869999999999998, 1.1949999999999998, -0.522, 0.6199999999999999, 0.46299999999999997, 0.879, 0.44999999999999996, -0.509, 0.46399999999999997, 1.252, 0.682, -1.011, 0.46299999999999997, -0.514, 1.4140000000000001, -0.513, 0.5289999999999999, -1.007, 0.755, 1.104, 0.849, -0.54, -0.518, -1.025, 1.02, 0.10599999999999987, 0.572, 0.46499999999999997, -1.004, 0.44999999999999996, 0.904, 0.8679999999999999, 0.9289999999999999], "policy_blue_0_reward": [-0.538, -0.506, 0.46499999999999997, -1.003, -1.015, 1.024, 1.307, 0.851, -0.5349999999999999, 1.029, -0.532, 0.46299999999999997, -0.522, 0.46099999999999997, -1.01, -0.523, 0.6609999999999999, -0.513, -0.502, 1.3479999999999999, 0.727, 0.31699999999999995, 0.692, 0.44999999999999996, -1.005, 0.879, 1.2389999999999999, -1.004, -0.521, -1.004, 1.272, -0.51, 0.708, -0.504, 1.366, -0.5099999999999999, -0.04900000000000004, -1.01, 1.258, -0.518, 0.632, 1.447, 0.872, 0.45599999999999996, 0.764, -1.015, -0.539, -1.01, 1.181, 1.2730000000000001, -1.0079999999999998, 1.325, -0.53, 0.45899999999999996, -1.001, -0.519, -0.529, 0.858, 0.46499999999999997, 0.782, 0.46199999999999997, -0.517, -0.518, -0.525, -0.504, 1.216, 0.45599999999999996, -0.509, -1.018, 1.116, -0.539, 0.46199999999999997, -1.003, 0.45099999999999996, 0.761, 0.45799999999999996, -0.509, -1.007, 0.8089999999999999, 0.46199999999999997, 1.205, -0.503, 0.985, -0.5159999999999999, 1.3010000000000002, -0.508, -1.015, -1.006, 0.736, 1.116, 1.256, -0.523, -0.5439999999999999, -0.543, 0.44999999999999996, 0.928, 0.46099999999999997, -1.002, -0.518, -0.528]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3317491272268003, "mean_inference_ms": 7.323372131341986, "mean_action_processing_ms": 0.39818733506155085, "mean_env_wait_ms": 0.5042720415639617, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14435172080993652, "StateBufferConnector_ms": 0.00979304313659668, "ViewRequirementAgentConnector_ms": 0.18864989280700684}}, "episode_reward_max": 1.2650000000000001, "episode_reward_min": -0.43800000000000006, "episode_reward_mean": 0.3919499999999999, "episode_len_mean": 147.15, "episodes_this_iter": 30, "policy_reward_min": {"red_0": -1.028, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.434, "blue_0": 1.447}, "policy_reward_mean": {"red_0": 0.3091299999999999, "blue_0": 0.08282000000000002}, "hist_stats": {"episode_reward": [0.02299999999999991, 0.819, 0.9219999999999999, 0.3500000000000001, 0.10400000000000009, 0.494, 0.30000000000000004, 0.32899999999999996, 0.32400000000000007, 0.509, 0.4019999999999999, 0.9219999999999999, 0.43299999999999983, 0.9139999999999999, -0.43099999999999994, 0.44399999999999995, 0.11399999999999988, 0.6240000000000001, 0.9319999999999999, 0.33999999999999997, 0.21599999999999997, -0.2400000000000001, 1.1549999999999998, 0.9069999999999999, -0.20600000000000007, 0.376, 0.735, -0.11399999999999999, 0.43699999999999983, 0.31499999999999995, 1.2650000000000001, 0.6219999999999999, -0.32000000000000006, 0.3700000000000001, 0.356, 0.815, -0.09600000000000007, 0.246, 0.747, -0.008000000000000007, -0.3879999999999999, 0.945, -0.1369999999999999, 0.9219999999999999, 0.252, -0.399, 0.08400000000000007, 0.31699999999999995, 0.664, 0.759, -0.1279999999999999, 0.31300000000000006, 0.35299999999999976, 0.9149999999999999, -0.10499999999999998, 0.48, 0.347, 0.356, 0.9359999999999999, 0.27300000000000013, 0.9169999999999999, -0.1180000000000001, 0.536, 0.6429999999999998, 0.7749999999999999, 0.699, 0.9149999999999999, 0.6779999999999999, 0.17700000000000005, 0.594, 0.08099999999999996, 0.9249999999999999, -0.124, 0.9009999999999999, 0.252, 0.9219999999999999, 0.7429999999999999, -0.32499999999999996, -0.20199999999999996, 0.9249999999999999, 0.691, 0.911, 0.472, 0.0129999999999999, 0.29400000000000004, 0.2469999999999999, 0.08899999999999997, -0.15700000000000003, 0.19599999999999995, 0.598, 0.23099999999999998, 0.4969999999999999, -0.43800000000000006, 0.028999999999999915, 0.9149999999999999, -0.07599999999999985, 0.9109999999999999, -0.09799999999999998, 0.34999999999999987, 0.4009999999999998], "episode_lengths": [298, 54, 300, 47, 121, 151, 62, 207, 206, 149, 181, 300, 174, 300, 136, 170, 273, 117, 21, 48, 86, 216, 258, 300, 63, 37, 85, 35, 171, 59, 74, 115, 256, 41, 43, 55, 300, 78, 79, 157, 119, 17, 42, 300, 76, 123, 278, 56, 102, 74, 39, 57, 195, 300, 34, 158, 197, 45, 300, 70, 300, 191, 141, 106, 70, 89, 300, 100, 98, 124, 279, 300, 36, 300, 77, 300, 80, 101, 59, 300, 94, 28, 166, 147, 64, 78, 125, 49, 244, 124, 77, 152, 283, 294, 300, 23, 300, 31, 204, 176], "policy_red_0_reward": [0.5609999999999999, 1.325, 0.45699999999999996, 1.353, 1.119, -0.53, -1.007, -0.522, 0.859, -0.5199999999999999, 0.9339999999999999, 0.45899999999999996, 0.955, 0.45299999999999996, 0.5790000000000001, 0.967, -0.547, 1.137, 1.434, -1.008, -0.511, -0.557, 0.46299999999999997, 0.45699999999999996, 0.7989999999999999, -0.503, -0.504, 0.89, 0.958, 1.319, -0.007, 1.1320000000000001, -1.028, 0.874, -1.01, 1.325, -0.047000000000000035, 1.256, -0.511, 0.51, -1.02, -0.502, -1.009, 0.46599999999999997, -0.512, 0.616, 0.623, 1.327, -0.5169999999999999, -0.514, 0.88, -1.0119999999999998, 0.8829999999999999, 0.45599999999999996, 0.896, 0.999, 0.876, -0.502, 0.471, -0.5089999999999999, 0.45499999999999996, 0.3989999999999999, 1.0539999999999998, 1.168, 1.279, -0.517, 0.45899999999999996, 1.1869999999999998, 1.1949999999999998, -0.522, 0.6199999999999999, 0.46299999999999997, 0.879, 0.44999999999999996, -0.509, 0.46399999999999997, 1.252, 0.682, -1.011, 0.46299999999999997, -0.514, 1.4140000000000001, -0.513, 0.5289999999999999, -1.007, 0.755, 1.104, 0.849, -0.54, -0.518, -1.025, 1.02, 0.10599999999999987, 0.572, 0.46499999999999997, -1.004, 0.44999999999999996, 0.904, 0.8679999999999999, 0.9289999999999999], "policy_blue_0_reward": [-0.538, -0.506, 0.46499999999999997, -1.003, -1.015, 1.024, 1.307, 0.851, -0.5349999999999999, 1.029, -0.532, 0.46299999999999997, -0.522, 0.46099999999999997, -1.01, -0.523, 0.6609999999999999, -0.513, -0.502, 1.3479999999999999, 0.727, 0.31699999999999995, 0.692, 0.44999999999999996, -1.005, 0.879, 1.2389999999999999, -1.004, -0.521, -1.004, 1.272, -0.51, 0.708, -0.504, 1.366, -0.5099999999999999, -0.04900000000000004, -1.01, 1.258, -0.518, 0.632, 1.447, 0.872, 0.45599999999999996, 0.764, -1.015, -0.539, -1.01, 1.181, 1.2730000000000001, -1.0079999999999998, 1.325, -0.53, 0.45899999999999996, -1.001, -0.519, -0.529, 0.858, 0.46499999999999997, 0.782, 0.46199999999999997, -0.517, -0.518, -0.525, -0.504, 1.216, 0.45599999999999996, -0.509, -1.018, 1.116, -0.539, 0.46199999999999997, -1.003, 0.45099999999999996, 0.761, 0.45799999999999996, -0.509, -1.007, 0.8089999999999999, 0.46199999999999997, 1.205, -0.503, 0.985, -0.5159999999999999, 1.3010000000000002, -0.508, -1.015, -1.006, 0.736, 1.116, 1.256, -0.523, -0.5439999999999999, -0.543, 0.44999999999999996, 0.928, 0.46099999999999997, -1.002, -0.518, -0.528]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3317491272268003, "mean_inference_ms": 7.323372131341986, "mean_action_processing_ms": 0.39818733506155085, "mean_env_wait_ms": 0.5042720415639617, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14435172080993652, "StateBufferConnector_ms": 0.00979304313659668, "ViewRequirementAgentConnector_ms": 0.18864989280700684}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 124.82358395969818, "num_env_steps_trained_throughput_per_sec": 124.82358395969818, "timesteps_total": 56000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 30213.829, "sample_time_ms": 3895.586, "learn_time_ms": 26290.639, "learn_throughput": 152.145, "synch_weights_time_ms": 25.964}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "episodes_total": 321, "training_iteration": 14, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-03-43", "timestamp": 1694837023, "time_this_iter_s": 32.06250476837158, "time_total_s": 412.2466161251068, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7234ba30>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 412.2466161251068, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 29.497872340425523, "ram_util_percent": 56.748936170212765}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.46, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.33, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.46, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.33, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.46, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.33, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5004057290498167, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07465149045892758, "policy_loss": -0.10315730609703072, "vf_loss": 0.009812246482518579, "vf_explained_var": 0.4695431734124819, "kl": 0.016711671901903147, "entropy": 1.7811582386493683, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 13920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5090468917352458, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08401809816423338, "policy_loss": -0.11169018831036132, "vf_loss": 0.009983136585651664, "vf_explained_var": 0.5174372380599379, "kl": 0.01610773622158968, "entropy": 1.7831015850106875, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 13920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "sampler_results": {"episode_reward_max": 1.589, "episode_reward_min": -0.48, "episode_reward_mean": 0.38476, "episode_len_mean": 143.97, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"red_0": -1.036, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.4140000000000001, "blue_0": 1.447}, "policy_reward_mean": {"red_0": 0.26859, "blue_0": 0.11617000000000005}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.46, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.33, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.46, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.33, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.46, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.33, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9069999999999999, -0.20600000000000007, 0.376, 0.735, -0.11399999999999999, 0.43699999999999983, 0.31499999999999995, 1.2650000000000001, 0.6219999999999999, -0.32000000000000006, 0.3700000000000001, 0.356, 0.815, -0.09600000000000007, 0.246, 0.747, -0.008000000000000007, -0.3879999999999999, 0.945, -0.1369999999999999, 0.9219999999999999, 0.252, -0.399, 0.08400000000000007, 0.31699999999999995, 0.664, 0.759, -0.1279999999999999, 0.31300000000000006, 0.35299999999999976, 0.9149999999999999, -0.10499999999999998, 0.48, 0.347, 0.356, 0.9359999999999999, 0.27300000000000013, 0.9169999999999999, -0.1180000000000001, 0.536, 0.6429999999999998, 0.7749999999999999, 0.699, 0.9149999999999999, 0.6779999999999999, 0.17700000000000005, 0.594, 0.08099999999999996, 0.9249999999999999, -0.124, 0.9009999999999999, 0.252, 0.9219999999999999, 0.7429999999999999, -0.32499999999999996, -0.20199999999999996, 0.9249999999999999, 0.691, 0.911, 0.472, 0.0129999999999999, 0.29400000000000004, 0.2469999999999999, 0.08899999999999997, -0.15700000000000003, 0.19599999999999995, 0.598, 0.23099999999999998, 0.4969999999999999, -0.43800000000000006, 0.028999999999999915, 0.9149999999999999, -0.07599999999999985, 0.9109999999999999, -0.09799999999999998, 0.34999999999999987, 0.4009999999999998, 0.244, 0.3910000000000001, -0.3440000000000001, -0.1050000000000001, -0.062000000000000055, 0.817, -0.48, 0.9239999999999999, 0.9269999999999999, -0.2390000000000001, 1.589, 0.702, 0.42099999999999993, 0.5880000000000001, 0.2589999999999999, 0.9219999999999999, 0.14200000000000002, 0.9239999999999999, 0.6210000000000001, 0.9289999999999999, 0.39400000000000013, -0.04400000000000004, -0.24], "episode_lengths": [300, 63, 37, 85, 35, 171, 59, 74, 115, 256, 41, 43, 55, 300, 78, 79, 157, 119, 17, 42, 300, 76, 123, 278, 56, 102, 74, 39, 57, 195, 300, 34, 158, 197, 45, 300, 70, 300, 191, 141, 106, 70, 89, 300, 100, 98, 124, 279, 300, 36, 300, 77, 300, 80, 101, 59, 300, 94, 28, 166, 147, 64, 78, 125, 49, 244, 124, 77, 152, 283, 294, 300, 23, 300, 31, 204, 176, 233, 33, 104, 180, 173, 57, 143, 300, 300, 73, 125, 89, 300, 127, 73, 300, 111, 300, 116, 300, 32, 14, 74], "policy_red_0_reward": [0.45699999999999996, 0.7989999999999999, -0.503, -0.504, 0.89, 0.958, 1.319, -0.007, 1.1320000000000001, -1.028, 0.874, -1.01, 1.325, -0.047000000000000035, 1.256, -0.511, 0.51, -1.02, -0.502, -1.009, 0.46599999999999997, -0.512, 0.616, 0.623, 1.327, -0.5169999999999999, -0.514, 0.88, -1.0119999999999998, 0.8829999999999999, 0.45599999999999996, 0.896, 0.999, 0.876, -0.502, 0.471, -0.5089999999999999, 0.45499999999999996, 0.3989999999999999, 1.0539999999999998, 1.168, 1.279, -0.517, 0.45899999999999996, 1.1869999999999998, 1.1949999999999998, -0.522, 0.6199999999999999, 0.46299999999999997, 0.879, 0.44999999999999996, -0.509, 0.46399999999999997, 1.252, 0.682, -1.011, 0.46299999999999997, -0.514, 1.4140000000000001, -0.513, 0.5289999999999999, -1.007, 0.755, 1.104, 0.849, -0.54, -0.518, -1.025, 1.02, 0.10599999999999987, 0.572, 0.46499999999999997, -1.004, 0.44999999999999996, 0.904, 0.8679999999999999, 0.9289999999999999, 0.77, -0.5049999999999999, 0.6689999999999999, -1.028, 0.46299999999999997, -0.505, -1.036, 0.45999999999999996, 0.476, -1.01, 0.484, 1.217, -0.03300000000000002, 1.101, 1.267, 0.45499999999999996, -0.519, 0.46199999999999997, -0.5129999999999999, 0.45899999999999996, 0.901, -1.001, 0.765], "policy_blue_0_reward": [0.44999999999999996, -1.005, 0.879, 1.2389999999999999, -1.004, -0.521, -1.004, 1.272, -0.51, 0.708, -0.504, 1.366, -0.5099999999999999, -0.04900000000000004, -1.01, 1.258, -0.518, 0.632, 1.447, 0.872, 0.45599999999999996, 0.764, -1.015, -0.539, -1.01, 1.181, 1.2730000000000001, -1.0079999999999998, 1.325, -0.53, 0.45899999999999996, -1.001, -0.519, -0.529, 0.858, 0.46499999999999997, 0.782, 0.46199999999999997, -0.517, -0.518, -0.525, -0.504, 1.216, 0.45599999999999996, -0.509, -1.018, 1.116, -0.539, 0.46199999999999997, -1.003, 0.45099999999999996, 0.761, 0.45799999999999996, -0.509, -1.007, 0.8089999999999999, 0.46199999999999997, 1.205, -0.503, 0.985, -0.5159999999999999, 1.3010000000000002, -0.508, -1.015, -1.006, 0.736, 1.116, 1.256, -0.523, -0.5439999999999999, -0.543, 0.44999999999999996, 0.928, 0.46099999999999997, -1.002, -0.518, -0.528, -0.526, 0.896, -1.013, 0.9229999999999999, -0.525, 1.322, 0.5559999999999999, 0.46399999999999997, 0.45099999999999996, 0.7709999999999999, 1.105, -0.515, 0.45399999999999996, -0.513, -1.008, 0.46699999999999997, 0.661, 0.46199999999999997, 1.134, 0.47, -0.507, 0.957, -1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3353259032509492, "mean_inference_ms": 7.341711366553711, "mean_action_processing_ms": 0.3984474028957186, "mean_env_wait_ms": 0.5058495134624414, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14758992195129395, "StateBufferConnector_ms": 0.00982511043548584, "ViewRequirementAgentConnector_ms": 0.19031691551208496}}, "episode_reward_max": 1.589, "episode_reward_min": -0.48, "episode_reward_mean": 0.38476, "episode_len_mean": 143.97, "episodes_this_iter": 23, "policy_reward_min": {"red_0": -1.036, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.4140000000000001, "blue_0": 1.447}, "policy_reward_mean": {"red_0": 0.26859, "blue_0": 0.11617000000000005}, "hist_stats": {"episode_reward": [0.9069999999999999, -0.20600000000000007, 0.376, 0.735, -0.11399999999999999, 0.43699999999999983, 0.31499999999999995, 1.2650000000000001, 0.6219999999999999, -0.32000000000000006, 0.3700000000000001, 0.356, 0.815, -0.09600000000000007, 0.246, 0.747, -0.008000000000000007, -0.3879999999999999, 0.945, -0.1369999999999999, 0.9219999999999999, 0.252, -0.399, 0.08400000000000007, 0.31699999999999995, 0.664, 0.759, -0.1279999999999999, 0.31300000000000006, 0.35299999999999976, 0.9149999999999999, -0.10499999999999998, 0.48, 0.347, 0.356, 0.9359999999999999, 0.27300000000000013, 0.9169999999999999, -0.1180000000000001, 0.536, 0.6429999999999998, 0.7749999999999999, 0.699, 0.9149999999999999, 0.6779999999999999, 0.17700000000000005, 0.594, 0.08099999999999996, 0.9249999999999999, -0.124, 0.9009999999999999, 0.252, 0.9219999999999999, 0.7429999999999999, -0.32499999999999996, -0.20199999999999996, 0.9249999999999999, 0.691, 0.911, 0.472, 0.0129999999999999, 0.29400000000000004, 0.2469999999999999, 0.08899999999999997, -0.15700000000000003, 0.19599999999999995, 0.598, 0.23099999999999998, 0.4969999999999999, -0.43800000000000006, 0.028999999999999915, 0.9149999999999999, -0.07599999999999985, 0.9109999999999999, -0.09799999999999998, 0.34999999999999987, 0.4009999999999998, 0.244, 0.3910000000000001, -0.3440000000000001, -0.1050000000000001, -0.062000000000000055, 0.817, -0.48, 0.9239999999999999, 0.9269999999999999, -0.2390000000000001, 1.589, 0.702, 0.42099999999999993, 0.5880000000000001, 0.2589999999999999, 0.9219999999999999, 0.14200000000000002, 0.9239999999999999, 0.6210000000000001, 0.9289999999999999, 0.39400000000000013, -0.04400000000000004, -0.24], "episode_lengths": [300, 63, 37, 85, 35, 171, 59, 74, 115, 256, 41, 43, 55, 300, 78, 79, 157, 119, 17, 42, 300, 76, 123, 278, 56, 102, 74, 39, 57, 195, 300, 34, 158, 197, 45, 300, 70, 300, 191, 141, 106, 70, 89, 300, 100, 98, 124, 279, 300, 36, 300, 77, 300, 80, 101, 59, 300, 94, 28, 166, 147, 64, 78, 125, 49, 244, 124, 77, 152, 283, 294, 300, 23, 300, 31, 204, 176, 233, 33, 104, 180, 173, 57, 143, 300, 300, 73, 125, 89, 300, 127, 73, 300, 111, 300, 116, 300, 32, 14, 74], "policy_red_0_reward": [0.45699999999999996, 0.7989999999999999, -0.503, -0.504, 0.89, 0.958, 1.319, -0.007, 1.1320000000000001, -1.028, 0.874, -1.01, 1.325, -0.047000000000000035, 1.256, -0.511, 0.51, -1.02, -0.502, -1.009, 0.46599999999999997, -0.512, 0.616, 0.623, 1.327, -0.5169999999999999, -0.514, 0.88, -1.0119999999999998, 0.8829999999999999, 0.45599999999999996, 0.896, 0.999, 0.876, -0.502, 0.471, -0.5089999999999999, 0.45499999999999996, 0.3989999999999999, 1.0539999999999998, 1.168, 1.279, -0.517, 0.45899999999999996, 1.1869999999999998, 1.1949999999999998, -0.522, 0.6199999999999999, 0.46299999999999997, 0.879, 0.44999999999999996, -0.509, 0.46399999999999997, 1.252, 0.682, -1.011, 0.46299999999999997, -0.514, 1.4140000000000001, -0.513, 0.5289999999999999, -1.007, 0.755, 1.104, 0.849, -0.54, -0.518, -1.025, 1.02, 0.10599999999999987, 0.572, 0.46499999999999997, -1.004, 0.44999999999999996, 0.904, 0.8679999999999999, 0.9289999999999999, 0.77, -0.5049999999999999, 0.6689999999999999, -1.028, 0.46299999999999997, -0.505, -1.036, 0.45999999999999996, 0.476, -1.01, 0.484, 1.217, -0.03300000000000002, 1.101, 1.267, 0.45499999999999996, -0.519, 0.46199999999999997, -0.5129999999999999, 0.45899999999999996, 0.901, -1.001, 0.765], "policy_blue_0_reward": [0.44999999999999996, -1.005, 0.879, 1.2389999999999999, -1.004, -0.521, -1.004, 1.272, -0.51, 0.708, -0.504, 1.366, -0.5099999999999999, -0.04900000000000004, -1.01, 1.258, -0.518, 0.632, 1.447, 0.872, 0.45599999999999996, 0.764, -1.015, -0.539, -1.01, 1.181, 1.2730000000000001, -1.0079999999999998, 1.325, -0.53, 0.45899999999999996, -1.001, -0.519, -0.529, 0.858, 0.46499999999999997, 0.782, 0.46199999999999997, -0.517, -0.518, -0.525, -0.504, 1.216, 0.45599999999999996, -0.509, -1.018, 1.116, -0.539, 0.46199999999999997, -1.003, 0.45099999999999996, 0.761, 0.45799999999999996, -0.509, -1.007, 0.8089999999999999, 0.46199999999999997, 1.205, -0.503, 0.985, -0.5159999999999999, 1.3010000000000002, -0.508, -1.015, -1.006, 0.736, 1.116, 1.256, -0.523, -0.5439999999999999, -0.543, 0.44999999999999996, 0.928, 0.46099999999999997, -1.002, -0.518, -0.528, -0.526, 0.896, -1.013, 0.9229999999999999, -0.525, 1.322, 0.5559999999999999, 0.46399999999999997, 0.45099999999999996, 0.7709999999999999, 1.105, -0.515, 0.45399999999999996, -0.513, -1.008, 0.46699999999999997, 0.661, 0.46199999999999997, 1.134, 0.47, -0.507, 0.957, -1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3353259032509492, "mean_inference_ms": 7.341711366553711, "mean_action_processing_ms": 0.3984474028957186, "mean_env_wait_ms": 0.5058495134624414, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14758992195129395, "StateBufferConnector_ms": 0.00982511043548584, "ViewRequirementAgentConnector_ms": 0.19031691551208496}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.54995026893215, "num_env_steps_trained_throughput_per_sec": 127.54995026893215, "timesteps_total": 60000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 120000, "timers": {"training_iteration_time_ms": 30476.078, "sample_time_ms": 3922.815, "learn_time_ms": 26525.53, "learn_throughput": 150.798, "synch_weights_time_ms": 26.123}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "done": false, "episodes_total": 344, "training_iteration": 15, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-04-15", "timestamp": 1694837055, "time_this_iter_s": 31.377185106277466, "time_total_s": 443.6238012313843, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80eba4d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 443.6238012313843, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 27.122222222222224, "ram_util_percent": 56.81111111111108}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.49, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.27, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.49, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.27, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.49, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.27, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49510380569845436, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07033229645943113, "policy_loss": -0.09507181290488613, "vf_loss": 0.008139702146339307, "vf_explained_var": 0.5849247358118494, "kl": 0.014781177763220453, "entropy": 1.7792478957523903, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 14880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5150802159681916, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07873784270135123, "policy_loss": -0.10663459334828077, "vf_loss": 0.011385237042607818, "vf_explained_var": 0.585019180054466, "kl": 0.015800269530685238, "entropy": 1.7925266169011593, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 14880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "sampler_results": {"episode_reward_max": 1.589, "episode_reward_min": -0.56, "episode_reward_mean": 0.4183699999999999, "episode_len_mean": 154.12, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"red_0": -1.036, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.4140000000000001, "blue_0": 1.325}, "policy_reward_mean": {"red_0": 0.35891, "blue_0": 0.059460000000000006}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.49, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.27, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.49, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.27, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.49, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.27, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.1279999999999999, 0.31300000000000006, 0.35299999999999976, 0.9149999999999999, -0.10499999999999998, 0.48, 0.347, 0.356, 0.9359999999999999, 0.27300000000000013, 0.9169999999999999, -0.1180000000000001, 0.536, 0.6429999999999998, 0.7749999999999999, 0.699, 0.9149999999999999, 0.6779999999999999, 0.17700000000000005, 0.594, 0.08099999999999996, 0.9249999999999999, -0.124, 0.9009999999999999, 0.252, 0.9219999999999999, 0.7429999999999999, -0.32499999999999996, -0.20199999999999996, 0.9249999999999999, 0.691, 0.911, 0.472, 0.0129999999999999, 0.29400000000000004, 0.2469999999999999, 0.08899999999999997, -0.15700000000000003, 0.19599999999999995, 0.598, 0.23099999999999998, 0.4969999999999999, -0.43800000000000006, 0.028999999999999915, 0.9149999999999999, -0.07599999999999985, 0.9109999999999999, -0.09799999999999998, 0.34999999999999987, 0.4009999999999998, 0.244, 0.3910000000000001, -0.3440000000000001, -0.1050000000000001, -0.062000000000000055, 0.817, -0.48, 0.9239999999999999, 0.9269999999999999, -0.2390000000000001, 1.589, 0.702, 0.42099999999999993, 0.5880000000000001, 0.2589999999999999, 0.9219999999999999, 0.14200000000000002, 0.9239999999999999, 0.6210000000000001, 0.9289999999999999, 0.39400000000000013, -0.04400000000000004, -0.24, 0.28100000000000014, 0.8319999999999999, 0.2709999999999999, 0.32299999999999995, 0.8959999999999999, 0.6419999999999999, 1.505, 0.865, 0.42099999999999993, 0.45599999999999996, 0.44199999999999995, 0.7430000000000001, 0.5189999999999999, 0.22100000000000009, 0.038000000000000034, -0.14700000000000002, 0.2499999999999999, 0.9049999999999999, 0.9339999999999999, -1.1102230246251565e-16, 0.8069999999999999, 0.9269999999999999, 0.31200000000000006, 0.09299999999999997, 0.9179999999999999, -0.06700000000000006, -0.56], "episode_lengths": [39, 57, 195, 300, 34, 158, 197, 45, 300, 70, 300, 191, 141, 106, 70, 89, 300, 100, 98, 124, 279, 300, 36, 300, 77, 300, 80, 101, 59, 300, 94, 28, 166, 147, 64, 78, 125, 49, 244, 124, 77, 152, 283, 294, 300, 23, 300, 31, 204, 176, 233, 33, 104, 180, 173, 57, 143, 300, 300, 73, 125, 89, 300, 127, 73, 300, 111, 300, 116, 300, 32, 14, 74, 64, 54, 69, 54, 300, 109, 150, 42, 300, 168, 172, 79, 147, 88, 141, 47, 227, 300, 300, 153, 61, 300, 208, 125, 300, 21, 171], "policy_red_0_reward": [0.88, -1.0119999999999998, 0.8829999999999999, 0.45599999999999996, 0.896, 0.999, 0.876, -0.502, 0.471, -0.5089999999999999, 0.45499999999999996, 0.3989999999999999, 1.0539999999999998, 1.168, 1.279, -0.517, 0.45899999999999996, 1.1869999999999998, 1.1949999999999998, -0.522, 0.6199999999999999, 0.46299999999999997, 0.879, 0.44999999999999996, -0.509, 0.46399999999999997, 1.252, 0.682, -1.011, 0.46299999999999997, -0.514, 1.4140000000000001, -0.513, 0.5289999999999999, -1.007, 0.755, 1.104, 0.849, -0.54, -0.518, -1.025, 1.02, 0.10599999999999987, 0.572, 0.46499999999999997, -1.004, 0.44999999999999996, 0.904, 0.8679999999999999, 0.9289999999999999, 0.77, -0.5049999999999999, 0.6689999999999999, -1.028, 0.46299999999999997, -0.505, -1.036, 0.45999999999999996, 0.476, -1.01, 0.484, 1.217, -0.03300000000000002, 1.101, 1.267, 0.45499999999999996, -0.519, 0.46199999999999997, -0.5129999999999999, 0.45899999999999996, 0.901, -1.001, 0.765, -1.019, 1.3359999999999999, 0.7849999999999999, 1.329, 0.45399999999999996, 1.158, 0.483, 1.369, -0.037000000000000026, 0.9779999999999999, 0.968, -0.5099999999999999, 1.037, 1.2309999999999999, 0.5549999999999999, 0.858, -0.537, 0.45099999999999996, 0.474, 0.5189999999999999, 1.313, 0.46799999999999997, 0.845, -0.517, 0.45499999999999996, -1.002, 0.45599999999999996], "policy_blue_0_reward": [-1.0079999999999998, 1.325, -0.53, 0.45899999999999996, -1.001, -0.519, -0.529, 0.858, 0.46499999999999997, 0.782, 0.46199999999999997, -0.517, -0.518, -0.525, -0.504, 1.216, 0.45599999999999996, -0.509, -1.018, 1.116, -0.539, 0.46199999999999997, -1.003, 0.45099999999999996, 0.761, 0.45799999999999996, -0.509, -1.007, 0.8089999999999999, 0.46199999999999997, 1.205, -0.503, 0.985, -0.5159999999999999, 1.3010000000000002, -0.508, -1.015, -1.006, 0.736, 1.116, 1.256, -0.523, -0.5439999999999999, -0.543, 0.44999999999999996, 0.928, 0.46099999999999997, -1.002, -0.518, -0.528, -0.526, 0.896, -1.013, 0.9229999999999999, -0.525, 1.322, 0.5559999999999999, 0.46399999999999997, 0.45099999999999996, 0.7709999999999999, 1.105, -0.515, 0.45399999999999996, -0.513, -1.008, 0.46699999999999997, 0.661, 0.46199999999999997, 1.134, 0.47, -0.507, 0.957, -1.005, 1.3, -0.504, -0.514, -1.006, 0.44199999999999995, -0.516, 1.022, -0.504, 0.45799999999999996, -0.522, -0.526, 1.2530000000000001, -0.518, -1.01, -0.5169999999999999, -1.005, 0.7869999999999999, 0.45399999999999996, 0.45999999999999996, -0.519, -0.506, 0.45899999999999996, -0.5329999999999999, 0.61, 0.46299999999999997, 0.9349999999999999, -1.016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3383494975844987, "mean_inference_ms": 7.348917471857074, "mean_action_processing_ms": 0.3991387845673087, "mean_env_wait_ms": 0.506247156772481, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14883100986480713, "StateBufferConnector_ms": 0.009674429893493652, "ViewRequirementAgentConnector_ms": 0.18859529495239258}}, "episode_reward_max": 1.589, "episode_reward_min": -0.56, "episode_reward_mean": 0.4183699999999999, "episode_len_mean": 154.12, "episodes_this_iter": 27, "policy_reward_min": {"red_0": -1.036, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.4140000000000001, "blue_0": 1.325}, "policy_reward_mean": {"red_0": 0.35891, "blue_0": 0.059460000000000006}, "hist_stats": {"episode_reward": [-0.1279999999999999, 0.31300000000000006, 0.35299999999999976, 0.9149999999999999, -0.10499999999999998, 0.48, 0.347, 0.356, 0.9359999999999999, 0.27300000000000013, 0.9169999999999999, -0.1180000000000001, 0.536, 0.6429999999999998, 0.7749999999999999, 0.699, 0.9149999999999999, 0.6779999999999999, 0.17700000000000005, 0.594, 0.08099999999999996, 0.9249999999999999, -0.124, 0.9009999999999999, 0.252, 0.9219999999999999, 0.7429999999999999, -0.32499999999999996, -0.20199999999999996, 0.9249999999999999, 0.691, 0.911, 0.472, 0.0129999999999999, 0.29400000000000004, 0.2469999999999999, 0.08899999999999997, -0.15700000000000003, 0.19599999999999995, 0.598, 0.23099999999999998, 0.4969999999999999, -0.43800000000000006, 0.028999999999999915, 0.9149999999999999, -0.07599999999999985, 0.9109999999999999, -0.09799999999999998, 0.34999999999999987, 0.4009999999999998, 0.244, 0.3910000000000001, -0.3440000000000001, -0.1050000000000001, -0.062000000000000055, 0.817, -0.48, 0.9239999999999999, 0.9269999999999999, -0.2390000000000001, 1.589, 0.702, 0.42099999999999993, 0.5880000000000001, 0.2589999999999999, 0.9219999999999999, 0.14200000000000002, 0.9239999999999999, 0.6210000000000001, 0.9289999999999999, 0.39400000000000013, -0.04400000000000004, -0.24, 0.28100000000000014, 0.8319999999999999, 0.2709999999999999, 0.32299999999999995, 0.8959999999999999, 0.6419999999999999, 1.505, 0.865, 0.42099999999999993, 0.45599999999999996, 0.44199999999999995, 0.7430000000000001, 0.5189999999999999, 0.22100000000000009, 0.038000000000000034, -0.14700000000000002, 0.2499999999999999, 0.9049999999999999, 0.9339999999999999, -1.1102230246251565e-16, 0.8069999999999999, 0.9269999999999999, 0.31200000000000006, 0.09299999999999997, 0.9179999999999999, -0.06700000000000006, -0.56], "episode_lengths": [39, 57, 195, 300, 34, 158, 197, 45, 300, 70, 300, 191, 141, 106, 70, 89, 300, 100, 98, 124, 279, 300, 36, 300, 77, 300, 80, 101, 59, 300, 94, 28, 166, 147, 64, 78, 125, 49, 244, 124, 77, 152, 283, 294, 300, 23, 300, 31, 204, 176, 233, 33, 104, 180, 173, 57, 143, 300, 300, 73, 125, 89, 300, 127, 73, 300, 111, 300, 116, 300, 32, 14, 74, 64, 54, 69, 54, 300, 109, 150, 42, 300, 168, 172, 79, 147, 88, 141, 47, 227, 300, 300, 153, 61, 300, 208, 125, 300, 21, 171], "policy_red_0_reward": [0.88, -1.0119999999999998, 0.8829999999999999, 0.45599999999999996, 0.896, 0.999, 0.876, -0.502, 0.471, -0.5089999999999999, 0.45499999999999996, 0.3989999999999999, 1.0539999999999998, 1.168, 1.279, -0.517, 0.45899999999999996, 1.1869999999999998, 1.1949999999999998, -0.522, 0.6199999999999999, 0.46299999999999997, 0.879, 0.44999999999999996, -0.509, 0.46399999999999997, 1.252, 0.682, -1.011, 0.46299999999999997, -0.514, 1.4140000000000001, -0.513, 0.5289999999999999, -1.007, 0.755, 1.104, 0.849, -0.54, -0.518, -1.025, 1.02, 0.10599999999999987, 0.572, 0.46499999999999997, -1.004, 0.44999999999999996, 0.904, 0.8679999999999999, 0.9289999999999999, 0.77, -0.5049999999999999, 0.6689999999999999, -1.028, 0.46299999999999997, -0.505, -1.036, 0.45999999999999996, 0.476, -1.01, 0.484, 1.217, -0.03300000000000002, 1.101, 1.267, 0.45499999999999996, -0.519, 0.46199999999999997, -0.5129999999999999, 0.45899999999999996, 0.901, -1.001, 0.765, -1.019, 1.3359999999999999, 0.7849999999999999, 1.329, 0.45399999999999996, 1.158, 0.483, 1.369, -0.037000000000000026, 0.9779999999999999, 0.968, -0.5099999999999999, 1.037, 1.2309999999999999, 0.5549999999999999, 0.858, -0.537, 0.45099999999999996, 0.474, 0.5189999999999999, 1.313, 0.46799999999999997, 0.845, -0.517, 0.45499999999999996, -1.002, 0.45599999999999996], "policy_blue_0_reward": [-1.0079999999999998, 1.325, -0.53, 0.45899999999999996, -1.001, -0.519, -0.529, 0.858, 0.46499999999999997, 0.782, 0.46199999999999997, -0.517, -0.518, -0.525, -0.504, 1.216, 0.45599999999999996, -0.509, -1.018, 1.116, -0.539, 0.46199999999999997, -1.003, 0.45099999999999996, 0.761, 0.45799999999999996, -0.509, -1.007, 0.8089999999999999, 0.46199999999999997, 1.205, -0.503, 0.985, -0.5159999999999999, 1.3010000000000002, -0.508, -1.015, -1.006, 0.736, 1.116, 1.256, -0.523, -0.5439999999999999, -0.543, 0.44999999999999996, 0.928, 0.46099999999999997, -1.002, -0.518, -0.528, -0.526, 0.896, -1.013, 0.9229999999999999, -0.525, 1.322, 0.5559999999999999, 0.46399999999999997, 0.45099999999999996, 0.7709999999999999, 1.105, -0.515, 0.45399999999999996, -0.513, -1.008, 0.46699999999999997, 0.661, 0.46199999999999997, 1.134, 0.47, -0.507, 0.957, -1.005, 1.3, -0.504, -0.514, -1.006, 0.44199999999999995, -0.516, 1.022, -0.504, 0.45799999999999996, -0.522, -0.526, 1.2530000000000001, -0.518, -1.01, -0.5169999999999999, -1.005, 0.7869999999999999, 0.45399999999999996, 0.45999999999999996, -0.519, -0.506, 0.45899999999999996, -0.5329999999999999, 0.61, 0.46299999999999997, 0.9349999999999999, -1.016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3383494975844987, "mean_inference_ms": 7.348917471857074, "mean_action_processing_ms": 0.3991387845673087, "mean_env_wait_ms": 0.506247156772481, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14883100986480713, "StateBufferConnector_ms": 0.009674429893493652, "ViewRequirementAgentConnector_ms": 0.18859529495239258}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 132.87007361360313, "num_env_steps_trained_throughput_per_sec": 132.87007361360313, "timesteps_total": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 30643.507, "sample_time_ms": 3924.524, "learn_time_ms": 26690.704, "learn_throughput": 149.865, "synch_weights_time_ms": 26.677}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "episodes_total": 371, "training_iteration": 16, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-04-46", "timestamp": 1694837086, "time_this_iter_s": 30.120490074157715, "time_total_s": 473.744291305542, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7234ab90>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 473.744291305542, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 25.972727272727276, "ram_util_percent": 56.75454545454547}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.49, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.29, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.49, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.29, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.49, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.29, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4957060214132071, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.06729716249319609, "policy_loss": -0.09426145801893047, "vf_loss": 0.012371528762984477, "vf_explained_var": 0.5536632335434357, "kl": 0.01484945357355351, "entropy": 1.7740759052336217, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 15840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5344168572065731, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07785514146962669, "policy_loss": -0.10731938581593567, "vf_loss": 0.012266855205477137, "vf_explained_var": 0.5753870333855351, "kl": 0.01653497573470304, "entropy": 1.7816766052196422, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 15840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000}, "sampler_results": {"episode_reward_max": 1.589, "episode_reward_min": -0.56, "episode_reward_mean": 0.37944999999999995, "episode_len_mean": 148.13, "episode_media": {}, "episodes_this_iter": 31, "policy_reward_min": {"red_0": -1.036, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.4140000000000001, "blue_0": 1.435}, "policy_reward_mean": {"red_0": 0.31233000000000005, "blue_0": 0.06712000000000001}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.49, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.29, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.49, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.02, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.29, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.49, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.29, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.911, 0.472, 0.0129999999999999, 0.29400000000000004, 0.2469999999999999, 0.08899999999999997, -0.15700000000000003, 0.19599999999999995, 0.598, 0.23099999999999998, 0.4969999999999999, -0.43800000000000006, 0.028999999999999915, 0.9149999999999999, -0.07599999999999985, 0.9109999999999999, -0.09799999999999998, 0.34999999999999987, 0.4009999999999998, 0.244, 0.3910000000000001, -0.3440000000000001, -0.1050000000000001, -0.062000000000000055, 0.817, -0.48, 0.9239999999999999, 0.9269999999999999, -0.2390000000000001, 1.589, 0.702, 0.42099999999999993, 0.5880000000000001, 0.2589999999999999, 0.9219999999999999, 0.14200000000000002, 0.9239999999999999, 0.6210000000000001, 0.9289999999999999, 0.39400000000000013, -0.04400000000000004, -0.24, 0.28100000000000014, 0.8319999999999999, 0.2709999999999999, 0.32299999999999995, 0.8959999999999999, 0.6419999999999999, 1.505, 0.865, 0.42099999999999993, 0.45599999999999996, 0.44199999999999995, 0.7430000000000001, 0.5189999999999999, 0.22100000000000009, 0.038000000000000034, -0.14700000000000002, 0.2499999999999999, 0.9049999999999999, 0.9339999999999999, -1.1102230246251565e-16, 0.8069999999999999, 0.9269999999999999, 0.31200000000000006, 0.09299999999999997, 0.9179999999999999, -0.06700000000000006, -0.56, 0.9179999999999999, 0.18500000000000005, 0.381, 0.42799999999999994, 0.4750000000000001, 0.76, 0.4069999999999999, 0.4059999999999999, 0.31199999999999983, 0.40700000000000003, 0.2650000000000001, -0.21700000000000008, 0.43399999999999994, 0.31400000000000006, 0.42299999999999993, 0.5249999999999999, 0.42499999999999993, 0.11799999999999988, 0.554, 0.46499999999999986, 0.28800000000000003, 0.347, 0.32999999999999996, 0.43899999999999995, 0.3460000000000001, -0.28400000000000003, 0.9189999999999999, -0.2609999999999999, 0.33000000000000007, 0.10899999999999999, -0.09500000000000007], "episode_lengths": [28, 166, 147, 64, 78, 125, 49, 244, 124, 77, 152, 283, 294, 300, 23, 300, 31, 204, 176, 233, 33, 104, 180, 173, 57, 143, 300, 300, 73, 125, 89, 300, 127, 73, 300, 111, 300, 116, 300, 32, 14, 74, 64, 54, 69, 54, 300, 109, 150, 42, 300, 168, 172, 79, 147, 88, 141, 47, 227, 300, 300, 153, 61, 300, 208, 125, 300, 21, 171, 300, 244, 36, 300, 8, 72, 181, 179, 56, 28, 70, 67, 20, 57, 300, 145, 300, 265, 136, 166, 66, 48, 50, 163, 48, 88, 300, 78, 52, 118, 300], "policy_red_0_reward": [1.4140000000000001, -0.513, 0.5289999999999999, -1.007, 0.755, 1.104, 0.849, -0.54, -0.518, -1.025, 1.02, 0.10599999999999987, 0.572, 0.46499999999999997, -1.004, 0.44999999999999996, 0.904, 0.8679999999999999, 0.9289999999999999, 0.77, -0.5049999999999999, 0.6689999999999999, -1.028, 0.46299999999999997, -0.505, -1.036, 0.45999999999999996, 0.476, -1.01, 0.484, 1.217, -0.03300000000000002, 1.101, 1.267, 0.45499999999999996, -0.519, 0.46199999999999997, -0.5129999999999999, 0.45899999999999996, 0.901, -1.001, 0.765, -1.019, 1.3359999999999999, 0.7849999999999999, 1.329, 0.45399999999999996, 1.158, 0.483, 1.369, -0.037000000000000026, 0.9779999999999999, 0.968, -0.5099999999999999, 1.037, 1.2309999999999999, 0.5549999999999999, 0.858, -0.537, 0.45099999999999996, 0.474, 0.5189999999999999, 1.313, 0.46799999999999997, 0.845, -0.517, 0.45499999999999996, -1.002, 0.45599999999999996, 0.45899999999999996, 0.724, 0.888, -0.03800000000000003, 0.976, 1.2730000000000001, -0.53, -0.525, 0.82, -1.006, 0.783, 0.7909999999999999, -1.001, 1.322, 0.46599999999999997, -0.524, 0.46499999999999997, -0.548, 1.0750000000000002, 0.979, 0.797, 0.852, -1.005, -0.534, 0.85, -1.008, 0.46099999999999997, -1.0159999999999998, 1.337, 0.633, -0.04000000000000003], "policy_blue_0_reward": [-0.503, 0.985, -0.5159999999999999, 1.3010000000000002, -0.508, -1.015, -1.006, 0.736, 1.116, 1.256, -0.523, -0.5439999999999999, -0.543, 0.44999999999999996, 0.928, 0.46099999999999997, -1.002, -0.518, -0.528, -0.526, 0.896, -1.013, 0.9229999999999999, -0.525, 1.322, 0.5559999999999999, 0.46399999999999997, 0.45099999999999996, 0.7709999999999999, 1.105, -0.515, 0.45399999999999996, -0.513, -1.008, 0.46699999999999997, 0.661, 0.46199999999999997, 1.134, 0.47, -0.507, 0.957, -1.005, 1.3, -0.504, -0.514, -1.006, 0.44199999999999995, -0.516, 1.022, -0.504, 0.45799999999999996, -0.522, -0.526, 1.2530000000000001, -0.518, -1.01, -0.5169999999999999, -1.005, 0.7869999999999999, 0.45399999999999996, 0.45999999999999996, -0.519, -0.506, 0.45899999999999996, -0.5329999999999999, 0.61, 0.46299999999999997, 0.9349999999999999, -1.016, 0.45899999999999996, -0.539, -0.507, 0.46599999999999997, -0.501, -0.513, 0.9369999999999999, 0.9309999999999999, -0.508, 1.413, -0.5179999999999999, -1.008, 1.435, -1.0079999999999998, -0.04300000000000003, 1.049, -0.04000000000000003, 0.6659999999999999, -0.521, -0.514, -0.509, -0.505, 1.335, 0.973, -0.504, 0.724, 0.45799999999999996, 0.755, -1.007, -0.524, -0.05500000000000004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3401198987664167, "mean_inference_ms": 7.354439611480648, "mean_action_processing_ms": 0.39654053039208326, "mean_env_wait_ms": 0.50686633344812, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14987170696258545, "StateBufferConnector_ms": 0.009718537330627441, "ViewRequirementAgentConnector_ms": 0.18961012363433838}}, "episode_reward_max": 1.589, "episode_reward_min": -0.56, "episode_reward_mean": 0.37944999999999995, "episode_len_mean": 148.13, "episodes_this_iter": 31, "policy_reward_min": {"red_0": -1.036, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.4140000000000001, "blue_0": 1.435}, "policy_reward_mean": {"red_0": 0.31233000000000005, "blue_0": 0.06712000000000001}, "hist_stats": {"episode_reward": [0.911, 0.472, 0.0129999999999999, 0.29400000000000004, 0.2469999999999999, 0.08899999999999997, -0.15700000000000003, 0.19599999999999995, 0.598, 0.23099999999999998, 0.4969999999999999, -0.43800000000000006, 0.028999999999999915, 0.9149999999999999, -0.07599999999999985, 0.9109999999999999, -0.09799999999999998, 0.34999999999999987, 0.4009999999999998, 0.244, 0.3910000000000001, -0.3440000000000001, -0.1050000000000001, -0.062000000000000055, 0.817, -0.48, 0.9239999999999999, 0.9269999999999999, -0.2390000000000001, 1.589, 0.702, 0.42099999999999993, 0.5880000000000001, 0.2589999999999999, 0.9219999999999999, 0.14200000000000002, 0.9239999999999999, 0.6210000000000001, 0.9289999999999999, 0.39400000000000013, -0.04400000000000004, -0.24, 0.28100000000000014, 0.8319999999999999, 0.2709999999999999, 0.32299999999999995, 0.8959999999999999, 0.6419999999999999, 1.505, 0.865, 0.42099999999999993, 0.45599999999999996, 0.44199999999999995, 0.7430000000000001, 0.5189999999999999, 0.22100000000000009, 0.038000000000000034, -0.14700000000000002, 0.2499999999999999, 0.9049999999999999, 0.9339999999999999, -1.1102230246251565e-16, 0.8069999999999999, 0.9269999999999999, 0.31200000000000006, 0.09299999999999997, 0.9179999999999999, -0.06700000000000006, -0.56, 0.9179999999999999, 0.18500000000000005, 0.381, 0.42799999999999994, 0.4750000000000001, 0.76, 0.4069999999999999, 0.4059999999999999, 0.31199999999999983, 0.40700000000000003, 0.2650000000000001, -0.21700000000000008, 0.43399999999999994, 0.31400000000000006, 0.42299999999999993, 0.5249999999999999, 0.42499999999999993, 0.11799999999999988, 0.554, 0.46499999999999986, 0.28800000000000003, 0.347, 0.32999999999999996, 0.43899999999999995, 0.3460000000000001, -0.28400000000000003, 0.9189999999999999, -0.2609999999999999, 0.33000000000000007, 0.10899999999999999, -0.09500000000000007], "episode_lengths": [28, 166, 147, 64, 78, 125, 49, 244, 124, 77, 152, 283, 294, 300, 23, 300, 31, 204, 176, 233, 33, 104, 180, 173, 57, 143, 300, 300, 73, 125, 89, 300, 127, 73, 300, 111, 300, 116, 300, 32, 14, 74, 64, 54, 69, 54, 300, 109, 150, 42, 300, 168, 172, 79, 147, 88, 141, 47, 227, 300, 300, 153, 61, 300, 208, 125, 300, 21, 171, 300, 244, 36, 300, 8, 72, 181, 179, 56, 28, 70, 67, 20, 57, 300, 145, 300, 265, 136, 166, 66, 48, 50, 163, 48, 88, 300, 78, 52, 118, 300], "policy_red_0_reward": [1.4140000000000001, -0.513, 0.5289999999999999, -1.007, 0.755, 1.104, 0.849, -0.54, -0.518, -1.025, 1.02, 0.10599999999999987, 0.572, 0.46499999999999997, -1.004, 0.44999999999999996, 0.904, 0.8679999999999999, 0.9289999999999999, 0.77, -0.5049999999999999, 0.6689999999999999, -1.028, 0.46299999999999997, -0.505, -1.036, 0.45999999999999996, 0.476, -1.01, 0.484, 1.217, -0.03300000000000002, 1.101, 1.267, 0.45499999999999996, -0.519, 0.46199999999999997, -0.5129999999999999, 0.45899999999999996, 0.901, -1.001, 0.765, -1.019, 1.3359999999999999, 0.7849999999999999, 1.329, 0.45399999999999996, 1.158, 0.483, 1.369, -0.037000000000000026, 0.9779999999999999, 0.968, -0.5099999999999999, 1.037, 1.2309999999999999, 0.5549999999999999, 0.858, -0.537, 0.45099999999999996, 0.474, 0.5189999999999999, 1.313, 0.46799999999999997, 0.845, -0.517, 0.45499999999999996, -1.002, 0.45599999999999996, 0.45899999999999996, 0.724, 0.888, -0.03800000000000003, 0.976, 1.2730000000000001, -0.53, -0.525, 0.82, -1.006, 0.783, 0.7909999999999999, -1.001, 1.322, 0.46599999999999997, -0.524, 0.46499999999999997, -0.548, 1.0750000000000002, 0.979, 0.797, 0.852, -1.005, -0.534, 0.85, -1.008, 0.46099999999999997, -1.0159999999999998, 1.337, 0.633, -0.04000000000000003], "policy_blue_0_reward": [-0.503, 0.985, -0.5159999999999999, 1.3010000000000002, -0.508, -1.015, -1.006, 0.736, 1.116, 1.256, -0.523, -0.5439999999999999, -0.543, 0.44999999999999996, 0.928, 0.46099999999999997, -1.002, -0.518, -0.528, -0.526, 0.896, -1.013, 0.9229999999999999, -0.525, 1.322, 0.5559999999999999, 0.46399999999999997, 0.45099999999999996, 0.7709999999999999, 1.105, -0.515, 0.45399999999999996, -0.513, -1.008, 0.46699999999999997, 0.661, 0.46199999999999997, 1.134, 0.47, -0.507, 0.957, -1.005, 1.3, -0.504, -0.514, -1.006, 0.44199999999999995, -0.516, 1.022, -0.504, 0.45799999999999996, -0.522, -0.526, 1.2530000000000001, -0.518, -1.01, -0.5169999999999999, -1.005, 0.7869999999999999, 0.45399999999999996, 0.45999999999999996, -0.519, -0.506, 0.45899999999999996, -0.5329999999999999, 0.61, 0.46299999999999997, 0.9349999999999999, -1.016, 0.45899999999999996, -0.539, -0.507, 0.46599999999999997, -0.501, -0.513, 0.9369999999999999, 0.9309999999999999, -0.508, 1.413, -0.5179999999999999, -1.008, 1.435, -1.0079999999999998, -0.04300000000000003, 1.049, -0.04000000000000003, 0.6659999999999999, -0.521, -0.514, -0.509, -0.505, 1.335, 0.973, -0.504, 0.724, 0.45799999999999996, 0.755, -1.007, -0.524, -0.05500000000000004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3401198987664167, "mean_inference_ms": 7.354439611480648, "mean_action_processing_ms": 0.39654053039208326, "mean_env_wait_ms": 0.50686633344812, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14987170696258545, "StateBufferConnector_ms": 0.009718537330627441, "ViewRequirementAgentConnector_ms": 0.18961012363433838}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.7769997827401, "num_env_steps_trained_throughput_per_sec": 130.7769997827401, "timesteps_total": 68000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 136000, "timers": {"training_iteration_time_ms": 30708.748, "sample_time_ms": 3935.332, "learn_time_ms": 26738.498, "learn_throughput": 149.597, "synch_weights_time_ms": 33.293}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000}, "done": false, "episodes_total": 402, "training_iteration": 17, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-05-18", "timestamp": 1694837118, "time_this_iter_s": 30.606017112731934, "time_total_s": 504.3503084182739, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a1135b0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 504.3503084182739, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 26.511363636363637, "ram_util_percent": 56.87954545454545}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.45, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.3, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.45, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.03, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.3, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.45, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.3, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5062521762214601, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07739212277034918, "policy_loss": -0.10432595282860954, "vf_loss": 0.009392428194890575, "vf_explained_var": 0.5288039412349462, "kl": 0.01580671482154988, "entropy": 1.7688312310725451, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 16800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5383161233738065, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07901774239617225, "policy_loss": -0.10709019038428474, "vf_loss": 0.009428845685397392, "vf_explained_var": 0.5409876846397916, "kl": 0.016560285544267684, "entropy": 1.7929077543318273, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 16800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "sampler_results": {"episode_reward_max": 1.589, "episode_reward_min": -0.56, "episode_reward_mean": 0.40256000000000003, "episode_len_mean": 150.97, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"red_0": -1.036, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.369, "blue_0": 1.435}, "policy_reward_mean": {"red_0": 0.29480999999999996, "blue_0": 0.10775}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.45, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.3, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.45, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.03, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.3, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.45, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.3, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.1050000000000001, -0.062000000000000055, 0.817, -0.48, 0.9239999999999999, 0.9269999999999999, -0.2390000000000001, 1.589, 0.702, 0.42099999999999993, 0.5880000000000001, 0.2589999999999999, 0.9219999999999999, 0.14200000000000002, 0.9239999999999999, 0.6210000000000001, 0.9289999999999999, 0.39400000000000013, -0.04400000000000004, -0.24, 0.28100000000000014, 0.8319999999999999, 0.2709999999999999, 0.32299999999999995, 0.8959999999999999, 0.6419999999999999, 1.505, 0.865, 0.42099999999999993, 0.45599999999999996, 0.44199999999999995, 0.7430000000000001, 0.5189999999999999, 0.22100000000000009, 0.038000000000000034, -0.14700000000000002, 0.2499999999999999, 0.9049999999999999, 0.9339999999999999, -1.1102230246251565e-16, 0.8069999999999999, 0.9269999999999999, 0.31200000000000006, 0.09299999999999997, 0.9179999999999999, -0.06700000000000006, -0.56, 0.9179999999999999, 0.18500000000000005, 0.381, 0.42799999999999994, 0.4750000000000001, 0.76, 0.4069999999999999, 0.4059999999999999, 0.31199999999999983, 0.40700000000000003, 0.2650000000000001, -0.21700000000000008, 0.43399999999999994, 0.31400000000000006, 0.42299999999999993, 0.5249999999999999, 0.42499999999999993, 0.11799999999999988, 0.554, 0.46499999999999986, 0.28800000000000003, 0.347, 0.32999999999999996, 0.43899999999999995, 0.3460000000000001, -0.28400000000000003, 0.9189999999999999, -0.2609999999999999, 0.33000000000000007, 0.10899999999999999, -0.09500000000000007, 0.6479999999999999, 0.385, 0.27, 0.9039999999999999, 0.667, 0.42899999999999994, 0.1529999999999999, 0.9169999999999999, 0.9029999999999999, -0.30700000000000005, 0.1080000000000001, -0.18499999999999994, 0.10099999999999998, 0.9199999999999999, 0.11499999999999988, 0.376, -0.02200000000000002, 0.23099999999999998, -0.009000000000000119, 1.307, -0.17099999999999993, 0.2469999999999999], "episode_lengths": [180, 173, 57, 143, 300, 300, 73, 125, 89, 300, 127, 73, 300, 111, 300, 116, 300, 32, 14, 74, 64, 54, 69, 54, 300, 109, 150, 42, 300, 168, 172, 79, 147, 88, 141, 47, 227, 300, 300, 153, 61, 300, 208, 125, 300, 21, 171, 300, 244, 36, 300, 8, 72, 181, 179, 56, 28, 70, 67, 20, 57, 300, 145, 300, 265, 136, 166, 66, 48, 50, 163, 48, 88, 300, 78, 52, 118, 300, 104, 187, 70, 300, 103, 169, 261, 300, 300, 93, 119, 58, 121, 300, 270, 37, 157, 80, 155, 209, 48, 78], "policy_red_0_reward": [-1.028, 0.46299999999999997, -0.505, -1.036, 0.45999999999999996, 0.476, -1.01, 0.484, 1.217, -0.03300000000000002, 1.101, 1.267, 0.45499999999999996, -0.519, 0.46199999999999997, -0.5129999999999999, 0.45899999999999996, 0.901, -1.001, 0.765, -1.019, 1.3359999999999999, 0.7849999999999999, 1.329, 0.45399999999999996, 1.158, 0.483, 1.369, -0.037000000000000026, 0.9779999999999999, 0.968, -0.5099999999999999, 1.037, 1.2309999999999999, 0.5549999999999999, 0.858, -0.537, 0.45099999999999996, 0.474, 0.5189999999999999, 1.313, 0.46799999999999997, 0.845, -0.517, 0.45499999999999996, -1.002, 0.45599999999999996, 0.45899999999999996, 0.724, 0.888, -0.03800000000000003, 0.976, 1.2730000000000001, -0.53, -0.525, 0.82, -1.006, 0.783, 0.7909999999999999, -1.001, 1.322, 0.46599999999999997, -0.524, 0.46499999999999997, -0.548, 1.0750000000000002, 0.979, 0.797, 0.852, -1.005, -0.534, 0.85, -1.008, 0.46099999999999997, -1.0159999999999998, 1.337, 0.633, -0.04000000000000003, 1.1629999999999998, 0.912, 1.282, 0.45999999999999996, -0.51, -0.534, -0.53, 0.45499999999999996, 0.45599999999999996, 0.71, 1.125, 0.8220000000000001, 0.623, 0.46099999999999997, -0.526, -1.006, -1.029, -1.013, 1.0099999999999998, 0.46799999999999997, -1.0179999999999998, 0.759], "policy_blue_0_reward": [0.9229999999999999, -0.525, 1.322, 0.5559999999999999, 0.46399999999999997, 0.45099999999999996, 0.7709999999999999, 1.105, -0.515, 0.45399999999999996, -0.513, -1.008, 0.46699999999999997, 0.661, 0.46199999999999997, 1.134, 0.47, -0.507, 0.957, -1.005, 1.3, -0.504, -0.514, -1.006, 0.44199999999999995, -0.516, 1.022, -0.504, 0.45799999999999996, -0.522, -0.526, 1.2530000000000001, -0.518, -1.01, -0.5169999999999999, -1.005, 0.7869999999999999, 0.45399999999999996, 0.45999999999999996, -0.519, -0.506, 0.45899999999999996, -0.5329999999999999, 0.61, 0.46299999999999997, 0.9349999999999999, -1.016, 0.45899999999999996, -0.539, -0.507, 0.46599999999999997, -0.501, -0.513, 0.9369999999999999, 0.9309999999999999, -0.508, 1.413, -0.5179999999999999, -1.008, 1.435, -1.0079999999999998, -0.04300000000000003, 1.049, -0.04000000000000003, 0.6659999999999999, -0.521, -0.514, -0.509, -0.505, 1.335, 0.973, -0.504, 0.724, 0.45799999999999996, 0.755, -1.007, -0.524, -0.05500000000000004, -0.515, -0.527, -1.012, 0.44399999999999995, 1.177, 0.963, 0.6829999999999999, 0.46199999999999997, 0.44699999999999995, -1.017, -1.017, -1.007, -0.522, 0.45899999999999996, 0.6409999999999999, 1.3820000000000001, 1.0070000000000001, 1.244, -1.019, 0.839, 0.847, -0.512]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3387230179886205, "mean_inference_ms": 7.349967167944226, "mean_action_processing_ms": 0.3969754980901313, "mean_env_wait_ms": 0.5063035770645964, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14753389358520508, "StateBufferConnector_ms": 0.009554743766784668, "ViewRequirementAgentConnector_ms": 0.18727731704711914}}, "episode_reward_max": 1.589, "episode_reward_min": -0.56, "episode_reward_mean": 0.40256000000000003, "episode_len_mean": 150.97, "episodes_this_iter": 22, "policy_reward_min": {"red_0": -1.036, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.369, "blue_0": 1.435}, "policy_reward_mean": {"red_0": 0.29480999999999996, "blue_0": 0.10775}, "hist_stats": {"episode_reward": [-0.1050000000000001, -0.062000000000000055, 0.817, -0.48, 0.9239999999999999, 0.9269999999999999, -0.2390000000000001, 1.589, 0.702, 0.42099999999999993, 0.5880000000000001, 0.2589999999999999, 0.9219999999999999, 0.14200000000000002, 0.9239999999999999, 0.6210000000000001, 0.9289999999999999, 0.39400000000000013, -0.04400000000000004, -0.24, 0.28100000000000014, 0.8319999999999999, 0.2709999999999999, 0.32299999999999995, 0.8959999999999999, 0.6419999999999999, 1.505, 0.865, 0.42099999999999993, 0.45599999999999996, 0.44199999999999995, 0.7430000000000001, 0.5189999999999999, 0.22100000000000009, 0.038000000000000034, -0.14700000000000002, 0.2499999999999999, 0.9049999999999999, 0.9339999999999999, -1.1102230246251565e-16, 0.8069999999999999, 0.9269999999999999, 0.31200000000000006, 0.09299999999999997, 0.9179999999999999, -0.06700000000000006, -0.56, 0.9179999999999999, 0.18500000000000005, 0.381, 0.42799999999999994, 0.4750000000000001, 0.76, 0.4069999999999999, 0.4059999999999999, 0.31199999999999983, 0.40700000000000003, 0.2650000000000001, -0.21700000000000008, 0.43399999999999994, 0.31400000000000006, 0.42299999999999993, 0.5249999999999999, 0.42499999999999993, 0.11799999999999988, 0.554, 0.46499999999999986, 0.28800000000000003, 0.347, 0.32999999999999996, 0.43899999999999995, 0.3460000000000001, -0.28400000000000003, 0.9189999999999999, -0.2609999999999999, 0.33000000000000007, 0.10899999999999999, -0.09500000000000007, 0.6479999999999999, 0.385, 0.27, 0.9039999999999999, 0.667, 0.42899999999999994, 0.1529999999999999, 0.9169999999999999, 0.9029999999999999, -0.30700000000000005, 0.1080000000000001, -0.18499999999999994, 0.10099999999999998, 0.9199999999999999, 0.11499999999999988, 0.376, -0.02200000000000002, 0.23099999999999998, -0.009000000000000119, 1.307, -0.17099999999999993, 0.2469999999999999], "episode_lengths": [180, 173, 57, 143, 300, 300, 73, 125, 89, 300, 127, 73, 300, 111, 300, 116, 300, 32, 14, 74, 64, 54, 69, 54, 300, 109, 150, 42, 300, 168, 172, 79, 147, 88, 141, 47, 227, 300, 300, 153, 61, 300, 208, 125, 300, 21, 171, 300, 244, 36, 300, 8, 72, 181, 179, 56, 28, 70, 67, 20, 57, 300, 145, 300, 265, 136, 166, 66, 48, 50, 163, 48, 88, 300, 78, 52, 118, 300, 104, 187, 70, 300, 103, 169, 261, 300, 300, 93, 119, 58, 121, 300, 270, 37, 157, 80, 155, 209, 48, 78], "policy_red_0_reward": [-1.028, 0.46299999999999997, -0.505, -1.036, 0.45999999999999996, 0.476, -1.01, 0.484, 1.217, -0.03300000000000002, 1.101, 1.267, 0.45499999999999996, -0.519, 0.46199999999999997, -0.5129999999999999, 0.45899999999999996, 0.901, -1.001, 0.765, -1.019, 1.3359999999999999, 0.7849999999999999, 1.329, 0.45399999999999996, 1.158, 0.483, 1.369, -0.037000000000000026, 0.9779999999999999, 0.968, -0.5099999999999999, 1.037, 1.2309999999999999, 0.5549999999999999, 0.858, -0.537, 0.45099999999999996, 0.474, 0.5189999999999999, 1.313, 0.46799999999999997, 0.845, -0.517, 0.45499999999999996, -1.002, 0.45599999999999996, 0.45899999999999996, 0.724, 0.888, -0.03800000000000003, 0.976, 1.2730000000000001, -0.53, -0.525, 0.82, -1.006, 0.783, 0.7909999999999999, -1.001, 1.322, 0.46599999999999997, -0.524, 0.46499999999999997, -0.548, 1.0750000000000002, 0.979, 0.797, 0.852, -1.005, -0.534, 0.85, -1.008, 0.46099999999999997, -1.0159999999999998, 1.337, 0.633, -0.04000000000000003, 1.1629999999999998, 0.912, 1.282, 0.45999999999999996, -0.51, -0.534, -0.53, 0.45499999999999996, 0.45599999999999996, 0.71, 1.125, 0.8220000000000001, 0.623, 0.46099999999999997, -0.526, -1.006, -1.029, -1.013, 1.0099999999999998, 0.46799999999999997, -1.0179999999999998, 0.759], "policy_blue_0_reward": [0.9229999999999999, -0.525, 1.322, 0.5559999999999999, 0.46399999999999997, 0.45099999999999996, 0.7709999999999999, 1.105, -0.515, 0.45399999999999996, -0.513, -1.008, 0.46699999999999997, 0.661, 0.46199999999999997, 1.134, 0.47, -0.507, 0.957, -1.005, 1.3, -0.504, -0.514, -1.006, 0.44199999999999995, -0.516, 1.022, -0.504, 0.45799999999999996, -0.522, -0.526, 1.2530000000000001, -0.518, -1.01, -0.5169999999999999, -1.005, 0.7869999999999999, 0.45399999999999996, 0.45999999999999996, -0.519, -0.506, 0.45899999999999996, -0.5329999999999999, 0.61, 0.46299999999999997, 0.9349999999999999, -1.016, 0.45899999999999996, -0.539, -0.507, 0.46599999999999997, -0.501, -0.513, 0.9369999999999999, 0.9309999999999999, -0.508, 1.413, -0.5179999999999999, -1.008, 1.435, -1.0079999999999998, -0.04300000000000003, 1.049, -0.04000000000000003, 0.6659999999999999, -0.521, -0.514, -0.509, -0.505, 1.335, 0.973, -0.504, 0.724, 0.45799999999999996, 0.755, -1.007, -0.524, -0.05500000000000004, -0.515, -0.527, -1.012, 0.44399999999999995, 1.177, 0.963, 0.6829999999999999, 0.46199999999999997, 0.44699999999999995, -1.017, -1.017, -1.007, -0.522, 0.45899999999999996, 0.6409999999999999, 1.3820000000000001, 1.0070000000000001, 1.244, -1.019, 0.839, 0.847, -0.512]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3387230179886205, "mean_inference_ms": 7.349967167944226, "mean_action_processing_ms": 0.3969754980901313, "mean_env_wait_ms": 0.5063035770645964, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14753389358520508, "StateBufferConnector_ms": 0.009554743766784668, "ViewRequirementAgentConnector_ms": 0.18727731704711914}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.06448266343946, "num_env_steps_trained_throughput_per_sec": 128.06448266343946, "timesteps_total": 72000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 30899.331, "sample_time_ms": 3927.252, "learn_time_ms": 26937.009, "learn_throughput": 148.495, "synch_weights_time_ms": 33.422}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "episodes_total": 424, "training_iteration": 18, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-05-50", "timestamp": 1694837150, "time_this_iter_s": 31.25178599357605, "time_total_s": 535.60209441185, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7239e050>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 535.60209441185, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 26.667391304347827, "ram_util_percent": 56.67391304347826}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.02, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.47, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.24, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.47, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.04, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.24, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.47, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.24, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49443471043681103, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07489470003444391, "policy_loss": -0.10111716905448702, "vf_loss": 0.007820587930594532, "vf_explained_var": 0.6035976092641552, "kl": 0.015855023939553396, "entropy": 1.7676421261082094, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 17760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5055312705536683, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07272205507276036, "policy_loss": -0.09936060762023165, "vf_loss": 0.010263437407532668, "vf_explained_var": 0.5577565165857474, "kl": 0.015339915329330689, "entropy": 1.7906622679283222, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 17760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000}, "sampler_results": {"episode_reward_max": 1.7229999999999999, "episode_reward_min": -0.56, "episode_reward_mean": 0.4323499999999999, "episode_len_mean": 152.14, "episode_media": {}, "episodes_this_iter": 28, "policy_reward_min": {"red_0": -1.029, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.435}, "policy_reward_mean": {"red_0": 0.3911999999999999, "blue_0": 0.041149999999999985}, "custom_metrics": {"red_0/door_open_done_mean": 0.02, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.47, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.24, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.47, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.04, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.24, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.47, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.24, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.42099999999999993, 0.45599999999999996, 0.44199999999999995, 0.7430000000000001, 0.5189999999999999, 0.22100000000000009, 0.038000000000000034, -0.14700000000000002, 0.2499999999999999, 0.9049999999999999, 0.9339999999999999, -1.1102230246251565e-16, 0.8069999999999999, 0.9269999999999999, 0.31200000000000006, 0.09299999999999997, 0.9179999999999999, -0.06700000000000006, -0.56, 0.9179999999999999, 0.18500000000000005, 0.381, 0.42799999999999994, 0.4750000000000001, 0.76, 0.4069999999999999, 0.4059999999999999, 0.31199999999999983, 0.40700000000000003, 0.2650000000000001, -0.21700000000000008, 0.43399999999999994, 0.31400000000000006, 0.42299999999999993, 0.5249999999999999, 0.42499999999999993, 0.11799999999999988, 0.554, 0.46499999999999986, 0.28800000000000003, 0.347, 0.32999999999999996, 0.43899999999999995, 0.3460000000000001, -0.28400000000000003, 0.9189999999999999, -0.2609999999999999, 0.33000000000000007, 0.10899999999999999, -0.09500000000000007, 0.6479999999999999, 0.385, 0.27, 0.9039999999999999, 0.667, 0.42899999999999994, 0.1529999999999999, 0.9169999999999999, 0.9029999999999999, -0.30700000000000005, 0.1080000000000001, -0.18499999999999994, 0.10099999999999998, 0.9199999999999999, 0.11499999999999988, 0.376, -0.02200000000000002, 0.23099999999999998, -0.009000000000000119, 1.307, -0.17099999999999993, 0.2469999999999999, 0.502, 0.9059999999999999, 0.9229999999999999, 0.567, 0.42199999999999993, 0.40600000000000014, -0.09399999999999997, 0.09200000000000008, 0.9249999999999999, 0.41999999999999993, 1.7109999999999999, 0.8969999999999999, 0.44599999999999995, 0.9019999999999999, 0.3999999999999999, 0.45399999999999996, 0.43900000000000006, -0.04300000000000004, 0.22399999999999998, 0.2849999999999999, 1.7229999999999999, 0.8679999999999999, 0.8999999999999999, 0.593, 0.373, -0.07199999999999995, 1.1039999999999999, 1.31], "episode_lengths": [300, 168, 172, 79, 147, 88, 141, 47, 227, 300, 300, 153, 61, 300, 208, 125, 300, 21, 171, 300, 244, 36, 300, 8, 72, 181, 179, 56, 28, 70, 67, 20, 57, 300, 145, 300, 265, 136, 166, 66, 48, 50, 163, 48, 88, 300, 78, 52, 118, 300, 104, 187, 70, 300, 103, 169, 261, 300, 300, 93, 119, 58, 121, 300, 270, 37, 157, 80, 155, 209, 48, 78, 150, 300, 300, 133, 300, 29, 29, 123, 300, 300, 89, 300, 16, 300, 31, 13, 19, 14, 86, 65, 86, 189, 300, 123, 39, 23, 280, 209], "policy_red_0_reward": [-0.037000000000000026, 0.9779999999999999, 0.968, -0.5099999999999999, 1.037, 1.2309999999999999, 0.5549999999999999, 0.858, -0.537, 0.45099999999999996, 0.474, 0.5189999999999999, 1.313, 0.46799999999999997, 0.845, -0.517, 0.45499999999999996, -1.002, 0.45599999999999996, 0.45899999999999996, 0.724, 0.888, -0.03800000000000003, 0.976, 1.2730000000000001, -0.53, -0.525, 0.82, -1.006, 0.783, 0.7909999999999999, -1.001, 1.322, 0.46599999999999997, -0.524, 0.46499999999999997, -0.548, 1.0750000000000002, 0.979, 0.797, 0.852, -1.005, -0.534, 0.85, -1.008, 0.46099999999999997, -1.0159999999999998, 1.337, 0.633, -0.04000000000000003, 1.1629999999999998, 0.912, 1.282, 0.45999999999999996, -0.51, -0.534, -0.53, 0.45499999999999996, 0.45599999999999996, 0.71, 1.125, 0.8220000000000001, 0.623, 0.46099999999999997, -0.526, -1.006, -1.029, -1.013, 1.0099999999999998, 0.46799999999999997, -1.0179999999999998, 0.759, 1.03, 0.46199999999999997, 0.46499999999999997, -0.516, -0.027000000000000017, 1.4100000000000001, 0.909, 0.611, 0.46399999999999997, -0.04400000000000003, 0.489, 0.44299999999999995, 1.452, 0.45299999999999996, 1.405, 1.4609999999999999, 1.4409999999999998, 0.958, 0.728, -1.015, 0.491, -0.026000000000000016, 0.45799999999999996, 1.109, 1.3820000000000001, 0.929, 0.6349999999999999, 0.842], "policy_blue_0_reward": [0.45799999999999996, -0.522, -0.526, 1.2530000000000001, -0.518, -1.01, -0.5169999999999999, -1.005, 0.7869999999999999, 0.45399999999999996, 0.45999999999999996, -0.519, -0.506, 0.45899999999999996, -0.5329999999999999, 0.61, 0.46299999999999997, 0.9349999999999999, -1.016, 0.45899999999999996, -0.539, -0.507, 0.46599999999999997, -0.501, -0.513, 0.9369999999999999, 0.9309999999999999, -0.508, 1.413, -0.5179999999999999, -1.008, 1.435, -1.0079999999999998, -0.04300000000000003, 1.049, -0.04000000000000003, 0.6659999999999999, -0.521, -0.514, -0.509, -0.505, 1.335, 0.973, -0.504, 0.724, 0.45799999999999996, 0.755, -1.007, -0.524, -0.05500000000000004, -0.515, -0.527, -1.012, 0.44399999999999995, 1.177, 0.963, 0.6829999999999999, 0.46199999999999997, 0.44699999999999995, -1.017, -1.017, -1.007, -0.522, 0.45899999999999996, 0.6409999999999999, 1.3820000000000001, 1.0070000000000001, 1.244, -1.019, 0.839, 0.847, -0.512, -0.528, 0.44399999999999995, 0.45799999999999996, 1.083, 0.44899999999999995, -1.004, -1.003, -0.519, 0.46099999999999997, 0.46399999999999997, 1.222, 0.45399999999999996, -1.006, 0.44899999999999995, -1.005, -1.007, -1.002, -1.001, -0.504, 1.2999999999999998, 1.232, 0.8939999999999999, 0.44199999999999995, -0.516, -1.009, -1.001, 0.469, 0.46799999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3364949056532422, "mean_inference_ms": 7.3360516924837205, "mean_action_processing_ms": 0.3947742762392892, "mean_env_wait_ms": 0.5055729420159952, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14041638374328613, "StateBufferConnector_ms": 0.009447336196899414, "ViewRequirementAgentConnector_ms": 0.1855067014694214}}, "episode_reward_max": 1.7229999999999999, "episode_reward_min": -0.56, "episode_reward_mean": 0.4323499999999999, "episode_len_mean": 152.14, "episodes_this_iter": 28, "policy_reward_min": {"red_0": -1.029, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.435}, "policy_reward_mean": {"red_0": 0.3911999999999999, "blue_0": 0.041149999999999985}, "hist_stats": {"episode_reward": [0.42099999999999993, 0.45599999999999996, 0.44199999999999995, 0.7430000000000001, 0.5189999999999999, 0.22100000000000009, 0.038000000000000034, -0.14700000000000002, 0.2499999999999999, 0.9049999999999999, 0.9339999999999999, -1.1102230246251565e-16, 0.8069999999999999, 0.9269999999999999, 0.31200000000000006, 0.09299999999999997, 0.9179999999999999, -0.06700000000000006, -0.56, 0.9179999999999999, 0.18500000000000005, 0.381, 0.42799999999999994, 0.4750000000000001, 0.76, 0.4069999999999999, 0.4059999999999999, 0.31199999999999983, 0.40700000000000003, 0.2650000000000001, -0.21700000000000008, 0.43399999999999994, 0.31400000000000006, 0.42299999999999993, 0.5249999999999999, 0.42499999999999993, 0.11799999999999988, 0.554, 0.46499999999999986, 0.28800000000000003, 0.347, 0.32999999999999996, 0.43899999999999995, 0.3460000000000001, -0.28400000000000003, 0.9189999999999999, -0.2609999999999999, 0.33000000000000007, 0.10899999999999999, -0.09500000000000007, 0.6479999999999999, 0.385, 0.27, 0.9039999999999999, 0.667, 0.42899999999999994, 0.1529999999999999, 0.9169999999999999, 0.9029999999999999, -0.30700000000000005, 0.1080000000000001, -0.18499999999999994, 0.10099999999999998, 0.9199999999999999, 0.11499999999999988, 0.376, -0.02200000000000002, 0.23099999999999998, -0.009000000000000119, 1.307, -0.17099999999999993, 0.2469999999999999, 0.502, 0.9059999999999999, 0.9229999999999999, 0.567, 0.42199999999999993, 0.40600000000000014, -0.09399999999999997, 0.09200000000000008, 0.9249999999999999, 0.41999999999999993, 1.7109999999999999, 0.8969999999999999, 0.44599999999999995, 0.9019999999999999, 0.3999999999999999, 0.45399999999999996, 0.43900000000000006, -0.04300000000000004, 0.22399999999999998, 0.2849999999999999, 1.7229999999999999, 0.8679999999999999, 0.8999999999999999, 0.593, 0.373, -0.07199999999999995, 1.1039999999999999, 1.31], "episode_lengths": [300, 168, 172, 79, 147, 88, 141, 47, 227, 300, 300, 153, 61, 300, 208, 125, 300, 21, 171, 300, 244, 36, 300, 8, 72, 181, 179, 56, 28, 70, 67, 20, 57, 300, 145, 300, 265, 136, 166, 66, 48, 50, 163, 48, 88, 300, 78, 52, 118, 300, 104, 187, 70, 300, 103, 169, 261, 300, 300, 93, 119, 58, 121, 300, 270, 37, 157, 80, 155, 209, 48, 78, 150, 300, 300, 133, 300, 29, 29, 123, 300, 300, 89, 300, 16, 300, 31, 13, 19, 14, 86, 65, 86, 189, 300, 123, 39, 23, 280, 209], "policy_red_0_reward": [-0.037000000000000026, 0.9779999999999999, 0.968, -0.5099999999999999, 1.037, 1.2309999999999999, 0.5549999999999999, 0.858, -0.537, 0.45099999999999996, 0.474, 0.5189999999999999, 1.313, 0.46799999999999997, 0.845, -0.517, 0.45499999999999996, -1.002, 0.45599999999999996, 0.45899999999999996, 0.724, 0.888, -0.03800000000000003, 0.976, 1.2730000000000001, -0.53, -0.525, 0.82, -1.006, 0.783, 0.7909999999999999, -1.001, 1.322, 0.46599999999999997, -0.524, 0.46499999999999997, -0.548, 1.0750000000000002, 0.979, 0.797, 0.852, -1.005, -0.534, 0.85, -1.008, 0.46099999999999997, -1.0159999999999998, 1.337, 0.633, -0.04000000000000003, 1.1629999999999998, 0.912, 1.282, 0.45999999999999996, -0.51, -0.534, -0.53, 0.45499999999999996, 0.45599999999999996, 0.71, 1.125, 0.8220000000000001, 0.623, 0.46099999999999997, -0.526, -1.006, -1.029, -1.013, 1.0099999999999998, 0.46799999999999997, -1.0179999999999998, 0.759, 1.03, 0.46199999999999997, 0.46499999999999997, -0.516, -0.027000000000000017, 1.4100000000000001, 0.909, 0.611, 0.46399999999999997, -0.04400000000000003, 0.489, 0.44299999999999995, 1.452, 0.45299999999999996, 1.405, 1.4609999999999999, 1.4409999999999998, 0.958, 0.728, -1.015, 0.491, -0.026000000000000016, 0.45799999999999996, 1.109, 1.3820000000000001, 0.929, 0.6349999999999999, 0.842], "policy_blue_0_reward": [0.45799999999999996, -0.522, -0.526, 1.2530000000000001, -0.518, -1.01, -0.5169999999999999, -1.005, 0.7869999999999999, 0.45399999999999996, 0.45999999999999996, -0.519, -0.506, 0.45899999999999996, -0.5329999999999999, 0.61, 0.46299999999999997, 0.9349999999999999, -1.016, 0.45899999999999996, -0.539, -0.507, 0.46599999999999997, -0.501, -0.513, 0.9369999999999999, 0.9309999999999999, -0.508, 1.413, -0.5179999999999999, -1.008, 1.435, -1.0079999999999998, -0.04300000000000003, 1.049, -0.04000000000000003, 0.6659999999999999, -0.521, -0.514, -0.509, -0.505, 1.335, 0.973, -0.504, 0.724, 0.45799999999999996, 0.755, -1.007, -0.524, -0.05500000000000004, -0.515, -0.527, -1.012, 0.44399999999999995, 1.177, 0.963, 0.6829999999999999, 0.46199999999999997, 0.44699999999999995, -1.017, -1.017, -1.007, -0.522, 0.45899999999999996, 0.6409999999999999, 1.3820000000000001, 1.0070000000000001, 1.244, -1.019, 0.839, 0.847, -0.512, -0.528, 0.44399999999999995, 0.45799999999999996, 1.083, 0.44899999999999995, -1.004, -1.003, -0.519, 0.46099999999999997, 0.46399999999999997, 1.222, 0.45399999999999996, -1.006, 0.44899999999999995, -1.005, -1.007, -1.002, -1.001, -0.504, 1.2999999999999998, 1.232, 0.8939999999999999, 0.44199999999999995, -0.516, -1.009, -1.001, 0.469, 0.46799999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3364949056532422, "mean_inference_ms": 7.3360516924837205, "mean_action_processing_ms": 0.3947742762392892, "mean_env_wait_ms": 0.5055729420159952, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14041638374328613, "StateBufferConnector_ms": 0.009447336196899414, "ViewRequirementAgentConnector_ms": 0.1855067014694214}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.76600953511488, "num_env_steps_trained_throughput_per_sec": 129.76600953511488, "timesteps_total": 76000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 152000, "timers": {"training_iteration_time_ms": 30994.842, "sample_time_ms": 3920.544, "learn_time_ms": 27039.263, "learn_throughput": 147.933, "synch_weights_time_ms": 33.33}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000}, "done": false, "episodes_total": 452, "training_iteration": 19, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-06-21", "timestamp": 1694837181, "time_this_iter_s": 30.840585947036743, "time_total_s": 566.4426803588867, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80ec92d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 566.4426803588867, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 26.722727272727273, "ram_util_percent": 56.83863636363637}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.02, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.47, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.24, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.47, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.05, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.24, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.47, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.24, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49306756254906453, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07995016723871232, "policy_loss": -0.10853014281601644, "vf_loss": 0.011152376585717624, "vf_explained_var": 0.5348559414347013, "kl": 0.01629844727510393, "entropy": 1.7494777015099923, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 18720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49321918496862055, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08407480025756134, "policy_loss": -0.11299685017972176, "vf_loss": 0.01321569548357123, "vf_explained_var": 0.6135705964639783, "kl": 0.0158660085874241, "entropy": 1.7822981362541517, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 18720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "sampler_results": {"episode_reward_max": 1.7229999999999999, "episode_reward_min": -0.484, "episode_reward_mean": 0.45674, "episode_len_mean": 148.07, "episode_media": {}, "episodes_this_iter": 31, "policy_reward_min": {"red_0": -1.029, "blue_0": -1.0239999999999998}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.435}, "policy_reward_mean": {"red_0": 0.41359999999999997, "blue_0": 0.04314}, "custom_metrics": {"red_0/door_open_done_mean": 0.02, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.47, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.24, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.47, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.05, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.24, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.47, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.24, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.43399999999999994, 0.31400000000000006, 0.42299999999999993, 0.5249999999999999, 0.42499999999999993, 0.11799999999999988, 0.554, 0.46499999999999986, 0.28800000000000003, 0.347, 0.32999999999999996, 0.43899999999999995, 0.3460000000000001, -0.28400000000000003, 0.9189999999999999, -0.2609999999999999, 0.33000000000000007, 0.10899999999999999, -0.09500000000000007, 0.6479999999999999, 0.385, 0.27, 0.9039999999999999, 0.667, 0.42899999999999994, 0.1529999999999999, 0.9169999999999999, 0.9029999999999999, -0.30700000000000005, 0.1080000000000001, -0.18499999999999994, 0.10099999999999998, 0.9199999999999999, 0.11499999999999988, 0.376, -0.02200000000000002, 0.23099999999999998, -0.009000000000000119, 1.307, -0.17099999999999993, 0.2469999999999999, 0.502, 0.9059999999999999, 0.9229999999999999, 0.567, 0.42199999999999993, 0.40600000000000014, -0.09399999999999997, 0.09200000000000008, 0.9249999999999999, 0.41999999999999993, 1.7109999999999999, 0.8969999999999999, 0.44599999999999995, 0.9019999999999999, 0.3999999999999999, 0.45399999999999996, 0.43900000000000006, -0.04300000000000004, 0.22399999999999998, 0.2849999999999999, 1.7229999999999999, 0.8679999999999999, 0.8999999999999999, 0.593, 0.373, -0.07199999999999995, 1.1039999999999999, 1.31, 0.583, 0.6549999999999999, 0.2629999999999999, 0.7330000000000001, -0.16399999999999992, 0.4079999999999999, 1.179, 0.4139999999999999, 0.6179999999999999, 0.373, -0.09899999999999987, 0.14400000000000002, 0.06000000000000005, 0.669, 0.4149999999999999, -0.3360000000000001, 0.513, 0.1519999999999999, 0.734, 0.39800000000000013, 0.9219999999999999, 0.645, 0.2959999999999998, 0.9179999999999999, 0.9249999999999999, 0.9269999999999999, 0.9, 0.5779999999999998, -0.484, 0.683, 0.35599999999999987], "episode_lengths": [20, 57, 300, 145, 300, 265, 136, 166, 66, 48, 50, 163, 48, 88, 300, 78, 52, 118, 300, 104, 187, 70, 300, 103, 169, 261, 300, 300, 93, 119, 58, 121, 300, 270, 37, 157, 80, 155, 209, 48, 78, 150, 300, 300, 133, 300, 29, 29, 123, 300, 300, 89, 300, 16, 300, 31, 13, 19, 14, 86, 65, 86, 189, 300, 123, 39, 23, 280, 209, 129, 108, 71, 78, 51, 181, 97, 300, 115, 40, 30, 109, 135, 101, 300, 102, 149, 261, 82, 31, 300, 110, 63, 300, 300, 300, 32, 129, 147, 95, 196], "policy_red_0_reward": [-1.001, 1.322, 0.46599999999999997, -0.524, 0.46499999999999997, -0.548, 1.0750000000000002, 0.979, 0.797, 0.852, -1.005, -0.534, 0.85, -1.008, 0.46099999999999997, -1.0159999999999998, 1.337, 0.633, -0.04000000000000003, 1.1629999999999998, 0.912, 1.282, 0.45999999999999996, -0.51, -0.534, -0.53, 0.45499999999999996, 0.45599999999999996, 0.71, 1.125, 0.8220000000000001, 0.623, 0.46099999999999997, -0.526, -1.006, -1.029, -1.013, 1.0099999999999998, 0.46799999999999997, -1.0179999999999998, 0.759, 1.03, 0.46199999999999997, 0.46499999999999997, -0.516, -0.027000000000000017, 1.4100000000000001, 0.909, 0.611, 0.46399999999999997, -0.04400000000000003, 0.489, 0.44299999999999995, 1.452, 0.45299999999999996, 1.405, 1.4609999999999999, 1.4409999999999998, 0.958, 0.728, -1.015, 0.491, -0.026000000000000016, 0.45799999999999996, 1.109, 1.3820000000000001, 0.929, 0.6349999999999999, 0.842, 1.103, -0.507, 1.2770000000000001, 1.244, -1.006, 0.938, -0.017000000000000008, -0.04100000000000003, 1.141, -0.505, -1.003, -1.015, 0.582, 1.183, 0.44999999999999996, 0.6739999999999999, -0.5159999999999999, 0.6849999999999999, 1.242, 1.405, 0.46499999999999997, 1.157, 1.3039999999999998, 0.46299999999999997, 0.471, 0.46799999999999997, -0.503, 1.095, 0.5399999999999999, 1.194, 0.892], "policy_blue_0_reward": [1.435, -1.0079999999999998, -0.04300000000000003, 1.049, -0.04000000000000003, 0.6659999999999999, -0.521, -0.514, -0.509, -0.505, 1.335, 0.973, -0.504, 0.724, 0.45799999999999996, 0.755, -1.007, -0.524, -0.05500000000000004, -0.515, -0.527, -1.012, 0.44399999999999995, 1.177, 0.963, 0.6829999999999999, 0.46199999999999997, 0.44699999999999995, -1.017, -1.017, -1.007, -0.522, 0.45899999999999996, 0.6409999999999999, 1.3820000000000001, 1.0070000000000001, 1.244, -1.019, 0.839, 0.847, -0.512, -0.528, 0.44399999999999995, 0.45799999999999996, 1.083, 0.44899999999999995, -1.004, -1.003, -0.519, 0.46099999999999997, 0.46399999999999997, 1.222, 0.45399999999999996, -1.006, 0.44899999999999995, -1.005, -1.007, -1.002, -1.001, -0.504, 1.2999999999999998, 1.232, 0.8939999999999999, 0.44199999999999995, -0.516, -1.009, -1.001, 0.469, 0.46799999999999997, -0.52, 1.162, -1.014, -0.511, 0.842, -0.53, 1.1960000000000002, 0.45499999999999996, -0.523, 0.878, 0.904, 1.159, -0.522, -0.514, -0.035000000000000024, -1.01, 1.029, -0.533, -0.508, -1.007, 0.45699999999999996, -0.512, -1.008, 0.45499999999999996, 0.45399999999999996, 0.45899999999999996, 1.403, -0.517, -1.0239999999999998, -0.511, -0.536]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3362915235855537, "mean_inference_ms": 7.332908327420716, "mean_action_processing_ms": 0.3940539326601932, "mean_env_wait_ms": 0.5053324588834951, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14011085033416748, "StateBufferConnector_ms": 0.00928354263305664, "ViewRequirementAgentConnector_ms": 0.18919575214385986}}, "episode_reward_max": 1.7229999999999999, "episode_reward_min": -0.484, "episode_reward_mean": 0.45674, "episode_len_mean": 148.07, "episodes_this_iter": 31, "policy_reward_min": {"red_0": -1.029, "blue_0": -1.0239999999999998}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.435}, "policy_reward_mean": {"red_0": 0.41359999999999997, "blue_0": 0.04314}, "hist_stats": {"episode_reward": [0.43399999999999994, 0.31400000000000006, 0.42299999999999993, 0.5249999999999999, 0.42499999999999993, 0.11799999999999988, 0.554, 0.46499999999999986, 0.28800000000000003, 0.347, 0.32999999999999996, 0.43899999999999995, 0.3460000000000001, -0.28400000000000003, 0.9189999999999999, -0.2609999999999999, 0.33000000000000007, 0.10899999999999999, -0.09500000000000007, 0.6479999999999999, 0.385, 0.27, 0.9039999999999999, 0.667, 0.42899999999999994, 0.1529999999999999, 0.9169999999999999, 0.9029999999999999, -0.30700000000000005, 0.1080000000000001, -0.18499999999999994, 0.10099999999999998, 0.9199999999999999, 0.11499999999999988, 0.376, -0.02200000000000002, 0.23099999999999998, -0.009000000000000119, 1.307, -0.17099999999999993, 0.2469999999999999, 0.502, 0.9059999999999999, 0.9229999999999999, 0.567, 0.42199999999999993, 0.40600000000000014, -0.09399999999999997, 0.09200000000000008, 0.9249999999999999, 0.41999999999999993, 1.7109999999999999, 0.8969999999999999, 0.44599999999999995, 0.9019999999999999, 0.3999999999999999, 0.45399999999999996, 0.43900000000000006, -0.04300000000000004, 0.22399999999999998, 0.2849999999999999, 1.7229999999999999, 0.8679999999999999, 0.8999999999999999, 0.593, 0.373, -0.07199999999999995, 1.1039999999999999, 1.31, 0.583, 0.6549999999999999, 0.2629999999999999, 0.7330000000000001, -0.16399999999999992, 0.4079999999999999, 1.179, 0.4139999999999999, 0.6179999999999999, 0.373, -0.09899999999999987, 0.14400000000000002, 0.06000000000000005, 0.669, 0.4149999999999999, -0.3360000000000001, 0.513, 0.1519999999999999, 0.734, 0.39800000000000013, 0.9219999999999999, 0.645, 0.2959999999999998, 0.9179999999999999, 0.9249999999999999, 0.9269999999999999, 0.9, 0.5779999999999998, -0.484, 0.683, 0.35599999999999987], "episode_lengths": [20, 57, 300, 145, 300, 265, 136, 166, 66, 48, 50, 163, 48, 88, 300, 78, 52, 118, 300, 104, 187, 70, 300, 103, 169, 261, 300, 300, 93, 119, 58, 121, 300, 270, 37, 157, 80, 155, 209, 48, 78, 150, 300, 300, 133, 300, 29, 29, 123, 300, 300, 89, 300, 16, 300, 31, 13, 19, 14, 86, 65, 86, 189, 300, 123, 39, 23, 280, 209, 129, 108, 71, 78, 51, 181, 97, 300, 115, 40, 30, 109, 135, 101, 300, 102, 149, 261, 82, 31, 300, 110, 63, 300, 300, 300, 32, 129, 147, 95, 196], "policy_red_0_reward": [-1.001, 1.322, 0.46599999999999997, -0.524, 0.46499999999999997, -0.548, 1.0750000000000002, 0.979, 0.797, 0.852, -1.005, -0.534, 0.85, -1.008, 0.46099999999999997, -1.0159999999999998, 1.337, 0.633, -0.04000000000000003, 1.1629999999999998, 0.912, 1.282, 0.45999999999999996, -0.51, -0.534, -0.53, 0.45499999999999996, 0.45599999999999996, 0.71, 1.125, 0.8220000000000001, 0.623, 0.46099999999999997, -0.526, -1.006, -1.029, -1.013, 1.0099999999999998, 0.46799999999999997, -1.0179999999999998, 0.759, 1.03, 0.46199999999999997, 0.46499999999999997, -0.516, -0.027000000000000017, 1.4100000000000001, 0.909, 0.611, 0.46399999999999997, -0.04400000000000003, 0.489, 0.44299999999999995, 1.452, 0.45299999999999996, 1.405, 1.4609999999999999, 1.4409999999999998, 0.958, 0.728, -1.015, 0.491, -0.026000000000000016, 0.45799999999999996, 1.109, 1.3820000000000001, 0.929, 0.6349999999999999, 0.842, 1.103, -0.507, 1.2770000000000001, 1.244, -1.006, 0.938, -0.017000000000000008, -0.04100000000000003, 1.141, -0.505, -1.003, -1.015, 0.582, 1.183, 0.44999999999999996, 0.6739999999999999, -0.5159999999999999, 0.6849999999999999, 1.242, 1.405, 0.46499999999999997, 1.157, 1.3039999999999998, 0.46299999999999997, 0.471, 0.46799999999999997, -0.503, 1.095, 0.5399999999999999, 1.194, 0.892], "policy_blue_0_reward": [1.435, -1.0079999999999998, -0.04300000000000003, 1.049, -0.04000000000000003, 0.6659999999999999, -0.521, -0.514, -0.509, -0.505, 1.335, 0.973, -0.504, 0.724, 0.45799999999999996, 0.755, -1.007, -0.524, -0.05500000000000004, -0.515, -0.527, -1.012, 0.44399999999999995, 1.177, 0.963, 0.6829999999999999, 0.46199999999999997, 0.44699999999999995, -1.017, -1.017, -1.007, -0.522, 0.45899999999999996, 0.6409999999999999, 1.3820000000000001, 1.0070000000000001, 1.244, -1.019, 0.839, 0.847, -0.512, -0.528, 0.44399999999999995, 0.45799999999999996, 1.083, 0.44899999999999995, -1.004, -1.003, -0.519, 0.46099999999999997, 0.46399999999999997, 1.222, 0.45399999999999996, -1.006, 0.44899999999999995, -1.005, -1.007, -1.002, -1.001, -0.504, 1.2999999999999998, 1.232, 0.8939999999999999, 0.44199999999999995, -0.516, -1.009, -1.001, 0.469, 0.46799999999999997, -0.52, 1.162, -1.014, -0.511, 0.842, -0.53, 1.1960000000000002, 0.45499999999999996, -0.523, 0.878, 0.904, 1.159, -0.522, -0.514, -0.035000000000000024, -1.01, 1.029, -0.533, -0.508, -1.007, 0.45699999999999996, -0.512, -1.008, 0.45499999999999996, 0.45399999999999996, 0.45899999999999996, 1.403, -0.517, -1.0239999999999998, -0.511, -0.536]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3362915235855537, "mean_inference_ms": 7.332908327420716, "mean_action_processing_ms": 0.3940539326601932, "mean_env_wait_ms": 0.5053324588834951, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14011085033416748, "StateBufferConnector_ms": 0.00928354263305664, "ViewRequirementAgentConnector_ms": 0.18919575214385986}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 124.7538834323555, "num_env_steps_trained_throughput_per_sec": 124.7538834323555, "timesteps_total": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 31301.04, "sample_time_ms": 3961.09, "learn_time_ms": 27304.644, "learn_throughput": 146.495, "synch_weights_time_ms": 33.569}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "episodes_total": 483, "training_iteration": 20, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-06-54", "timestamp": 1694837214, "time_this_iter_s": 32.08076786994934, "time_total_s": 598.5234482288361, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80eba200>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 598.5234482288361, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 27.119148936170216, "ram_util_percent": 56.84468085106383}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.02, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.53, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.22, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.53, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.07, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.22, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.53, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.22, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5247128622916838, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07687000320778073, "policy_loss": -0.1078581610932209, "vf_loss": 0.016093650727028338, "vf_explained_var": 0.5892998924478888, "kl": 0.016245921732943695, "entropy": 1.732159943630298, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 19680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5110102865534524, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08075132864954261, "policy_loss": -0.11443565660301828, "vf_loss": 0.0197465210648564, "vf_explained_var": 0.5731098294258118, "kl": 0.016843790067948672, "entropy": 1.770438712462783, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 19680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "sampler_results": {"episode_reward_max": 1.7530000000000001, "episode_reward_min": -0.484, "episode_reward_mean": 0.5203899999999999, "episode_len_mean": 124.69, "episode_media": {}, "episodes_this_iter": 40, "policy_reward_min": {"red_0": -1.015, "blue_0": -1.0239999999999998}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.49923, "blue_0": 0.021160000000000005}, "custom_metrics": {"red_0/door_open_done_mean": 0.02, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.53, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.22, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.53, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.07, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.22, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.53, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.22, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.2469999999999999, 0.502, 0.9059999999999999, 0.9229999999999999, 0.567, 0.42199999999999993, 0.40600000000000014, -0.09399999999999997, 0.09200000000000008, 0.9249999999999999, 0.41999999999999993, 1.7109999999999999, 0.8969999999999999, 0.44599999999999995, 0.9019999999999999, 0.3999999999999999, 0.45399999999999996, 0.43900000000000006, -0.04300000000000004, 0.22399999999999998, 0.2849999999999999, 1.7229999999999999, 0.8679999999999999, 0.8999999999999999, 0.593, 0.373, -0.07199999999999995, 1.1039999999999999, 1.31, 0.583, 0.6549999999999999, 0.2629999999999999, 0.7330000000000001, -0.16399999999999992, 0.4079999999999999, 1.179, 0.4139999999999999, 0.6179999999999999, 0.373, -0.09899999999999987, 0.14400000000000002, 0.06000000000000005, 0.669, 0.4149999999999999, -0.3360000000000001, 0.513, 0.1519999999999999, 0.734, 0.39800000000000013, 0.9219999999999999, 0.645, 0.2959999999999998, 0.9179999999999999, 0.9249999999999999, 0.9269999999999999, 0.9, 0.5779999999999998, -0.484, 0.683, 0.35599999999999987, -0.42000000000000004, 1.584, 0.5429999999999999, 0.639, -0.09199999999999986, 1.7530000000000001, -0.03400000000000003, 0.708, 0.5619999999999998, 0.605, 0.377, 0.9149999999999999, 0.7400000000000001, 0.9089999999999999, -0.3450000000000001, 0.7949999999999999, 0.08699999999999997, -0.01200000000000001, 0.2789999999999999, 0.33499999999999996, -0.18100000000000005, 0.19199999999999995, 1.271, 0.371, 0.696, 0.3639999999999999, 0.889, 0.757, 0.43799999999999994, 0.705, -0.247, 0.401, 0.35199999999999987, -0.09299999999999997, 0.7919999999999999, 0.935, 0.794, 0.3320000000000001, 0.2610000000000001, 0.874], "episode_lengths": [78, 150, 300, 300, 133, 300, 29, 29, 123, 300, 300, 89, 300, 16, 300, 31, 13, 19, 14, 86, 65, 86, 189, 300, 123, 39, 23, 280, 209, 129, 108, 71, 78, 51, 181, 97, 300, 115, 40, 30, 109, 135, 101, 300, 102, 149, 261, 82, 31, 300, 110, 63, 300, 300, 300, 32, 129, 147, 95, 196, 128, 125, 140, 112, 29, 77, 161, 90, 135, 120, 37, 300, 81, 300, 104, 63, 126, 154, 221, 49, 57, 96, 70, 40, 93, 43, 35, 71, 20, 89, 75, 30, 198, 29, 60, 20, 62, 52, 72, 39], "policy_red_0_reward": [0.759, 1.03, 0.46199999999999997, 0.46499999999999997, -0.516, -0.027000000000000017, 1.4100000000000001, 0.909, 0.611, 0.46399999999999997, -0.04400000000000003, 0.489, 0.44299999999999995, 1.452, 0.45299999999999996, 1.405, 1.4609999999999999, 1.4409999999999998, 0.958, 0.728, -1.015, 0.491, -0.026000000000000016, 0.45799999999999996, 1.109, 1.3820000000000001, 0.929, 0.6349999999999999, 0.842, 1.103, -0.507, 1.2770000000000001, 1.244, -1.006, 0.938, -0.017000000000000008, -0.04100000000000003, 1.141, -0.505, -1.003, -1.015, 0.582, 1.183, 0.44999999999999996, 0.6739999999999999, -0.5159999999999999, 0.6849999999999999, 1.242, 1.405, 0.46499999999999997, 1.157, 1.3039999999999998, 0.46299999999999997, 0.471, 0.46799999999999997, -0.503, 1.095, 0.5399999999999999, 1.194, 0.892, 0.599, 0.479, 1.059, -0.5169999999999999, -1.003, 0.49, 0.491, 1.217, 1.077, 1.1219999999999999, 0.882, 0.44899999999999995, -0.5099999999999999, 0.44699999999999995, 0.6659999999999999, -0.507, 0.6, 1.005, -0.532, 1.3439999999999999, 0.824, 0.702, -0.008, -0.504, 1.2069999999999999, 1.369, -0.503, -0.516, 0.94, -0.51, 0.763, 1.403, -0.528, 0.91, -0.511, 1.439, 1.3090000000000002, -1.0059999999999998, 0.771, -0.504], "policy_blue_0_reward": [-0.512, -0.528, 0.44399999999999995, 0.45799999999999996, 1.083, 0.44899999999999995, -1.004, -1.003, -0.519, 0.46099999999999997, 0.46399999999999997, 1.222, 0.45399999999999996, -1.006, 0.44899999999999995, -1.005, -1.007, -1.002, -1.001, -0.504, 1.2999999999999998, 1.232, 0.8939999999999999, 0.44199999999999995, -0.516, -1.009, -1.001, 0.469, 0.46799999999999997, -0.52, 1.162, -1.014, -0.511, 0.842, -0.53, 1.1960000000000002, 0.45499999999999996, -0.523, 0.878, 0.904, 1.159, -0.522, -0.514, -0.035000000000000024, -1.01, 1.029, -0.533, -0.508, -1.007, 0.45699999999999996, -0.512, -1.008, 0.45499999999999996, 0.45399999999999996, 0.45899999999999996, 1.403, -0.517, -1.0239999999999998, -0.511, -0.536, -1.019, 1.105, -0.516, 1.156, 0.911, 1.263, -0.525, -0.509, -0.515, -0.517, -0.505, 0.46599999999999997, 1.25, 0.46199999999999997, -1.011, 1.302, -0.513, -1.017, 0.8109999999999999, -1.009, -1.005, -0.51, 1.279, 0.875, -0.511, -1.005, 1.392, 1.2730000000000001, -0.502, 1.2149999999999999, -1.01, -1.002, 0.8799999999999999, -1.003, 1.303, -0.504, -0.515, 1.338, -0.51, 1.3780000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3391779615743835, "mean_inference_ms": 7.34054069912057, "mean_action_processing_ms": 0.3946718929006224, "mean_env_wait_ms": 0.5062547501571062, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14649200439453125, "StateBufferConnector_ms": 0.009437918663024902, "ViewRequirementAgentConnector_ms": 0.19192910194396973}}, "episode_reward_max": 1.7530000000000001, "episode_reward_min": -0.484, "episode_reward_mean": 0.5203899999999999, "episode_len_mean": 124.69, "episodes_this_iter": 40, "policy_reward_min": {"red_0": -1.015, "blue_0": -1.0239999999999998}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.49923, "blue_0": 0.021160000000000005}, "hist_stats": {"episode_reward": [0.2469999999999999, 0.502, 0.9059999999999999, 0.9229999999999999, 0.567, 0.42199999999999993, 0.40600000000000014, -0.09399999999999997, 0.09200000000000008, 0.9249999999999999, 0.41999999999999993, 1.7109999999999999, 0.8969999999999999, 0.44599999999999995, 0.9019999999999999, 0.3999999999999999, 0.45399999999999996, 0.43900000000000006, -0.04300000000000004, 0.22399999999999998, 0.2849999999999999, 1.7229999999999999, 0.8679999999999999, 0.8999999999999999, 0.593, 0.373, -0.07199999999999995, 1.1039999999999999, 1.31, 0.583, 0.6549999999999999, 0.2629999999999999, 0.7330000000000001, -0.16399999999999992, 0.4079999999999999, 1.179, 0.4139999999999999, 0.6179999999999999, 0.373, -0.09899999999999987, 0.14400000000000002, 0.06000000000000005, 0.669, 0.4149999999999999, -0.3360000000000001, 0.513, 0.1519999999999999, 0.734, 0.39800000000000013, 0.9219999999999999, 0.645, 0.2959999999999998, 0.9179999999999999, 0.9249999999999999, 0.9269999999999999, 0.9, 0.5779999999999998, -0.484, 0.683, 0.35599999999999987, -0.42000000000000004, 1.584, 0.5429999999999999, 0.639, -0.09199999999999986, 1.7530000000000001, -0.03400000000000003, 0.708, 0.5619999999999998, 0.605, 0.377, 0.9149999999999999, 0.7400000000000001, 0.9089999999999999, -0.3450000000000001, 0.7949999999999999, 0.08699999999999997, -0.01200000000000001, 0.2789999999999999, 0.33499999999999996, -0.18100000000000005, 0.19199999999999995, 1.271, 0.371, 0.696, 0.3639999999999999, 0.889, 0.757, 0.43799999999999994, 0.705, -0.247, 0.401, 0.35199999999999987, -0.09299999999999997, 0.7919999999999999, 0.935, 0.794, 0.3320000000000001, 0.2610000000000001, 0.874], "episode_lengths": [78, 150, 300, 300, 133, 300, 29, 29, 123, 300, 300, 89, 300, 16, 300, 31, 13, 19, 14, 86, 65, 86, 189, 300, 123, 39, 23, 280, 209, 129, 108, 71, 78, 51, 181, 97, 300, 115, 40, 30, 109, 135, 101, 300, 102, 149, 261, 82, 31, 300, 110, 63, 300, 300, 300, 32, 129, 147, 95, 196, 128, 125, 140, 112, 29, 77, 161, 90, 135, 120, 37, 300, 81, 300, 104, 63, 126, 154, 221, 49, 57, 96, 70, 40, 93, 43, 35, 71, 20, 89, 75, 30, 198, 29, 60, 20, 62, 52, 72, 39], "policy_red_0_reward": [0.759, 1.03, 0.46199999999999997, 0.46499999999999997, -0.516, -0.027000000000000017, 1.4100000000000001, 0.909, 0.611, 0.46399999999999997, -0.04400000000000003, 0.489, 0.44299999999999995, 1.452, 0.45299999999999996, 1.405, 1.4609999999999999, 1.4409999999999998, 0.958, 0.728, -1.015, 0.491, -0.026000000000000016, 0.45799999999999996, 1.109, 1.3820000000000001, 0.929, 0.6349999999999999, 0.842, 1.103, -0.507, 1.2770000000000001, 1.244, -1.006, 0.938, -0.017000000000000008, -0.04100000000000003, 1.141, -0.505, -1.003, -1.015, 0.582, 1.183, 0.44999999999999996, 0.6739999999999999, -0.5159999999999999, 0.6849999999999999, 1.242, 1.405, 0.46499999999999997, 1.157, 1.3039999999999998, 0.46299999999999997, 0.471, 0.46799999999999997, -0.503, 1.095, 0.5399999999999999, 1.194, 0.892, 0.599, 0.479, 1.059, -0.5169999999999999, -1.003, 0.49, 0.491, 1.217, 1.077, 1.1219999999999999, 0.882, 0.44899999999999995, -0.5099999999999999, 0.44699999999999995, 0.6659999999999999, -0.507, 0.6, 1.005, -0.532, 1.3439999999999999, 0.824, 0.702, -0.008, -0.504, 1.2069999999999999, 1.369, -0.503, -0.516, 0.94, -0.51, 0.763, 1.403, -0.528, 0.91, -0.511, 1.439, 1.3090000000000002, -1.0059999999999998, 0.771, -0.504], "policy_blue_0_reward": [-0.512, -0.528, 0.44399999999999995, 0.45799999999999996, 1.083, 0.44899999999999995, -1.004, -1.003, -0.519, 0.46099999999999997, 0.46399999999999997, 1.222, 0.45399999999999996, -1.006, 0.44899999999999995, -1.005, -1.007, -1.002, -1.001, -0.504, 1.2999999999999998, 1.232, 0.8939999999999999, 0.44199999999999995, -0.516, -1.009, -1.001, 0.469, 0.46799999999999997, -0.52, 1.162, -1.014, -0.511, 0.842, -0.53, 1.1960000000000002, 0.45499999999999996, -0.523, 0.878, 0.904, 1.159, -0.522, -0.514, -0.035000000000000024, -1.01, 1.029, -0.533, -0.508, -1.007, 0.45699999999999996, -0.512, -1.008, 0.45499999999999996, 0.45399999999999996, 0.45899999999999996, 1.403, -0.517, -1.0239999999999998, -0.511, -0.536, -1.019, 1.105, -0.516, 1.156, 0.911, 1.263, -0.525, -0.509, -0.515, -0.517, -0.505, 0.46599999999999997, 1.25, 0.46199999999999997, -1.011, 1.302, -0.513, -1.017, 0.8109999999999999, -1.009, -1.005, -0.51, 1.279, 0.875, -0.511, -1.005, 1.392, 1.2730000000000001, -0.502, 1.2149999999999999, -1.01, -1.002, 0.8799999999999999, -1.003, 1.303, -0.504, -0.515, 1.338, -0.51, 1.3780000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3391779615743835, "mean_inference_ms": 7.34054069912057, "mean_action_processing_ms": 0.3946718929006224, "mean_env_wait_ms": 0.5062547501571062, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14649200439453125, "StateBufferConnector_ms": 0.009437918663024902, "ViewRequirementAgentConnector_ms": 0.19192910194396973}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 118.69647549089774, "num_env_steps_trained_throughput_per_sec": 118.69647549089774, "timesteps_total": 84000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 168000, "timers": {"training_iteration_time_ms": 31362.202, "sample_time_ms": 3980.226, "learn_time_ms": 27346.462, "learn_throughput": 146.271, "synch_weights_time_ms": 33.813}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "done": false, "episodes_total": 523, "training_iteration": 21, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-07-29", "timestamp": 1694837249, "time_this_iter_s": 33.71617817878723, "time_total_s": 632.2396264076233, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7239e0e0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 632.2396264076233, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 28.406122448979595, "ram_util_percent": 56.60408163265307}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.6, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.23, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.05, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.23, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.23, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5456222079694271, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08066560216860429, "policy_loss": -0.11153129229254168, "vf_loss": 0.010813457009013898, "vf_explained_var": 0.5399451830734809, "kl": 0.017906404769090993, "entropy": 1.7363899269451697, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 20640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5176529818214476, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08762223665156246, "policy_loss": -0.11809551091137109, "vf_loss": 0.012899820742071218, "vf_explained_var": 0.5943235231563448, "kl": 0.01699429733964924, "entropy": 1.7867245697726806, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 20640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "sampler_results": {"episode_reward_max": 1.7530000000000001, "episode_reward_min": -0.484, "episode_reward_mean": 0.47909000000000007, "episode_len_mean": 120.35, "episode_media": {}, "episodes_this_iter": 30, "policy_reward_min": {"red_0": -1.015, "blue_0": -1.036}, "policy_reward_max": {"red_0": 1.444, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.5313599999999999, "blue_0": -0.05226999999999997}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.6, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.23, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.05, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.23, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.23, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.6549999999999999, 0.2629999999999999, 0.7330000000000001, -0.16399999999999992, 0.4079999999999999, 1.179, 0.4139999999999999, 0.6179999999999999, 0.373, -0.09899999999999987, 0.14400000000000002, 0.06000000000000005, 0.669, 0.4149999999999999, -0.3360000000000001, 0.513, 0.1519999999999999, 0.734, 0.39800000000000013, 0.9219999999999999, 0.645, 0.2959999999999998, 0.9179999999999999, 0.9249999999999999, 0.9269999999999999, 0.9, 0.5779999999999998, -0.484, 0.683, 0.35599999999999987, -0.42000000000000004, 1.584, 0.5429999999999999, 0.639, -0.09199999999999986, 1.7530000000000001, -0.03400000000000003, 0.708, 0.5619999999999998, 0.605, 0.377, 0.9149999999999999, 0.7400000000000001, 0.9089999999999999, -0.3450000000000001, 0.7949999999999999, 0.08699999999999997, -0.01200000000000001, 0.2789999999999999, 0.33499999999999996, -0.18100000000000005, 0.19199999999999995, 1.271, 0.371, 0.696, 0.3639999999999999, 0.889, 0.757, 0.43799999999999994, 0.705, -0.247, 0.401, 0.35199999999999987, -0.09299999999999997, 0.7919999999999999, 0.935, 0.794, 0.3320000000000001, 0.2610000000000001, 0.874, 0.3770000000000001, 0.3979999999999999, 0.18199999999999994, 0.15800000000000014, 0.7610000000000001, -0.12, 0.825, 0.9179999999999999, 0.891, 0.9289999999999999, 0.32499999999999996, 0.07799999999999985, 0.869, 0.942, 0.4159999999999999, -0.3440000000000001, 0.32600000000000007, 0.702, 0.3420000000000001, -0.03200000000000014, 1.589, -0.05399999999999994, 0.33899999999999997, 0.796, 0.45999999999999996, 0.34299999999999997, 0.33999999999999986, 0.391, 0.23099999999999987, 0.9049999999999999], "episode_lengths": [108, 71, 78, 51, 181, 97, 300, 115, 40, 30, 109, 135, 101, 300, 102, 149, 261, 82, 31, 300, 110, 63, 300, 300, 300, 32, 129, 147, 95, 196, 128, 125, 140, 112, 29, 77, 161, 90, 135, 120, 37, 300, 81, 300, 104, 63, 126, 154, 221, 49, 57, 96, 70, 40, 93, 43, 35, 71, 20, 89, 75, 30, 198, 29, 60, 20, 62, 52, 72, 39, 190, 300, 249, 103, 72, 38, 55, 300, 33, 300, 54, 130, 39, 17, 26, 261, 207, 91, 49, 165, 129, 16, 49, 64, 162, 49, 204, 34, 233, 300], "policy_red_0_reward": [-0.507, 1.2770000000000001, 1.244, -1.006, 0.938, -0.017000000000000008, -0.04100000000000003, 1.141, -0.505, -1.003, -1.015, 0.582, 1.183, 0.44999999999999996, 0.6739999999999999, -0.5159999999999999, 0.6849999999999999, 1.242, 1.405, 0.46499999999999997, 1.157, 1.3039999999999998, 0.46299999999999997, 0.471, 0.46799999999999997, -0.503, 1.095, 0.5399999999999999, 1.194, 0.892, 0.599, 0.479, 1.059, -0.5169999999999999, -1.003, 0.49, 0.491, 1.217, 1.077, 1.1219999999999999, 0.882, 0.44899999999999995, -0.5099999999999999, 0.44699999999999995, 0.6659999999999999, -0.507, 0.6, 1.005, -0.532, 1.3439999999999999, 0.824, 0.702, -0.008, -0.504, 1.2069999999999999, 1.369, -0.503, -0.516, 0.94, -0.51, 0.763, 1.403, -0.528, 0.91, -0.511, 1.439, 1.3090000000000002, -1.0059999999999998, 0.771, -0.504, -0.5309999999999999, -0.05300000000000004, 0.716, 1.174, 1.27, -1.003, 1.33, 0.45499999999999996, 1.399, 0.46099999999999997, 1.329, 0.596, 1.3780000000000001, 1.444, 0.918, 0.692, 0.848, 1.214, 1.346, 0.9869999999999999, 0.482, 0.948, 0.847, 1.303, 0.988, 0.849, -0.53, 1.3940000000000001, 0.772, 0.45099999999999996], "policy_blue_0_reward": [1.162, -1.014, -0.511, 0.842, -0.53, 1.1960000000000002, 0.45499999999999996, -0.523, 0.878, 0.904, 1.159, -0.522, -0.514, -0.035000000000000024, -1.01, 1.029, -0.533, -0.508, -1.007, 0.45699999999999996, -0.512, -1.008, 0.45499999999999996, 0.45399999999999996, 0.45899999999999996, 1.403, -0.517, -1.0239999999999998, -0.511, -0.536, -1.019, 1.105, -0.516, 1.156, 0.911, 1.263, -0.525, -0.509, -0.515, -0.517, -0.505, 0.46599999999999997, 1.25, 0.46199999999999997, -1.011, 1.302, -0.513, -1.017, 0.8109999999999999, -1.009, -1.005, -0.51, 1.279, 0.875, -0.511, -1.005, 1.392, 1.2730000000000001, -0.502, 1.2149999999999999, -1.01, -1.002, 0.8799999999999999, -1.003, 1.303, -0.504, -0.515, 1.338, -0.51, 1.3780000000000001, 0.908, 0.45099999999999996, -0.534, -1.0159999999999998, -0.509, 0.883, -0.505, 0.46299999999999997, -0.508, 0.46799999999999997, -1.004, -0.518, -0.509, -0.502, -0.502, -1.036, -0.522, -0.512, -1.004, -1.019, 1.107, -1.0019999999999998, -0.508, -0.507, -0.528, -0.506, 0.8699999999999999, -1.003, -0.541, 0.45399999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3422152358301274, "mean_inference_ms": 7.357179416293374, "mean_action_processing_ms": 0.3962523128152076, "mean_env_wait_ms": 0.5071288585021412, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15173184871673584, "StateBufferConnector_ms": 0.00966334342956543, "ViewRequirementAgentConnector_ms": 0.19395756721496582}}, "episode_reward_max": 1.7530000000000001, "episode_reward_min": -0.484, "episode_reward_mean": 0.47909000000000007, "episode_len_mean": 120.35, "episodes_this_iter": 30, "policy_reward_min": {"red_0": -1.015, "blue_0": -1.036}, "policy_reward_max": {"red_0": 1.444, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.5313599999999999, "blue_0": -0.05226999999999997}, "hist_stats": {"episode_reward": [0.6549999999999999, 0.2629999999999999, 0.7330000000000001, -0.16399999999999992, 0.4079999999999999, 1.179, 0.4139999999999999, 0.6179999999999999, 0.373, -0.09899999999999987, 0.14400000000000002, 0.06000000000000005, 0.669, 0.4149999999999999, -0.3360000000000001, 0.513, 0.1519999999999999, 0.734, 0.39800000000000013, 0.9219999999999999, 0.645, 0.2959999999999998, 0.9179999999999999, 0.9249999999999999, 0.9269999999999999, 0.9, 0.5779999999999998, -0.484, 0.683, 0.35599999999999987, -0.42000000000000004, 1.584, 0.5429999999999999, 0.639, -0.09199999999999986, 1.7530000000000001, -0.03400000000000003, 0.708, 0.5619999999999998, 0.605, 0.377, 0.9149999999999999, 0.7400000000000001, 0.9089999999999999, -0.3450000000000001, 0.7949999999999999, 0.08699999999999997, -0.01200000000000001, 0.2789999999999999, 0.33499999999999996, -0.18100000000000005, 0.19199999999999995, 1.271, 0.371, 0.696, 0.3639999999999999, 0.889, 0.757, 0.43799999999999994, 0.705, -0.247, 0.401, 0.35199999999999987, -0.09299999999999997, 0.7919999999999999, 0.935, 0.794, 0.3320000000000001, 0.2610000000000001, 0.874, 0.3770000000000001, 0.3979999999999999, 0.18199999999999994, 0.15800000000000014, 0.7610000000000001, -0.12, 0.825, 0.9179999999999999, 0.891, 0.9289999999999999, 0.32499999999999996, 0.07799999999999985, 0.869, 0.942, 0.4159999999999999, -0.3440000000000001, 0.32600000000000007, 0.702, 0.3420000000000001, -0.03200000000000014, 1.589, -0.05399999999999994, 0.33899999999999997, 0.796, 0.45999999999999996, 0.34299999999999997, 0.33999999999999986, 0.391, 0.23099999999999987, 0.9049999999999999], "episode_lengths": [108, 71, 78, 51, 181, 97, 300, 115, 40, 30, 109, 135, 101, 300, 102, 149, 261, 82, 31, 300, 110, 63, 300, 300, 300, 32, 129, 147, 95, 196, 128, 125, 140, 112, 29, 77, 161, 90, 135, 120, 37, 300, 81, 300, 104, 63, 126, 154, 221, 49, 57, 96, 70, 40, 93, 43, 35, 71, 20, 89, 75, 30, 198, 29, 60, 20, 62, 52, 72, 39, 190, 300, 249, 103, 72, 38, 55, 300, 33, 300, 54, 130, 39, 17, 26, 261, 207, 91, 49, 165, 129, 16, 49, 64, 162, 49, 204, 34, 233, 300], "policy_red_0_reward": [-0.507, 1.2770000000000001, 1.244, -1.006, 0.938, -0.017000000000000008, -0.04100000000000003, 1.141, -0.505, -1.003, -1.015, 0.582, 1.183, 0.44999999999999996, 0.6739999999999999, -0.5159999999999999, 0.6849999999999999, 1.242, 1.405, 0.46499999999999997, 1.157, 1.3039999999999998, 0.46299999999999997, 0.471, 0.46799999999999997, -0.503, 1.095, 0.5399999999999999, 1.194, 0.892, 0.599, 0.479, 1.059, -0.5169999999999999, -1.003, 0.49, 0.491, 1.217, 1.077, 1.1219999999999999, 0.882, 0.44899999999999995, -0.5099999999999999, 0.44699999999999995, 0.6659999999999999, -0.507, 0.6, 1.005, -0.532, 1.3439999999999999, 0.824, 0.702, -0.008, -0.504, 1.2069999999999999, 1.369, -0.503, -0.516, 0.94, -0.51, 0.763, 1.403, -0.528, 0.91, -0.511, 1.439, 1.3090000000000002, -1.0059999999999998, 0.771, -0.504, -0.5309999999999999, -0.05300000000000004, 0.716, 1.174, 1.27, -1.003, 1.33, 0.45499999999999996, 1.399, 0.46099999999999997, 1.329, 0.596, 1.3780000000000001, 1.444, 0.918, 0.692, 0.848, 1.214, 1.346, 0.9869999999999999, 0.482, 0.948, 0.847, 1.303, 0.988, 0.849, -0.53, 1.3940000000000001, 0.772, 0.45099999999999996], "policy_blue_0_reward": [1.162, -1.014, -0.511, 0.842, -0.53, 1.1960000000000002, 0.45499999999999996, -0.523, 0.878, 0.904, 1.159, -0.522, -0.514, -0.035000000000000024, -1.01, 1.029, -0.533, -0.508, -1.007, 0.45699999999999996, -0.512, -1.008, 0.45499999999999996, 0.45399999999999996, 0.45899999999999996, 1.403, -0.517, -1.0239999999999998, -0.511, -0.536, -1.019, 1.105, -0.516, 1.156, 0.911, 1.263, -0.525, -0.509, -0.515, -0.517, -0.505, 0.46599999999999997, 1.25, 0.46199999999999997, -1.011, 1.302, -0.513, -1.017, 0.8109999999999999, -1.009, -1.005, -0.51, 1.279, 0.875, -0.511, -1.005, 1.392, 1.2730000000000001, -0.502, 1.2149999999999999, -1.01, -1.002, 0.8799999999999999, -1.003, 1.303, -0.504, -0.515, 1.338, -0.51, 1.3780000000000001, 0.908, 0.45099999999999996, -0.534, -1.0159999999999998, -0.509, 0.883, -0.505, 0.46299999999999997, -0.508, 0.46799999999999997, -1.004, -0.518, -0.509, -0.502, -0.502, -1.036, -0.522, -0.512, -1.004, -1.019, 1.107, -1.0019999999999998, -0.508, -0.507, -0.528, -0.506, 0.8699999999999999, -1.003, -0.541, 0.45399999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3422152358301274, "mean_inference_ms": 7.357179416293374, "mean_action_processing_ms": 0.3962523128152076, "mean_env_wait_ms": 0.5071288585021412, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15173184871673584, "StateBufferConnector_ms": 0.00966334342956543, "ViewRequirementAgentConnector_ms": 0.19395756721496582}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.88994139313262, "num_env_steps_trained_throughput_per_sec": 127.88994139313262, "timesteps_total": 88000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 31451.166, "sample_time_ms": 3989.702, "learn_time_ms": 27426.137, "learn_throughput": 145.846, "synch_weights_time_ms": 33.624}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "episodes_total": 553, "training_iteration": 22, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-08-02", "timestamp": 1694837282, "time_this_iter_s": 31.29249405860901, "time_total_s": 663.5321204662323, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7234a290>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 663.5321204662323, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 25.1608695652174, "ram_util_percent": 56.66956521739129}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.61, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.25, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.61, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.05, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.25, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.61, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.25, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.524184035199384, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08130893099684423, "policy_loss": -0.1130678025103407, "vf_loss": 0.011146892581988747, "vf_explained_var": 0.5495283442238966, "kl": 0.01839130085453416, "entropy": 1.7463619905213514, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 21600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5388033163733781, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08440347280314503, "policy_loss": -0.11391753056329132, "vf_loss": 0.011614026847867838, "vf_explained_var": 0.6439966077605883, "kl": 0.0167867276167881, "entropy": 1.787798195456465, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 21600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000}, "sampler_results": {"episode_reward_max": 1.7530000000000001, "episode_reward_min": -0.4650000000000001, "episode_reward_mean": 0.44529999999999986, "episode_len_mean": 117.77, "episode_media": {}, "episodes_this_iter": 30, "policy_reward_min": {"red_0": -1.024, "blue_0": -1.038}, "policy_reward_max": {"red_0": 1.444, "blue_0": 1.392}, "policy_reward_mean": {"red_0": 0.50774, "blue_0": -0.06244000000000001}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.61, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.25, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.61, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.05, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.25, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.61, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.25, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.42000000000000004, 1.584, 0.5429999999999999, 0.639, -0.09199999999999986, 1.7530000000000001, -0.03400000000000003, 0.708, 0.5619999999999998, 0.605, 0.377, 0.9149999999999999, 0.7400000000000001, 0.9089999999999999, -0.3450000000000001, 0.7949999999999999, 0.08699999999999997, -0.01200000000000001, 0.2789999999999999, 0.33499999999999996, -0.18100000000000005, 0.19199999999999995, 1.271, 0.371, 0.696, 0.3639999999999999, 0.889, 0.757, 0.43799999999999994, 0.705, -0.247, 0.401, 0.35199999999999987, -0.09299999999999997, 0.7919999999999999, 0.935, 0.794, 0.3320000000000001, 0.2610000000000001, 0.874, 0.3770000000000001, 0.3979999999999999, 0.18199999999999994, 0.15800000000000014, 0.7610000000000001, -0.12, 0.825, 0.9179999999999999, 0.891, 0.9289999999999999, 0.32499999999999996, 0.07799999999999985, 0.869, 0.942, 0.4159999999999999, -0.3440000000000001, 0.32600000000000007, 0.702, 0.3420000000000001, -0.03200000000000014, 1.589, -0.05399999999999994, 0.33899999999999997, 0.796, 0.45999999999999996, 0.34299999999999997, 0.33999999999999986, 0.391, 0.23099999999999987, 0.9049999999999999, -0.026000000000000023, -0.2599999999999999, 0.241, 0.15600000000000014, -0.21800000000000008, 0.22699999999999987, 1.745, 0.05500000000000016, 0.20299999999999996, 0.9209999999999999, 0.698, -0.16900000000000004, -0.118, 0.8019999999999999, 0.2849999999999999, 0.9059999999999999, 0.22399999999999998, 0.6989999999999998, 0.8570000000000002, 0.20900000000000007, 0.9039999999999999, 0.5589999999999999, -0.4650000000000001, 0.121, -0.19600000000000006, -0.118, 0.43399999999999994, 0.40700000000000003, 0.609, 0.724], "episode_lengths": [128, 125, 140, 112, 29, 77, 161, 90, 135, 120, 37, 300, 81, 300, 104, 63, 126, 154, 221, 49, 57, 96, 70, 40, 93, 43, 35, 71, 20, 89, 75, 30, 198, 29, 60, 20, 62, 52, 72, 39, 190, 300, 249, 103, 72, 38, 55, 300, 33, 300, 54, 130, 39, 17, 26, 261, 207, 91, 49, 165, 129, 16, 49, 64, 162, 49, 204, 34, 233, 300, 161, 77, 232, 104, 222, 84, 78, 136, 245, 300, 93, 52, 36, 60, 67, 300, 239, 91, 45, 89, 300, 137, 141, 113, 212, 37, 170, 29, 120, 85], "policy_red_0_reward": [0.599, 0.479, 1.059, -0.5169999999999999, -1.003, 0.49, 0.491, 1.217, 1.077, 1.1219999999999999, 0.882, 0.44899999999999995, -0.5099999999999999, 0.44699999999999995, 0.6659999999999999, -0.507, 0.6, 1.005, -0.532, 1.3439999999999999, 0.824, 0.702, -0.008, -0.504, 1.2069999999999999, 1.369, -0.503, -0.516, 0.94, -0.51, 0.763, 1.403, -0.528, 0.91, -0.511, 1.439, 1.3090000000000002, -1.0059999999999998, 0.771, -0.504, -0.5309999999999999, -0.05300000000000004, 0.716, 1.174, 1.27, -1.003, 1.33, 0.45499999999999996, 1.399, 0.46099999999999997, 1.329, 0.596, 1.3780000000000001, 1.444, 0.918, 0.692, 0.848, 1.214, 1.346, 0.9869999999999999, 0.482, 0.948, 0.847, 1.303, 0.988, 0.849, -0.53, 1.3940000000000001, 0.772, 0.45099999999999996, 0.496, -1.01, -0.53, 0.6709999999999999, 0.8079999999999999, 1.237, 0.493, 0.5720000000000001, -0.535, 0.45799999999999996, -0.512, 0.839, 0.886, -0.51, -0.507, 0.45699999999999996, 0.753, 1.212, 1.363, 0.721, 0.45999999999999996, 1.075, -1.022, -1.024, 0.842, 0.885, 0.967, -0.503, 1.121, 1.232], "policy_blue_0_reward": [-1.019, 1.105, -0.516, 1.156, 0.911, 1.263, -0.525, -0.509, -0.515, -0.517, -0.505, 0.46599999999999997, 1.25, 0.46199999999999997, -1.011, 1.302, -0.513, -1.017, 0.8109999999999999, -1.009, -1.005, -0.51, 1.279, 0.875, -0.511, -1.005, 1.392, 1.2730000000000001, -0.502, 1.2149999999999999, -1.01, -1.002, 0.8799999999999999, -1.003, 1.303, -0.504, -0.515, 1.338, -0.51, 1.3780000000000001, 0.908, 0.45099999999999996, -0.534, -1.0159999999999998, -0.509, 0.883, -0.505, 0.46299999999999997, -0.508, 0.46799999999999997, -1.004, -0.518, -0.509, -0.502, -0.502, -1.036, -0.522, -0.512, -1.004, -1.019, 1.107, -1.0019999999999998, -0.508, -0.507, -0.528, -0.506, 0.8699999999999999, -1.003, -0.541, 0.45399999999999996, -0.522, 0.75, 0.771, -0.5149999999999999, -1.026, -1.01, 1.252, -0.517, 0.738, 0.46299999999999997, 1.21, -1.008, -1.004, 1.3119999999999998, 0.7919999999999999, 0.44899999999999995, -0.529, -0.513, -0.5059999999999999, -0.512, 0.44399999999999995, -0.516, 0.5569999999999999, 1.145, -1.038, -1.003, -0.533, 0.91, -0.5119999999999999, -0.508]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3450448145361127, "mean_inference_ms": 7.369476618059473, "mean_action_processing_ms": 0.39636979180678095, "mean_env_wait_ms": 0.5084625173956381, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1510934829711914, "StateBufferConnector_ms": 0.00956869125366211, "ViewRequirementAgentConnector_ms": 0.19421815872192383}}, "episode_reward_max": 1.7530000000000001, "episode_reward_min": -0.4650000000000001, "episode_reward_mean": 0.44529999999999986, "episode_len_mean": 117.77, "episodes_this_iter": 30, "policy_reward_min": {"red_0": -1.024, "blue_0": -1.038}, "policy_reward_max": {"red_0": 1.444, "blue_0": 1.392}, "policy_reward_mean": {"red_0": 0.50774, "blue_0": -0.06244000000000001}, "hist_stats": {"episode_reward": [-0.42000000000000004, 1.584, 0.5429999999999999, 0.639, -0.09199999999999986, 1.7530000000000001, -0.03400000000000003, 0.708, 0.5619999999999998, 0.605, 0.377, 0.9149999999999999, 0.7400000000000001, 0.9089999999999999, -0.3450000000000001, 0.7949999999999999, 0.08699999999999997, -0.01200000000000001, 0.2789999999999999, 0.33499999999999996, -0.18100000000000005, 0.19199999999999995, 1.271, 0.371, 0.696, 0.3639999999999999, 0.889, 0.757, 0.43799999999999994, 0.705, -0.247, 0.401, 0.35199999999999987, -0.09299999999999997, 0.7919999999999999, 0.935, 0.794, 0.3320000000000001, 0.2610000000000001, 0.874, 0.3770000000000001, 0.3979999999999999, 0.18199999999999994, 0.15800000000000014, 0.7610000000000001, -0.12, 0.825, 0.9179999999999999, 0.891, 0.9289999999999999, 0.32499999999999996, 0.07799999999999985, 0.869, 0.942, 0.4159999999999999, -0.3440000000000001, 0.32600000000000007, 0.702, 0.3420000000000001, -0.03200000000000014, 1.589, -0.05399999999999994, 0.33899999999999997, 0.796, 0.45999999999999996, 0.34299999999999997, 0.33999999999999986, 0.391, 0.23099999999999987, 0.9049999999999999, -0.026000000000000023, -0.2599999999999999, 0.241, 0.15600000000000014, -0.21800000000000008, 0.22699999999999987, 1.745, 0.05500000000000016, 0.20299999999999996, 0.9209999999999999, 0.698, -0.16900000000000004, -0.118, 0.8019999999999999, 0.2849999999999999, 0.9059999999999999, 0.22399999999999998, 0.6989999999999998, 0.8570000000000002, 0.20900000000000007, 0.9039999999999999, 0.5589999999999999, -0.4650000000000001, 0.121, -0.19600000000000006, -0.118, 0.43399999999999994, 0.40700000000000003, 0.609, 0.724], "episode_lengths": [128, 125, 140, 112, 29, 77, 161, 90, 135, 120, 37, 300, 81, 300, 104, 63, 126, 154, 221, 49, 57, 96, 70, 40, 93, 43, 35, 71, 20, 89, 75, 30, 198, 29, 60, 20, 62, 52, 72, 39, 190, 300, 249, 103, 72, 38, 55, 300, 33, 300, 54, 130, 39, 17, 26, 261, 207, 91, 49, 165, 129, 16, 49, 64, 162, 49, 204, 34, 233, 300, 161, 77, 232, 104, 222, 84, 78, 136, 245, 300, 93, 52, 36, 60, 67, 300, 239, 91, 45, 89, 300, 137, 141, 113, 212, 37, 170, 29, 120, 85], "policy_red_0_reward": [0.599, 0.479, 1.059, -0.5169999999999999, -1.003, 0.49, 0.491, 1.217, 1.077, 1.1219999999999999, 0.882, 0.44899999999999995, -0.5099999999999999, 0.44699999999999995, 0.6659999999999999, -0.507, 0.6, 1.005, -0.532, 1.3439999999999999, 0.824, 0.702, -0.008, -0.504, 1.2069999999999999, 1.369, -0.503, -0.516, 0.94, -0.51, 0.763, 1.403, -0.528, 0.91, -0.511, 1.439, 1.3090000000000002, -1.0059999999999998, 0.771, -0.504, -0.5309999999999999, -0.05300000000000004, 0.716, 1.174, 1.27, -1.003, 1.33, 0.45499999999999996, 1.399, 0.46099999999999997, 1.329, 0.596, 1.3780000000000001, 1.444, 0.918, 0.692, 0.848, 1.214, 1.346, 0.9869999999999999, 0.482, 0.948, 0.847, 1.303, 0.988, 0.849, -0.53, 1.3940000000000001, 0.772, 0.45099999999999996, 0.496, -1.01, -0.53, 0.6709999999999999, 0.8079999999999999, 1.237, 0.493, 0.5720000000000001, -0.535, 0.45799999999999996, -0.512, 0.839, 0.886, -0.51, -0.507, 0.45699999999999996, 0.753, 1.212, 1.363, 0.721, 0.45999999999999996, 1.075, -1.022, -1.024, 0.842, 0.885, 0.967, -0.503, 1.121, 1.232], "policy_blue_0_reward": [-1.019, 1.105, -0.516, 1.156, 0.911, 1.263, -0.525, -0.509, -0.515, -0.517, -0.505, 0.46599999999999997, 1.25, 0.46199999999999997, -1.011, 1.302, -0.513, -1.017, 0.8109999999999999, -1.009, -1.005, -0.51, 1.279, 0.875, -0.511, -1.005, 1.392, 1.2730000000000001, -0.502, 1.2149999999999999, -1.01, -1.002, 0.8799999999999999, -1.003, 1.303, -0.504, -0.515, 1.338, -0.51, 1.3780000000000001, 0.908, 0.45099999999999996, -0.534, -1.0159999999999998, -0.509, 0.883, -0.505, 0.46299999999999997, -0.508, 0.46799999999999997, -1.004, -0.518, -0.509, -0.502, -0.502, -1.036, -0.522, -0.512, -1.004, -1.019, 1.107, -1.0019999999999998, -0.508, -0.507, -0.528, -0.506, 0.8699999999999999, -1.003, -0.541, 0.45399999999999996, -0.522, 0.75, 0.771, -0.5149999999999999, -1.026, -1.01, 1.252, -0.517, 0.738, 0.46299999999999997, 1.21, -1.008, -1.004, 1.3119999999999998, 0.7919999999999999, 0.44899999999999995, -0.529, -0.513, -0.5059999999999999, -0.512, 0.44399999999999995, -0.516, 0.5569999999999999, 1.145, -1.038, -1.003, -0.533, 0.91, -0.5119999999999999, -0.508]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3450448145361127, "mean_inference_ms": 7.369476618059473, "mean_action_processing_ms": 0.39636979180678095, "mean_env_wait_ms": 0.5084625173956381, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1510934829711914, "StateBufferConnector_ms": 0.00956869125366211, "ViewRequirementAgentConnector_ms": 0.19421815872192383}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.71601666006316, "num_env_steps_trained_throughput_per_sec": 129.71601666006316, "timesteps_total": 92000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 184000, "timers": {"training_iteration_time_ms": 31403.117, "sample_time_ms": 3976.472, "learn_time_ms": 27391.548, "learn_throughput": 146.03, "synch_weights_time_ms": 33.453}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000}, "done": false, "episodes_total": 583, "training_iteration": 23, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-08-33", "timestamp": 1694837313, "time_this_iter_s": 30.852618932724, "time_total_s": 694.3847393989563, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7239ef80>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 694.3847393989563, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 25.424999999999997, "ram_util_percent": 56.68181818181818}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.63, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.25, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.63, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.04, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.25, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.63, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.25, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5327695267274976, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07254289081320167, "policy_loss": -0.10469084435680998, "vf_loss": 0.018444022437324747, "vf_explained_var": 0.5430325293913484, "kl": 0.016236495786012467, "entropy": 1.7332350394378107, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 22560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5219590974971652, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08377373717376031, "policy_loss": -0.11840222199340739, "vf_loss": 0.02009945611061994, "vf_explained_var": 0.5934039465462168, "kl": 0.01734508661847105, "entropy": 1.764092683295409, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 22560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "sampler_results": {"episode_reward_max": 1.7570000000000001, "episode_reward_min": -0.508, "episode_reward_mean": 0.42717999999999995, "episode_len_mean": 116.09, "episode_media": {}, "episodes_this_iter": 42, "policy_reward_min": {"red_0": -1.024, "blue_0": -1.038}, "policy_reward_max": {"red_0": 1.444, "blue_0": 1.45}, "policy_reward_mean": {"red_0": 0.51538, "blue_0": -0.08819999999999995}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.63, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.25, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.63, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.04, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.25, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.63, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.25, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.18199999999999994, 0.15800000000000014, 0.7610000000000001, -0.12, 0.825, 0.9179999999999999, 0.891, 0.9289999999999999, 0.32499999999999996, 0.07799999999999985, 0.869, 0.942, 0.4159999999999999, -0.3440000000000001, 0.32600000000000007, 0.702, 0.3420000000000001, -0.03200000000000014, 1.589, -0.05399999999999994, 0.33899999999999997, 0.796, 0.45999999999999996, 0.34299999999999997, 0.33999999999999986, 0.391, 0.23099999999999987, 0.9049999999999999, -0.026000000000000023, -0.2599999999999999, 0.241, 0.15600000000000014, -0.21800000000000008, 0.22699999999999987, 1.745, 0.05500000000000016, 0.20299999999999996, 0.9209999999999999, 0.698, -0.16900000000000004, -0.118, 0.8019999999999999, 0.2849999999999999, 0.9059999999999999, 0.22399999999999998, 0.6989999999999998, 0.8570000000000002, 0.20900000000000007, 0.9039999999999999, 0.5589999999999999, -0.4650000000000001, 0.121, -0.19600000000000006, -0.118, 0.43399999999999994, 0.40700000000000003, 0.609, 0.724, -0.28500000000000014, 0.399, 0.893, 0.6540000000000001, 0.6669999999999998, 0.915, 0.573, -0.17699999999999994, 0.809, 0.41900000000000004, 0.7090000000000001, 0.28400000000000003, 1.7570000000000001, 0.15300000000000002, 1.734, 0.401, 0.31800000000000006, 0.7269999999999999, -0.10499999999999998, 0.6160000000000001, -0.259, 0.2889999999999999, 0.33999999999999986, 0.42300000000000004, 0.44999999999999996, 0.4169999999999999, 0.42100000000000026, 0.5209999999999999, 0.41800000000000004, 0.7639999999999998, 0.41100000000000003, 0.20200000000000007, -0.508, 0.007999999999999896, -0.19300000000000006, 0.3919999999999999, 0.871, -0.031000000000000028, 0.9189999999999999, 0.4019999999999999, 0.2370000000000001, 0.839], "episode_lengths": [249, 103, 72, 38, 55, 300, 33, 300, 54, 130, 39, 17, 26, 261, 207, 91, 49, 165, 129, 16, 49, 64, 162, 49, 204, 34, 233, 300, 161, 77, 232, 104, 222, 84, 78, 136, 245, 300, 93, 52, 36, 60, 67, 300, 239, 91, 45, 89, 300, 137, 141, 113, 212, 37, 170, 29, 120, 85, 240, 183, 34, 105, 100, 27, 130, 52, 58, 25, 90, 68, 74, 104, 79, 32, 55, 84, 32, 118, 232, 213, 202, 25, 16, 300, 25, 147, 25, 73, 27, 91, 155, 146, 59, 32, 40, 10, 300, 185, 82, 50], "policy_red_0_reward": [0.716, 1.174, 1.27, -1.003, 1.33, 0.45499999999999996, 1.399, 0.46099999999999997, 1.329, 0.596, 1.3780000000000001, 1.444, 0.918, 0.692, 0.848, 1.214, 1.346, 0.9869999999999999, 0.482, 0.948, 0.847, 1.303, 0.988, 0.849, -0.53, 1.3940000000000001, 0.772, 0.45099999999999996, 0.496, -1.01, -0.53, 0.6709999999999999, 0.8079999999999999, 1.237, 0.493, 0.5720000000000001, -0.535, 0.45799999999999996, -0.512, 0.839, 0.886, -0.51, -0.507, 0.45699999999999996, 0.753, 1.212, 1.363, 0.721, 0.45999999999999996, 1.075, -1.022, -1.024, 0.842, 0.885, 0.967, -0.503, 1.121, 1.232, 0.24399999999999988, 0.9229999999999999, -0.501, -0.5189999999999999, 1.178, 1.416, 1.092, 0.831, -0.505, 0.922, 1.2149999999999999, -1.007, 0.489, 1.166, 0.481, 0.903, 1.326, 1.237, 0.899, 1.127, -0.531, -0.545, 0.872, 1.424, -1.0, 0.44899999999999995, 0.922, -0.517, -1.002, 1.274, -1.004, -1.0139999999999998, 0.5049999999999999, -1.023, -1.009, 0.896, 1.377, 0.97, 0.45799999999999996, 0.9249999999999999, 1.248, -0.507], "policy_blue_0_reward": [-0.534, -1.0159999999999998, -0.509, 0.883, -0.505, 0.46299999999999997, -0.508, 0.46799999999999997, -1.004, -0.518, -0.509, -0.502, -0.502, -1.036, -0.522, -0.512, -1.004, -1.019, 1.107, -1.0019999999999998, -0.508, -0.507, -0.528, -0.506, 0.8699999999999999, -1.003, -0.541, 0.45399999999999996, -0.522, 0.75, 0.771, -0.5149999999999999, -1.026, -1.01, 1.252, -0.517, 0.738, 0.46299999999999997, 1.21, -1.008, -1.004, 1.3119999999999998, 0.7919999999999999, 0.44899999999999995, -0.529, -0.513, -0.5059999999999999, -0.512, 0.44399999999999995, -0.516, 0.5569999999999999, 1.145, -1.038, -1.003, -0.533, 0.91, -0.5119999999999999, -0.508, -0.529, -0.524, 1.3940000000000001, 1.173, -0.511, -0.501, -0.519, -1.0079999999999998, 1.314, -0.503, -0.506, 1.291, 1.268, -1.013, 1.2530000000000001, -0.502, -1.008, -0.51, -1.004, -0.511, 0.272, 0.834, -0.532, -1.001, 1.45, -0.03200000000000002, -0.5009999999999999, 1.0379999999999998, 1.42, -0.51, 1.415, 1.216, -1.013, 1.031, 0.816, -0.504, -0.506, -1.001, 0.46099999999999997, -0.523, -1.011, 1.346]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3451471564889883, "mean_inference_ms": 7.375705733636501, "mean_action_processing_ms": 0.39745223711030925, "mean_env_wait_ms": 0.5085612222642905, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15788555145263672, "StateBufferConnector_ms": 0.00965738296508789, "ViewRequirementAgentConnector_ms": 0.19330203533172607}}, "episode_reward_max": 1.7570000000000001, "episode_reward_min": -0.508, "episode_reward_mean": 0.42717999999999995, "episode_len_mean": 116.09, "episodes_this_iter": 42, "policy_reward_min": {"red_0": -1.024, "blue_0": -1.038}, "policy_reward_max": {"red_0": 1.444, "blue_0": 1.45}, "policy_reward_mean": {"red_0": 0.51538, "blue_0": -0.08819999999999995}, "hist_stats": {"episode_reward": [0.18199999999999994, 0.15800000000000014, 0.7610000000000001, -0.12, 0.825, 0.9179999999999999, 0.891, 0.9289999999999999, 0.32499999999999996, 0.07799999999999985, 0.869, 0.942, 0.4159999999999999, -0.3440000000000001, 0.32600000000000007, 0.702, 0.3420000000000001, -0.03200000000000014, 1.589, -0.05399999999999994, 0.33899999999999997, 0.796, 0.45999999999999996, 0.34299999999999997, 0.33999999999999986, 0.391, 0.23099999999999987, 0.9049999999999999, -0.026000000000000023, -0.2599999999999999, 0.241, 0.15600000000000014, -0.21800000000000008, 0.22699999999999987, 1.745, 0.05500000000000016, 0.20299999999999996, 0.9209999999999999, 0.698, -0.16900000000000004, -0.118, 0.8019999999999999, 0.2849999999999999, 0.9059999999999999, 0.22399999999999998, 0.6989999999999998, 0.8570000000000002, 0.20900000000000007, 0.9039999999999999, 0.5589999999999999, -0.4650000000000001, 0.121, -0.19600000000000006, -0.118, 0.43399999999999994, 0.40700000000000003, 0.609, 0.724, -0.28500000000000014, 0.399, 0.893, 0.6540000000000001, 0.6669999999999998, 0.915, 0.573, -0.17699999999999994, 0.809, 0.41900000000000004, 0.7090000000000001, 0.28400000000000003, 1.7570000000000001, 0.15300000000000002, 1.734, 0.401, 0.31800000000000006, 0.7269999999999999, -0.10499999999999998, 0.6160000000000001, -0.259, 0.2889999999999999, 0.33999999999999986, 0.42300000000000004, 0.44999999999999996, 0.4169999999999999, 0.42100000000000026, 0.5209999999999999, 0.41800000000000004, 0.7639999999999998, 0.41100000000000003, 0.20200000000000007, -0.508, 0.007999999999999896, -0.19300000000000006, 0.3919999999999999, 0.871, -0.031000000000000028, 0.9189999999999999, 0.4019999999999999, 0.2370000000000001, 0.839], "episode_lengths": [249, 103, 72, 38, 55, 300, 33, 300, 54, 130, 39, 17, 26, 261, 207, 91, 49, 165, 129, 16, 49, 64, 162, 49, 204, 34, 233, 300, 161, 77, 232, 104, 222, 84, 78, 136, 245, 300, 93, 52, 36, 60, 67, 300, 239, 91, 45, 89, 300, 137, 141, 113, 212, 37, 170, 29, 120, 85, 240, 183, 34, 105, 100, 27, 130, 52, 58, 25, 90, 68, 74, 104, 79, 32, 55, 84, 32, 118, 232, 213, 202, 25, 16, 300, 25, 147, 25, 73, 27, 91, 155, 146, 59, 32, 40, 10, 300, 185, 82, 50], "policy_red_0_reward": [0.716, 1.174, 1.27, -1.003, 1.33, 0.45499999999999996, 1.399, 0.46099999999999997, 1.329, 0.596, 1.3780000000000001, 1.444, 0.918, 0.692, 0.848, 1.214, 1.346, 0.9869999999999999, 0.482, 0.948, 0.847, 1.303, 0.988, 0.849, -0.53, 1.3940000000000001, 0.772, 0.45099999999999996, 0.496, -1.01, -0.53, 0.6709999999999999, 0.8079999999999999, 1.237, 0.493, 0.5720000000000001, -0.535, 0.45799999999999996, -0.512, 0.839, 0.886, -0.51, -0.507, 0.45699999999999996, 0.753, 1.212, 1.363, 0.721, 0.45999999999999996, 1.075, -1.022, -1.024, 0.842, 0.885, 0.967, -0.503, 1.121, 1.232, 0.24399999999999988, 0.9229999999999999, -0.501, -0.5189999999999999, 1.178, 1.416, 1.092, 0.831, -0.505, 0.922, 1.2149999999999999, -1.007, 0.489, 1.166, 0.481, 0.903, 1.326, 1.237, 0.899, 1.127, -0.531, -0.545, 0.872, 1.424, -1.0, 0.44899999999999995, 0.922, -0.517, -1.002, 1.274, -1.004, -1.0139999999999998, 0.5049999999999999, -1.023, -1.009, 0.896, 1.377, 0.97, 0.45799999999999996, 0.9249999999999999, 1.248, -0.507], "policy_blue_0_reward": [-0.534, -1.0159999999999998, -0.509, 0.883, -0.505, 0.46299999999999997, -0.508, 0.46799999999999997, -1.004, -0.518, -0.509, -0.502, -0.502, -1.036, -0.522, -0.512, -1.004, -1.019, 1.107, -1.0019999999999998, -0.508, -0.507, -0.528, -0.506, 0.8699999999999999, -1.003, -0.541, 0.45399999999999996, -0.522, 0.75, 0.771, -0.5149999999999999, -1.026, -1.01, 1.252, -0.517, 0.738, 0.46299999999999997, 1.21, -1.008, -1.004, 1.3119999999999998, 0.7919999999999999, 0.44899999999999995, -0.529, -0.513, -0.5059999999999999, -0.512, 0.44399999999999995, -0.516, 0.5569999999999999, 1.145, -1.038, -1.003, -0.533, 0.91, -0.5119999999999999, -0.508, -0.529, -0.524, 1.3940000000000001, 1.173, -0.511, -0.501, -0.519, -1.0079999999999998, 1.314, -0.503, -0.506, 1.291, 1.268, -1.013, 1.2530000000000001, -0.502, -1.008, -0.51, -1.004, -0.511, 0.272, 0.834, -0.532, -1.001, 1.45, -0.03200000000000002, -0.5009999999999999, 1.0379999999999998, 1.42, -0.51, 1.415, 1.216, -1.013, 1.031, 0.816, -0.504, -0.506, -1.001, 0.46099999999999997, -0.523, -1.011, 1.346]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3451471564889883, "mean_inference_ms": 7.375705733636501, "mean_action_processing_ms": 0.39745223711030925, "mean_env_wait_ms": 0.5085612222642905, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15788555145263672, "StateBufferConnector_ms": 0.00965738296508789, "ViewRequirementAgentConnector_ms": 0.19330203533172607}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 126.99639594364034, "num_env_steps_trained_throughput_per_sec": 126.99639594364034, "timesteps_total": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 31348.29, "sample_time_ms": 3961.281, "learn_time_ms": 27352.325, "learn_throughput": 146.24, "synch_weights_time_ms": 33.098}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "episodes_total": 625, "training_iteration": 24, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-09-06", "timestamp": 1694837346, "time_this_iter_s": 31.51464605331421, "time_total_s": 725.8993854522705, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb72348430>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 725.8993854522705, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 23.971739130434784, "ram_util_percent": 56.7065217391304}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.56, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.3, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.56, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.05, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.3, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.56, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.3, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5421027767471969, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08045596178490086, "policy_loss": -0.11327699003110563, "vf_loss": 0.012744856137578609, "vf_explained_var": 0.6279702872658769, "kl": 0.018546979397021345, "entropy": 1.7196235353748004, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 23520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5595744723764559, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08277548998618538, "policy_loss": -0.11569417149439687, "vf_loss": 0.0159534614928513, "vf_explained_var": 0.6069723231717944, "kl": 0.01758466199259677, "entropy": 1.764752804984649, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 23520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000}, "sampler_results": {"episode_reward_max": 1.772, "episode_reward_min": -0.508, "episode_reward_mean": 0.4652799999999999, "episode_len_mean": 110.33, "episode_media": {}, "episodes_this_iter": 35, "policy_reward_min": {"red_0": -1.024, "blue_0": -1.038}, "policy_reward_max": {"red_0": 1.459, "blue_0": 1.45}, "policy_reward_mean": {"red_0": 0.43550999999999995, "blue_0": 0.029770000000000022}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.56, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.3, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.56, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.05, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.3, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.56, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.3, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.05500000000000016, 0.20299999999999996, 0.9209999999999999, 0.698, -0.16900000000000004, -0.118, 0.8019999999999999, 0.2849999999999999, 0.9059999999999999, 0.22399999999999998, 0.6989999999999998, 0.8570000000000002, 0.20900000000000007, 0.9039999999999999, 0.5589999999999999, -0.4650000000000001, 0.121, -0.19600000000000006, -0.118, 0.43399999999999994, 0.40700000000000003, 0.609, 0.724, -0.28500000000000014, 0.399, 0.893, 0.6540000000000001, 0.6669999999999998, 0.915, 0.573, -0.17699999999999994, 0.809, 0.41900000000000004, 0.7090000000000001, 0.28400000000000003, 1.7570000000000001, 0.15300000000000002, 1.734, 0.401, 0.31800000000000006, 0.7269999999999999, -0.10499999999999998, 0.6160000000000001, -0.259, 0.2889999999999999, 0.33999999999999986, 0.42300000000000004, 0.44999999999999996, 0.4169999999999999, 0.42100000000000026, 0.5209999999999999, 0.41800000000000004, 0.7639999999999998, 0.41100000000000003, 0.20200000000000007, -0.508, 0.007999999999999896, -0.19300000000000006, 0.3919999999999999, 0.871, -0.031000000000000028, 0.9189999999999999, 0.4019999999999999, 0.2370000000000001, 0.839, -0.09000000000000008, 0.77, 0.16499999999999992, 0.853, 0.1449999999999999, 0.9039999999999999, 0.392, 0.9269999999999999, 0.45799999999999996, -0.09399999999999997, 1.772, 0.7430000000000001, 0.9249999999999999, 1.3279999999999998, 0.43300000000000005, 1.4969999999999999, 0.381, -0.32500000000000007, 0.81, 0.797, 0.4119999999999999, 0.33599999999999985, 0.18700000000000006, 0.43599999999999994, 0.3540000000000001, 0.903, 0.45799999999999996, 0.819, -0.1519999999999999, -0.08499999999999996, 0.32799999999999985, 0.4830000000000001, 0.5699999999999998, 0.9049999999999999, 0.43799999999999994], "episode_lengths": [136, 245, 300, 93, 52, 36, 60, 67, 300, 239, 91, 45, 89, 300, 137, 141, 113, 212, 37, 170, 29, 120, 85, 240, 183, 34, 105, 100, 27, 130, 52, 58, 25, 90, 68, 74, 104, 79, 32, 55, 84, 32, 118, 232, 213, 202, 25, 16, 300, 25, 147, 25, 73, 27, 91, 155, 146, 59, 32, 40, 10, 300, 185, 82, 50, 182, 71, 102, 47, 108, 300, 34, 300, 14, 29, 70, 76, 300, 205, 20, 158, 37, 254, 57, 64, 182, 49, 97, 20, 45, 30, 13, 53, 200, 27, 53, 161, 133, 300, 20], "policy_red_0_reward": [0.5720000000000001, -0.535, 0.45799999999999996, -0.512, 0.839, 0.886, -0.51, -0.507, 0.45699999999999996, 0.753, 1.212, 1.363, 0.721, 0.45999999999999996, 1.075, -1.022, -1.024, 0.842, 0.885, 0.967, -0.503, 1.121, 1.232, 0.24399999999999988, 0.9229999999999999, -0.501, -0.5189999999999999, 1.178, 1.416, 1.092, 0.831, -0.505, 0.922, 1.2149999999999999, -1.007, 0.489, 1.166, 0.481, 0.903, 1.326, 1.237, 0.899, 1.127, -0.531, -0.545, 0.872, 1.424, -1.0, 0.44899999999999995, 0.922, -0.517, -1.002, 1.274, -1.004, -1.0139999999999998, 0.5049999999999999, -1.023, -1.009, 0.896, 1.377, 0.97, 0.45799999999999996, 0.9249999999999999, 1.248, -0.507, 0.9329999999999999, -0.508, -1.013, 1.355, -0.52, 0.44999999999999996, -1.002, 0.46399999999999997, 1.458, 0.911, 0.491, 1.254, 0.46199999999999997, 0.469, 1.435, 0.484, -0.505, 0.20699999999999996, 1.322, -0.506, 0.9299999999999999, 1.343, -0.516, 0.938, 1.359, -0.503, 1.459, -0.516, 0.37, 0.916, 0.834, 1.0, 1.088, 0.45499999999999996, 1.438], "policy_blue_0_reward": [-0.517, 0.738, 0.46299999999999997, 1.21, -1.008, -1.004, 1.3119999999999998, 0.7919999999999999, 0.44899999999999995, -0.529, -0.513, -0.5059999999999999, -0.512, 0.44399999999999995, -0.516, 0.5569999999999999, 1.145, -1.038, -1.003, -0.533, 0.91, -0.5119999999999999, -0.508, -0.529, -0.524, 1.3940000000000001, 1.173, -0.511, -0.501, -0.519, -1.0079999999999998, 1.314, -0.503, -0.506, 1.291, 1.268, -1.013, 1.2530000000000001, -0.502, -1.008, -0.51, -1.004, -0.511, 0.272, 0.834, -0.532, -1.001, 1.45, -0.03200000000000002, -0.5009999999999999, 1.0379999999999998, 1.42, -0.51, 1.415, 1.216, -1.013, 1.031, 0.816, -0.504, -0.506, -1.001, 0.46099999999999997, -0.523, -1.011, 1.346, -1.023, 1.278, 1.178, -0.502, 0.6649999999999999, 0.45399999999999996, 1.3940000000000001, 0.46299999999999997, -1.0, -1.005, 1.2810000000000001, -0.5109999999999999, 0.46299999999999997, 0.859, -1.0019999999999998, 1.013, 0.886, -0.532, -0.512, 1.303, -0.518, -1.007, 0.7030000000000001, -0.502, -1.005, 1.4060000000000001, -1.001, 1.335, -0.5219999999999999, -1.001, -0.506, -0.517, -0.518, 0.44999999999999996, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.346187339631796, "mean_inference_ms": 7.36710425899593, "mean_action_processing_ms": 0.3955145936187817, "mean_env_wait_ms": 0.5090545868702455, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15583133697509766, "StateBufferConnector_ms": 0.009440183639526367, "ViewRequirementAgentConnector_ms": 0.1884075403213501}}, "episode_reward_max": 1.772, "episode_reward_min": -0.508, "episode_reward_mean": 0.4652799999999999, "episode_len_mean": 110.33, "episodes_this_iter": 35, "policy_reward_min": {"red_0": -1.024, "blue_0": -1.038}, "policy_reward_max": {"red_0": 1.459, "blue_0": 1.45}, "policy_reward_mean": {"red_0": 0.43550999999999995, "blue_0": 0.029770000000000022}, "hist_stats": {"episode_reward": [0.05500000000000016, 0.20299999999999996, 0.9209999999999999, 0.698, -0.16900000000000004, -0.118, 0.8019999999999999, 0.2849999999999999, 0.9059999999999999, 0.22399999999999998, 0.6989999999999998, 0.8570000000000002, 0.20900000000000007, 0.9039999999999999, 0.5589999999999999, -0.4650000000000001, 0.121, -0.19600000000000006, -0.118, 0.43399999999999994, 0.40700000000000003, 0.609, 0.724, -0.28500000000000014, 0.399, 0.893, 0.6540000000000001, 0.6669999999999998, 0.915, 0.573, -0.17699999999999994, 0.809, 0.41900000000000004, 0.7090000000000001, 0.28400000000000003, 1.7570000000000001, 0.15300000000000002, 1.734, 0.401, 0.31800000000000006, 0.7269999999999999, -0.10499999999999998, 0.6160000000000001, -0.259, 0.2889999999999999, 0.33999999999999986, 0.42300000000000004, 0.44999999999999996, 0.4169999999999999, 0.42100000000000026, 0.5209999999999999, 0.41800000000000004, 0.7639999999999998, 0.41100000000000003, 0.20200000000000007, -0.508, 0.007999999999999896, -0.19300000000000006, 0.3919999999999999, 0.871, -0.031000000000000028, 0.9189999999999999, 0.4019999999999999, 0.2370000000000001, 0.839, -0.09000000000000008, 0.77, 0.16499999999999992, 0.853, 0.1449999999999999, 0.9039999999999999, 0.392, 0.9269999999999999, 0.45799999999999996, -0.09399999999999997, 1.772, 0.7430000000000001, 0.9249999999999999, 1.3279999999999998, 0.43300000000000005, 1.4969999999999999, 0.381, -0.32500000000000007, 0.81, 0.797, 0.4119999999999999, 0.33599999999999985, 0.18700000000000006, 0.43599999999999994, 0.3540000000000001, 0.903, 0.45799999999999996, 0.819, -0.1519999999999999, -0.08499999999999996, 0.32799999999999985, 0.4830000000000001, 0.5699999999999998, 0.9049999999999999, 0.43799999999999994], "episode_lengths": [136, 245, 300, 93, 52, 36, 60, 67, 300, 239, 91, 45, 89, 300, 137, 141, 113, 212, 37, 170, 29, 120, 85, 240, 183, 34, 105, 100, 27, 130, 52, 58, 25, 90, 68, 74, 104, 79, 32, 55, 84, 32, 118, 232, 213, 202, 25, 16, 300, 25, 147, 25, 73, 27, 91, 155, 146, 59, 32, 40, 10, 300, 185, 82, 50, 182, 71, 102, 47, 108, 300, 34, 300, 14, 29, 70, 76, 300, 205, 20, 158, 37, 254, 57, 64, 182, 49, 97, 20, 45, 30, 13, 53, 200, 27, 53, 161, 133, 300, 20], "policy_red_0_reward": [0.5720000000000001, -0.535, 0.45799999999999996, -0.512, 0.839, 0.886, -0.51, -0.507, 0.45699999999999996, 0.753, 1.212, 1.363, 0.721, 0.45999999999999996, 1.075, -1.022, -1.024, 0.842, 0.885, 0.967, -0.503, 1.121, 1.232, 0.24399999999999988, 0.9229999999999999, -0.501, -0.5189999999999999, 1.178, 1.416, 1.092, 0.831, -0.505, 0.922, 1.2149999999999999, -1.007, 0.489, 1.166, 0.481, 0.903, 1.326, 1.237, 0.899, 1.127, -0.531, -0.545, 0.872, 1.424, -1.0, 0.44899999999999995, 0.922, -0.517, -1.002, 1.274, -1.004, -1.0139999999999998, 0.5049999999999999, -1.023, -1.009, 0.896, 1.377, 0.97, 0.45799999999999996, 0.9249999999999999, 1.248, -0.507, 0.9329999999999999, -0.508, -1.013, 1.355, -0.52, 0.44999999999999996, -1.002, 0.46399999999999997, 1.458, 0.911, 0.491, 1.254, 0.46199999999999997, 0.469, 1.435, 0.484, -0.505, 0.20699999999999996, 1.322, -0.506, 0.9299999999999999, 1.343, -0.516, 0.938, 1.359, -0.503, 1.459, -0.516, 0.37, 0.916, 0.834, 1.0, 1.088, 0.45499999999999996, 1.438], "policy_blue_0_reward": [-0.517, 0.738, 0.46299999999999997, 1.21, -1.008, -1.004, 1.3119999999999998, 0.7919999999999999, 0.44899999999999995, -0.529, -0.513, -0.5059999999999999, -0.512, 0.44399999999999995, -0.516, 0.5569999999999999, 1.145, -1.038, -1.003, -0.533, 0.91, -0.5119999999999999, -0.508, -0.529, -0.524, 1.3940000000000001, 1.173, -0.511, -0.501, -0.519, -1.0079999999999998, 1.314, -0.503, -0.506, 1.291, 1.268, -1.013, 1.2530000000000001, -0.502, -1.008, -0.51, -1.004, -0.511, 0.272, 0.834, -0.532, -1.001, 1.45, -0.03200000000000002, -0.5009999999999999, 1.0379999999999998, 1.42, -0.51, 1.415, 1.216, -1.013, 1.031, 0.816, -0.504, -0.506, -1.001, 0.46099999999999997, -0.523, -1.011, 1.346, -1.023, 1.278, 1.178, -0.502, 0.6649999999999999, 0.45399999999999996, 1.3940000000000001, 0.46299999999999997, -1.0, -1.005, 1.2810000000000001, -0.5109999999999999, 0.46299999999999997, 0.859, -1.0019999999999998, 1.013, 0.886, -0.532, -0.512, 1.303, -0.518, -1.007, 0.7030000000000001, -0.502, -1.005, 1.4060000000000001, -1.001, 1.335, -0.5219999999999999, -1.001, -0.506, -0.517, -0.518, 0.44999999999999996, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.346187339631796, "mean_inference_ms": 7.36710425899593, "mean_action_processing_ms": 0.3955145936187817, "mean_env_wait_ms": 0.5090545868702455, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15583133697509766, "StateBufferConnector_ms": 0.009440183639526367, "ViewRequirementAgentConnector_ms": 0.1884075403213501}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.2972227476849, "num_env_steps_trained_throughput_per_sec": 128.2972227476849, "timesteps_total": 100000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 200000, "timers": {"training_iteration_time_ms": 31330.024, "sample_time_ms": 3931.735, "learn_time_ms": 27363.538, "learn_throughput": 146.18, "synch_weights_time_ms": 33.143}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000}, "done": false, "episodes_total": 660, "training_iteration": 25, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-09-38", "timestamp": 1694837378, "time_this_iter_s": 31.19357180595398, "time_total_s": 757.0929572582245, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7239f010>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 757.0929572582245, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 25.53111111111111, "ram_util_percent": 56.68666666666668}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.62, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.26, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.62, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.05, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.26, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.62, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.26, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5359659682027995, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07709628621426722, "policy_loss": -0.10785260143893538, "vf_loss": 0.013776104977538731, "vf_explained_var": 0.5807715136557817, "kl": 0.016857759224892625, "entropy": 1.73445821305116, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 24480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5280586250126362, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08629873127986988, "policy_loss": -0.11944265641213861, "vf_loss": 0.017074230083623358, "vf_explained_var": 0.6247811297575633, "kl": 0.017366715243905727, "entropy": 1.7688875178496042, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 24480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "sampler_results": {"episode_reward_max": 1.772, "episode_reward_min": -0.508, "episode_reward_mean": 0.45640000000000003, "episode_len_mean": 104.54, "episode_media": {}, "episodes_this_iter": 36, "policy_reward_min": {"red_0": -1.023, "blue_0": -1.023}, "policy_reward_max": {"red_0": 1.459, "blue_0": 1.45}, "policy_reward_mean": {"red_0": 0.5013700000000001, "blue_0": -0.04496999999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.62, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.26, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.62, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.05, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.26, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.62, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.26, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.15300000000000002, 1.734, 0.401, 0.31800000000000006, 0.7269999999999999, -0.10499999999999998, 0.6160000000000001, -0.259, 0.2889999999999999, 0.33999999999999986, 0.42300000000000004, 0.44999999999999996, 0.4169999999999999, 0.42100000000000026, 0.5209999999999999, 0.41800000000000004, 0.7639999999999998, 0.41100000000000003, 0.20200000000000007, -0.508, 0.007999999999999896, -0.19300000000000006, 0.3919999999999999, 0.871, -0.031000000000000028, 0.9189999999999999, 0.4019999999999999, 0.2370000000000001, 0.839, -0.09000000000000008, 0.77, 0.16499999999999992, 0.853, 0.1449999999999999, 0.9039999999999999, 0.392, 0.9269999999999999, 0.45799999999999996, -0.09399999999999997, 1.772, 0.7430000000000001, 0.9249999999999999, 1.3279999999999998, 0.43300000000000005, 1.4969999999999999, 0.381, -0.32500000000000007, 0.81, 0.797, 0.4119999999999999, 0.33599999999999985, 0.18700000000000006, 0.43599999999999994, 0.3540000000000001, 0.903, 0.45799999999999996, 0.819, -0.1519999999999999, -0.08499999999999996, 0.32799999999999985, 0.4830000000000001, 0.5699999999999998, 0.9049999999999999, 0.43799999999999994, -0.252, 0.34799999999999986, 0.24, 0.30699999999999994, 0.018999999999999906, -0.21499999999999986, 0.836, 0.9180000000000001, 0.401, 1.604, 0.5219999999999999, 0.506, 0.33699999999999997, 0.40200000000000014, 0.11299999999999999, 0.9119999999999999, 0.7609999999999999, -0.138, 0.1160000000000001, 0.20799999999999996, 0.44300000000000006, 0.793, 0.6859999999999999, 0.32699999999999996, 0.9239999999999999, 0.2919999999999998, -0.09699999999999998, 0.41999999999999993, 0.9329999999999998, 0.6859999999999999, 0.02200000000000002, 0.06400000000000006, 0.756, 0.589, 0.33299999999999996, 0.16399999999999992], "episode_lengths": [104, 79, 32, 55, 84, 32, 118, 232, 213, 202, 25, 16, 300, 25, 147, 25, 73, 27, 91, 155, 146, 59, 32, 40, 10, 300, 185, 82, 50, 182, 71, 102, 47, 108, 300, 34, 300, 14, 29, 70, 76, 300, 205, 20, 158, 37, 254, 57, 64, 182, 49, 97, 20, 45, 30, 13, 53, 200, 27, 53, 161, 133, 300, 20, 226, 45, 77, 59, 300, 66, 50, 25, 31, 122, 145, 150, 49, 32, 119, 28, 73, 42, 270, 91, 17, 64, 95, 54, 300, 221, 29, 25, 20, 98, 144, 132, 75, 124, 51, 255], "policy_red_0_reward": [1.166, 0.481, 0.903, 1.326, 1.237, 0.899, 1.127, -0.531, -0.545, 0.872, 1.424, -1.0, 0.44899999999999995, 0.922, -0.517, -1.002, 1.274, -1.004, -1.0139999999999998, 0.5049999999999999, -1.023, -1.009, 0.896, 1.377, 0.97, 0.45799999999999996, 0.9249999999999999, 1.248, -0.507, 0.9329999999999999, -0.508, -1.013, 1.355, -0.52, 0.44999999999999996, -1.002, 0.46399999999999997, 1.458, 0.911, 0.491, 1.254, 0.46199999999999997, 0.469, 1.435, 0.484, -0.505, 0.20699999999999996, 1.322, -0.506, 0.9299999999999999, 1.343, -0.516, 0.938, 1.359, -0.503, 1.459, -0.516, 0.37, 0.916, 0.834, 1.0, 1.088, 0.45499999999999996, 1.438, 0.29000000000000004, 0.856, 0.759, 0.815, 0.577, -1.007, -0.508, 1.421, 0.902, 0.486, -0.527, 1.033, 0.843, 0.902, 0.629, 1.412, -0.513, 0.869, 0.6519999999999999, 0.714, 1.447, -0.505, 1.202, 0.831, 0.46199999999999997, 0.813, 0.909, 1.424, 1.439, -0.506, -1.021, 0.578, 1.2690000000000001, 1.109, 0.838, 0.7], "policy_blue_0_reward": [-1.013, 1.2530000000000001, -0.502, -1.008, -0.51, -1.004, -0.511, 0.272, 0.834, -0.532, -1.001, 1.45, -0.03200000000000002, -0.5009999999999999, 1.0379999999999998, 1.42, -0.51, 1.415, 1.216, -1.013, 1.031, 0.816, -0.504, -0.506, -1.001, 0.46099999999999997, -0.523, -1.011, 1.346, -1.023, 1.278, 1.178, -0.502, 0.6649999999999999, 0.45399999999999996, 1.3940000000000001, 0.46299999999999997, -1.0, -1.005, 1.2810000000000001, -0.5109999999999999, 0.46299999999999997, 0.859, -1.0019999999999998, 1.013, 0.886, -0.532, -0.512, 1.303, -0.518, -1.007, 0.7030000000000001, -0.502, -1.005, 1.4060000000000001, -1.001, 1.335, -0.5219999999999999, -1.001, -0.506, -0.517, -0.518, 0.44999999999999996, -1.0, -0.542, -0.508, -0.519, -0.508, -0.558, 0.792, 1.3439999999999999, -0.503, -0.501, 1.1179999999999999, 1.049, -0.527, -0.506, -0.5, -0.516, -0.5, 1.274, -1.007, -0.5359999999999999, -0.506, -1.0039999999999998, 1.298, -0.516, -0.504, 0.46199999999999997, -0.521, -1.006, -1.004, -0.506, 1.192, 1.0430000000000001, -0.514, -0.513, -0.5199999999999999, -0.505, -0.536]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3456400893608906, "mean_inference_ms": 7.357065458942023, "mean_action_processing_ms": 0.3953252079684884, "mean_env_wait_ms": 0.5076050384265013, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1466735601425171, "StateBufferConnector_ms": 0.009326934814453125, "ViewRequirementAgentConnector_ms": 0.19101190567016602}}, "episode_reward_max": 1.772, "episode_reward_min": -0.508, "episode_reward_mean": 0.45640000000000003, "episode_len_mean": 104.54, "episodes_this_iter": 36, "policy_reward_min": {"red_0": -1.023, "blue_0": -1.023}, "policy_reward_max": {"red_0": 1.459, "blue_0": 1.45}, "policy_reward_mean": {"red_0": 0.5013700000000001, "blue_0": -0.04496999999999999}, "hist_stats": {"episode_reward": [0.15300000000000002, 1.734, 0.401, 0.31800000000000006, 0.7269999999999999, -0.10499999999999998, 0.6160000000000001, -0.259, 0.2889999999999999, 0.33999999999999986, 0.42300000000000004, 0.44999999999999996, 0.4169999999999999, 0.42100000000000026, 0.5209999999999999, 0.41800000000000004, 0.7639999999999998, 0.41100000000000003, 0.20200000000000007, -0.508, 0.007999999999999896, -0.19300000000000006, 0.3919999999999999, 0.871, -0.031000000000000028, 0.9189999999999999, 0.4019999999999999, 0.2370000000000001, 0.839, -0.09000000000000008, 0.77, 0.16499999999999992, 0.853, 0.1449999999999999, 0.9039999999999999, 0.392, 0.9269999999999999, 0.45799999999999996, -0.09399999999999997, 1.772, 0.7430000000000001, 0.9249999999999999, 1.3279999999999998, 0.43300000000000005, 1.4969999999999999, 0.381, -0.32500000000000007, 0.81, 0.797, 0.4119999999999999, 0.33599999999999985, 0.18700000000000006, 0.43599999999999994, 0.3540000000000001, 0.903, 0.45799999999999996, 0.819, -0.1519999999999999, -0.08499999999999996, 0.32799999999999985, 0.4830000000000001, 0.5699999999999998, 0.9049999999999999, 0.43799999999999994, -0.252, 0.34799999999999986, 0.24, 0.30699999999999994, 0.018999999999999906, -0.21499999999999986, 0.836, 0.9180000000000001, 0.401, 1.604, 0.5219999999999999, 0.506, 0.33699999999999997, 0.40200000000000014, 0.11299999999999999, 0.9119999999999999, 0.7609999999999999, -0.138, 0.1160000000000001, 0.20799999999999996, 0.44300000000000006, 0.793, 0.6859999999999999, 0.32699999999999996, 0.9239999999999999, 0.2919999999999998, -0.09699999999999998, 0.41999999999999993, 0.9329999999999998, 0.6859999999999999, 0.02200000000000002, 0.06400000000000006, 0.756, 0.589, 0.33299999999999996, 0.16399999999999992], "episode_lengths": [104, 79, 32, 55, 84, 32, 118, 232, 213, 202, 25, 16, 300, 25, 147, 25, 73, 27, 91, 155, 146, 59, 32, 40, 10, 300, 185, 82, 50, 182, 71, 102, 47, 108, 300, 34, 300, 14, 29, 70, 76, 300, 205, 20, 158, 37, 254, 57, 64, 182, 49, 97, 20, 45, 30, 13, 53, 200, 27, 53, 161, 133, 300, 20, 226, 45, 77, 59, 300, 66, 50, 25, 31, 122, 145, 150, 49, 32, 119, 28, 73, 42, 270, 91, 17, 64, 95, 54, 300, 221, 29, 25, 20, 98, 144, 132, 75, 124, 51, 255], "policy_red_0_reward": [1.166, 0.481, 0.903, 1.326, 1.237, 0.899, 1.127, -0.531, -0.545, 0.872, 1.424, -1.0, 0.44899999999999995, 0.922, -0.517, -1.002, 1.274, -1.004, -1.0139999999999998, 0.5049999999999999, -1.023, -1.009, 0.896, 1.377, 0.97, 0.45799999999999996, 0.9249999999999999, 1.248, -0.507, 0.9329999999999999, -0.508, -1.013, 1.355, -0.52, 0.44999999999999996, -1.002, 0.46399999999999997, 1.458, 0.911, 0.491, 1.254, 0.46199999999999997, 0.469, 1.435, 0.484, -0.505, 0.20699999999999996, 1.322, -0.506, 0.9299999999999999, 1.343, -0.516, 0.938, 1.359, -0.503, 1.459, -0.516, 0.37, 0.916, 0.834, 1.0, 1.088, 0.45499999999999996, 1.438, 0.29000000000000004, 0.856, 0.759, 0.815, 0.577, -1.007, -0.508, 1.421, 0.902, 0.486, -0.527, 1.033, 0.843, 0.902, 0.629, 1.412, -0.513, 0.869, 0.6519999999999999, 0.714, 1.447, -0.505, 1.202, 0.831, 0.46199999999999997, 0.813, 0.909, 1.424, 1.439, -0.506, -1.021, 0.578, 1.2690000000000001, 1.109, 0.838, 0.7], "policy_blue_0_reward": [-1.013, 1.2530000000000001, -0.502, -1.008, -0.51, -1.004, -0.511, 0.272, 0.834, -0.532, -1.001, 1.45, -0.03200000000000002, -0.5009999999999999, 1.0379999999999998, 1.42, -0.51, 1.415, 1.216, -1.013, 1.031, 0.816, -0.504, -0.506, -1.001, 0.46099999999999997, -0.523, -1.011, 1.346, -1.023, 1.278, 1.178, -0.502, 0.6649999999999999, 0.45399999999999996, 1.3940000000000001, 0.46299999999999997, -1.0, -1.005, 1.2810000000000001, -0.5109999999999999, 0.46299999999999997, 0.859, -1.0019999999999998, 1.013, 0.886, -0.532, -0.512, 1.303, -0.518, -1.007, 0.7030000000000001, -0.502, -1.005, 1.4060000000000001, -1.001, 1.335, -0.5219999999999999, -1.001, -0.506, -0.517, -0.518, 0.44999999999999996, -1.0, -0.542, -0.508, -0.519, -0.508, -0.558, 0.792, 1.3439999999999999, -0.503, -0.501, 1.1179999999999999, 1.049, -0.527, -0.506, -0.5, -0.516, -0.5, 1.274, -1.007, -0.5359999999999999, -0.506, -1.0039999999999998, 1.298, -0.516, -0.504, 0.46199999999999997, -0.521, -1.006, -1.004, -0.506, 1.192, 1.0430000000000001, -0.514, -0.513, -0.5199999999999999, -0.505, -0.536]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3456400893608906, "mean_inference_ms": 7.357065458942023, "mean_action_processing_ms": 0.3953252079684884, "mean_env_wait_ms": 0.5076050384265013, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1466735601425171, "StateBufferConnector_ms": 0.009326934814453125, "ViewRequirementAgentConnector_ms": 0.19101190567016602}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.82288665041875, "num_env_steps_trained_throughput_per_sec": 130.82288665041875, "timesteps_total": 104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 31377.134, "sample_time_ms": 3940.157, "learn_time_ms": 27402.018, "learn_throughput": 145.975, "synch_weights_time_ms": 33.354}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "episodes_total": 696, "training_iteration": 26, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-10-10", "timestamp": 1694837410, "time_this_iter_s": 30.591691970825195, "time_total_s": 787.6846492290497, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb72348b80>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 787.6846492290497, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 24.7, "ram_util_percent": 56.7533333333333}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.72, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.2, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.72, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.04, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.2, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.72, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.2, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5650615048905213, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07701016092081166, "policy_loss": -0.10897628828485419, "vf_loss": 0.013766532365601354, "vf_explained_var": 0.6177553988372286, "kl": 0.01764459722118661, "entropy": 1.7148698527365922, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 25440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5464066979164879, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08382036125597854, "policy_loss": -0.11890846400056035, "vf_loss": 0.019675489491055485, "vf_explained_var": 0.6162539867063364, "kl": 0.017785000653330683, "entropy": 1.7606112107634544, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 25440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000}, "sampler_results": {"episode_reward_max": 1.798, "episode_reward_min": -0.32500000000000007, "episode_reward_mean": 0.44472, "episode_len_mean": 101.48, "episode_media": {}, "episodes_this_iter": 42, "policy_reward_min": {"red_0": -1.021, "blue_0": -1.022}, "policy_reward_max": {"red_0": 1.459, "blue_0": 1.4060000000000001}, "policy_reward_mean": {"red_0": 0.61601, "blue_0": -0.17128999999999997}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.72, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.2, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.72, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.04, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.2, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.72, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.2, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.3279999999999998, 0.43300000000000005, 1.4969999999999999, 0.381, -0.32500000000000007, 0.81, 0.797, 0.4119999999999999, 0.33599999999999985, 0.18700000000000006, 0.43599999999999994, 0.3540000000000001, 0.903, 0.45799999999999996, 0.819, -0.1519999999999999, -0.08499999999999996, 0.32799999999999985, 0.4830000000000001, 0.5699999999999998, 0.9049999999999999, 0.43799999999999994, -0.252, 0.34799999999999986, 0.24, 0.30699999999999994, 0.018999999999999906, -0.21499999999999986, 0.836, 0.9180000000000001, 0.401, 1.604, 0.5219999999999999, 0.506, 0.33699999999999997, 0.40200000000000014, 0.11299999999999999, 0.9119999999999999, 0.7609999999999999, -0.138, 0.1160000000000001, 0.20799999999999996, 0.44300000000000006, 0.793, 0.6859999999999999, 0.32699999999999996, 0.9239999999999999, 0.2919999999999998, -0.09699999999999998, 0.41999999999999993, 0.9329999999999998, 0.6859999999999999, 0.02200000000000002, 0.06400000000000006, 0.756, 0.589, 0.33299999999999996, 0.16399999999999992, 0.32699999999999996, 0.2600000000000001, -0.16700000000000004, -0.28, 0.9099999999999999, 0.020000000000000018, 0.667, -0.026000000000000023, 0.8900000000000001, 0.29400000000000004, 0.32699999999999996, 0.5049999999999999, 0.833, 1.798, 0.677, 0.4079999999999999, 0.901, 0.8069999999999999, -0.131, 0.21399999999999997, -0.05500000000000005, -0.17000000000000004, 0.9249999999999999, 0.62, 0.697, 0.7349999999999999, 0.853, 0.8719999999999999, 0.619, 0.41800000000000015, -0.263, -0.10199999999999987, 0.30799999999999983, 0.21999999999999997, 0.46199999999999997, 0.31300000000000017, 0.785, 0.802, 0.06299999999999994, 0.347, -0.16500000000000004, 0.36099999999999977], "episode_lengths": [205, 20, 158, 37, 254, 57, 64, 182, 49, 97, 20, 45, 30, 13, 53, 200, 27, 53, 161, 133, 300, 20, 226, 45, 77, 59, 300, 66, 50, 25, 31, 122, 145, 150, 49, 32, 119, 28, 73, 42, 270, 91, 17, 64, 95, 54, 300, 221, 29, 25, 20, 98, 144, 132, 75, 124, 51, 255, 210, 71, 48, 84, 300, 145, 103, 162, 34, 216, 53, 154, 53, 60, 95, 27, 29, 61, 40, 89, 16, 50, 300, 119, 96, 81, 43, 40, 119, 26, 80, 31, 60, 241, 12, 211, 66, 62, 285, 48, 51, 195], "policy_red_0_reward": [0.469, 1.435, 0.484, -0.505, 0.20699999999999996, 1.322, -0.506, 0.9299999999999999, 1.343, -0.516, 0.938, 1.359, -0.503, 1.459, -0.516, 0.37, 0.916, 0.834, 1.0, 1.088, 0.45499999999999996, 1.438, 0.29000000000000004, 0.856, 0.759, 0.815, 0.577, -1.007, -0.508, 1.421, 0.902, 0.486, -0.527, 1.033, 0.843, 0.902, 0.629, 1.412, -0.513, 0.869, 0.6519999999999999, 0.714, 1.447, -0.505, 1.202, 0.831, 0.46199999999999997, 0.813, 0.909, 1.424, 1.439, -0.506, -1.021, 0.578, 1.2690000000000001, 1.109, 0.838, 0.7, 0.848, -1.0159999999999998, 0.849, 0.742, 0.45099999999999996, 0.5289999999999999, 1.177, 0.493, 1.395, 0.817, 0.839, 1.021, 1.335, 0.486, -0.518, 0.913, 1.409, -0.505, 0.875, -1.009, 0.949, 0.843, 0.46499999999999997, -0.508, -0.509, 1.244, 1.3639999999999999, 1.376, 1.1320000000000001, 0.921, 0.744, -1.007, 1.315, 0.751, 0.964, 0.842, -0.509, 1.308, 0.609, 1.3519999999999999, 0.845, 0.8839999999999999], "policy_blue_0_reward": [0.859, -1.0019999999999998, 1.013, 0.886, -0.532, -0.512, 1.303, -0.518, -1.007, 0.7030000000000001, -0.502, -1.005, 1.4060000000000001, -1.001, 1.335, -0.5219999999999999, -1.001, -0.506, -0.517, -0.518, 0.44999999999999996, -1.0, -0.542, -0.508, -0.519, -0.508, -0.558, 0.792, 1.3439999999999999, -0.503, -0.501, 1.1179999999999999, 1.049, -0.527, -0.506, -0.5, -0.516, -0.5, 1.274, -1.007, -0.5359999999999999, -0.506, -1.0039999999999998, 1.298, -0.516, -0.504, 0.46199999999999997, -0.521, -1.006, -1.004, -0.506, 1.192, 1.0430000000000001, -0.514, -0.513, -0.5199999999999999, -0.505, -0.536, -0.521, 1.276, -1.016, -1.022, 0.45899999999999996, -0.509, -0.51, -0.519, -0.505, -0.523, -0.512, -0.516, -0.502, 1.3119999999999998, 1.195, -0.505, -0.508, 1.3119999999999998, -1.006, 1.2229999999999999, -1.004, -1.013, 0.45999999999999996, 1.1280000000000001, 1.206, -0.509, -0.511, -0.504, -0.513, -0.503, -1.007, 0.905, -1.007, -0.531, -0.502, -0.5289999999999999, 1.294, -0.506, -0.546, -1.005, -1.01, -0.523]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3449411183156785, "mean_inference_ms": 7.347087843618649, "mean_action_processing_ms": 0.39450405586773135, "mean_env_wait_ms": 0.5073101736435286, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1398472785949707, "StateBufferConnector_ms": 0.009061217308044434, "ViewRequirementAgentConnector_ms": 0.18702447414398193}}, "episode_reward_max": 1.798, "episode_reward_min": -0.32500000000000007, "episode_reward_mean": 0.44472, "episode_len_mean": 101.48, "episodes_this_iter": 42, "policy_reward_min": {"red_0": -1.021, "blue_0": -1.022}, "policy_reward_max": {"red_0": 1.459, "blue_0": 1.4060000000000001}, "policy_reward_mean": {"red_0": 0.61601, "blue_0": -0.17128999999999997}, "hist_stats": {"episode_reward": [1.3279999999999998, 0.43300000000000005, 1.4969999999999999, 0.381, -0.32500000000000007, 0.81, 0.797, 0.4119999999999999, 0.33599999999999985, 0.18700000000000006, 0.43599999999999994, 0.3540000000000001, 0.903, 0.45799999999999996, 0.819, -0.1519999999999999, -0.08499999999999996, 0.32799999999999985, 0.4830000000000001, 0.5699999999999998, 0.9049999999999999, 0.43799999999999994, -0.252, 0.34799999999999986, 0.24, 0.30699999999999994, 0.018999999999999906, -0.21499999999999986, 0.836, 0.9180000000000001, 0.401, 1.604, 0.5219999999999999, 0.506, 0.33699999999999997, 0.40200000000000014, 0.11299999999999999, 0.9119999999999999, 0.7609999999999999, -0.138, 0.1160000000000001, 0.20799999999999996, 0.44300000000000006, 0.793, 0.6859999999999999, 0.32699999999999996, 0.9239999999999999, 0.2919999999999998, -0.09699999999999998, 0.41999999999999993, 0.9329999999999998, 0.6859999999999999, 0.02200000000000002, 0.06400000000000006, 0.756, 0.589, 0.33299999999999996, 0.16399999999999992, 0.32699999999999996, 0.2600000000000001, -0.16700000000000004, -0.28, 0.9099999999999999, 0.020000000000000018, 0.667, -0.026000000000000023, 0.8900000000000001, 0.29400000000000004, 0.32699999999999996, 0.5049999999999999, 0.833, 1.798, 0.677, 0.4079999999999999, 0.901, 0.8069999999999999, -0.131, 0.21399999999999997, -0.05500000000000005, -0.17000000000000004, 0.9249999999999999, 0.62, 0.697, 0.7349999999999999, 0.853, 0.8719999999999999, 0.619, 0.41800000000000015, -0.263, -0.10199999999999987, 0.30799999999999983, 0.21999999999999997, 0.46199999999999997, 0.31300000000000017, 0.785, 0.802, 0.06299999999999994, 0.347, -0.16500000000000004, 0.36099999999999977], "episode_lengths": [205, 20, 158, 37, 254, 57, 64, 182, 49, 97, 20, 45, 30, 13, 53, 200, 27, 53, 161, 133, 300, 20, 226, 45, 77, 59, 300, 66, 50, 25, 31, 122, 145, 150, 49, 32, 119, 28, 73, 42, 270, 91, 17, 64, 95, 54, 300, 221, 29, 25, 20, 98, 144, 132, 75, 124, 51, 255, 210, 71, 48, 84, 300, 145, 103, 162, 34, 216, 53, 154, 53, 60, 95, 27, 29, 61, 40, 89, 16, 50, 300, 119, 96, 81, 43, 40, 119, 26, 80, 31, 60, 241, 12, 211, 66, 62, 285, 48, 51, 195], "policy_red_0_reward": [0.469, 1.435, 0.484, -0.505, 0.20699999999999996, 1.322, -0.506, 0.9299999999999999, 1.343, -0.516, 0.938, 1.359, -0.503, 1.459, -0.516, 0.37, 0.916, 0.834, 1.0, 1.088, 0.45499999999999996, 1.438, 0.29000000000000004, 0.856, 0.759, 0.815, 0.577, -1.007, -0.508, 1.421, 0.902, 0.486, -0.527, 1.033, 0.843, 0.902, 0.629, 1.412, -0.513, 0.869, 0.6519999999999999, 0.714, 1.447, -0.505, 1.202, 0.831, 0.46199999999999997, 0.813, 0.909, 1.424, 1.439, -0.506, -1.021, 0.578, 1.2690000000000001, 1.109, 0.838, 0.7, 0.848, -1.0159999999999998, 0.849, 0.742, 0.45099999999999996, 0.5289999999999999, 1.177, 0.493, 1.395, 0.817, 0.839, 1.021, 1.335, 0.486, -0.518, 0.913, 1.409, -0.505, 0.875, -1.009, 0.949, 0.843, 0.46499999999999997, -0.508, -0.509, 1.244, 1.3639999999999999, 1.376, 1.1320000000000001, 0.921, 0.744, -1.007, 1.315, 0.751, 0.964, 0.842, -0.509, 1.308, 0.609, 1.3519999999999999, 0.845, 0.8839999999999999], "policy_blue_0_reward": [0.859, -1.0019999999999998, 1.013, 0.886, -0.532, -0.512, 1.303, -0.518, -1.007, 0.7030000000000001, -0.502, -1.005, 1.4060000000000001, -1.001, 1.335, -0.5219999999999999, -1.001, -0.506, -0.517, -0.518, 0.44999999999999996, -1.0, -0.542, -0.508, -0.519, -0.508, -0.558, 0.792, 1.3439999999999999, -0.503, -0.501, 1.1179999999999999, 1.049, -0.527, -0.506, -0.5, -0.516, -0.5, 1.274, -1.007, -0.5359999999999999, -0.506, -1.0039999999999998, 1.298, -0.516, -0.504, 0.46199999999999997, -0.521, -1.006, -1.004, -0.506, 1.192, 1.0430000000000001, -0.514, -0.513, -0.5199999999999999, -0.505, -0.536, -0.521, 1.276, -1.016, -1.022, 0.45899999999999996, -0.509, -0.51, -0.519, -0.505, -0.523, -0.512, -0.516, -0.502, 1.3119999999999998, 1.195, -0.505, -0.508, 1.3119999999999998, -1.006, 1.2229999999999999, -1.004, -1.013, 0.45999999999999996, 1.1280000000000001, 1.206, -0.509, -0.511, -0.504, -0.513, -0.503, -1.007, 0.905, -1.007, -0.531, -0.502, -0.5289999999999999, 1.294, -0.506, -0.546, -1.005, -1.01, -0.523]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3449411183156785, "mean_inference_ms": 7.347087843618649, "mean_action_processing_ms": 0.39450405586773135, "mean_env_wait_ms": 0.5073101736435286, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1398472785949707, "StateBufferConnector_ms": 0.009061217308044434, "ViewRequirementAgentConnector_ms": 0.18702447414398193}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.26638820545463, "num_env_steps_trained_throughput_per_sec": 128.26638820545463, "timesteps_total": 108000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 216000, "timers": {"training_iteration_time_ms": 31437.004, "sample_time_ms": 3922.042, "learn_time_ms": 27486.748, "learn_throughput": 145.525, "synch_weights_time_ms": 26.647}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000}, "done": false, "episodes_total": 738, "training_iteration": 27, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-10-42", "timestamp": 1694837442, "time_this_iter_s": 31.2016441822052, "time_total_s": 818.8862934112549, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7239f520>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 818.8862934112549, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 25.851111111111116, "ram_util_percent": 56.6822222222222}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.7, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.18, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.05, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.18, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.18, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5469043325943251, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07976020629527435, "policy_loss": -0.1079002637809026, "vf_loss": 0.009405313187744468, "vf_explained_var": 0.5631282515823841, "kl": 0.016555133900927405, "entropy": 1.705707131822904, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 26400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5593182212052246, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.0833577333149151, "policy_loss": -0.11465840982079195, "vf_loss": 0.013829898495653954, "vf_explained_var": 0.5733795511846741, "kl": 0.017209065488619352, "entropy": 1.750540616735816, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 26400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "sampler_results": {"episode_reward_max": 1.8940000000000001, "episode_reward_min": -0.3670000000000001, "episode_reward_mean": 0.46749, "episode_len_mean": 112.3, "episode_media": {}, "episodes_this_iter": 29, "policy_reward_min": {"red_0": -1.032, "blue_0": -1.022}, "policy_reward_max": {"red_0": 1.4569999999999999, "blue_0": 1.3980000000000001}, "policy_reward_mean": {"red_0": 0.62517, "blue_0": -0.15768000000000001}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.7, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.18, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.05, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.18, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.18, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9180000000000001, 0.401, 1.604, 0.5219999999999999, 0.506, 0.33699999999999997, 0.40200000000000014, 0.11299999999999999, 0.9119999999999999, 0.7609999999999999, -0.138, 0.1160000000000001, 0.20799999999999996, 0.44300000000000006, 0.793, 0.6859999999999999, 0.32699999999999996, 0.9239999999999999, 0.2919999999999998, -0.09699999999999998, 0.41999999999999993, 0.9329999999999998, 0.6859999999999999, 0.02200000000000002, 0.06400000000000006, 0.756, 0.589, 0.33299999999999996, 0.16399999999999992, 0.32699999999999996, 0.2600000000000001, -0.16700000000000004, -0.28, 0.9099999999999999, 0.020000000000000018, 0.667, -0.026000000000000023, 0.8900000000000001, 0.29400000000000004, 0.32699999999999996, 0.5049999999999999, 0.833, 1.798, 0.677, 0.4079999999999999, 0.901, 0.8069999999999999, -0.131, 0.21399999999999997, -0.05500000000000005, -0.17000000000000004, 0.9249999999999999, 0.62, 0.697, 0.7349999999999999, 0.853, 0.8719999999999999, 0.619, 0.41800000000000015, -0.263, -0.10199999999999987, 0.30799999999999983, 0.21999999999999997, 0.46199999999999997, 0.31300000000000017, 0.785, 0.802, 0.06299999999999994, 0.347, -0.16500000000000004, 0.36099999999999977, 0.944, 0.48, 0.31699999999999995, 0.6179999999999999, 0.7570000000000001, -0.11199999999999999, 0.2879999999999998, 0.742, 0.03799999999999992, 0.536, 0.613, 1.8940000000000001, 0.01200000000000001, 1.216, 0.18799999999999994, -0.3670000000000001, 0.8079999999999998, 0.1439999999999999, 0.956, 1.322, 0.347, -0.06600000000000006, 0.9209999999999999, -0.32599999999999996, 0.9079999999999999, 0.9239999999999999, -0.14100000000000001, 0.5529999999999999, 0.359], "episode_lengths": [25, 31, 122, 145, 150, 49, 32, 119, 28, 73, 42, 270, 91, 17, 64, 95, 54, 300, 221, 29, 25, 20, 98, 144, 132, 75, 124, 51, 255, 210, 71, 48, 84, 300, 145, 103, 162, 34, 216, 53, 154, 53, 60, 95, 27, 29, 61, 40, 89, 16, 50, 300, 119, 96, 81, 43, 40, 119, 26, 80, 31, 60, 241, 12, 211, 66, 62, 285, 48, 51, 195, 300, 158, 56, 117, 74, 35, 67, 79, 139, 144, 119, 33, 152, 246, 252, 270, 61, 112, 14, 207, 47, 20, 300, 103, 300, 300, 43, 136, 199], "policy_red_0_reward": [1.421, 0.902, 0.486, -0.527, 1.033, 0.843, 0.902, 0.629, 1.412, -0.513, 0.869, 0.6519999999999999, 0.714, 1.447, -0.505, 1.202, 0.831, 0.46199999999999997, 0.813, 0.909, 1.424, 1.439, -0.506, -1.021, 0.578, 1.2690000000000001, 1.109, 0.838, 0.7, 0.848, -1.0159999999999998, 0.849, 0.742, 0.45099999999999996, 0.5289999999999999, 1.177, 0.493, 1.395, 0.817, 0.839, 1.021, 1.335, 0.486, -0.518, 0.913, 1.409, -0.505, 0.875, -1.009, 0.949, 0.843, 0.46499999999999997, -0.508, -0.509, 1.244, 1.3639999999999999, 1.376, 1.1320000000000001, 0.921, 0.744, -1.007, 1.315, 0.751, 0.964, 0.842, -0.509, 1.308, 0.609, 1.3519999999999999, 0.845, 0.8839999999999999, 0.473, -0.525, -1.012, 1.13, 1.2730000000000001, 0.89, 0.7899999999999999, 1.252, -1.032, 1.048, 1.125, 0.496, 1.0259999999999998, 0.47, 0.716, -1.027, 1.314, 1.158, 1.4569999999999999, 0.469, 0.852, -1.003, 0.44999999999999996, 0.68, 0.45099999999999996, 0.46299999999999997, 0.866, 1.0710000000000002, 0.878], "policy_blue_0_reward": [-0.503, -0.501, 1.1179999999999999, 1.049, -0.527, -0.506, -0.5, -0.516, -0.5, 1.274, -1.007, -0.5359999999999999, -0.506, -1.0039999999999998, 1.298, -0.516, -0.504, 0.46199999999999997, -0.521, -1.006, -1.004, -0.506, 1.192, 1.0430000000000001, -0.514, -0.513, -0.5199999999999999, -0.505, -0.536, -0.521, 1.276, -1.016, -1.022, 0.45899999999999996, -0.509, -0.51, -0.519, -0.505, -0.523, -0.512, -0.516, -0.502, 1.3119999999999998, 1.195, -0.505, -0.508, 1.3119999999999998, -1.006, 1.2229999999999999, -1.004, -1.013, 0.45999999999999996, 1.1280000000000001, 1.206, -0.509, -0.511, -0.504, -0.513, -0.503, -1.007, 0.905, -1.007, -0.531, -0.502, -0.5289999999999999, 1.294, -0.506, -0.546, -1.005, -1.01, -0.523, 0.471, 1.005, 1.329, -0.512, -0.516, -1.002, -0.502, -0.51, 1.0699999999999998, -0.512, -0.512, 1.3980000000000001, -1.014, 0.746, -0.528, 0.6599999999999999, -0.506, -1.014, -0.501, 0.853, -0.505, 0.9369999999999999, 0.471, -1.006, 0.45699999999999996, 0.46099999999999997, -1.007, -0.518, -0.519]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3428413614377148, "mean_inference_ms": 7.3463326916600655, "mean_action_processing_ms": 0.3954509223545399, "mean_env_wait_ms": 0.5069046652181134, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13745713233947754, "StateBufferConnector_ms": 0.009025096893310547, "ViewRequirementAgentConnector_ms": 0.18221378326416016}}, "episode_reward_max": 1.8940000000000001, "episode_reward_min": -0.3670000000000001, "episode_reward_mean": 0.46749, "episode_len_mean": 112.3, "episodes_this_iter": 29, "policy_reward_min": {"red_0": -1.032, "blue_0": -1.022}, "policy_reward_max": {"red_0": 1.4569999999999999, "blue_0": 1.3980000000000001}, "policy_reward_mean": {"red_0": 0.62517, "blue_0": -0.15768000000000001}, "hist_stats": {"episode_reward": [0.9180000000000001, 0.401, 1.604, 0.5219999999999999, 0.506, 0.33699999999999997, 0.40200000000000014, 0.11299999999999999, 0.9119999999999999, 0.7609999999999999, -0.138, 0.1160000000000001, 0.20799999999999996, 0.44300000000000006, 0.793, 0.6859999999999999, 0.32699999999999996, 0.9239999999999999, 0.2919999999999998, -0.09699999999999998, 0.41999999999999993, 0.9329999999999998, 0.6859999999999999, 0.02200000000000002, 0.06400000000000006, 0.756, 0.589, 0.33299999999999996, 0.16399999999999992, 0.32699999999999996, 0.2600000000000001, -0.16700000000000004, -0.28, 0.9099999999999999, 0.020000000000000018, 0.667, -0.026000000000000023, 0.8900000000000001, 0.29400000000000004, 0.32699999999999996, 0.5049999999999999, 0.833, 1.798, 0.677, 0.4079999999999999, 0.901, 0.8069999999999999, -0.131, 0.21399999999999997, -0.05500000000000005, -0.17000000000000004, 0.9249999999999999, 0.62, 0.697, 0.7349999999999999, 0.853, 0.8719999999999999, 0.619, 0.41800000000000015, -0.263, -0.10199999999999987, 0.30799999999999983, 0.21999999999999997, 0.46199999999999997, 0.31300000000000017, 0.785, 0.802, 0.06299999999999994, 0.347, -0.16500000000000004, 0.36099999999999977, 0.944, 0.48, 0.31699999999999995, 0.6179999999999999, 0.7570000000000001, -0.11199999999999999, 0.2879999999999998, 0.742, 0.03799999999999992, 0.536, 0.613, 1.8940000000000001, 0.01200000000000001, 1.216, 0.18799999999999994, -0.3670000000000001, 0.8079999999999998, 0.1439999999999999, 0.956, 1.322, 0.347, -0.06600000000000006, 0.9209999999999999, -0.32599999999999996, 0.9079999999999999, 0.9239999999999999, -0.14100000000000001, 0.5529999999999999, 0.359], "episode_lengths": [25, 31, 122, 145, 150, 49, 32, 119, 28, 73, 42, 270, 91, 17, 64, 95, 54, 300, 221, 29, 25, 20, 98, 144, 132, 75, 124, 51, 255, 210, 71, 48, 84, 300, 145, 103, 162, 34, 216, 53, 154, 53, 60, 95, 27, 29, 61, 40, 89, 16, 50, 300, 119, 96, 81, 43, 40, 119, 26, 80, 31, 60, 241, 12, 211, 66, 62, 285, 48, 51, 195, 300, 158, 56, 117, 74, 35, 67, 79, 139, 144, 119, 33, 152, 246, 252, 270, 61, 112, 14, 207, 47, 20, 300, 103, 300, 300, 43, 136, 199], "policy_red_0_reward": [1.421, 0.902, 0.486, -0.527, 1.033, 0.843, 0.902, 0.629, 1.412, -0.513, 0.869, 0.6519999999999999, 0.714, 1.447, -0.505, 1.202, 0.831, 0.46199999999999997, 0.813, 0.909, 1.424, 1.439, -0.506, -1.021, 0.578, 1.2690000000000001, 1.109, 0.838, 0.7, 0.848, -1.0159999999999998, 0.849, 0.742, 0.45099999999999996, 0.5289999999999999, 1.177, 0.493, 1.395, 0.817, 0.839, 1.021, 1.335, 0.486, -0.518, 0.913, 1.409, -0.505, 0.875, -1.009, 0.949, 0.843, 0.46499999999999997, -0.508, -0.509, 1.244, 1.3639999999999999, 1.376, 1.1320000000000001, 0.921, 0.744, -1.007, 1.315, 0.751, 0.964, 0.842, -0.509, 1.308, 0.609, 1.3519999999999999, 0.845, 0.8839999999999999, 0.473, -0.525, -1.012, 1.13, 1.2730000000000001, 0.89, 0.7899999999999999, 1.252, -1.032, 1.048, 1.125, 0.496, 1.0259999999999998, 0.47, 0.716, -1.027, 1.314, 1.158, 1.4569999999999999, 0.469, 0.852, -1.003, 0.44999999999999996, 0.68, 0.45099999999999996, 0.46299999999999997, 0.866, 1.0710000000000002, 0.878], "policy_blue_0_reward": [-0.503, -0.501, 1.1179999999999999, 1.049, -0.527, -0.506, -0.5, -0.516, -0.5, 1.274, -1.007, -0.5359999999999999, -0.506, -1.0039999999999998, 1.298, -0.516, -0.504, 0.46199999999999997, -0.521, -1.006, -1.004, -0.506, 1.192, 1.0430000000000001, -0.514, -0.513, -0.5199999999999999, -0.505, -0.536, -0.521, 1.276, -1.016, -1.022, 0.45899999999999996, -0.509, -0.51, -0.519, -0.505, -0.523, -0.512, -0.516, -0.502, 1.3119999999999998, 1.195, -0.505, -0.508, 1.3119999999999998, -1.006, 1.2229999999999999, -1.004, -1.013, 0.45999999999999996, 1.1280000000000001, 1.206, -0.509, -0.511, -0.504, -0.513, -0.503, -1.007, 0.905, -1.007, -0.531, -0.502, -0.5289999999999999, 1.294, -0.506, -0.546, -1.005, -1.01, -0.523, 0.471, 1.005, 1.329, -0.512, -0.516, -1.002, -0.502, -0.51, 1.0699999999999998, -0.512, -0.512, 1.3980000000000001, -1.014, 0.746, -0.528, 0.6599999999999999, -0.506, -1.014, -0.501, 0.853, -0.505, 0.9369999999999999, 0.471, -1.006, 0.45699999999999996, 0.46099999999999997, -1.007, -0.518, -0.519]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3428413614377148, "mean_inference_ms": 7.3463326916600655, "mean_action_processing_ms": 0.3954509223545399, "mean_env_wait_ms": 0.5069046652181134, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13745713233947754, "StateBufferConnector_ms": 0.009025096893310547, "ViewRequirementAgentConnector_ms": 0.18221378326416016}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.30548612198032, "num_env_steps_trained_throughput_per_sec": 130.30548612198032, "timesteps_total": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 31383.287, "sample_time_ms": 3928.924, "learn_time_ms": 27426.263, "learn_throughput": 145.846, "synch_weights_time_ms": 26.549}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "episodes_total": 767, "training_iteration": 28, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-11-13", "timestamp": 1694837473, "time_this_iter_s": 30.712682962417603, "time_total_s": 849.5989763736725, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7234bac0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 849.5989763736725, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 22.502222222222223, "ram_util_percent": 56.695555555555536}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.65, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.2, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.65, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.07, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.2, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.65, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.2, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.520358458502839, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08216625170074016, "policy_loss": -0.1146102822739825, "vf_loss": 0.01649218008678872, "vf_explained_var": 0.537217199926575, "kl": 0.017050442426976294, "entropy": 1.6974182109038034, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 27360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5586301226789753, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08552344147077141, "policy_loss": -0.11847815563814948, "vf_loss": 0.018064767268515424, "vf_explained_var": 0.617403696787854, "kl": 0.016911821062955655, "entropy": 1.762496587013205, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 27360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000}, "sampler_results": {"episode_reward_max": 1.8940000000000001, "episode_reward_min": -0.3670000000000001, "episode_reward_mean": 0.5155699999999999, "episode_len_mean": 109.74, "episode_media": {}, "episodes_this_iter": 40, "policy_reward_min": {"red_0": -1.032, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.3980000000000001}, "policy_reward_mean": {"red_0": 0.61478, "blue_0": -0.09920999999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.65, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.2, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.65, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.07, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.2, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.65, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.2, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.5049999999999999, 0.833, 1.798, 0.677, 0.4079999999999999, 0.901, 0.8069999999999999, -0.131, 0.21399999999999997, -0.05500000000000005, -0.17000000000000004, 0.9249999999999999, 0.62, 0.697, 0.7349999999999999, 0.853, 0.8719999999999999, 0.619, 0.41800000000000015, -0.263, -0.10199999999999987, 0.30799999999999983, 0.21999999999999997, 0.46199999999999997, 0.31300000000000017, 0.785, 0.802, 0.06299999999999994, 0.347, -0.16500000000000004, 0.36099999999999977, 0.944, 0.48, 0.31699999999999995, 0.6179999999999999, 0.7570000000000001, -0.11199999999999999, 0.2879999999999998, 0.742, 0.03799999999999992, 0.536, 0.613, 1.8940000000000001, 0.01200000000000001, 1.216, 0.18799999999999994, -0.3670000000000001, 0.8079999999999998, 0.1439999999999999, 0.956, 1.322, 0.347, -0.06600000000000006, 0.9209999999999999, -0.32599999999999996, 0.9079999999999999, 0.9239999999999999, -0.14100000000000001, 0.5529999999999999, 0.359, 0.29699999999999993, -0.21599999999999997, 0.858, 0.905, 0.40900000000000003, 0.1499999999999999, 0.2509999999999999, 0.43900000000000006, 0.3660000000000001, 0.266, 0.44399999999999995, 0.819, 0.9199999999999999, 0.563, 0.06399999999999995, 0.7390000000000001, 0.6560000000000001, 0.43299999999999994, 1.778, 1.7810000000000001, -0.07499999999999996, 0.4620000000000002, 0.9309999999999999, -0.10499999999999998, 0.623, -0.061000000000000054, 0.7749999999999999, -0.259, 0.31099999999999994, -0.16599999999999993, 0.29499999999999993, 1.811, 0.575, 0.405, 0.43199999999999994, 0.897, 0.7849999999999999, 0.9249999999999999, 0.601, 0.9430000000000001], "episode_lengths": [154, 53, 60, 95, 27, 29, 61, 40, 89, 16, 50, 300, 119, 96, 81, 43, 40, 119, 26, 80, 31, 60, 241, 12, 211, 66, 62, 285, 48, 51, 195, 300, 158, 56, 117, 74, 35, 67, 79, 139, 144, 119, 33, 152, 246, 252, 270, 61, 112, 14, 207, 47, 20, 300, 103, 300, 300, 43, 136, 199, 63, 65, 44, 29, 27, 108, 230, 170, 42, 72, 171, 59, 300, 135, 285, 80, 105, 21, 69, 68, 22, 12, 300, 34, 115, 175, 70, 78, 210, 51, 61, 58, 130, 29, 21, 32, 67, 300, 125, 18], "policy_red_0_reward": [1.021, 1.335, 0.486, -0.518, 0.913, 1.409, -0.505, 0.875, -1.009, 0.949, 0.843, 0.46499999999999997, -0.508, -0.509, 1.244, 1.3639999999999999, 1.376, 1.1320000000000001, 0.921, 0.744, -1.007, 1.315, 0.751, 0.964, 0.842, -0.509, 1.308, 0.609, 1.3519999999999999, 0.845, 0.8839999999999999, 0.473, -0.525, -1.012, 1.13, 1.2730000000000001, 0.89, 0.7899999999999999, 1.252, -1.032, 1.048, 1.125, 0.496, 1.0259999999999998, 0.47, 0.716, -1.027, 1.314, 1.158, 1.4569999999999999, 0.469, 0.852, -1.003, 0.44999999999999996, 0.68, 0.45099999999999996, 0.46299999999999997, 0.866, 1.0710000000000002, 0.878, 0.8019999999999999, 0.7979999999999999, -0.503, 1.4100000000000001, 1.4140000000000001, 0.6699999999999999, 0.7839999999999999, 0.97, 1.37, 0.774, -0.522, 1.319, 0.46399999999999997, -0.516, -0.535, 1.2469999999999999, 1.171, -0.501, 0.491, 0.49, 0.9299999999999999, 1.464, 0.469, 0.897, 1.1400000000000001, -1.013, 1.282, 0.758, 0.841, -1.004, 0.8079999999999999, 0.49, 1.095, -0.504, 0.9339999999999999, 1.4020000000000001, 1.289, 0.46399999999999997, 1.1139999999999999, 1.444], "policy_blue_0_reward": [-0.516, -0.502, 1.3119999999999998, 1.195, -0.505, -0.508, 1.3119999999999998, -1.006, 1.2229999999999999, -1.004, -1.013, 0.45999999999999996, 1.1280000000000001, 1.206, -0.509, -0.511, -0.504, -0.513, -0.503, -1.007, 0.905, -1.007, -0.531, -0.502, -0.5289999999999999, 1.294, -0.506, -0.546, -1.005, -1.01, -0.523, 0.471, 1.005, 1.329, -0.512, -0.516, -1.002, -0.502, -0.51, 1.0699999999999998, -0.512, -0.512, 1.3980000000000001, -1.014, 0.746, -0.528, 0.6599999999999999, -0.506, -1.014, -0.501, 0.853, -0.505, 0.9369999999999999, 0.471, -1.006, 0.45699999999999996, 0.46099999999999997, -1.007, -0.518, -0.519, -0.505, -1.0139999999999998, 1.361, -0.505, -1.005, -0.52, -0.533, -0.531, -1.0039999999999998, -0.508, 0.966, -0.5, 0.45599999999999996, 1.079, 0.599, -0.5079999999999999, -0.515, 0.9339999999999999, 1.287, 1.291, -1.005, -1.0019999999999998, 0.46199999999999997, -1.002, -0.517, 0.952, -0.507, -1.017, -0.53, 0.838, -0.5129999999999999, 1.3210000000000002, -0.52, 0.909, -0.502, -0.505, -0.504, 0.46099999999999997, -0.513, -0.501]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.343270576786889, "mean_inference_ms": 7.339376786048058, "mean_action_processing_ms": 0.3933427467022759, "mean_env_wait_ms": 0.5078333832022619, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13929176330566406, "StateBufferConnector_ms": 0.010303139686584473, "ViewRequirementAgentConnector_ms": 0.18348979949951172}}, "episode_reward_max": 1.8940000000000001, "episode_reward_min": -0.3670000000000001, "episode_reward_mean": 0.5155699999999999, "episode_len_mean": 109.74, "episodes_this_iter": 40, "policy_reward_min": {"red_0": -1.032, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.3980000000000001}, "policy_reward_mean": {"red_0": 0.61478, "blue_0": -0.09920999999999999}, "hist_stats": {"episode_reward": [0.5049999999999999, 0.833, 1.798, 0.677, 0.4079999999999999, 0.901, 0.8069999999999999, -0.131, 0.21399999999999997, -0.05500000000000005, -0.17000000000000004, 0.9249999999999999, 0.62, 0.697, 0.7349999999999999, 0.853, 0.8719999999999999, 0.619, 0.41800000000000015, -0.263, -0.10199999999999987, 0.30799999999999983, 0.21999999999999997, 0.46199999999999997, 0.31300000000000017, 0.785, 0.802, 0.06299999999999994, 0.347, -0.16500000000000004, 0.36099999999999977, 0.944, 0.48, 0.31699999999999995, 0.6179999999999999, 0.7570000000000001, -0.11199999999999999, 0.2879999999999998, 0.742, 0.03799999999999992, 0.536, 0.613, 1.8940000000000001, 0.01200000000000001, 1.216, 0.18799999999999994, -0.3670000000000001, 0.8079999999999998, 0.1439999999999999, 0.956, 1.322, 0.347, -0.06600000000000006, 0.9209999999999999, -0.32599999999999996, 0.9079999999999999, 0.9239999999999999, -0.14100000000000001, 0.5529999999999999, 0.359, 0.29699999999999993, -0.21599999999999997, 0.858, 0.905, 0.40900000000000003, 0.1499999999999999, 0.2509999999999999, 0.43900000000000006, 0.3660000000000001, 0.266, 0.44399999999999995, 0.819, 0.9199999999999999, 0.563, 0.06399999999999995, 0.7390000000000001, 0.6560000000000001, 0.43299999999999994, 1.778, 1.7810000000000001, -0.07499999999999996, 0.4620000000000002, 0.9309999999999999, -0.10499999999999998, 0.623, -0.061000000000000054, 0.7749999999999999, -0.259, 0.31099999999999994, -0.16599999999999993, 0.29499999999999993, 1.811, 0.575, 0.405, 0.43199999999999994, 0.897, 0.7849999999999999, 0.9249999999999999, 0.601, 0.9430000000000001], "episode_lengths": [154, 53, 60, 95, 27, 29, 61, 40, 89, 16, 50, 300, 119, 96, 81, 43, 40, 119, 26, 80, 31, 60, 241, 12, 211, 66, 62, 285, 48, 51, 195, 300, 158, 56, 117, 74, 35, 67, 79, 139, 144, 119, 33, 152, 246, 252, 270, 61, 112, 14, 207, 47, 20, 300, 103, 300, 300, 43, 136, 199, 63, 65, 44, 29, 27, 108, 230, 170, 42, 72, 171, 59, 300, 135, 285, 80, 105, 21, 69, 68, 22, 12, 300, 34, 115, 175, 70, 78, 210, 51, 61, 58, 130, 29, 21, 32, 67, 300, 125, 18], "policy_red_0_reward": [1.021, 1.335, 0.486, -0.518, 0.913, 1.409, -0.505, 0.875, -1.009, 0.949, 0.843, 0.46499999999999997, -0.508, -0.509, 1.244, 1.3639999999999999, 1.376, 1.1320000000000001, 0.921, 0.744, -1.007, 1.315, 0.751, 0.964, 0.842, -0.509, 1.308, 0.609, 1.3519999999999999, 0.845, 0.8839999999999999, 0.473, -0.525, -1.012, 1.13, 1.2730000000000001, 0.89, 0.7899999999999999, 1.252, -1.032, 1.048, 1.125, 0.496, 1.0259999999999998, 0.47, 0.716, -1.027, 1.314, 1.158, 1.4569999999999999, 0.469, 0.852, -1.003, 0.44999999999999996, 0.68, 0.45099999999999996, 0.46299999999999997, 0.866, 1.0710000000000002, 0.878, 0.8019999999999999, 0.7979999999999999, -0.503, 1.4100000000000001, 1.4140000000000001, 0.6699999999999999, 0.7839999999999999, 0.97, 1.37, 0.774, -0.522, 1.319, 0.46399999999999997, -0.516, -0.535, 1.2469999999999999, 1.171, -0.501, 0.491, 0.49, 0.9299999999999999, 1.464, 0.469, 0.897, 1.1400000000000001, -1.013, 1.282, 0.758, 0.841, -1.004, 0.8079999999999999, 0.49, 1.095, -0.504, 0.9339999999999999, 1.4020000000000001, 1.289, 0.46399999999999997, 1.1139999999999999, 1.444], "policy_blue_0_reward": [-0.516, -0.502, 1.3119999999999998, 1.195, -0.505, -0.508, 1.3119999999999998, -1.006, 1.2229999999999999, -1.004, -1.013, 0.45999999999999996, 1.1280000000000001, 1.206, -0.509, -0.511, -0.504, -0.513, -0.503, -1.007, 0.905, -1.007, -0.531, -0.502, -0.5289999999999999, 1.294, -0.506, -0.546, -1.005, -1.01, -0.523, 0.471, 1.005, 1.329, -0.512, -0.516, -1.002, -0.502, -0.51, 1.0699999999999998, -0.512, -0.512, 1.3980000000000001, -1.014, 0.746, -0.528, 0.6599999999999999, -0.506, -1.014, -0.501, 0.853, -0.505, 0.9369999999999999, 0.471, -1.006, 0.45699999999999996, 0.46099999999999997, -1.007, -0.518, -0.519, -0.505, -1.0139999999999998, 1.361, -0.505, -1.005, -0.52, -0.533, -0.531, -1.0039999999999998, -0.508, 0.966, -0.5, 0.45599999999999996, 1.079, 0.599, -0.5079999999999999, -0.515, 0.9339999999999999, 1.287, 1.291, -1.005, -1.0019999999999998, 0.46199999999999997, -1.002, -0.517, 0.952, -0.507, -1.017, -0.53, 0.838, -0.5129999999999999, 1.3210000000000002, -0.52, 0.909, -0.502, -0.505, -0.504, 0.46099999999999997, -0.513, -0.501]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.343270576786889, "mean_inference_ms": 7.339376786048058, "mean_action_processing_ms": 0.3933427467022759, "mean_env_wait_ms": 0.5078333832022619, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13929176330566406, "StateBufferConnector_ms": 0.010303139686584473, "ViewRequirementAgentConnector_ms": 0.18348979949951172}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.55335532615504, "num_env_steps_trained_throughput_per_sec": 129.55335532615504, "timesteps_total": 116000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 232000, "timers": {"training_iteration_time_ms": 31388.346, "sample_time_ms": 3942.81, "learn_time_ms": 27415.149, "learn_throughput": 145.905, "synch_weights_time_ms": 28.879}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000}, "done": false, "episodes_total": 807, "training_iteration": 29, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-11-45", "timestamp": 1694837505, "time_this_iter_s": 30.90281581878662, "time_total_s": 880.5017921924591, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7239d750>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 880.5017921924591, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 24.96222222222222, "ram_util_percent": 56.71555555555554}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.64, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.19, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.64, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.08, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.19, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.64, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.19, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5379831140550474, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07756535207639294, "policy_loss": -0.10748460283017873, "vf_loss": 0.01083187955179407, "vf_explained_var": 0.5813368023683627, "kl": 0.01727123076721811, "entropy": 1.7273696751644214, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 28320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5352859297767282, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08187994311156217, "policy_loss": -0.11371688493867017, "vf_loss": 0.016442784642761884, "vf_explained_var": 0.5664064132298032, "kl": 0.016707652358567533, "entropy": 1.7591966286301612, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 28320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "sampler_results": {"episode_reward_max": 1.8940000000000001, "episode_reward_min": -0.3670000000000001, "episode_reward_mean": 0.5147600000000001, "episode_len_mean": 115.9, "episode_media": {}, "episodes_this_iter": 31, "policy_reward_min": {"red_0": -1.032, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.3980000000000001}, "policy_reward_mean": {"red_0": 0.60213, "blue_0": -0.08736999999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.64, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.19, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.64, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.08, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.19, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.64, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.19, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.944, 0.48, 0.31699999999999995, 0.6179999999999999, 0.7570000000000001, -0.11199999999999999, 0.2879999999999998, 0.742, 0.03799999999999992, 0.536, 0.613, 1.8940000000000001, 0.01200000000000001, 1.216, 0.18799999999999994, -0.3670000000000001, 0.8079999999999998, 0.1439999999999999, 0.956, 1.322, 0.347, -0.06600000000000006, 0.9209999999999999, -0.32599999999999996, 0.9079999999999999, 0.9239999999999999, -0.14100000000000001, 0.5529999999999999, 0.359, 0.29699999999999993, -0.21599999999999997, 0.858, 0.905, 0.40900000000000003, 0.1499999999999999, 0.2509999999999999, 0.43900000000000006, 0.3660000000000001, 0.266, 0.44399999999999995, 0.819, 0.9199999999999999, 0.563, 0.06399999999999995, 0.7390000000000001, 0.6560000000000001, 0.43299999999999994, 1.778, 1.7810000000000001, -0.07499999999999996, 0.4620000000000002, 0.9309999999999999, -0.10499999999999998, 0.623, -0.061000000000000054, 0.7749999999999999, -0.259, 0.31099999999999994, -0.16599999999999993, 0.29499999999999993, 1.811, 0.575, 0.405, 0.43199999999999994, 0.897, 0.7849999999999999, 0.9249999999999999, 0.601, 0.9430000000000001, 0.6019999999999999, 0.11699999999999999, 0.40700000000000003, 0.1479999999999999, 0.389, 0.5760000000000001, 0.43699999999999994, 0.21700000000000008, 0.31599999999999995, 0.33099999999999996, 0.17799999999999994, 0.6890000000000001, -0.32500000000000007, 0.42500000000000004, 1.2610000000000001, 0.45500000000000007, 0.3540000000000001, 0.9339999999999999, 0.9279999999999999, 0.7530000000000001, 0.3619999999999999, -0.07899999999999996, -0.16100000000000003, 0.9180000000000001, 1.793, 0.21399999999999997, 0.32600000000000007, 0.07299999999999995, 0.802, 0.8099999999999999, 0.32600000000000007], "episode_lengths": [300, 158, 56, 117, 74, 35, 67, 79, 139, 144, 119, 33, 152, 246, 252, 270, 61, 112, 14, 207, 47, 20, 300, 103, 300, 300, 43, 136, 199, 63, 65, 44, 29, 27, 108, 230, 170, 42, 72, 171, 59, 300, 135, 285, 80, 105, 21, 69, 68, 22, 12, 300, 34, 115, 175, 70, 78, 210, 51, 61, 58, 130, 29, 21, 32, 67, 300, 125, 18, 123, 119, 29, 262, 34, 129, 174, 90, 56, 53, 98, 95, 251, 23, 75, 169, 196, 300, 300, 76, 192, 25, 49, 27, 63, 88, 53, 133, 61, 59, 54], "policy_red_0_reward": [0.473, -0.525, -1.012, 1.13, 1.2730000000000001, 0.89, 0.7899999999999999, 1.252, -1.032, 1.048, 1.125, 0.496, 1.0259999999999998, 0.47, 0.716, -1.027, 1.314, 1.158, 1.4569999999999999, 0.469, 0.852, -1.003, 0.44999999999999996, 0.68, 0.45099999999999996, 0.46299999999999997, 0.866, 1.0710000000000002, 0.878, 0.8019999999999999, 0.7979999999999999, -0.503, 1.4100000000000001, 1.4140000000000001, 0.6699999999999999, 0.7839999999999999, 0.97, 1.37, 0.774, -0.522, 1.319, 0.46399999999999997, -0.516, -0.535, 1.2469999999999999, 1.171, -0.501, 0.491, 0.49, 0.9299999999999999, 1.464, 0.469, 0.897, 1.1400000000000001, -1.013, 1.282, 0.758, 0.841, -1.004, 0.8079999999999999, 0.49, 1.095, -0.504, 0.9339999999999999, 1.4020000000000001, 1.289, 0.46399999999999997, 1.1139999999999999, 1.444, 1.115, 1.131, 0.909, 0.6829999999999999, 1.393, 1.099, -0.523, 1.225, -1.003, -0.506, 0.6859999999999999, 1.2040000000000002, 0.21799999999999997, 0.928, -0.009000000000000001, 0.975, -0.5319999999999999, 0.46599999999999997, 0.46499999999999997, 1.264, 0.8879999999999999, -1.003, 0.843, 1.4180000000000001, 0.49, 0.725, 1.333, 0.59, 1.3159999999999998, -0.505, 0.834], "policy_blue_0_reward": [0.471, 1.005, 1.329, -0.512, -0.516, -1.002, -0.502, -0.51, 1.0699999999999998, -0.512, -0.512, 1.3980000000000001, -1.014, 0.746, -0.528, 0.6599999999999999, -0.506, -1.014, -0.501, 0.853, -0.505, 0.9369999999999999, 0.471, -1.006, 0.45699999999999996, 0.46099999999999997, -1.007, -0.518, -0.519, -0.505, -1.0139999999999998, 1.361, -0.505, -1.005, -0.52, -0.533, -0.531, -1.0039999999999998, -0.508, 0.966, -0.5, 0.45599999999999996, 1.079, 0.599, -0.5079999999999999, -0.515, 0.9339999999999999, 1.287, 1.291, -1.005, -1.0019999999999998, 0.46199999999999997, -1.002, -0.517, 0.952, -0.507, -1.017, -0.53, 0.838, -0.5129999999999999, 1.3210000000000002, -0.52, 0.909, -0.502, -0.505, -0.504, 0.46099999999999997, -0.513, -0.501, -0.513, -1.014, -0.502, -0.535, -1.004, -0.523, 0.96, -1.008, 1.319, 0.837, -0.508, -0.515, -0.543, -0.503, 1.27, -0.5199999999999999, 0.886, 0.46799999999999997, 0.46299999999999997, -0.511, -0.526, 0.924, -1.004, -0.5, 1.303, -0.511, -1.007, -0.5169999999999999, -0.514, 1.315, -0.508]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3446478440748577, "mean_inference_ms": 7.339416570074004, "mean_action_processing_ms": 0.39241668140597313, "mean_env_wait_ms": 0.5088513774831823, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14701342582702637, "StateBufferConnector_ms": 0.010537028312683105, "ViewRequirementAgentConnector_ms": 0.20220673084259033}}, "episode_reward_max": 1.8940000000000001, "episode_reward_min": -0.3670000000000001, "episode_reward_mean": 0.5147600000000001, "episode_len_mean": 115.9, "episodes_this_iter": 31, "policy_reward_min": {"red_0": -1.032, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.3980000000000001}, "policy_reward_mean": {"red_0": 0.60213, "blue_0": -0.08736999999999999}, "hist_stats": {"episode_reward": [0.944, 0.48, 0.31699999999999995, 0.6179999999999999, 0.7570000000000001, -0.11199999999999999, 0.2879999999999998, 0.742, 0.03799999999999992, 0.536, 0.613, 1.8940000000000001, 0.01200000000000001, 1.216, 0.18799999999999994, -0.3670000000000001, 0.8079999999999998, 0.1439999999999999, 0.956, 1.322, 0.347, -0.06600000000000006, 0.9209999999999999, -0.32599999999999996, 0.9079999999999999, 0.9239999999999999, -0.14100000000000001, 0.5529999999999999, 0.359, 0.29699999999999993, -0.21599999999999997, 0.858, 0.905, 0.40900000000000003, 0.1499999999999999, 0.2509999999999999, 0.43900000000000006, 0.3660000000000001, 0.266, 0.44399999999999995, 0.819, 0.9199999999999999, 0.563, 0.06399999999999995, 0.7390000000000001, 0.6560000000000001, 0.43299999999999994, 1.778, 1.7810000000000001, -0.07499999999999996, 0.4620000000000002, 0.9309999999999999, -0.10499999999999998, 0.623, -0.061000000000000054, 0.7749999999999999, -0.259, 0.31099999999999994, -0.16599999999999993, 0.29499999999999993, 1.811, 0.575, 0.405, 0.43199999999999994, 0.897, 0.7849999999999999, 0.9249999999999999, 0.601, 0.9430000000000001, 0.6019999999999999, 0.11699999999999999, 0.40700000000000003, 0.1479999999999999, 0.389, 0.5760000000000001, 0.43699999999999994, 0.21700000000000008, 0.31599999999999995, 0.33099999999999996, 0.17799999999999994, 0.6890000000000001, -0.32500000000000007, 0.42500000000000004, 1.2610000000000001, 0.45500000000000007, 0.3540000000000001, 0.9339999999999999, 0.9279999999999999, 0.7530000000000001, 0.3619999999999999, -0.07899999999999996, -0.16100000000000003, 0.9180000000000001, 1.793, 0.21399999999999997, 0.32600000000000007, 0.07299999999999995, 0.802, 0.8099999999999999, 0.32600000000000007], "episode_lengths": [300, 158, 56, 117, 74, 35, 67, 79, 139, 144, 119, 33, 152, 246, 252, 270, 61, 112, 14, 207, 47, 20, 300, 103, 300, 300, 43, 136, 199, 63, 65, 44, 29, 27, 108, 230, 170, 42, 72, 171, 59, 300, 135, 285, 80, 105, 21, 69, 68, 22, 12, 300, 34, 115, 175, 70, 78, 210, 51, 61, 58, 130, 29, 21, 32, 67, 300, 125, 18, 123, 119, 29, 262, 34, 129, 174, 90, 56, 53, 98, 95, 251, 23, 75, 169, 196, 300, 300, 76, 192, 25, 49, 27, 63, 88, 53, 133, 61, 59, 54], "policy_red_0_reward": [0.473, -0.525, -1.012, 1.13, 1.2730000000000001, 0.89, 0.7899999999999999, 1.252, -1.032, 1.048, 1.125, 0.496, 1.0259999999999998, 0.47, 0.716, -1.027, 1.314, 1.158, 1.4569999999999999, 0.469, 0.852, -1.003, 0.44999999999999996, 0.68, 0.45099999999999996, 0.46299999999999997, 0.866, 1.0710000000000002, 0.878, 0.8019999999999999, 0.7979999999999999, -0.503, 1.4100000000000001, 1.4140000000000001, 0.6699999999999999, 0.7839999999999999, 0.97, 1.37, 0.774, -0.522, 1.319, 0.46399999999999997, -0.516, -0.535, 1.2469999999999999, 1.171, -0.501, 0.491, 0.49, 0.9299999999999999, 1.464, 0.469, 0.897, 1.1400000000000001, -1.013, 1.282, 0.758, 0.841, -1.004, 0.8079999999999999, 0.49, 1.095, -0.504, 0.9339999999999999, 1.4020000000000001, 1.289, 0.46399999999999997, 1.1139999999999999, 1.444, 1.115, 1.131, 0.909, 0.6829999999999999, 1.393, 1.099, -0.523, 1.225, -1.003, -0.506, 0.6859999999999999, 1.2040000000000002, 0.21799999999999997, 0.928, -0.009000000000000001, 0.975, -0.5319999999999999, 0.46599999999999997, 0.46499999999999997, 1.264, 0.8879999999999999, -1.003, 0.843, 1.4180000000000001, 0.49, 0.725, 1.333, 0.59, 1.3159999999999998, -0.505, 0.834], "policy_blue_0_reward": [0.471, 1.005, 1.329, -0.512, -0.516, -1.002, -0.502, -0.51, 1.0699999999999998, -0.512, -0.512, 1.3980000000000001, -1.014, 0.746, -0.528, 0.6599999999999999, -0.506, -1.014, -0.501, 0.853, -0.505, 0.9369999999999999, 0.471, -1.006, 0.45699999999999996, 0.46099999999999997, -1.007, -0.518, -0.519, -0.505, -1.0139999999999998, 1.361, -0.505, -1.005, -0.52, -0.533, -0.531, -1.0039999999999998, -0.508, 0.966, -0.5, 0.45599999999999996, 1.079, 0.599, -0.5079999999999999, -0.515, 0.9339999999999999, 1.287, 1.291, -1.005, -1.0019999999999998, 0.46199999999999997, -1.002, -0.517, 0.952, -0.507, -1.017, -0.53, 0.838, -0.5129999999999999, 1.3210000000000002, -0.52, 0.909, -0.502, -0.505, -0.504, 0.46099999999999997, -0.513, -0.501, -0.513, -1.014, -0.502, -0.535, -1.004, -0.523, 0.96, -1.008, 1.319, 0.837, -0.508, -0.515, -0.543, -0.503, 1.27, -0.5199999999999999, 0.886, 0.46799999999999997, 0.46299999999999997, -0.511, -0.526, 0.924, -1.004, -0.5, 1.303, -0.511, -1.007, -0.5169999999999999, -0.514, 1.315, -0.508]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3446478440748577, "mean_inference_ms": 7.339416570074004, "mean_action_processing_ms": 0.39241668140597313, "mean_env_wait_ms": 0.5088513774831823, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14701342582702637, "StateBufferConnector_ms": 0.010537028312683105, "ViewRequirementAgentConnector_ms": 0.20220673084259033}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.04571869542772, "num_env_steps_trained_throughput_per_sec": 127.04571869542772, "timesteps_total": 120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 31330.505, "sample_time_ms": 3952.48, "learn_time_ms": 27347.655, "learn_throughput": 146.265, "synch_weights_time_ms": 28.848}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "episodes_total": 838, "training_iteration": 30, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-12-17", "timestamp": 1694837537, "time_this_iter_s": 31.499935150146484, "time_total_s": 912.0017273426056, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a1bcca0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 912.0017273426056, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 25.228888888888893, "ram_util_percent": 56.773333333333355}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.69, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.18, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.69, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.06, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.18, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.69, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.18, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.553864308570822, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08045305143362687, "policy_loss": -0.1166363366911052, "vf_loss": 0.02139461843277483, "vf_explained_var": 0.5164616590986649, "kl": 0.01788922796827986, "entropy": 1.6832881993303697, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 29280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5674485490657389, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08160404973896221, "policy_loss": -0.12041312844133548, "vf_loss": 0.024899981886846945, "vf_explained_var": 0.5837571805963914, "kl": 0.01849809295914046, "entropy": 1.7348892079045375, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 29280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000}, "sampler_results": {"episode_reward_max": 1.811, "episode_reward_min": -0.3550000000000001, "episode_reward_mean": 0.5211000000000001, "episode_len_mean": 102.56, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"red_0": -1.013, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.407}, "policy_reward_mean": {"red_0": 0.6679199999999998, "blue_0": -0.14681999999999998}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.69, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.18, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.69, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.06, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.18, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.69, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.18, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.7810000000000001, -0.07499999999999996, 0.4620000000000002, 0.9309999999999999, -0.10499999999999998, 0.623, -0.061000000000000054, 0.7749999999999999, -0.259, 0.31099999999999994, -0.16599999999999993, 0.29499999999999993, 1.811, 0.575, 0.405, 0.43199999999999994, 0.897, 0.7849999999999999, 0.9249999999999999, 0.601, 0.9430000000000001, 0.6019999999999999, 0.11699999999999999, 0.40700000000000003, 0.1479999999999999, 0.389, 0.5760000000000001, 0.43699999999999994, 0.21700000000000008, 0.31599999999999995, 0.33099999999999996, 0.17799999999999994, 0.6890000000000001, -0.32500000000000007, 0.42500000000000004, 1.2610000000000001, 0.45500000000000007, 0.3540000000000001, 0.9339999999999999, 0.9279999999999999, 0.7530000000000001, 0.3619999999999999, -0.07899999999999996, -0.16100000000000003, 0.9180000000000001, 1.793, 0.21399999999999997, 0.32600000000000007, 0.07299999999999995, 0.802, 0.8099999999999999, 0.32600000000000007, 0.2370000000000001, 0.569, -0.16800000000000004, 0.797, 0.04400000000000004, 0.747, 0.822, 1.67, 0.702, -0.07900000000000007, 0.9259999999999999, 0.16400000000000003, 0.2789999999999999, 0.5430000000000001, 0.7709999999999999, 0.488, 0.8740000000000001, 0.905, 0.3340000000000001, 0.2450000000000001, 0.40200000000000014, 0.33899999999999986, 0.9259999999999999, -0.28300000000000003, 0.33099999999999996, 0.5580000000000003, 0.7410000000000001, 0.2759999999999998, -0.3550000000000001, 0.8140000000000001, 0.2469999999999999, 1.8039999999999998, 0.8639999999999999, 0.585, 0.27600000000000025, 0.391, 0.4119999999999999, 0.8639999999999999, 0.43299999999999994, 0.44499999999999984, -0.008000000000000118, 1.734, 0.8540000000000001, 0.885, 0.266, 0.30799999999999983, 0.2829999999999999, 0.3860000000000001], "episode_lengths": [68, 22, 12, 300, 34, 115, 175, 70, 78, 210, 51, 61, 58, 130, 29, 21, 32, 67, 300, 125, 18, 123, 119, 29, 262, 34, 129, 174, 90, 56, 53, 98, 95, 251, 23, 75, 169, 196, 300, 300, 76, 192, 25, 49, 27, 63, 88, 53, 133, 61, 59, 54, 238, 133, 50, 64, 140, 77, 56, 103, 92, 24, 300, 101, 218, 142, 71, 158, 37, 31, 51, 232, 31, 204, 300, 86, 51, 136, 80, 69, 261, 57, 80, 61, 43, 127, 223, 34, 26, 41, 21, 17, 155, 82, 47, 37, 75, 60, 66, 36], "policy_red_0_reward": [0.49, 0.9299999999999999, 1.464, 0.469, 0.897, 1.1400000000000001, -1.013, 1.282, 0.758, 0.841, -1.004, 0.8079999999999999, 0.49, 1.095, -0.504, 0.9339999999999999, 1.4020000000000001, 1.289, 0.46399999999999997, 1.1139999999999999, 1.444, 1.115, 1.131, 0.909, 0.6829999999999999, 1.393, 1.099, -0.523, 1.225, -1.003, -0.506, 0.6859999999999999, 1.2040000000000002, 0.21799999999999997, 0.928, -0.009000000000000001, 0.975, -0.5319999999999999, 0.46599999999999997, 0.46499999999999997, 1.264, 0.8879999999999999, -1.003, 0.843, 1.4180000000000001, 0.49, 0.725, 1.333, 0.59, 1.3159999999999998, -0.505, 0.834, 0.765, 1.091, -1.013, -0.504, 0.5599999999999999, -0.515, -0.505, 0.49, -0.509, 0.9279999999999999, 0.46199999999999997, -1.012, 0.8089999999999999, 1.057, 1.2850000000000001, 1.01, 1.379, -0.502, 1.3399999999999999, 0.77, 1.404, -0.528, 0.46099999999999997, 0.724, 1.337, 1.074, 1.2530000000000001, 0.7859999999999999, 0.18399999999999994, 1.325, 1.254, 1.3119999999999998, 1.367, 1.105, 0.802, 0.894, 0.914, 1.371, -0.502, 1.447, 1.013, 0.492, 1.358, 1.389, 0.771, 1.3119999999999998, 1.291, 0.889], "policy_blue_0_reward": [1.291, -1.005, -1.0019999999999998, 0.46199999999999997, -1.002, -0.517, 0.952, -0.507, -1.017, -0.53, 0.838, -0.5129999999999999, 1.3210000000000002, -0.52, 0.909, -0.502, -0.505, -0.504, 0.46099999999999997, -0.513, -0.501, -0.513, -1.014, -0.502, -0.535, -1.004, -0.523, 0.96, -1.008, 1.319, 0.837, -0.508, -0.515, -0.543, -0.503, 1.27, -0.5199999999999999, 0.886, 0.46799999999999997, 0.46299999999999997, -0.511, -0.526, 0.924, -1.004, -0.5, 1.303, -0.511, -1.007, -0.5169999999999999, -0.514, 1.315, -0.508, -0.528, -0.522, 0.845, 1.3010000000000002, -0.516, 1.262, 1.327, 1.1800000000000002, 1.2109999999999999, -1.007, 0.46399999999999997, 1.1760000000000002, -0.53, -0.514, -0.514, -0.5219999999999999, -0.5049999999999999, 1.407, -1.006, -0.525, -1.002, 0.8669999999999999, 0.46499999999999997, -1.007, -1.0059999999999998, -0.5159999999999999, -0.512, -0.51, -0.539, -0.5109999999999999, -1.007, 0.492, -0.503, -0.52, -0.5259999999999999, -0.503, -0.502, -0.507, 0.9349999999999999, -1.002, -1.021, 1.242, -0.504, -0.504, -0.505, -1.004, -1.008, -0.503]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3492212413886222, "mean_inference_ms": 7.343023526238728, "mean_action_processing_ms": 0.39121447729492764, "mean_env_wait_ms": 0.5100914750220766, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15009307861328125, "StateBufferConnector_ms": 0.009540796279907227, "ViewRequirementAgentConnector_ms": 0.2091764211654663}}, "episode_reward_max": 1.811, "episode_reward_min": -0.3550000000000001, "episode_reward_mean": 0.5211000000000001, "episode_len_mean": 102.56, "episodes_this_iter": 48, "policy_reward_min": {"red_0": -1.013, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.407}, "policy_reward_mean": {"red_0": 0.6679199999999998, "blue_0": -0.14681999999999998}, "hist_stats": {"episode_reward": [1.7810000000000001, -0.07499999999999996, 0.4620000000000002, 0.9309999999999999, -0.10499999999999998, 0.623, -0.061000000000000054, 0.7749999999999999, -0.259, 0.31099999999999994, -0.16599999999999993, 0.29499999999999993, 1.811, 0.575, 0.405, 0.43199999999999994, 0.897, 0.7849999999999999, 0.9249999999999999, 0.601, 0.9430000000000001, 0.6019999999999999, 0.11699999999999999, 0.40700000000000003, 0.1479999999999999, 0.389, 0.5760000000000001, 0.43699999999999994, 0.21700000000000008, 0.31599999999999995, 0.33099999999999996, 0.17799999999999994, 0.6890000000000001, -0.32500000000000007, 0.42500000000000004, 1.2610000000000001, 0.45500000000000007, 0.3540000000000001, 0.9339999999999999, 0.9279999999999999, 0.7530000000000001, 0.3619999999999999, -0.07899999999999996, -0.16100000000000003, 0.9180000000000001, 1.793, 0.21399999999999997, 0.32600000000000007, 0.07299999999999995, 0.802, 0.8099999999999999, 0.32600000000000007, 0.2370000000000001, 0.569, -0.16800000000000004, 0.797, 0.04400000000000004, 0.747, 0.822, 1.67, 0.702, -0.07900000000000007, 0.9259999999999999, 0.16400000000000003, 0.2789999999999999, 0.5430000000000001, 0.7709999999999999, 0.488, 0.8740000000000001, 0.905, 0.3340000000000001, 0.2450000000000001, 0.40200000000000014, 0.33899999999999986, 0.9259999999999999, -0.28300000000000003, 0.33099999999999996, 0.5580000000000003, 0.7410000000000001, 0.2759999999999998, -0.3550000000000001, 0.8140000000000001, 0.2469999999999999, 1.8039999999999998, 0.8639999999999999, 0.585, 0.27600000000000025, 0.391, 0.4119999999999999, 0.8639999999999999, 0.43299999999999994, 0.44499999999999984, -0.008000000000000118, 1.734, 0.8540000000000001, 0.885, 0.266, 0.30799999999999983, 0.2829999999999999, 0.3860000000000001], "episode_lengths": [68, 22, 12, 300, 34, 115, 175, 70, 78, 210, 51, 61, 58, 130, 29, 21, 32, 67, 300, 125, 18, 123, 119, 29, 262, 34, 129, 174, 90, 56, 53, 98, 95, 251, 23, 75, 169, 196, 300, 300, 76, 192, 25, 49, 27, 63, 88, 53, 133, 61, 59, 54, 238, 133, 50, 64, 140, 77, 56, 103, 92, 24, 300, 101, 218, 142, 71, 158, 37, 31, 51, 232, 31, 204, 300, 86, 51, 136, 80, 69, 261, 57, 80, 61, 43, 127, 223, 34, 26, 41, 21, 17, 155, 82, 47, 37, 75, 60, 66, 36], "policy_red_0_reward": [0.49, 0.9299999999999999, 1.464, 0.469, 0.897, 1.1400000000000001, -1.013, 1.282, 0.758, 0.841, -1.004, 0.8079999999999999, 0.49, 1.095, -0.504, 0.9339999999999999, 1.4020000000000001, 1.289, 0.46399999999999997, 1.1139999999999999, 1.444, 1.115, 1.131, 0.909, 0.6829999999999999, 1.393, 1.099, -0.523, 1.225, -1.003, -0.506, 0.6859999999999999, 1.2040000000000002, 0.21799999999999997, 0.928, -0.009000000000000001, 0.975, -0.5319999999999999, 0.46599999999999997, 0.46499999999999997, 1.264, 0.8879999999999999, -1.003, 0.843, 1.4180000000000001, 0.49, 0.725, 1.333, 0.59, 1.3159999999999998, -0.505, 0.834, 0.765, 1.091, -1.013, -0.504, 0.5599999999999999, -0.515, -0.505, 0.49, -0.509, 0.9279999999999999, 0.46199999999999997, -1.012, 0.8089999999999999, 1.057, 1.2850000000000001, 1.01, 1.379, -0.502, 1.3399999999999999, 0.77, 1.404, -0.528, 0.46099999999999997, 0.724, 1.337, 1.074, 1.2530000000000001, 0.7859999999999999, 0.18399999999999994, 1.325, 1.254, 1.3119999999999998, 1.367, 1.105, 0.802, 0.894, 0.914, 1.371, -0.502, 1.447, 1.013, 0.492, 1.358, 1.389, 0.771, 1.3119999999999998, 1.291, 0.889], "policy_blue_0_reward": [1.291, -1.005, -1.0019999999999998, 0.46199999999999997, -1.002, -0.517, 0.952, -0.507, -1.017, -0.53, 0.838, -0.5129999999999999, 1.3210000000000002, -0.52, 0.909, -0.502, -0.505, -0.504, 0.46099999999999997, -0.513, -0.501, -0.513, -1.014, -0.502, -0.535, -1.004, -0.523, 0.96, -1.008, 1.319, 0.837, -0.508, -0.515, -0.543, -0.503, 1.27, -0.5199999999999999, 0.886, 0.46799999999999997, 0.46299999999999997, -0.511, -0.526, 0.924, -1.004, -0.5, 1.303, -0.511, -1.007, -0.5169999999999999, -0.514, 1.315, -0.508, -0.528, -0.522, 0.845, 1.3010000000000002, -0.516, 1.262, 1.327, 1.1800000000000002, 1.2109999999999999, -1.007, 0.46399999999999997, 1.1760000000000002, -0.53, -0.514, -0.514, -0.5219999999999999, -0.5049999999999999, 1.407, -1.006, -0.525, -1.002, 0.8669999999999999, 0.46499999999999997, -1.007, -1.0059999999999998, -0.5159999999999999, -0.512, -0.51, -0.539, -0.5109999999999999, -1.007, 0.492, -0.503, -0.52, -0.5259999999999999, -0.503, -0.502, -0.507, 0.9349999999999999, -1.002, -1.021, 1.242, -0.504, -0.504, -0.505, -1.004, -1.008, -0.503]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3492212413886222, "mean_inference_ms": 7.343023526238728, "mean_action_processing_ms": 0.39121447729492764, "mean_env_wait_ms": 0.5100914750220766, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15009307861328125, "StateBufferConnector_ms": 0.009540796279907227, "ViewRequirementAgentConnector_ms": 0.2091764211654663}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 118.39315160219714, "num_env_steps_trained_throughput_per_sec": 118.39315160219714, "timesteps_total": 124000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 248000, "timers": {"training_iteration_time_ms": 31339.139, "sample_time_ms": 3930.944, "learn_time_ms": 27377.858, "learn_throughput": 146.103, "synch_weights_time_ms": 28.816}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000}, "done": false, "episodes_total": 886, "training_iteration": 31, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-12-52", "timestamp": 1694837572, "time_this_iter_s": 33.80256795883179, "time_total_s": 945.8042953014374, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7239f9a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 945.8042953014374, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 28.659183673469386, "ram_util_percent": 56.85510204081633}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.03, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.68, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.68, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.08, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.68, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5545140722766518, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07859561112806356, "policy_loss": -0.10985767440821897, "vf_loss": 0.011058417638074995, "vf_explained_var": 0.5450019378835956, "kl": 0.018056957370110163, "entropy": 1.6911480646580457, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 30240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5581291518174112, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07632082099638259, "policy_loss": -0.10906018846920536, "vf_loss": 0.01799366666430918, "vf_explained_var": 0.5699170640980203, "kl": 0.016781998935107366, "entropy": 1.745125571017464, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 30240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "sampler_results": {"episode_reward_max": 1.893, "episode_reward_min": -0.5680000000000001, "episode_reward_mean": 0.5706700000000001, "episode_len_mean": 106.1, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"red_0": -1.013, "blue_0": -1.023}, "policy_reward_max": {"red_0": 1.447, "blue_0": 1.42}, "policy_reward_mean": {"red_0": 0.6931400000000001, "blue_0": -0.12247}, "custom_metrics": {"red_0/door_open_done_mean": 0.03, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.68, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.68, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.08, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.68, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.42500000000000004, 1.2610000000000001, 0.45500000000000007, 0.3540000000000001, 0.9339999999999999, 0.9279999999999999, 0.7530000000000001, 0.3619999999999999, -0.07899999999999996, -0.16100000000000003, 0.9180000000000001, 1.793, 0.21399999999999997, 0.32600000000000007, 0.07299999999999995, 0.802, 0.8099999999999999, 0.32600000000000007, 0.2370000000000001, 0.569, -0.16800000000000004, 0.797, 0.04400000000000004, 0.747, 0.822, 1.67, 0.702, -0.07900000000000007, 0.9259999999999999, 0.16400000000000003, 0.2789999999999999, 0.5430000000000001, 0.7709999999999999, 0.488, 0.8740000000000001, 0.905, 0.3340000000000001, 0.2450000000000001, 0.40200000000000014, 0.33899999999999986, 0.9259999999999999, -0.28300000000000003, 0.33099999999999996, 0.5580000000000003, 0.7410000000000001, 0.2759999999999998, -0.3550000000000001, 0.8140000000000001, 0.2469999999999999, 1.8039999999999998, 0.8639999999999999, 0.585, 0.27600000000000025, 0.391, 0.4119999999999999, 0.8639999999999999, 0.43299999999999994, 0.44499999999999984, -0.008000000000000118, 1.734, 0.8540000000000001, 0.885, 0.266, 0.30799999999999983, 0.2829999999999999, 0.3860000000000001, 0.03299999999999992, 1.7770000000000001, 0.7610000000000001, 0.44499999999999984, -0.23399999999999999, 0.833, 1.3980000000000001, -0.17999999999999994, 0.19199999999999995, 0.2819999999999999, 0.6789999999999998, 0.43900000000000006, 0.808, 0.5569999999999999, 0.4159999999999999, 0.16800000000000015, 0.7970000000000002, 0.6499999999999999, 1.5819999999999999, 0.6339999999999999, 0.5489999999999999, 1.76, -0.5680000000000001, 0.41400000000000015, 0.04899999999999993, 1.893, 0.9129999999999999, 0.41800000000000004, 1.254, 0.0019999999999997797, 0.502, 0.493, 0.7639999999999998, 0.44499999999999984], "episode_lengths": [23, 75, 169, 196, 300, 300, 76, 192, 25, 49, 27, 63, 88, 53, 133, 61, 59, 54, 238, 133, 50, 64, 140, 77, 56, 103, 92, 24, 300, 101, 218, 142, 71, 158, 37, 31, 51, 232, 31, 204, 300, 86, 51, 136, 80, 69, 261, 57, 80, 61, 43, 127, 223, 34, 26, 41, 21, 17, 155, 82, 47, 37, 75, 60, 66, 36, 297, 66, 71, 16, 75, 54, 32, 57, 246, 65, 98, 20, 62, 137, 182, 256, 64, 109, 129, 112, 139, 75, 175, 26, 137, 33, 300, 26, 74, 155, 153, 156, 73, 173], "policy_red_0_reward": [0.928, -0.009000000000000001, 0.975, -0.5319999999999999, 0.46599999999999997, 0.46499999999999997, 1.264, 0.8879999999999999, -1.003, 0.843, 1.4180000000000001, 0.49, 0.725, 1.333, 0.59, 1.3159999999999998, -0.505, 0.834, 0.765, 1.091, -1.013, -0.504, 0.5599999999999999, -0.515, -0.505, 0.49, -0.509, 0.9279999999999999, 0.46199999999999997, -1.012, 0.8089999999999999, 1.057, 1.2850000000000001, 1.01, 1.379, -0.502, 1.3399999999999999, 0.77, 1.404, -0.528, 0.46099999999999997, 0.724, 1.337, 1.074, 1.2530000000000001, 0.7859999999999999, 0.18399999999999994, 1.325, 1.254, 1.3119999999999998, 1.367, 1.105, 0.802, 0.894, 0.914, 1.371, -0.502, 1.447, 1.013, 0.492, 1.358, 1.389, 0.771, 1.3119999999999998, 1.291, 0.889, 0.573, 0.487, 1.274, 0.948, 0.772, 1.3359999999999999, -0.003, 0.824, 0.73, -0.515, 1.188, 1.44, -0.504, 1.069, 0.9369999999999999, 0.7, 1.3010000000000002, 1.163, 1.101, 1.146, 1.067, 0.494, 0.45499999999999996, 1.417, 1.071, 0.496, 0.45799999999999996, -1.002, 1.2610000000000001, 0.5199999999999999, 1.023, -0.52, 1.274, 0.962], "policy_blue_0_reward": [-0.503, 1.27, -0.5199999999999999, 0.886, 0.46799999999999997, 0.46299999999999997, -0.511, -0.526, 0.924, -1.004, -0.5, 1.303, -0.511, -1.007, -0.5169999999999999, -0.514, 1.315, -0.508, -0.528, -0.522, 0.845, 1.3010000000000002, -0.516, 1.262, 1.327, 1.1800000000000002, 1.2109999999999999, -1.007, 0.46399999999999997, 1.1760000000000002, -0.53, -0.514, -0.514, -0.5219999999999999, -0.5049999999999999, 1.407, -1.006, -0.525, -1.002, 0.8669999999999999, 0.46499999999999997, -1.007, -1.0059999999999998, -0.5159999999999999, -0.512, -0.51, -0.539, -0.5109999999999999, -1.007, 0.492, -0.503, -0.52, -0.5259999999999999, -0.503, -0.502, -0.507, 0.9349999999999999, -1.002, -1.021, 1.242, -0.504, -0.504, -0.505, -1.004, -1.008, -0.503, -0.5399999999999999, 1.29, -0.513, -0.503, -1.006, -0.503, 1.401, -1.0039999999999998, -0.538, 0.7969999999999999, -0.509, -1.001, 1.312, -0.512, -0.521, -0.5319999999999999, -0.504, -0.513, 0.481, -0.512, -0.518, 1.266, -1.023, -1.003, -1.022, 1.397, 0.45499999999999996, 1.42, -0.007, -0.518, -0.5209999999999999, 1.013, -0.51, -0.517]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3518783818324196, "mean_inference_ms": 7.355309011509795, "mean_action_processing_ms": 0.3920919701510105, "mean_env_wait_ms": 0.5106705881648315, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1545400619506836, "StateBufferConnector_ms": 0.009935498237609863, "ViewRequirementAgentConnector_ms": 0.21530497074127197}}, "episode_reward_max": 1.893, "episode_reward_min": -0.5680000000000001, "episode_reward_mean": 0.5706700000000001, "episode_len_mean": 106.1, "episodes_this_iter": 34, "policy_reward_min": {"red_0": -1.013, "blue_0": -1.023}, "policy_reward_max": {"red_0": 1.447, "blue_0": 1.42}, "policy_reward_mean": {"red_0": 0.6931400000000001, "blue_0": -0.12247}, "hist_stats": {"episode_reward": [0.42500000000000004, 1.2610000000000001, 0.45500000000000007, 0.3540000000000001, 0.9339999999999999, 0.9279999999999999, 0.7530000000000001, 0.3619999999999999, -0.07899999999999996, -0.16100000000000003, 0.9180000000000001, 1.793, 0.21399999999999997, 0.32600000000000007, 0.07299999999999995, 0.802, 0.8099999999999999, 0.32600000000000007, 0.2370000000000001, 0.569, -0.16800000000000004, 0.797, 0.04400000000000004, 0.747, 0.822, 1.67, 0.702, -0.07900000000000007, 0.9259999999999999, 0.16400000000000003, 0.2789999999999999, 0.5430000000000001, 0.7709999999999999, 0.488, 0.8740000000000001, 0.905, 0.3340000000000001, 0.2450000000000001, 0.40200000000000014, 0.33899999999999986, 0.9259999999999999, -0.28300000000000003, 0.33099999999999996, 0.5580000000000003, 0.7410000000000001, 0.2759999999999998, -0.3550000000000001, 0.8140000000000001, 0.2469999999999999, 1.8039999999999998, 0.8639999999999999, 0.585, 0.27600000000000025, 0.391, 0.4119999999999999, 0.8639999999999999, 0.43299999999999994, 0.44499999999999984, -0.008000000000000118, 1.734, 0.8540000000000001, 0.885, 0.266, 0.30799999999999983, 0.2829999999999999, 0.3860000000000001, 0.03299999999999992, 1.7770000000000001, 0.7610000000000001, 0.44499999999999984, -0.23399999999999999, 0.833, 1.3980000000000001, -0.17999999999999994, 0.19199999999999995, 0.2819999999999999, 0.6789999999999998, 0.43900000000000006, 0.808, 0.5569999999999999, 0.4159999999999999, 0.16800000000000015, 0.7970000000000002, 0.6499999999999999, 1.5819999999999999, 0.6339999999999999, 0.5489999999999999, 1.76, -0.5680000000000001, 0.41400000000000015, 0.04899999999999993, 1.893, 0.9129999999999999, 0.41800000000000004, 1.254, 0.0019999999999997797, 0.502, 0.493, 0.7639999999999998, 0.44499999999999984], "episode_lengths": [23, 75, 169, 196, 300, 300, 76, 192, 25, 49, 27, 63, 88, 53, 133, 61, 59, 54, 238, 133, 50, 64, 140, 77, 56, 103, 92, 24, 300, 101, 218, 142, 71, 158, 37, 31, 51, 232, 31, 204, 300, 86, 51, 136, 80, 69, 261, 57, 80, 61, 43, 127, 223, 34, 26, 41, 21, 17, 155, 82, 47, 37, 75, 60, 66, 36, 297, 66, 71, 16, 75, 54, 32, 57, 246, 65, 98, 20, 62, 137, 182, 256, 64, 109, 129, 112, 139, 75, 175, 26, 137, 33, 300, 26, 74, 155, 153, 156, 73, 173], "policy_red_0_reward": [0.928, -0.009000000000000001, 0.975, -0.5319999999999999, 0.46599999999999997, 0.46499999999999997, 1.264, 0.8879999999999999, -1.003, 0.843, 1.4180000000000001, 0.49, 0.725, 1.333, 0.59, 1.3159999999999998, -0.505, 0.834, 0.765, 1.091, -1.013, -0.504, 0.5599999999999999, -0.515, -0.505, 0.49, -0.509, 0.9279999999999999, 0.46199999999999997, -1.012, 0.8089999999999999, 1.057, 1.2850000000000001, 1.01, 1.379, -0.502, 1.3399999999999999, 0.77, 1.404, -0.528, 0.46099999999999997, 0.724, 1.337, 1.074, 1.2530000000000001, 0.7859999999999999, 0.18399999999999994, 1.325, 1.254, 1.3119999999999998, 1.367, 1.105, 0.802, 0.894, 0.914, 1.371, -0.502, 1.447, 1.013, 0.492, 1.358, 1.389, 0.771, 1.3119999999999998, 1.291, 0.889, 0.573, 0.487, 1.274, 0.948, 0.772, 1.3359999999999999, -0.003, 0.824, 0.73, -0.515, 1.188, 1.44, -0.504, 1.069, 0.9369999999999999, 0.7, 1.3010000000000002, 1.163, 1.101, 1.146, 1.067, 0.494, 0.45499999999999996, 1.417, 1.071, 0.496, 0.45799999999999996, -1.002, 1.2610000000000001, 0.5199999999999999, 1.023, -0.52, 1.274, 0.962], "policy_blue_0_reward": [-0.503, 1.27, -0.5199999999999999, 0.886, 0.46799999999999997, 0.46299999999999997, -0.511, -0.526, 0.924, -1.004, -0.5, 1.303, -0.511, -1.007, -0.5169999999999999, -0.514, 1.315, -0.508, -0.528, -0.522, 0.845, 1.3010000000000002, -0.516, 1.262, 1.327, 1.1800000000000002, 1.2109999999999999, -1.007, 0.46399999999999997, 1.1760000000000002, -0.53, -0.514, -0.514, -0.5219999999999999, -0.5049999999999999, 1.407, -1.006, -0.525, -1.002, 0.8669999999999999, 0.46499999999999997, -1.007, -1.0059999999999998, -0.5159999999999999, -0.512, -0.51, -0.539, -0.5109999999999999, -1.007, 0.492, -0.503, -0.52, -0.5259999999999999, -0.503, -0.502, -0.507, 0.9349999999999999, -1.002, -1.021, 1.242, -0.504, -0.504, -0.505, -1.004, -1.008, -0.503, -0.5399999999999999, 1.29, -0.513, -0.503, -1.006, -0.503, 1.401, -1.0039999999999998, -0.538, 0.7969999999999999, -0.509, -1.001, 1.312, -0.512, -0.521, -0.5319999999999999, -0.504, -0.513, 0.481, -0.512, -0.518, 1.266, -1.023, -1.003, -1.022, 1.397, 0.45499999999999996, 1.42, -0.007, -0.518, -0.5209999999999999, 1.013, -0.51, -0.517]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3518783818324196, "mean_inference_ms": 7.355309011509795, "mean_action_processing_ms": 0.3920919701510105, "mean_env_wait_ms": 0.5106705881648315, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1545400619506836, "StateBufferConnector_ms": 0.009935498237609863, "ViewRequirementAgentConnector_ms": 0.21530497074127197}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 126.78940360753946, "num_env_steps_trained_throughput_per_sec": 126.78940360753946, "timesteps_total": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 31366.288, "sample_time_ms": 3944.227, "learn_time_ms": 27391.59, "learn_throughput": 146.03, "synch_weights_time_ms": 28.957}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "episodes_total": 920, "training_iteration": 32, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-13-25", "timestamp": 1694837605, "time_this_iter_s": 31.56398892402649, "time_total_s": 977.3682842254639, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a1bd630>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 977.3682842254639, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 23.09130434782608, "ram_util_percent": 56.81739130434785}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.03, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.75, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.75, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.75, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5429758870353302, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.0759838154510362, "policy_loss": -0.10774380840205898, "vf_loss": 0.014296217685356775, "vf_explained_var": 0.5549015661080678, "kl": 0.017318368107555427, "entropy": 1.690386705348889, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 31200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5503752591088414, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08000305054495888, "policy_loss": -0.11518148021811309, "vf_loss": 0.020136021051439457, "vf_explained_var": 0.6268532393500209, "kl": 0.017678099652918413, "entropy": 1.7381936298062404, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 31200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000}, "sampler_results": {"episode_reward_max": 1.893, "episode_reward_min": -0.5680000000000001, "episode_reward_mean": 0.5734699999999999, "episode_len_mean": 97.1, "episode_media": {}, "episodes_this_iter": 43, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.026}, "policy_reward_max": {"red_0": 1.447, "blue_0": 1.451}, "policy_reward_mean": {"red_0": 0.8001599999999999, "blue_0": -0.22669}, "custom_metrics": {"red_0/door_open_done_mean": 0.03, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.75, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.75, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.75, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.5580000000000003, 0.7410000000000001, 0.2759999999999998, -0.3550000000000001, 0.8140000000000001, 0.2469999999999999, 1.8039999999999998, 0.8639999999999999, 0.585, 0.27600000000000025, 0.391, 0.4119999999999999, 0.8639999999999999, 0.43299999999999994, 0.44499999999999984, -0.008000000000000118, 1.734, 0.8540000000000001, 0.885, 0.266, 0.30799999999999983, 0.2829999999999999, 0.3860000000000001, 0.03299999999999992, 1.7770000000000001, 0.7610000000000001, 0.44499999999999984, -0.23399999999999999, 0.833, 1.3980000000000001, -0.17999999999999994, 0.19199999999999995, 0.2819999999999999, 0.6789999999999998, 0.43900000000000006, 0.808, 0.5569999999999999, 0.4159999999999999, 0.16800000000000015, 0.7970000000000002, 0.6499999999999999, 1.5819999999999999, 0.6339999999999999, 0.5489999999999999, 1.76, -0.5680000000000001, 0.41400000000000015, 0.04899999999999993, 1.893, 0.9129999999999999, 0.41800000000000004, 1.254, 0.0019999999999997797, 0.502, 0.493, 0.7639999999999998, 0.44499999999999984, 0.47699999999999987, 0.907, 1.688, 0.32599999999999996, -0.14700000000000013, 0.873, 0.9199999999999999, 0.949, 0.3979999999999999, 0.17300000000000004, 0.3380000000000001, 0.47299999999999986, 0.12400000000000011, 0.1629999999999998, 0.782, 0.34399999999999986, 0.05600000000000005, 1.537, -0.04300000000000004, 1.645, 0.7629999999999999, 0.5459999999999998, 0.351, 0.859, 0.831, 0.42200000000000015, 0.2869999999999999, 0.19599999999999995, 0.3330000000000002, -0.3810000000000001, 0.9629999999999999, 1.334, 0.46399999999999997, 0.909, 1.827, 0.3500000000000001, 0.08199999999999985, 0.65, 0.347, 0.5609999999999999, -0.52, 0.254, -0.052000000000000046], "episode_lengths": [136, 80, 69, 261, 57, 80, 61, 43, 127, 223, 34, 26, 41, 21, 17, 155, 82, 47, 37, 75, 60, 66, 36, 297, 66, 71, 16, 75, 54, 32, 57, 246, 65, 98, 20, 62, 137, 182, 256, 64, 109, 129, 112, 139, 75, 175, 26, 137, 33, 300, 26, 74, 155, 153, 156, 73, 173, 162, 29, 94, 207, 198, 38, 25, 14, 183, 101, 50, 9, 117, 254, 67, 48, 140, 144, 13, 112, 72, 139, 44, 44, 52, 23, 65, 93, 52, 114, 159, 207, 167, 28, 54, 47, 127, 109, 47, 134, 160, 75, 16], "policy_red_0_reward": [1.074, 1.2530000000000001, 0.7859999999999999, 0.18399999999999994, 1.325, 1.254, 1.3119999999999998, 1.367, 1.105, 0.802, 0.894, 0.914, 1.371, -0.502, 1.447, 1.013, 0.492, 1.358, 1.389, 0.771, 1.3119999999999998, 1.291, 0.889, 0.573, 0.487, 1.274, 0.948, 0.772, 1.3359999999999999, -0.003, 0.824, 0.73, -0.515, 1.188, 1.44, -0.504, 1.069, 0.9369999999999999, 0.7, 1.3010000000000002, 1.163, 1.101, 1.146, 1.067, 0.494, 0.45499999999999996, 1.417, 1.071, 0.496, 0.45799999999999996, -1.002, 1.2610000000000001, 0.5199999999999999, 1.023, -0.52, 1.274, 0.962, 0.992, 1.411, 0.488, -0.528, 0.8749999999999999, -0.506, 1.423, -0.502, 0.9269999999999999, 0.6900000000000001, 0.845, 0.973, 0.632, 0.7, 1.294, 0.851, 1.065, 0.489, 0.96, 0.491, 1.274, 1.069, -1.007, 1.365, 1.339, 1.429, 0.7969999999999999, 0.711, 1.339, 0.6429999999999999, -0.016000000000000007, 0.478, 0.981, 1.409, 0.494, 0.856, 0.601, -0.511, 1.354, 1.0739999999999998, 0.506, 1.266, 0.951], "policy_blue_0_reward": [-0.5159999999999999, -0.512, -0.51, -0.539, -0.5109999999999999, -1.007, 0.492, -0.503, -0.52, -0.5259999999999999, -0.503, -0.502, -0.507, 0.9349999999999999, -1.002, -1.021, 1.242, -0.504, -0.504, -0.505, -1.004, -1.008, -0.503, -0.5399999999999999, 1.29, -0.513, -0.503, -1.006, -0.503, 1.401, -1.0039999999999998, -0.538, 0.7969999999999999, -0.509, -1.001, 1.312, -0.512, -0.521, -0.5319999999999999, -0.504, -0.513, 0.481, -0.512, -0.518, 1.266, -1.023, -1.003, -1.022, 1.397, 0.45499999999999996, 1.42, -0.007, -0.518, -0.5209999999999999, 1.013, -0.51, -0.517, -0.515, -0.504, 1.2, 0.854, -1.022, 1.379, -0.503, 1.451, -0.529, -0.517, -0.507, -0.5, -0.508, -0.537, -0.512, -0.507, -1.009, 1.048, -1.003, 1.154, -0.511, -0.523, 1.358, -0.506, -0.508, -1.007, -0.51, -0.515, -1.0059999999999998, -1.024, 0.9789999999999999, 0.856, -0.517, -0.5, 1.333, -0.506, -0.519, 1.161, -1.007, -0.513, -1.026, -1.012, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3553653943282797, "mean_inference_ms": 7.3753986280329284, "mean_action_processing_ms": 0.39210224202773014, "mean_env_wait_ms": 0.5119390675084398, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15977799892425537, "StateBufferConnector_ms": 0.009970545768737793, "ViewRequirementAgentConnector_ms": 0.19803333282470703}}, "episode_reward_max": 1.893, "episode_reward_min": -0.5680000000000001, "episode_reward_mean": 0.5734699999999999, "episode_len_mean": 97.1, "episodes_this_iter": 43, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.026}, "policy_reward_max": {"red_0": 1.447, "blue_0": 1.451}, "policy_reward_mean": {"red_0": 0.8001599999999999, "blue_0": -0.22669}, "hist_stats": {"episode_reward": [0.5580000000000003, 0.7410000000000001, 0.2759999999999998, -0.3550000000000001, 0.8140000000000001, 0.2469999999999999, 1.8039999999999998, 0.8639999999999999, 0.585, 0.27600000000000025, 0.391, 0.4119999999999999, 0.8639999999999999, 0.43299999999999994, 0.44499999999999984, -0.008000000000000118, 1.734, 0.8540000000000001, 0.885, 0.266, 0.30799999999999983, 0.2829999999999999, 0.3860000000000001, 0.03299999999999992, 1.7770000000000001, 0.7610000000000001, 0.44499999999999984, -0.23399999999999999, 0.833, 1.3980000000000001, -0.17999999999999994, 0.19199999999999995, 0.2819999999999999, 0.6789999999999998, 0.43900000000000006, 0.808, 0.5569999999999999, 0.4159999999999999, 0.16800000000000015, 0.7970000000000002, 0.6499999999999999, 1.5819999999999999, 0.6339999999999999, 0.5489999999999999, 1.76, -0.5680000000000001, 0.41400000000000015, 0.04899999999999993, 1.893, 0.9129999999999999, 0.41800000000000004, 1.254, 0.0019999999999997797, 0.502, 0.493, 0.7639999999999998, 0.44499999999999984, 0.47699999999999987, 0.907, 1.688, 0.32599999999999996, -0.14700000000000013, 0.873, 0.9199999999999999, 0.949, 0.3979999999999999, 0.17300000000000004, 0.3380000000000001, 0.47299999999999986, 0.12400000000000011, 0.1629999999999998, 0.782, 0.34399999999999986, 0.05600000000000005, 1.537, -0.04300000000000004, 1.645, 0.7629999999999999, 0.5459999999999998, 0.351, 0.859, 0.831, 0.42200000000000015, 0.2869999999999999, 0.19599999999999995, 0.3330000000000002, -0.3810000000000001, 0.9629999999999999, 1.334, 0.46399999999999997, 0.909, 1.827, 0.3500000000000001, 0.08199999999999985, 0.65, 0.347, 0.5609999999999999, -0.52, 0.254, -0.052000000000000046], "episode_lengths": [136, 80, 69, 261, 57, 80, 61, 43, 127, 223, 34, 26, 41, 21, 17, 155, 82, 47, 37, 75, 60, 66, 36, 297, 66, 71, 16, 75, 54, 32, 57, 246, 65, 98, 20, 62, 137, 182, 256, 64, 109, 129, 112, 139, 75, 175, 26, 137, 33, 300, 26, 74, 155, 153, 156, 73, 173, 162, 29, 94, 207, 198, 38, 25, 14, 183, 101, 50, 9, 117, 254, 67, 48, 140, 144, 13, 112, 72, 139, 44, 44, 52, 23, 65, 93, 52, 114, 159, 207, 167, 28, 54, 47, 127, 109, 47, 134, 160, 75, 16], "policy_red_0_reward": [1.074, 1.2530000000000001, 0.7859999999999999, 0.18399999999999994, 1.325, 1.254, 1.3119999999999998, 1.367, 1.105, 0.802, 0.894, 0.914, 1.371, -0.502, 1.447, 1.013, 0.492, 1.358, 1.389, 0.771, 1.3119999999999998, 1.291, 0.889, 0.573, 0.487, 1.274, 0.948, 0.772, 1.3359999999999999, -0.003, 0.824, 0.73, -0.515, 1.188, 1.44, -0.504, 1.069, 0.9369999999999999, 0.7, 1.3010000000000002, 1.163, 1.101, 1.146, 1.067, 0.494, 0.45499999999999996, 1.417, 1.071, 0.496, 0.45799999999999996, -1.002, 1.2610000000000001, 0.5199999999999999, 1.023, -0.52, 1.274, 0.962, 0.992, 1.411, 0.488, -0.528, 0.8749999999999999, -0.506, 1.423, -0.502, 0.9269999999999999, 0.6900000000000001, 0.845, 0.973, 0.632, 0.7, 1.294, 0.851, 1.065, 0.489, 0.96, 0.491, 1.274, 1.069, -1.007, 1.365, 1.339, 1.429, 0.7969999999999999, 0.711, 1.339, 0.6429999999999999, -0.016000000000000007, 0.478, 0.981, 1.409, 0.494, 0.856, 0.601, -0.511, 1.354, 1.0739999999999998, 0.506, 1.266, 0.951], "policy_blue_0_reward": [-0.5159999999999999, -0.512, -0.51, -0.539, -0.5109999999999999, -1.007, 0.492, -0.503, -0.52, -0.5259999999999999, -0.503, -0.502, -0.507, 0.9349999999999999, -1.002, -1.021, 1.242, -0.504, -0.504, -0.505, -1.004, -1.008, -0.503, -0.5399999999999999, 1.29, -0.513, -0.503, -1.006, -0.503, 1.401, -1.0039999999999998, -0.538, 0.7969999999999999, -0.509, -1.001, 1.312, -0.512, -0.521, -0.5319999999999999, -0.504, -0.513, 0.481, -0.512, -0.518, 1.266, -1.023, -1.003, -1.022, 1.397, 0.45499999999999996, 1.42, -0.007, -0.518, -0.5209999999999999, 1.013, -0.51, -0.517, -0.515, -0.504, 1.2, 0.854, -1.022, 1.379, -0.503, 1.451, -0.529, -0.517, -0.507, -0.5, -0.508, -0.537, -0.512, -0.507, -1.009, 1.048, -1.003, 1.154, -0.511, -0.523, 1.358, -0.506, -0.508, -1.007, -0.51, -0.515, -1.0059999999999998, -1.024, 0.9789999999999999, 0.856, -0.517, -0.5, 1.333, -0.506, -0.519, 1.161, -1.007, -0.513, -1.026, -1.012, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3553653943282797, "mean_inference_ms": 7.3753986280329284, "mean_action_processing_ms": 0.39210224202773014, "mean_env_wait_ms": 0.5119390675084398, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15977799892425537, "StateBufferConnector_ms": 0.009970545768737793, "ViewRequirementAgentConnector_ms": 0.19803333282470703}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 121.28497700350198, "num_env_steps_trained_throughput_per_sec": 121.28497700350198, "timesteps_total": 132000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 264000, "timers": {"training_iteration_time_ms": 31580.646, "sample_time_ms": 3983.932, "learn_time_ms": 27566.279, "learn_throughput": 145.105, "synch_weights_time_ms": 28.936}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000}, "done": false, "episodes_total": 963, "training_iteration": 33, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-13-59", "timestamp": 1694837639, "time_this_iter_s": 32.997520208358765, "time_total_s": 1010.3658044338226, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80ec8c10>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1010.3658044338226, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 26.756249999999998, "ram_util_percent": 56.912499999999994}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.03, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.68, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.68, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.68, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5453964802746971, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07863498361645421, "policy_loss": -0.11096232331716843, "vf_loss": 0.01378500204057976, "vf_explained_var": 0.5760239290073514, "kl": 0.017862219142765014, "entropy": 1.6934054336200157, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 32160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.567300118599087, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08037465100060218, "policy_loss": -0.11211768797268935, "vf_loss": 0.015633174553659045, "vf_explained_var": 0.6786038814112544, "kl": 0.016898176816791496, "entropy": 1.7376548810551564, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 32160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "sampler_results": {"episode_reward_max": 1.893, "episode_reward_min": -0.5680000000000001, "episode_reward_mean": 0.6171699999999999, "episode_len_mean": 101.87, "episode_media": {}, "episodes_this_iter": 38, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.026}, "policy_reward_max": {"red_0": 1.439, "blue_0": 1.451}, "policy_reward_mean": {"red_0": 0.7131399999999999, "blue_0": -0.09597000000000001}, "custom_metrics": {"red_0/door_open_done_mean": 0.03, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.68, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.68, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.68, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.16800000000000015, 0.7970000000000002, 0.6499999999999999, 1.5819999999999999, 0.6339999999999999, 0.5489999999999999, 1.76, -0.5680000000000001, 0.41400000000000015, 0.04899999999999993, 1.893, 0.9129999999999999, 0.41800000000000004, 1.254, 0.0019999999999997797, 0.502, 0.493, 0.7639999999999998, 0.44499999999999984, 0.47699999999999987, 0.907, 1.688, 0.32599999999999996, -0.14700000000000013, 0.873, 0.9199999999999999, 0.949, 0.3979999999999999, 0.17300000000000004, 0.3380000000000001, 0.47299999999999986, 0.12400000000000011, 0.1629999999999998, 0.782, 0.34399999999999986, 0.05600000000000005, 1.537, -0.04300000000000004, 1.645, 0.7629999999999999, 0.5459999999999998, 0.351, 0.859, 0.831, 0.42200000000000015, 0.2869999999999999, 0.19599999999999995, 0.3330000000000002, -0.3810000000000001, 0.9629999999999999, 1.334, 0.46399999999999997, 0.909, 1.827, 0.3500000000000001, 0.08199999999999985, 0.65, 0.347, 0.5609999999999999, -0.52, 0.254, -0.052000000000000046, 1.665, -0.17500000000000004, 0.391, -0.22599999999999987, 0.6459999999999999, 0.8919999999999999, 0.5549999999999999, 0.41700000000000004, 0.31599999999999984, 0.876, 0.373, -0.16500000000000004, 0.9349999999999999, 0.7030000000000001, 0.43399999999999994, 0.30299999999999994, 0.31199999999999983, -0.136, 1.794, 0.4830000000000001, -0.03700000000000003, 0.829, 0.5129999999999999, 1.603, 0.901, 0.86, 1.435, 0.829, 0.9359999999999999, 0.6240000000000001, 0.476, 1.7149999999999999, 0.6859999999999999, 0.651, 0.4289999999999998, 0.726, 0.2450000000000001, 1.825], "episode_lengths": [256, 64, 109, 129, 112, 139, 75, 175, 26, 137, 33, 300, 26, 74, 155, 153, 156, 73, 173, 162, 29, 94, 207, 198, 38, 25, 14, 183, 101, 50, 9, 117, 254, 67, 48, 140, 144, 13, 112, 72, 139, 44, 44, 52, 23, 65, 93, 52, 114, 159, 207, 167, 28, 54, 47, 127, 109, 47, 134, 160, 75, 16, 103, 53, 34, 71, 112, 33, 135, 27, 207, 37, 39, 51, 300, 91, 176, 219, 56, 43, 65, 160, 166, 52, 143, 125, 31, 43, 20, 51, 20, 118, 163, 89, 98, 105, 179, 85, 236, 53], "policy_red_0_reward": [0.7, 1.3010000000000002, 1.163, 1.101, 1.146, 1.067, 0.494, 0.45499999999999996, 1.417, 1.071, 0.496, 0.45799999999999996, -1.002, 1.2610000000000001, 0.5199999999999999, 1.023, -0.52, 1.274, 0.962, 0.992, 1.411, 0.488, -0.528, 0.8749999999999999, -0.506, 1.423, -0.502, 0.9269999999999999, 0.6900000000000001, 0.845, 0.973, 0.632, 0.7, 1.294, 0.851, 1.065, 0.489, 0.96, 0.491, 1.274, 1.069, -1.007, 1.365, 1.339, 1.429, 0.7969999999999999, 0.711, 1.339, 0.6429999999999999, -0.016000000000000007, 0.478, 0.981, 1.409, 0.494, 0.856, 0.601, -0.511, 1.354, 1.0739999999999998, 0.506, 1.266, 0.951, 1.179, 0.832, -1.001, -1.004, 1.1549999999999998, 1.396, 1.079, 0.918, 0.854, -0.509, 1.3780000000000001, 0.84, 0.46199999999999997, -0.5119999999999999, -0.52, 0.825, 0.824, 0.869, 0.493, 0.998, 0.984, 1.335, -0.528, 0.491, 1.404, -0.504, -0.002, 1.342, 1.439, 1.1360000000000001, 0.996, 0.49, 1.196, 1.17, 0.948, 1.236, 0.773, 0.493], "policy_blue_0_reward": [-0.5319999999999999, -0.504, -0.513, 0.481, -0.512, -0.518, 1.266, -1.023, -1.003, -1.022, 1.397, 0.45499999999999996, 1.42, -0.007, -0.518, -0.5209999999999999, 1.013, -0.51, -0.517, -0.515, -0.504, 1.2, 0.854, -1.022, 1.379, -0.503, 1.451, -0.529, -0.517, -0.507, -0.5, -0.508, -0.537, -0.512, -0.507, -1.009, 1.048, -1.003, 1.154, -0.511, -0.523, 1.358, -0.506, -0.508, -1.007, -0.51, -0.515, -1.0059999999999998, -1.024, 0.9789999999999999, 0.856, -0.517, -0.5, 1.333, -0.506, -0.519, 1.161, -1.007, -0.513, -1.026, -1.012, -1.003, 0.486, -1.007, 1.392, 0.778, -0.509, -0.504, -0.524, -0.501, -0.538, 1.385, -1.005, -1.005, 0.473, 1.2149999999999999, 0.954, -0.522, -0.512, -1.005, 1.301, -0.515, -1.021, -0.506, 1.041, 1.112, -0.503, 1.3639999999999999, 1.4369999999999998, -0.513, -0.503, -0.512, -0.52, 1.225, -0.51, -0.519, -0.519, -0.51, -0.528, 1.3319999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3579394330150172, "mean_inference_ms": 7.394223597718651, "mean_action_processing_ms": 0.3929354752701551, "mean_env_wait_ms": 0.5124197184895412, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1600576639175415, "StateBufferConnector_ms": 0.01004183292388916, "ViewRequirementAgentConnector_ms": 0.19980156421661377}}, "episode_reward_max": 1.893, "episode_reward_min": -0.5680000000000001, "episode_reward_mean": 0.6171699999999999, "episode_len_mean": 101.87, "episodes_this_iter": 38, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.026}, "policy_reward_max": {"red_0": 1.439, "blue_0": 1.451}, "policy_reward_mean": {"red_0": 0.7131399999999999, "blue_0": -0.09597000000000001}, "hist_stats": {"episode_reward": [0.16800000000000015, 0.7970000000000002, 0.6499999999999999, 1.5819999999999999, 0.6339999999999999, 0.5489999999999999, 1.76, -0.5680000000000001, 0.41400000000000015, 0.04899999999999993, 1.893, 0.9129999999999999, 0.41800000000000004, 1.254, 0.0019999999999997797, 0.502, 0.493, 0.7639999999999998, 0.44499999999999984, 0.47699999999999987, 0.907, 1.688, 0.32599999999999996, -0.14700000000000013, 0.873, 0.9199999999999999, 0.949, 0.3979999999999999, 0.17300000000000004, 0.3380000000000001, 0.47299999999999986, 0.12400000000000011, 0.1629999999999998, 0.782, 0.34399999999999986, 0.05600000000000005, 1.537, -0.04300000000000004, 1.645, 0.7629999999999999, 0.5459999999999998, 0.351, 0.859, 0.831, 0.42200000000000015, 0.2869999999999999, 0.19599999999999995, 0.3330000000000002, -0.3810000000000001, 0.9629999999999999, 1.334, 0.46399999999999997, 0.909, 1.827, 0.3500000000000001, 0.08199999999999985, 0.65, 0.347, 0.5609999999999999, -0.52, 0.254, -0.052000000000000046, 1.665, -0.17500000000000004, 0.391, -0.22599999999999987, 0.6459999999999999, 0.8919999999999999, 0.5549999999999999, 0.41700000000000004, 0.31599999999999984, 0.876, 0.373, -0.16500000000000004, 0.9349999999999999, 0.7030000000000001, 0.43399999999999994, 0.30299999999999994, 0.31199999999999983, -0.136, 1.794, 0.4830000000000001, -0.03700000000000003, 0.829, 0.5129999999999999, 1.603, 0.901, 0.86, 1.435, 0.829, 0.9359999999999999, 0.6240000000000001, 0.476, 1.7149999999999999, 0.6859999999999999, 0.651, 0.4289999999999998, 0.726, 0.2450000000000001, 1.825], "episode_lengths": [256, 64, 109, 129, 112, 139, 75, 175, 26, 137, 33, 300, 26, 74, 155, 153, 156, 73, 173, 162, 29, 94, 207, 198, 38, 25, 14, 183, 101, 50, 9, 117, 254, 67, 48, 140, 144, 13, 112, 72, 139, 44, 44, 52, 23, 65, 93, 52, 114, 159, 207, 167, 28, 54, 47, 127, 109, 47, 134, 160, 75, 16, 103, 53, 34, 71, 112, 33, 135, 27, 207, 37, 39, 51, 300, 91, 176, 219, 56, 43, 65, 160, 166, 52, 143, 125, 31, 43, 20, 51, 20, 118, 163, 89, 98, 105, 179, 85, 236, 53], "policy_red_0_reward": [0.7, 1.3010000000000002, 1.163, 1.101, 1.146, 1.067, 0.494, 0.45499999999999996, 1.417, 1.071, 0.496, 0.45799999999999996, -1.002, 1.2610000000000001, 0.5199999999999999, 1.023, -0.52, 1.274, 0.962, 0.992, 1.411, 0.488, -0.528, 0.8749999999999999, -0.506, 1.423, -0.502, 0.9269999999999999, 0.6900000000000001, 0.845, 0.973, 0.632, 0.7, 1.294, 0.851, 1.065, 0.489, 0.96, 0.491, 1.274, 1.069, -1.007, 1.365, 1.339, 1.429, 0.7969999999999999, 0.711, 1.339, 0.6429999999999999, -0.016000000000000007, 0.478, 0.981, 1.409, 0.494, 0.856, 0.601, -0.511, 1.354, 1.0739999999999998, 0.506, 1.266, 0.951, 1.179, 0.832, -1.001, -1.004, 1.1549999999999998, 1.396, 1.079, 0.918, 0.854, -0.509, 1.3780000000000001, 0.84, 0.46199999999999997, -0.5119999999999999, -0.52, 0.825, 0.824, 0.869, 0.493, 0.998, 0.984, 1.335, -0.528, 0.491, 1.404, -0.504, -0.002, 1.342, 1.439, 1.1360000000000001, 0.996, 0.49, 1.196, 1.17, 0.948, 1.236, 0.773, 0.493], "policy_blue_0_reward": [-0.5319999999999999, -0.504, -0.513, 0.481, -0.512, -0.518, 1.266, -1.023, -1.003, -1.022, 1.397, 0.45499999999999996, 1.42, -0.007, -0.518, -0.5209999999999999, 1.013, -0.51, -0.517, -0.515, -0.504, 1.2, 0.854, -1.022, 1.379, -0.503, 1.451, -0.529, -0.517, -0.507, -0.5, -0.508, -0.537, -0.512, -0.507, -1.009, 1.048, -1.003, 1.154, -0.511, -0.523, 1.358, -0.506, -0.508, -1.007, -0.51, -0.515, -1.0059999999999998, -1.024, 0.9789999999999999, 0.856, -0.517, -0.5, 1.333, -0.506, -0.519, 1.161, -1.007, -0.513, -1.026, -1.012, -1.003, 0.486, -1.007, 1.392, 0.778, -0.509, -0.504, -0.524, -0.501, -0.538, 1.385, -1.005, -1.005, 0.473, 1.2149999999999999, 0.954, -0.522, -0.512, -1.005, 1.301, -0.515, -1.021, -0.506, 1.041, 1.112, -0.503, 1.3639999999999999, 1.4369999999999998, -0.513, -0.503, -0.512, -0.52, 1.225, -0.51, -0.519, -0.519, -0.51, -0.528, 1.3319999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3579394330150172, "mean_inference_ms": 7.394223597718651, "mean_action_processing_ms": 0.3929354752701551, "mean_env_wait_ms": 0.5124197184895412, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1600576639175415, "StateBufferConnector_ms": 0.01004183292388916, "ViewRequirementAgentConnector_ms": 0.19980156421661377}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 126.04996836807867, "num_env_steps_trained_throughput_per_sec": 126.04996836807867, "timesteps_total": 136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 31604.295, "sample_time_ms": 3994.44, "learn_time_ms": 27579.25, "learn_throughput": 145.037, "synch_weights_time_ms": 29.084}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "episodes_total": 1001, "training_iteration": 34, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-14-31", "timestamp": 1694837671, "time_this_iter_s": 31.748942136764526, "time_total_s": 1042.1147465705872, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a1bdf30>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1042.1147465705872, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 25.945652173913043, "ram_util_percent": 56.91521739130435}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.67, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.17, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.67, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.17, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.67, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.17, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5338510711366932, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.0774590984423412, "policy_loss": -0.10991940513486043, "vf_loss": 0.01789984229884188, "vf_explained_var": 0.5514634221792221, "kl": 0.016595532440601347, "entropy": 1.6940779651204745, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 33120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5468838328495622, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08260187098555132, "policy_loss": -0.11613346506783273, "vf_loss": 0.0190746244295345, "vf_explained_var": 0.6348817535986503, "kl": 0.016945360311168164, "entropy": 1.741482444976767, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 33120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000}, "sampler_results": {"episode_reward_max": 1.827, "episode_reward_min": -0.52, "episode_reward_mean": 0.5196200000000001, "episode_len_mean": 96.96, "episode_media": {}, "episodes_this_iter": 46, "policy_reward_min": {"red_0": -1.019, "blue_0": -1.026}, "policy_reward_max": {"red_0": 1.439, "blue_0": 1.459}, "policy_reward_mean": {"red_0": 0.65402, "blue_0": -0.13440000000000002}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.67, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.17, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.67, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.17, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.67, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.17, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.19599999999999995, 0.3330000000000002, -0.3810000000000001, 0.9629999999999999, 1.334, 0.46399999999999997, 0.909, 1.827, 0.3500000000000001, 0.08199999999999985, 0.65, 0.347, 0.5609999999999999, -0.52, 0.254, -0.052000000000000046, 1.665, -0.17500000000000004, 0.391, -0.22599999999999987, 0.6459999999999999, 0.8919999999999999, 0.5549999999999999, 0.41700000000000004, 0.31599999999999984, 0.876, 0.373, -0.16500000000000004, 0.9349999999999999, 0.7030000000000001, 0.43399999999999994, 0.30299999999999994, 0.31199999999999983, -0.136, 1.794, 0.4830000000000001, -0.03700000000000003, 0.829, 0.5129999999999999, 1.603, 0.901, 0.86, 1.435, 0.829, 0.9359999999999999, 0.6240000000000001, 0.476, 1.7149999999999999, 0.6859999999999999, 0.651, 0.4289999999999998, 0.726, 0.2450000000000001, 1.825, 0.46399999999999997, 0.855, 0.893, 0.756, 0.897, 0.40900000000000025, 0.2470000000000001, 1.323, 0.9199999999999999, 0.30400000000000005, 0.13200000000000012, 0.8260000000000001, -0.08999999999999997, -0.18900000000000006, 0.2330000000000001, 0.238, 0.6059999999999999, 0.42099999999999993, 0.25, 0.9149999999999999, -0.012000000000000122, 0.6819999999999999, 0.4289999999999998, 0.3639999999999999, 0.41700000000000026, -0.31200000000000006, 0.665, -0.08100000000000006, -0.19999999999999996, 0.953, 0.573, 0.6480000000000001, -0.18200000000000005, 0.8799999999999999, 0.958, -0.09999999999999998, 0.08099999999999996, -0.07499999999999996, 0.7070000000000001, 0.909, 0.8479999999999999, 0.364, -0.04400000000000004, 0.4249999999999998, -0.07099999999999995, -0.2300000000000001], "episode_lengths": [93, 52, 114, 159, 207, 167, 28, 54, 47, 127, 109, 47, 134, 160, 75, 16, 103, 53, 34, 71, 112, 33, 135, 27, 207, 37, 39, 51, 300, 91, 176, 219, 56, 43, 65, 160, 166, 52, 143, 125, 31, 43, 20, 51, 20, 118, 163, 89, 98, 105, 179, 85, 236, 53, 165, 44, 32, 75, 32, 27, 74, 209, 300, 60, 113, 52, 26, 214, 85, 79, 119, 300, 77, 300, 159, 99, 21, 40, 25, 93, 106, 300, 63, 166, 129, 109, 55, 37, 13, 30, 127, 23, 91, 28, 49, 40, 13, 24, 22, 73], "policy_red_0_reward": [0.711, 1.339, 0.6429999999999999, -0.016000000000000007, 0.478, 0.981, 1.409, 0.494, 0.856, 0.601, -0.511, 1.354, 1.0739999999999998, 0.506, 1.266, 0.951, 1.179, 0.832, -1.001, -1.004, 1.1549999999999998, 1.396, 1.079, 0.918, 0.854, -0.509, 1.3780000000000001, 0.84, 0.46199999999999997, -0.5119999999999999, -0.52, 0.825, 0.824, 0.869, 0.493, 0.998, 0.984, 1.335, -0.528, 0.491, 1.404, -0.504, -0.002, 1.342, 1.439, 1.1360000000000001, 0.996, 0.49, 1.196, 1.17, 0.948, 1.236, 0.773, 0.493, 0.9869999999999999, 1.3639999999999999, 1.3980000000000001, 1.266, 1.4020000000000001, 1.417, 0.766, 0.475, 0.46699999999999997, -0.5099999999999999, 1.149, -0.5109999999999999, 0.919, -1.019, 0.74, 0.748, 1.129, 0.45399999999999996, -0.514, 0.45299999999999996, -1.019, 1.192, 0.9349999999999999, 0.875, 0.921, 0.693, 1.173, -0.047000000000000035, -1.006, -0.027000000000000017, 1.091, 1.163, 0.825, 1.385, -0.501, 0.905, 1.095, 0.929, 1.2189999999999999, -0.506, 1.351, -1.009, 0.96, 1.427, 0.9319999999999999, 0.7749999999999999], "policy_blue_0_reward": [-0.515, -1.0059999999999998, -1.024, 0.9789999999999999, 0.856, -0.517, -0.5, 1.333, -0.506, -0.519, 1.161, -1.007, -0.513, -1.026, -1.012, -1.003, 0.486, -1.007, 1.392, 0.778, -0.509, -0.504, -0.524, -0.501, -0.538, 1.385, -1.005, -1.005, 0.473, 1.2149999999999999, 0.954, -0.522, -0.512, -1.005, 1.301, -0.515, -1.021, -0.506, 1.041, 1.112, -0.503, 1.3639999999999999, 1.4369999999999998, -0.513, -0.503, -0.512, -0.52, 1.225, -0.51, -0.519, -0.519, -0.51, -0.528, 1.3319999999999999, -0.5229999999999999, -0.5089999999999999, -0.505, -0.51, -0.505, -1.0079999999999998, -0.5189999999999999, 0.848, 0.45299999999999996, 0.814, -1.017, 1.337, -1.009, 0.83, -0.507, -0.51, -0.523, -0.03300000000000002, 0.764, 0.46199999999999997, 1.007, -0.51, -0.506, -0.511, -0.5039999999999999, -1.005, -0.508, -0.03400000000000002, 0.8059999999999999, 0.98, -0.5179999999999999, -0.515, -1.007, -0.505, 1.459, -1.005, -1.014, -1.004, -0.5119999999999999, 1.415, -0.503, 1.373, -1.004, -1.002, -1.003, -1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3613046270305398, "mean_inference_ms": 7.3929808354901345, "mean_action_processing_ms": 0.39343013630460427, "mean_env_wait_ms": 0.51263989938361, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.16652631759643555, "StateBufferConnector_ms": 0.009828329086303711, "ViewRequirementAgentConnector_ms": 0.19652092456817627}}, "episode_reward_max": 1.827, "episode_reward_min": -0.52, "episode_reward_mean": 0.5196200000000001, "episode_len_mean": 96.96, "episodes_this_iter": 46, "policy_reward_min": {"red_0": -1.019, "blue_0": -1.026}, "policy_reward_max": {"red_0": 1.439, "blue_0": 1.459}, "policy_reward_mean": {"red_0": 0.65402, "blue_0": -0.13440000000000002}, "hist_stats": {"episode_reward": [0.19599999999999995, 0.3330000000000002, -0.3810000000000001, 0.9629999999999999, 1.334, 0.46399999999999997, 0.909, 1.827, 0.3500000000000001, 0.08199999999999985, 0.65, 0.347, 0.5609999999999999, -0.52, 0.254, -0.052000000000000046, 1.665, -0.17500000000000004, 0.391, -0.22599999999999987, 0.6459999999999999, 0.8919999999999999, 0.5549999999999999, 0.41700000000000004, 0.31599999999999984, 0.876, 0.373, -0.16500000000000004, 0.9349999999999999, 0.7030000000000001, 0.43399999999999994, 0.30299999999999994, 0.31199999999999983, -0.136, 1.794, 0.4830000000000001, -0.03700000000000003, 0.829, 0.5129999999999999, 1.603, 0.901, 0.86, 1.435, 0.829, 0.9359999999999999, 0.6240000000000001, 0.476, 1.7149999999999999, 0.6859999999999999, 0.651, 0.4289999999999998, 0.726, 0.2450000000000001, 1.825, 0.46399999999999997, 0.855, 0.893, 0.756, 0.897, 0.40900000000000025, 0.2470000000000001, 1.323, 0.9199999999999999, 0.30400000000000005, 0.13200000000000012, 0.8260000000000001, -0.08999999999999997, -0.18900000000000006, 0.2330000000000001, 0.238, 0.6059999999999999, 0.42099999999999993, 0.25, 0.9149999999999999, -0.012000000000000122, 0.6819999999999999, 0.4289999999999998, 0.3639999999999999, 0.41700000000000026, -0.31200000000000006, 0.665, -0.08100000000000006, -0.19999999999999996, 0.953, 0.573, 0.6480000000000001, -0.18200000000000005, 0.8799999999999999, 0.958, -0.09999999999999998, 0.08099999999999996, -0.07499999999999996, 0.7070000000000001, 0.909, 0.8479999999999999, 0.364, -0.04400000000000004, 0.4249999999999998, -0.07099999999999995, -0.2300000000000001], "episode_lengths": [93, 52, 114, 159, 207, 167, 28, 54, 47, 127, 109, 47, 134, 160, 75, 16, 103, 53, 34, 71, 112, 33, 135, 27, 207, 37, 39, 51, 300, 91, 176, 219, 56, 43, 65, 160, 166, 52, 143, 125, 31, 43, 20, 51, 20, 118, 163, 89, 98, 105, 179, 85, 236, 53, 165, 44, 32, 75, 32, 27, 74, 209, 300, 60, 113, 52, 26, 214, 85, 79, 119, 300, 77, 300, 159, 99, 21, 40, 25, 93, 106, 300, 63, 166, 129, 109, 55, 37, 13, 30, 127, 23, 91, 28, 49, 40, 13, 24, 22, 73], "policy_red_0_reward": [0.711, 1.339, 0.6429999999999999, -0.016000000000000007, 0.478, 0.981, 1.409, 0.494, 0.856, 0.601, -0.511, 1.354, 1.0739999999999998, 0.506, 1.266, 0.951, 1.179, 0.832, -1.001, -1.004, 1.1549999999999998, 1.396, 1.079, 0.918, 0.854, -0.509, 1.3780000000000001, 0.84, 0.46199999999999997, -0.5119999999999999, -0.52, 0.825, 0.824, 0.869, 0.493, 0.998, 0.984, 1.335, -0.528, 0.491, 1.404, -0.504, -0.002, 1.342, 1.439, 1.1360000000000001, 0.996, 0.49, 1.196, 1.17, 0.948, 1.236, 0.773, 0.493, 0.9869999999999999, 1.3639999999999999, 1.3980000000000001, 1.266, 1.4020000000000001, 1.417, 0.766, 0.475, 0.46699999999999997, -0.5099999999999999, 1.149, -0.5109999999999999, 0.919, -1.019, 0.74, 0.748, 1.129, 0.45399999999999996, -0.514, 0.45299999999999996, -1.019, 1.192, 0.9349999999999999, 0.875, 0.921, 0.693, 1.173, -0.047000000000000035, -1.006, -0.027000000000000017, 1.091, 1.163, 0.825, 1.385, -0.501, 0.905, 1.095, 0.929, 1.2189999999999999, -0.506, 1.351, -1.009, 0.96, 1.427, 0.9319999999999999, 0.7749999999999999], "policy_blue_0_reward": [-0.515, -1.0059999999999998, -1.024, 0.9789999999999999, 0.856, -0.517, -0.5, 1.333, -0.506, -0.519, 1.161, -1.007, -0.513, -1.026, -1.012, -1.003, 0.486, -1.007, 1.392, 0.778, -0.509, -0.504, -0.524, -0.501, -0.538, 1.385, -1.005, -1.005, 0.473, 1.2149999999999999, 0.954, -0.522, -0.512, -1.005, 1.301, -0.515, -1.021, -0.506, 1.041, 1.112, -0.503, 1.3639999999999999, 1.4369999999999998, -0.513, -0.503, -0.512, -0.52, 1.225, -0.51, -0.519, -0.519, -0.51, -0.528, 1.3319999999999999, -0.5229999999999999, -0.5089999999999999, -0.505, -0.51, -0.505, -1.0079999999999998, -0.5189999999999999, 0.848, 0.45299999999999996, 0.814, -1.017, 1.337, -1.009, 0.83, -0.507, -0.51, -0.523, -0.03300000000000002, 0.764, 0.46199999999999997, 1.007, -0.51, -0.506, -0.511, -0.5039999999999999, -1.005, -0.508, -0.03400000000000002, 0.8059999999999999, 0.98, -0.5179999999999999, -0.515, -1.007, -0.505, 1.459, -1.005, -1.014, -1.004, -0.5119999999999999, 1.415, -0.503, 1.373, -1.004, -1.002, -1.003, -1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3613046270305398, "mean_inference_ms": 7.3929808354901345, "mean_action_processing_ms": 0.39343013630460427, "mean_env_wait_ms": 0.51263989938361, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.16652631759643555, "StateBufferConnector_ms": 0.009828329086303711, "ViewRequirementAgentConnector_ms": 0.19652092456817627}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.78730811042738, "num_env_steps_trained_throughput_per_sec": 127.78730811042738, "timesteps_total": 140000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 280000, "timers": {"training_iteration_time_ms": 31616.737, "sample_time_ms": 4014.746, "learn_time_ms": 27571.472, "learn_throughput": 145.077, "synch_weights_time_ms": 29.009}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000}, "done": false, "episodes_total": 1047, "training_iteration": 35, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-15-04", "timestamp": 1694837704, "time_this_iter_s": 31.31680989265442, "time_total_s": 1073.4315564632416, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80ec8310>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1073.4315564632416, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 24.267391304347825, "ram_util_percent": 56.90000000000001}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.03, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5509109536185861, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08769257785364365, "policy_loss": -0.12088969320563289, "vf_loss": 0.012808152010741954, "vf_explained_var": 0.5760346448669831, "kl": 0.018755665857471293, "entropy": 1.6921266958117485, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 34080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5460969901022812, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.079253753524002, "policy_loss": -0.11211120616838646, "vf_loss": 0.01824339248026566, "vf_explained_var": 0.5795499437178174, "kl": 0.01677193245979538, "entropy": 1.7366153339544932, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 34080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "sampler_results": {"episode_reward_max": 1.927, "episode_reward_min": -0.31200000000000006, "episode_reward_mean": 0.57774, "episode_len_mean": 96.29, "episode_media": {}, "episodes_this_iter": 40, "policy_reward_min": {"red_0": -1.019, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.459}, "policy_reward_mean": {"red_0": 0.7585200000000001, "blue_0": -0.18077999999999997}, "custom_metrics": {"red_0/door_open_done_mean": 0.03, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.901, 0.86, 1.435, 0.829, 0.9359999999999999, 0.6240000000000001, 0.476, 1.7149999999999999, 0.6859999999999999, 0.651, 0.4289999999999998, 0.726, 0.2450000000000001, 1.825, 0.46399999999999997, 0.855, 0.893, 0.756, 0.897, 0.40900000000000025, 0.2470000000000001, 1.323, 0.9199999999999999, 0.30400000000000005, 0.13200000000000012, 0.8260000000000001, -0.08999999999999997, -0.18900000000000006, 0.2330000000000001, 0.238, 0.6059999999999999, 0.42099999999999993, 0.25, 0.9149999999999999, -0.012000000000000122, 0.6819999999999999, 0.4289999999999998, 0.3639999999999999, 0.41700000000000026, -0.31200000000000006, 0.665, -0.08100000000000006, -0.19999999999999996, 0.953, 0.573, 0.6480000000000001, -0.18200000000000005, 0.8799999999999999, 0.958, -0.09999999999999998, 0.08099999999999996, -0.07499999999999996, 0.7070000000000001, 0.909, 0.8479999999999999, 0.364, -0.04400000000000004, 0.4249999999999998, -0.07099999999999995, -0.2300000000000001, -0.05400000000000005, 0.10699999999999998, 1.531, 0.33699999999999997, 0.5979999999999999, 0.1359999999999999, 1.644, 0.943, 0.5960000000000001, 1.165, 0.33599999999999985, 0.9329999999999999, 1.575, 0.663, 0.31299999999999994, 0.4929999999999999, 0.5449999999999999, 1.576, 0.7, 0.774, 0.41900000000000004, 0.4079999999999999, 0.33699999999999997, 0.31899999999999995, 0.46399999999999997, 0.6190000000000002, -0.10499999999999998, 0.704, 0.46599999999999997, 0.41999999999999993, 0.363, 1.434, 0.2639999999999999, -0.09699999999999998, 0.39400000000000013, 1.607, 0.24099999999999988, 1.927, 0.8820000000000001, 0.45299999999999985], "episode_lengths": [31, 43, 20, 51, 20, 118, 163, 89, 98, 105, 179, 85, 236, 53, 165, 44, 32, 75, 32, 27, 74, 209, 300, 60, 113, 52, 26, 214, 85, 79, 119, 300, 77, 300, 159, 99, 21, 40, 25, 93, 106, 300, 63, 166, 129, 109, 55, 37, 13, 30, 127, 23, 91, 28, 49, 40, 13, 24, 22, 73, 169, 275, 143, 50, 124, 265, 108, 17, 125, 256, 205, 21, 130, 105, 53, 154, 139, 133, 91, 69, 26, 29, 50, 56, 12, 118, 33, 92, 11, 25, 44, 174, 227, 31, 34, 121, 231, 22, 38, 14], "policy_red_0_reward": [1.404, -0.504, -0.002, 1.342, 1.439, 1.1360000000000001, 0.996, 0.49, 1.196, 1.17, 0.948, 1.236, 0.773, 0.493, 0.9869999999999999, 1.3639999999999999, 1.3980000000000001, 1.266, 1.4020000000000001, 1.417, 0.766, 0.475, 0.46699999999999997, -0.5099999999999999, 1.149, -0.5109999999999999, 0.919, -1.019, 0.74, 0.748, 1.129, 0.45399999999999996, -0.514, 0.45299999999999996, -1.019, 1.192, 0.9349999999999999, 0.875, 0.921, 0.693, 1.173, -0.047000000000000035, -1.006, -0.027000000000000017, 1.091, 1.163, 0.825, 1.385, -0.501, 0.905, 1.095, 0.929, 1.2189999999999999, -0.506, 1.351, -1.009, 0.96, 1.427, 0.9319999999999999, 0.7749999999999999, 0.46299999999999997, 0.652, 0.478, 0.844, 1.112, 0.6729999999999999, 1.1629999999999998, -0.505, 1.108, 0.473, 0.862, -0.502, 1.0899999999999999, 1.1720000000000002, 1.3279999999999998, 1.016, 1.0659999999999998, 0.491, 1.2149999999999999, 1.2799999999999998, 1.42, 1.411, 1.343, 0.823, 1.464, 1.13, 0.901, 1.216, 0.966, 0.923, 1.365, 0.48, -0.529, 0.905, 1.396, 1.124, 0.7699999999999999, 0.499, 1.385, 0.953], "policy_blue_0_reward": [-0.503, 1.3639999999999999, 1.4369999999999998, -0.513, -0.503, -0.512, -0.52, 1.225, -0.51, -0.519, -0.519, -0.51, -0.528, 1.3319999999999999, -0.5229999999999999, -0.5089999999999999, -0.505, -0.51, -0.505, -1.0079999999999998, -0.5189999999999999, 0.848, 0.45299999999999996, 0.814, -1.017, 1.337, -1.009, 0.83, -0.507, -0.51, -0.523, -0.03300000000000002, 0.764, 0.46199999999999997, 1.007, -0.51, -0.506, -0.511, -0.5039999999999999, -1.005, -0.508, -0.03400000000000002, 0.8059999999999999, 0.98, -0.5179999999999999, -0.515, -1.007, -0.505, 1.459, -1.005, -1.014, -1.004, -0.5119999999999999, 1.415, -0.503, 1.373, -1.004, -1.002, -1.003, -1.005, -0.517, -0.545, 1.053, -0.507, -0.514, -0.537, 0.481, 1.448, -0.512, 0.692, -0.526, 1.435, 0.485, -0.509, -1.015, -0.523, -0.521, 1.085, -0.515, -0.506, -1.001, -1.003, -1.006, -0.504, -1.0, -0.5109999999999999, -1.006, -0.512, -0.5, -0.503, -1.002, 0.954, 0.7929999999999999, -1.002, -1.002, 0.483, -0.529, 1.428, -0.503, -0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3623346020202416, "mean_inference_ms": 7.396107482175987, "mean_action_processing_ms": 0.39288340130568905, "mean_env_wait_ms": 0.5127019943840011, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15986180305480957, "StateBufferConnector_ms": 0.00975179672241211, "ViewRequirementAgentConnector_ms": 0.1953510046005249}}, "episode_reward_max": 1.927, "episode_reward_min": -0.31200000000000006, "episode_reward_mean": 0.57774, "episode_len_mean": 96.29, "episodes_this_iter": 40, "policy_reward_min": {"red_0": -1.019, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.459}, "policy_reward_mean": {"red_0": 0.7585200000000001, "blue_0": -0.18077999999999997}, "hist_stats": {"episode_reward": [0.901, 0.86, 1.435, 0.829, 0.9359999999999999, 0.6240000000000001, 0.476, 1.7149999999999999, 0.6859999999999999, 0.651, 0.4289999999999998, 0.726, 0.2450000000000001, 1.825, 0.46399999999999997, 0.855, 0.893, 0.756, 0.897, 0.40900000000000025, 0.2470000000000001, 1.323, 0.9199999999999999, 0.30400000000000005, 0.13200000000000012, 0.8260000000000001, -0.08999999999999997, -0.18900000000000006, 0.2330000000000001, 0.238, 0.6059999999999999, 0.42099999999999993, 0.25, 0.9149999999999999, -0.012000000000000122, 0.6819999999999999, 0.4289999999999998, 0.3639999999999999, 0.41700000000000026, -0.31200000000000006, 0.665, -0.08100000000000006, -0.19999999999999996, 0.953, 0.573, 0.6480000000000001, -0.18200000000000005, 0.8799999999999999, 0.958, -0.09999999999999998, 0.08099999999999996, -0.07499999999999996, 0.7070000000000001, 0.909, 0.8479999999999999, 0.364, -0.04400000000000004, 0.4249999999999998, -0.07099999999999995, -0.2300000000000001, -0.05400000000000005, 0.10699999999999998, 1.531, 0.33699999999999997, 0.5979999999999999, 0.1359999999999999, 1.644, 0.943, 0.5960000000000001, 1.165, 0.33599999999999985, 0.9329999999999999, 1.575, 0.663, 0.31299999999999994, 0.4929999999999999, 0.5449999999999999, 1.576, 0.7, 0.774, 0.41900000000000004, 0.4079999999999999, 0.33699999999999997, 0.31899999999999995, 0.46399999999999997, 0.6190000000000002, -0.10499999999999998, 0.704, 0.46599999999999997, 0.41999999999999993, 0.363, 1.434, 0.2639999999999999, -0.09699999999999998, 0.39400000000000013, 1.607, 0.24099999999999988, 1.927, 0.8820000000000001, 0.45299999999999985], "episode_lengths": [31, 43, 20, 51, 20, 118, 163, 89, 98, 105, 179, 85, 236, 53, 165, 44, 32, 75, 32, 27, 74, 209, 300, 60, 113, 52, 26, 214, 85, 79, 119, 300, 77, 300, 159, 99, 21, 40, 25, 93, 106, 300, 63, 166, 129, 109, 55, 37, 13, 30, 127, 23, 91, 28, 49, 40, 13, 24, 22, 73, 169, 275, 143, 50, 124, 265, 108, 17, 125, 256, 205, 21, 130, 105, 53, 154, 139, 133, 91, 69, 26, 29, 50, 56, 12, 118, 33, 92, 11, 25, 44, 174, 227, 31, 34, 121, 231, 22, 38, 14], "policy_red_0_reward": [1.404, -0.504, -0.002, 1.342, 1.439, 1.1360000000000001, 0.996, 0.49, 1.196, 1.17, 0.948, 1.236, 0.773, 0.493, 0.9869999999999999, 1.3639999999999999, 1.3980000000000001, 1.266, 1.4020000000000001, 1.417, 0.766, 0.475, 0.46699999999999997, -0.5099999999999999, 1.149, -0.5109999999999999, 0.919, -1.019, 0.74, 0.748, 1.129, 0.45399999999999996, -0.514, 0.45299999999999996, -1.019, 1.192, 0.9349999999999999, 0.875, 0.921, 0.693, 1.173, -0.047000000000000035, -1.006, -0.027000000000000017, 1.091, 1.163, 0.825, 1.385, -0.501, 0.905, 1.095, 0.929, 1.2189999999999999, -0.506, 1.351, -1.009, 0.96, 1.427, 0.9319999999999999, 0.7749999999999999, 0.46299999999999997, 0.652, 0.478, 0.844, 1.112, 0.6729999999999999, 1.1629999999999998, -0.505, 1.108, 0.473, 0.862, -0.502, 1.0899999999999999, 1.1720000000000002, 1.3279999999999998, 1.016, 1.0659999999999998, 0.491, 1.2149999999999999, 1.2799999999999998, 1.42, 1.411, 1.343, 0.823, 1.464, 1.13, 0.901, 1.216, 0.966, 0.923, 1.365, 0.48, -0.529, 0.905, 1.396, 1.124, 0.7699999999999999, 0.499, 1.385, 0.953], "policy_blue_0_reward": [-0.503, 1.3639999999999999, 1.4369999999999998, -0.513, -0.503, -0.512, -0.52, 1.225, -0.51, -0.519, -0.519, -0.51, -0.528, 1.3319999999999999, -0.5229999999999999, -0.5089999999999999, -0.505, -0.51, -0.505, -1.0079999999999998, -0.5189999999999999, 0.848, 0.45299999999999996, 0.814, -1.017, 1.337, -1.009, 0.83, -0.507, -0.51, -0.523, -0.03300000000000002, 0.764, 0.46199999999999997, 1.007, -0.51, -0.506, -0.511, -0.5039999999999999, -1.005, -0.508, -0.03400000000000002, 0.8059999999999999, 0.98, -0.5179999999999999, -0.515, -1.007, -0.505, 1.459, -1.005, -1.014, -1.004, -0.5119999999999999, 1.415, -0.503, 1.373, -1.004, -1.002, -1.003, -1.005, -0.517, -0.545, 1.053, -0.507, -0.514, -0.537, 0.481, 1.448, -0.512, 0.692, -0.526, 1.435, 0.485, -0.509, -1.015, -0.523, -0.521, 1.085, -0.515, -0.506, -1.001, -1.003, -1.006, -0.504, -1.0, -0.5109999999999999, -1.006, -0.512, -0.5, -0.503, -1.002, 0.954, 0.7929999999999999, -1.002, -1.002, 0.483, -0.529, 1.428, -0.503, -0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3623346020202416, "mean_inference_ms": 7.396107482175987, "mean_action_processing_ms": 0.39288340130568905, "mean_env_wait_ms": 0.5127019943840011, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15986180305480957, "StateBufferConnector_ms": 0.00975179672241211, "ViewRequirementAgentConnector_ms": 0.1953510046005249}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.0737788295311, "num_env_steps_trained_throughput_per_sec": 128.0737788295311, "timesteps_total": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 31682.367, "sample_time_ms": 4030.139, "learn_time_ms": 27621.799, "learn_throughput": 144.813, "synch_weights_time_ms": 28.927}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "episodes_total": 1087, "training_iteration": 36, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-15-36", "timestamp": 1694837736, "time_this_iter_s": 31.24787712097168, "time_total_s": 1104.6794335842133, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a1becb0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1104.6794335842133, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 24.628260869565214, "ram_util_percent": 56.83695652173914}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.03, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.74, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.74, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.09, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.11, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.74, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5711666244082153, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08313279708284729, "policy_loss": -0.11701463818462798, "vf_loss": 0.013388450735995623, "vf_explained_var": 0.633627696832021, "kl": 0.019007358582184053, "entropy": 1.6798090375959873, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 35040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5490112934261561, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08272962832803993, "policy_loss": -0.11581932043579096, "vf_loss": 0.01865658694805461, "vf_explained_var": 0.6335832607621948, "kl": 0.016791952403082087, "entropy": 1.7413776862124601, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 35040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000}, "sampler_results": {"episode_reward_max": 1.927, "episode_reward_min": -0.2300000000000001, "episode_reward_mean": 0.5896899999999999, "episode_len_mean": 92.92, "episode_media": {}, "episodes_this_iter": 41, "policy_reward_min": {"red_0": -1.009, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.459}, "policy_reward_mean": {"red_0": 0.8359999999999999, "blue_0": -0.24631}, "custom_metrics": {"red_0/door_open_done_mean": 0.03, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.74, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.74, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.09, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.11, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.74, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.08100000000000006, -0.19999999999999996, 0.953, 0.573, 0.6480000000000001, -0.18200000000000005, 0.8799999999999999, 0.958, -0.09999999999999998, 0.08099999999999996, -0.07499999999999996, 0.7070000000000001, 0.909, 0.8479999999999999, 0.364, -0.04400000000000004, 0.4249999999999998, -0.07099999999999995, -0.2300000000000001, -0.05400000000000005, 0.10699999999999998, 1.531, 0.33699999999999997, 0.5979999999999999, 0.1359999999999999, 1.644, 0.943, 0.5960000000000001, 1.165, 0.33599999999999985, 0.9329999999999999, 1.575, 0.663, 0.31299999999999994, 0.4929999999999999, 0.5449999999999999, 1.576, 0.7, 0.774, 0.41900000000000004, 0.4079999999999999, 0.33699999999999997, 0.31899999999999995, 0.46399999999999997, 0.6190000000000002, -0.10499999999999998, 0.704, 0.46599999999999997, 0.41999999999999993, 0.363, 1.434, 0.2639999999999999, -0.09699999999999998, 0.39400000000000013, 1.607, 0.24099999999999988, 1.927, 0.8820000000000001, 0.45299999999999985, 0.373, 0.9329999999999998, 0.42200000000000015, 0.22599999999999998, 0.3729999999999998, 0.22299999999999986, 0.20599999999999996, 0.6350000000000001, 0.762, 0.8440000000000001, 0.556, 0.9359999999999999, 0.7639999999999998, 0.41200000000000003, 0.813, 0.6579999999999999, -0.02400000000000002, 0.718, 0.31599999999999995, 0.3979999999999999, 1.568, 0.878, 0.7029999999999998, 0.30899999999999994, 0.9299999999999999, 1.694, 0.4849999999999999, 0.9269999999999999, 1.855, 0.7999999999999998, 0.44199999999999995, 0.40600000000000014, 0.42500000000000004, 0.6880000000000002, 0.7549999999999999, -0.07700000000000007, 0.3250000000000002, 0.7349999999999999, 0.569, 0.33599999999999985, 0.879], "episode_lengths": [300, 63, 166, 129, 109, 55, 37, 13, 30, 127, 23, 91, 28, 49, 40, 13, 24, 22, 73, 169, 275, 143, 50, 124, 265, 108, 17, 125, 256, 205, 21, 130, 105, 53, 154, 139, 133, 91, 69, 26, 29, 50, 56, 12, 118, 33, 92, 11, 25, 44, 174, 227, 31, 34, 121, 231, 22, 38, 14, 38, 20, 25, 84, 195, 232, 241, 110, 73, 48, 137, 20, 73, 28, 59, 107, 8, 85, 56, 188, 136, 37, 92, 56, 300, 94, 161, 300, 43, 63, 19, 29, 23, 97, 74, 24, 54, 80, 133, 200, 38], "policy_red_0_reward": [-0.047000000000000035, -1.006, -0.027000000000000017, 1.091, 1.163, 0.825, 1.385, -0.501, 0.905, 1.095, 0.929, 1.2189999999999999, -0.506, 1.351, -1.009, 0.96, 1.427, 0.9319999999999999, 0.7749999999999999, 0.46299999999999997, 0.652, 0.478, 0.844, 1.112, 0.6729999999999999, 1.1629999999999998, -0.505, 1.108, 0.473, 0.862, -0.502, 1.0899999999999999, 1.1720000000000002, 1.3279999999999998, 1.016, 1.0659999999999998, 0.491, 1.2149999999999999, 1.2799999999999998, 1.42, 1.411, 1.343, 0.823, 1.464, 1.13, 0.901, 1.216, 0.966, 0.923, 1.365, 0.48, -0.529, 0.905, 1.396, 1.124, 0.7699999999999999, 0.499, 1.385, 0.953, 1.381, 1.4369999999999998, 0.923, 0.735, 0.8939999999999999, 0.776, 0.736, -0.5139999999999999, 1.271, 1.351, 1.071, 1.4369999999999998, 1.2759999999999998, -0.502, 1.318, 1.171, 0.976, 1.226, -0.505, 0.9129999999999999, 0.491, -0.507, 1.2149999999999999, 1.323, 0.473, 0.487, 1.004, 0.46699999999999997, 0.492, 1.309, 1.442, 1.411, 0.929, 1.1960000000000002, 1.2650000000000001, 0.9249999999999999, 1.3319999999999999, 1.2530000000000001, 1.085, 0.871, 1.381], "policy_blue_0_reward": [-0.03400000000000002, 0.8059999999999999, 0.98, -0.5179999999999999, -0.515, -1.007, -0.505, 1.459, -1.005, -1.014, -1.004, -0.5119999999999999, 1.415, -0.503, 1.373, -1.004, -1.002, -1.003, -1.005, -0.517, -0.545, 1.053, -0.507, -0.514, -0.537, 0.481, 1.448, -0.512, 0.692, -0.526, 1.435, 0.485, -0.509, -1.015, -0.523, -0.521, 1.085, -0.515, -0.506, -1.001, -1.003, -1.006, -0.504, -1.0, -0.5109999999999999, -1.006, -0.512, -0.5, -0.503, -1.002, 0.954, 0.7929999999999999, -1.002, -1.002, 0.483, -0.529, 1.428, -0.503, -0.5, -1.008, -0.504, -0.501, -0.509, -0.521, -0.553, -0.53, 1.149, -0.509, -0.5069999999999999, -0.515, -0.501, -0.512, 0.914, -0.505, -0.513, -1.0, -0.508, 0.821, -0.515, 1.077, 1.385, -0.512, -1.014, 0.45699999999999996, 1.2069999999999999, -0.519, 0.45999999999999996, 1.363, -0.509, -1.0, -1.005, -0.504, -0.508, -0.51, -1.002, -1.007, -0.518, -0.516, -0.535, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.361661390313972, "mean_inference_ms": 7.393469966555347, "mean_action_processing_ms": 0.3930911159806555, "mean_env_wait_ms": 0.513006993757914, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14513254165649414, "StateBufferConnector_ms": 0.009609222412109375, "ViewRequirementAgentConnector_ms": 0.1902221441268921}}, "episode_reward_max": 1.927, "episode_reward_min": -0.2300000000000001, "episode_reward_mean": 0.5896899999999999, "episode_len_mean": 92.92, "episodes_this_iter": 41, "policy_reward_min": {"red_0": -1.009, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.459}, "policy_reward_mean": {"red_0": 0.8359999999999999, "blue_0": -0.24631}, "hist_stats": {"episode_reward": [-0.08100000000000006, -0.19999999999999996, 0.953, 0.573, 0.6480000000000001, -0.18200000000000005, 0.8799999999999999, 0.958, -0.09999999999999998, 0.08099999999999996, -0.07499999999999996, 0.7070000000000001, 0.909, 0.8479999999999999, 0.364, -0.04400000000000004, 0.4249999999999998, -0.07099999999999995, -0.2300000000000001, -0.05400000000000005, 0.10699999999999998, 1.531, 0.33699999999999997, 0.5979999999999999, 0.1359999999999999, 1.644, 0.943, 0.5960000000000001, 1.165, 0.33599999999999985, 0.9329999999999999, 1.575, 0.663, 0.31299999999999994, 0.4929999999999999, 0.5449999999999999, 1.576, 0.7, 0.774, 0.41900000000000004, 0.4079999999999999, 0.33699999999999997, 0.31899999999999995, 0.46399999999999997, 0.6190000000000002, -0.10499999999999998, 0.704, 0.46599999999999997, 0.41999999999999993, 0.363, 1.434, 0.2639999999999999, -0.09699999999999998, 0.39400000000000013, 1.607, 0.24099999999999988, 1.927, 0.8820000000000001, 0.45299999999999985, 0.373, 0.9329999999999998, 0.42200000000000015, 0.22599999999999998, 0.3729999999999998, 0.22299999999999986, 0.20599999999999996, 0.6350000000000001, 0.762, 0.8440000000000001, 0.556, 0.9359999999999999, 0.7639999999999998, 0.41200000000000003, 0.813, 0.6579999999999999, -0.02400000000000002, 0.718, 0.31599999999999995, 0.3979999999999999, 1.568, 0.878, 0.7029999999999998, 0.30899999999999994, 0.9299999999999999, 1.694, 0.4849999999999999, 0.9269999999999999, 1.855, 0.7999999999999998, 0.44199999999999995, 0.40600000000000014, 0.42500000000000004, 0.6880000000000002, 0.7549999999999999, -0.07700000000000007, 0.3250000000000002, 0.7349999999999999, 0.569, 0.33599999999999985, 0.879], "episode_lengths": [300, 63, 166, 129, 109, 55, 37, 13, 30, 127, 23, 91, 28, 49, 40, 13, 24, 22, 73, 169, 275, 143, 50, 124, 265, 108, 17, 125, 256, 205, 21, 130, 105, 53, 154, 139, 133, 91, 69, 26, 29, 50, 56, 12, 118, 33, 92, 11, 25, 44, 174, 227, 31, 34, 121, 231, 22, 38, 14, 38, 20, 25, 84, 195, 232, 241, 110, 73, 48, 137, 20, 73, 28, 59, 107, 8, 85, 56, 188, 136, 37, 92, 56, 300, 94, 161, 300, 43, 63, 19, 29, 23, 97, 74, 24, 54, 80, 133, 200, 38], "policy_red_0_reward": [-0.047000000000000035, -1.006, -0.027000000000000017, 1.091, 1.163, 0.825, 1.385, -0.501, 0.905, 1.095, 0.929, 1.2189999999999999, -0.506, 1.351, -1.009, 0.96, 1.427, 0.9319999999999999, 0.7749999999999999, 0.46299999999999997, 0.652, 0.478, 0.844, 1.112, 0.6729999999999999, 1.1629999999999998, -0.505, 1.108, 0.473, 0.862, -0.502, 1.0899999999999999, 1.1720000000000002, 1.3279999999999998, 1.016, 1.0659999999999998, 0.491, 1.2149999999999999, 1.2799999999999998, 1.42, 1.411, 1.343, 0.823, 1.464, 1.13, 0.901, 1.216, 0.966, 0.923, 1.365, 0.48, -0.529, 0.905, 1.396, 1.124, 0.7699999999999999, 0.499, 1.385, 0.953, 1.381, 1.4369999999999998, 0.923, 0.735, 0.8939999999999999, 0.776, 0.736, -0.5139999999999999, 1.271, 1.351, 1.071, 1.4369999999999998, 1.2759999999999998, -0.502, 1.318, 1.171, 0.976, 1.226, -0.505, 0.9129999999999999, 0.491, -0.507, 1.2149999999999999, 1.323, 0.473, 0.487, 1.004, 0.46699999999999997, 0.492, 1.309, 1.442, 1.411, 0.929, 1.1960000000000002, 1.2650000000000001, 0.9249999999999999, 1.3319999999999999, 1.2530000000000001, 1.085, 0.871, 1.381], "policy_blue_0_reward": [-0.03400000000000002, 0.8059999999999999, 0.98, -0.5179999999999999, -0.515, -1.007, -0.505, 1.459, -1.005, -1.014, -1.004, -0.5119999999999999, 1.415, -0.503, 1.373, -1.004, -1.002, -1.003, -1.005, -0.517, -0.545, 1.053, -0.507, -0.514, -0.537, 0.481, 1.448, -0.512, 0.692, -0.526, 1.435, 0.485, -0.509, -1.015, -0.523, -0.521, 1.085, -0.515, -0.506, -1.001, -1.003, -1.006, -0.504, -1.0, -0.5109999999999999, -1.006, -0.512, -0.5, -0.503, -1.002, 0.954, 0.7929999999999999, -1.002, -1.002, 0.483, -0.529, 1.428, -0.503, -0.5, -1.008, -0.504, -0.501, -0.509, -0.521, -0.553, -0.53, 1.149, -0.509, -0.5069999999999999, -0.515, -0.501, -0.512, 0.914, -0.505, -0.513, -1.0, -0.508, 0.821, -0.515, 1.077, 1.385, -0.512, -1.014, 0.45699999999999996, 1.2069999999999999, -0.519, 0.45999999999999996, 1.363, -0.509, -1.0, -1.005, -0.504, -0.508, -0.51, -1.002, -1.007, -0.518, -0.516, -0.535, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.361661390313972, "mean_inference_ms": 7.393469966555347, "mean_action_processing_ms": 0.3930911159806555, "mean_env_wait_ms": 0.513006993757914, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14513254165649414, "StateBufferConnector_ms": 0.009609222412109375, "ViewRequirementAgentConnector_ms": 0.1902221441268921}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.2406190309457, "num_env_steps_trained_throughput_per_sec": 129.2406190309457, "timesteps_total": 148000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 296000, "timers": {"training_iteration_time_ms": 31658.858, "sample_time_ms": 4035.814, "learn_time_ms": 27592.632, "learn_throughput": 144.966, "synch_weights_time_ms": 28.889}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000}, "done": false, "episodes_total": 1128, "training_iteration": 37, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-16-08", "timestamp": 1694837768, "time_this_iter_s": 30.965771913528442, "time_total_s": 1135.6452054977417, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80eb8b80>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1135.6452054977417, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 24.306666666666672, "ram_util_percent": 56.90444444444445}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.77, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.77, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.77, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5626378445265193, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07317649900214747, "policy_loss": -0.10609489025106693, "vf_loss": 0.014761478415554545, "vf_explained_var": 0.5993413184459011, "kl": 0.017900296637315564, "entropy": 1.6484232301513353, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.584045725936691, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08218651925805413, "policy_loss": -0.11867021508563387, "vf_loss": 0.022405894215141112, "vf_explained_var": 0.600369845268627, "kl": 0.017782491564494237, "entropy": 1.7264098313947518, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "sampler_results": {"episode_reward_max": 1.927, "episode_reward_min": -0.17700000000000005, "episode_reward_mean": 0.61087, "episode_len_mean": 89.36, "episode_media": {}, "episodes_this_iter": 45, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.45, "blue_0": 1.428}, "policy_reward_mean": {"red_0": 0.8849899999999999, "blue_0": -0.27412}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.77, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.77, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.77, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.10499999999999998, 0.704, 0.46599999999999997, 0.41999999999999993, 0.363, 1.434, 0.2639999999999999, -0.09699999999999998, 0.39400000000000013, 1.607, 0.24099999999999988, 1.927, 0.8820000000000001, 0.45299999999999985, 0.373, 0.9329999999999998, 0.42200000000000015, 0.22599999999999998, 0.3729999999999998, 0.22299999999999986, 0.20599999999999996, 0.6350000000000001, 0.762, 0.8440000000000001, 0.556, 0.9359999999999999, 0.7639999999999998, 0.41200000000000003, 0.813, 0.6579999999999999, -0.02400000000000002, 0.718, 0.31599999999999995, 0.3979999999999999, 1.568, 0.878, 0.7029999999999998, 0.30899999999999994, 0.9299999999999999, 1.694, 0.4849999999999999, 0.9269999999999999, 1.855, 0.7999999999999998, 0.44199999999999995, 0.40600000000000014, 0.42500000000000004, 0.6880000000000002, 0.7549999999999999, -0.07700000000000007, 0.3250000000000002, 0.7349999999999999, 0.569, 0.33599999999999985, 0.879, 0.48999999999999977, 1.797, -0.07300000000000006, 0.7190000000000001, 0.3080000000000003, 0.42500000000000004, 0.20100000000000007, 0.1259999999999999, 0.43299999999999983, 0.3500000000000001, 0.8160000000000001, 0.7240000000000002, 0.2689999999999999, -0.17700000000000005, 0.42799999999999994, 0.9179999999999999, 0.6880000000000001, 0.7949999999999999, 0.2290000000000001, 0.42700000000000016, 0.30100000000000016, 0.44799999999999995, 0.381, -0.09699999999999998, 1.443, 0.8820000000000001, 0.2530000000000001, 1.865, -0.14900000000000002, 0.7749999999999999, 1.838, 0.3380000000000001, 0.919, 1.157, 0.938, 0.05800000000000005, 0.9280000000000002, 0.79, 0.33399999999999996, 0.7010000000000001, 0.492, -0.11699999999999999, 0.5960000000000001, 0.6840000000000002, 0.30699999999999994], "episode_lengths": [33, 92, 11, 25, 44, 174, 227, 31, 34, 121, 231, 22, 38, 14, 38, 20, 25, 84, 195, 232, 241, 110, 73, 48, 137, 20, 73, 28, 59, 107, 8, 85, 56, 188, 136, 37, 92, 56, 300, 94, 161, 300, 43, 63, 19, 29, 23, 97, 74, 24, 54, 80, 133, 200, 38, 155, 61, 173, 85, 58, 23, 244, 267, 20, 200, 56, 81, 222, 56, 23, 300, 97, 61, 83, 23, 62, 16, 38, 31, 172, 37, 75, 42, 47, 67, 50, 50, 25, 104, 19, 136, 23, 66, 53, 92, 151, 36, 125, 95, 59], "policy_red_0_reward": [0.901, 1.216, 0.966, 0.923, 1.365, 0.48, -0.529, 0.905, 1.396, 1.124, 0.7699999999999999, 0.499, 1.385, 0.953, 1.381, 1.4369999999999998, 0.923, 0.735, 0.8939999999999999, 0.776, 0.736, -0.5139999999999999, 1.271, 1.351, 1.071, 1.4369999999999998, 1.2759999999999998, -0.502, 1.318, 1.171, 0.976, 1.226, -0.505, 0.9129999999999999, 0.491, -0.507, 1.2149999999999999, 1.323, 0.473, 0.487, 1.004, 0.46699999999999997, 0.492, 1.309, 1.442, 1.411, 0.929, 1.1960000000000002, 1.2650000000000001, 0.9249999999999999, 1.3319999999999999, 1.2530000000000001, 1.085, 0.871, 1.381, 1.016, 0.494, 0.948, 1.234, 1.3210000000000002, 0.927, 0.733, 0.6629999999999999, 1.436, 0.875, 1.323, 1.242, 0.8059999999999999, 0.83, 1.429, 0.46299999999999997, -0.509, 1.3079999999999998, 1.24, -0.5039999999999999, 1.307, 1.45, -1.002, 0.907, 0.48, 1.3860000000000001, 1.2650000000000001, 0.497, 0.853, 1.289, 0.495, 0.846, 1.4220000000000002, -0.01800000000000001, 1.4409999999999998, 0.5770000000000001, 1.4300000000000002, 1.294, -0.505, 1.2149999999999999, 1.012, 0.89, 1.113, 1.201, 0.8099999999999999], "policy_blue_0_reward": [-1.006, -0.512, -0.5, -0.503, -1.002, 0.954, 0.7929999999999999, -1.002, -1.002, 0.483, -0.529, 1.428, -0.503, -0.5, -1.008, -0.504, -0.501, -0.509, -0.521, -0.553, -0.53, 1.149, -0.509, -0.5069999999999999, -0.515, -0.501, -0.512, 0.914, -0.505, -0.513, -1.0, -0.508, 0.821, -0.515, 1.077, 1.385, -0.512, -1.014, 0.45699999999999996, 1.2069999999999999, -0.519, 0.45999999999999996, 1.363, -0.509, -1.0, -1.005, -0.504, -0.508, -0.51, -1.002, -1.007, -0.518, -0.516, -0.535, -0.502, -0.526, 1.303, -1.021, -0.5149999999999999, -1.013, -0.502, -0.532, -0.537, -1.003, -0.5249999999999999, -0.5069999999999999, -0.5179999999999999, -0.537, -1.007, -1.001, 0.45499999999999996, 1.197, -0.513, -1.011, 0.931, -1.006, -1.002, 1.383, -1.004, 0.963, -0.504, -1.012, 1.3679999999999999, -1.002, -0.5139999999999999, 1.343, -0.508, -0.5029999999999999, 1.1749999999999998, -0.503, -0.519, -0.5019999999999999, -0.504, 0.839, -0.514, -0.52, -1.007, -0.517, -0.517, -0.503]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3603818505773757, "mean_inference_ms": 7.385452575839651, "mean_action_processing_ms": 0.3923961544621811, "mean_env_wait_ms": 0.5122678249991419, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1434992551803589, "StateBufferConnector_ms": 0.009418964385986328, "ViewRequirementAgentConnector_ms": 0.18610024452209473}}, "episode_reward_max": 1.927, "episode_reward_min": -0.17700000000000005, "episode_reward_mean": 0.61087, "episode_len_mean": 89.36, "episodes_this_iter": 45, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.45, "blue_0": 1.428}, "policy_reward_mean": {"red_0": 0.8849899999999999, "blue_0": -0.27412}, "hist_stats": {"episode_reward": [-0.10499999999999998, 0.704, 0.46599999999999997, 0.41999999999999993, 0.363, 1.434, 0.2639999999999999, -0.09699999999999998, 0.39400000000000013, 1.607, 0.24099999999999988, 1.927, 0.8820000000000001, 0.45299999999999985, 0.373, 0.9329999999999998, 0.42200000000000015, 0.22599999999999998, 0.3729999999999998, 0.22299999999999986, 0.20599999999999996, 0.6350000000000001, 0.762, 0.8440000000000001, 0.556, 0.9359999999999999, 0.7639999999999998, 0.41200000000000003, 0.813, 0.6579999999999999, -0.02400000000000002, 0.718, 0.31599999999999995, 0.3979999999999999, 1.568, 0.878, 0.7029999999999998, 0.30899999999999994, 0.9299999999999999, 1.694, 0.4849999999999999, 0.9269999999999999, 1.855, 0.7999999999999998, 0.44199999999999995, 0.40600000000000014, 0.42500000000000004, 0.6880000000000002, 0.7549999999999999, -0.07700000000000007, 0.3250000000000002, 0.7349999999999999, 0.569, 0.33599999999999985, 0.879, 0.48999999999999977, 1.797, -0.07300000000000006, 0.7190000000000001, 0.3080000000000003, 0.42500000000000004, 0.20100000000000007, 0.1259999999999999, 0.43299999999999983, 0.3500000000000001, 0.8160000000000001, 0.7240000000000002, 0.2689999999999999, -0.17700000000000005, 0.42799999999999994, 0.9179999999999999, 0.6880000000000001, 0.7949999999999999, 0.2290000000000001, 0.42700000000000016, 0.30100000000000016, 0.44799999999999995, 0.381, -0.09699999999999998, 1.443, 0.8820000000000001, 0.2530000000000001, 1.865, -0.14900000000000002, 0.7749999999999999, 1.838, 0.3380000000000001, 0.919, 1.157, 0.938, 0.05800000000000005, 0.9280000000000002, 0.79, 0.33399999999999996, 0.7010000000000001, 0.492, -0.11699999999999999, 0.5960000000000001, 0.6840000000000002, 0.30699999999999994], "episode_lengths": [33, 92, 11, 25, 44, 174, 227, 31, 34, 121, 231, 22, 38, 14, 38, 20, 25, 84, 195, 232, 241, 110, 73, 48, 137, 20, 73, 28, 59, 107, 8, 85, 56, 188, 136, 37, 92, 56, 300, 94, 161, 300, 43, 63, 19, 29, 23, 97, 74, 24, 54, 80, 133, 200, 38, 155, 61, 173, 85, 58, 23, 244, 267, 20, 200, 56, 81, 222, 56, 23, 300, 97, 61, 83, 23, 62, 16, 38, 31, 172, 37, 75, 42, 47, 67, 50, 50, 25, 104, 19, 136, 23, 66, 53, 92, 151, 36, 125, 95, 59], "policy_red_0_reward": [0.901, 1.216, 0.966, 0.923, 1.365, 0.48, -0.529, 0.905, 1.396, 1.124, 0.7699999999999999, 0.499, 1.385, 0.953, 1.381, 1.4369999999999998, 0.923, 0.735, 0.8939999999999999, 0.776, 0.736, -0.5139999999999999, 1.271, 1.351, 1.071, 1.4369999999999998, 1.2759999999999998, -0.502, 1.318, 1.171, 0.976, 1.226, -0.505, 0.9129999999999999, 0.491, -0.507, 1.2149999999999999, 1.323, 0.473, 0.487, 1.004, 0.46699999999999997, 0.492, 1.309, 1.442, 1.411, 0.929, 1.1960000000000002, 1.2650000000000001, 0.9249999999999999, 1.3319999999999999, 1.2530000000000001, 1.085, 0.871, 1.381, 1.016, 0.494, 0.948, 1.234, 1.3210000000000002, 0.927, 0.733, 0.6629999999999999, 1.436, 0.875, 1.323, 1.242, 0.8059999999999999, 0.83, 1.429, 0.46299999999999997, -0.509, 1.3079999999999998, 1.24, -0.5039999999999999, 1.307, 1.45, -1.002, 0.907, 0.48, 1.3860000000000001, 1.2650000000000001, 0.497, 0.853, 1.289, 0.495, 0.846, 1.4220000000000002, -0.01800000000000001, 1.4409999999999998, 0.5770000000000001, 1.4300000000000002, 1.294, -0.505, 1.2149999999999999, 1.012, 0.89, 1.113, 1.201, 0.8099999999999999], "policy_blue_0_reward": [-1.006, -0.512, -0.5, -0.503, -1.002, 0.954, 0.7929999999999999, -1.002, -1.002, 0.483, -0.529, 1.428, -0.503, -0.5, -1.008, -0.504, -0.501, -0.509, -0.521, -0.553, -0.53, 1.149, -0.509, -0.5069999999999999, -0.515, -0.501, -0.512, 0.914, -0.505, -0.513, -1.0, -0.508, 0.821, -0.515, 1.077, 1.385, -0.512, -1.014, 0.45699999999999996, 1.2069999999999999, -0.519, 0.45999999999999996, 1.363, -0.509, -1.0, -1.005, -0.504, -0.508, -0.51, -1.002, -1.007, -0.518, -0.516, -0.535, -0.502, -0.526, 1.303, -1.021, -0.5149999999999999, -1.013, -0.502, -0.532, -0.537, -1.003, -0.5249999999999999, -0.5069999999999999, -0.5179999999999999, -0.537, -1.007, -1.001, 0.45499999999999996, 1.197, -0.513, -1.011, 0.931, -1.006, -1.002, 1.383, -1.004, 0.963, -0.504, -1.012, 1.3679999999999999, -1.002, -0.5139999999999999, 1.343, -0.508, -0.5029999999999999, 1.1749999999999998, -0.503, -0.519, -0.5019999999999999, -0.504, 0.839, -0.514, -0.52, -1.007, -0.517, -0.517, -0.503]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3603818505773757, "mean_inference_ms": 7.385452575839651, "mean_action_processing_ms": 0.3923961544621811, "mean_env_wait_ms": 0.5122678249991419, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1434992551803589, "StateBufferConnector_ms": 0.009418964385986328, "ViewRequirementAgentConnector_ms": 0.18610024452209473}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 125.88381935189433, "num_env_steps_trained_throughput_per_sec": 125.88381935189433, "timesteps_total": 152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 31766.681, "sample_time_ms": 4030.271, "learn_time_ms": 27705.871, "learn_throughput": 144.374, "synch_weights_time_ms": 29.007}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "episodes_total": 1173, "training_iteration": 38, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-16-41", "timestamp": 1694837801, "time_this_iter_s": 31.791505098342896, "time_total_s": 1167.4367105960846, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a1bf9a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1167.4367105960846, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 26.15434782608696, "ram_util_percent": 56.88913043478262}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.75, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.75, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.75, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5702671917465826, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.0774970406491775, "policy_loss": -0.11215635765596138, "vf_loss": 0.01584021776652662, "vf_explained_var": 0.5985252914950252, "kl": 0.01870086596723013, "entropy": 1.6627301041036844, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5598312259962162, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07549709183028123, "policy_loss": -0.11391721929685446, "vf_loss": 0.02130961540581969, "vf_explained_var": 0.6095401904235284, "kl": 0.019413895288039384, "entropy": 1.719532572478056, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000}, "sampler_results": {"episode_reward_max": 1.919, "episode_reward_min": -0.3979999999999999, "episode_reward_mean": 0.59816, "episode_len_mean": 86.91, "episode_media": {}, "episodes_this_iter": 46, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.45, "blue_0": 1.478}, "policy_reward_mean": {"red_0": 0.84295, "blue_0": -0.24478999999999998}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.75, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.75, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.75, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.42500000000000004, 0.6880000000000002, 0.7549999999999999, -0.07700000000000007, 0.3250000000000002, 0.7349999999999999, 0.569, 0.33599999999999985, 0.879, 0.48999999999999977, 1.797, -0.07300000000000006, 0.7190000000000001, 0.3080000000000003, 0.42500000000000004, 0.20100000000000007, 0.1259999999999999, 0.43299999999999983, 0.3500000000000001, 0.8160000000000001, 0.7240000000000002, 0.2689999999999999, -0.17700000000000005, 0.42799999999999994, 0.9179999999999999, 0.6880000000000001, 0.7949999999999999, 0.2290000000000001, 0.42700000000000016, 0.30100000000000016, 0.44799999999999995, 0.381, -0.09699999999999998, 1.443, 0.8820000000000001, 0.2530000000000001, 1.865, -0.14900000000000002, 0.7749999999999999, 1.838, 0.3380000000000001, 0.919, 1.157, 0.938, 0.05800000000000005, 0.9280000000000002, 0.79, 0.33399999999999996, 0.7010000000000001, 0.492, -0.11699999999999999, 0.5960000000000001, 0.6840000000000002, 0.30699999999999994, 0.11599999999999988, 0.44399999999999995, 0.2639999999999999, -0.10899999999999987, 0.42399999999999993, -0.3979999999999999, 0.357, 0.685, 0.3639999999999999, 0.6840000000000002, 0.8999999999999999, 0.681, 0.853, 1.4260000000000002, 0.3819999999999999, -0.31799999999999995, 0.9219999999999999, 1.4979999999999998, 0.484, 0.7969999999999999, 0.41800000000000015, 0.7769999999999999, 0.33699999999999997, 0.9329999999999999, 0.609, 0.32099999999999995, 0.238, 0.369, 0.15399999999999991, 0.29499999999999993, 0.2560000000000002, -0.05700000000000005, 1.771, 0.40600000000000014, 1.611, 0.42399999999999993, 1.919, 0.8089999999999999, 1.8439999999999999, 1.793, 0.877, 0.9180000000000001, 0.8860000000000001, 0.43799999999999994, -0.05700000000000005, 0.478], "episode_lengths": [23, 97, 74, 24, 54, 80, 133, 200, 38, 155, 61, 173, 85, 58, 23, 244, 267, 20, 200, 56, 81, 222, 56, 23, 300, 97, 61, 83, 23, 62, 16, 38, 31, 172, 37, 75, 42, 47, 67, 50, 50, 25, 104, 19, 136, 23, 66, 53, 92, 151, 36, 125, 95, 59, 273, 18, 221, 34, 24, 122, 44, 96, 42, 95, 30, 100, 45, 23, 192, 247, 300, 153, 156, 63, 25, 67, 51, 300, 119, 203, 80, 42, 109, 63, 72, 17, 70, 30, 119, 23, 26, 59, 48, 63, 39, 27, 35, 20, 17, 7], "policy_red_0_reward": [0.929, 1.1960000000000002, 1.2650000000000001, 0.9249999999999999, 1.3319999999999999, 1.2530000000000001, 1.085, 0.871, 1.381, 1.016, 0.494, 0.948, 1.234, 1.3210000000000002, 0.927, 0.733, 0.6629999999999999, 1.436, 0.875, 1.323, 1.242, 0.8059999999999999, 0.83, 1.429, 0.46299999999999997, -0.509, 1.3079999999999998, 1.24, -0.5039999999999999, 1.307, 1.45, -1.002, 0.907, 0.48, 1.3860000000000001, 1.2650000000000001, 0.497, 0.853, 1.289, 0.495, 0.846, 1.4220000000000002, -0.01800000000000001, 1.4409999999999998, 0.5770000000000001, 1.4300000000000002, 1.294, -0.505, 1.2149999999999999, 1.012, 0.89, 1.113, 1.201, 0.8099999999999999, 0.6529999999999999, 1.4449999999999998, -0.529, -1.003, -1.001, 0.622, 0.867, 1.197, 1.37, 1.203, 1.407, 1.192, 1.359, -0.002, 0.9009999999999999, 0.22799999999999998, 0.46199999999999997, 0.476, 1.016, 1.3039999999999998, 1.421, 1.29, 0.841, 0.46499999999999997, 1.131, -0.529, 1.248, 0.871, 1.162, 1.305, 1.2730000000000001, 0.944, 0.492, 0.91, 0.479, 1.427, 0.499, 1.3159999999999998, 0.492, 1.2999999999999998, 1.38, 1.419, 1.3900000000000001, 1.44, -1.005, -1.0], "policy_blue_0_reward": [-0.504, -0.508, -0.51, -1.002, -1.007, -0.518, -0.516, -0.535, -0.502, -0.526, 1.303, -1.021, -0.5149999999999999, -1.013, -0.502, -0.532, -0.537, -1.003, -0.5249999999999999, -0.5069999999999999, -0.5179999999999999, -0.537, -1.007, -1.001, 0.45499999999999996, 1.197, -0.513, -1.011, 0.931, -1.006, -1.002, 1.383, -1.004, 0.963, -0.504, -1.012, 1.3679999999999999, -1.002, -0.5139999999999999, 1.343, -0.508, -0.5029999999999999, 1.1749999999999998, -0.503, -0.519, -0.5019999999999999, -0.504, 0.839, -0.514, -0.52, -1.007, -0.517, -0.517, -0.503, -0.537, -1.001, 0.7929999999999999, 0.894, 1.4249999999999998, -1.0199999999999998, -0.51, -0.512, -1.006, -0.5189999999999999, -0.507, -0.511, -0.506, 1.428, -0.519, -0.5459999999999999, 0.45999999999999996, 1.0219999999999998, -0.532, -0.507, -1.003, -0.513, -0.504, 0.46799999999999997, -0.522, 0.85, -1.01, -0.502, -1.008, -1.01, -1.017, -1.001, 1.279, -0.504, 1.1320000000000001, -1.003, 1.42, -0.507, 1.3519999999999999, 0.493, -0.503, -0.501, -0.504, -1.002, 0.948, 1.478]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.360325235955209, "mean_inference_ms": 7.383552198874047, "mean_action_processing_ms": 0.391468773674813, "mean_env_wait_ms": 0.5127537036765911, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1434077024459839, "StateBufferConnector_ms": 0.009309768676757812, "ViewRequirementAgentConnector_ms": 0.1854327917098999}}, "episode_reward_max": 1.919, "episode_reward_min": -0.3979999999999999, "episode_reward_mean": 0.59816, "episode_len_mean": 86.91, "episodes_this_iter": 46, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.45, "blue_0": 1.478}, "policy_reward_mean": {"red_0": 0.84295, "blue_0": -0.24478999999999998}, "hist_stats": {"episode_reward": [0.42500000000000004, 0.6880000000000002, 0.7549999999999999, -0.07700000000000007, 0.3250000000000002, 0.7349999999999999, 0.569, 0.33599999999999985, 0.879, 0.48999999999999977, 1.797, -0.07300000000000006, 0.7190000000000001, 0.3080000000000003, 0.42500000000000004, 0.20100000000000007, 0.1259999999999999, 0.43299999999999983, 0.3500000000000001, 0.8160000000000001, 0.7240000000000002, 0.2689999999999999, -0.17700000000000005, 0.42799999999999994, 0.9179999999999999, 0.6880000000000001, 0.7949999999999999, 0.2290000000000001, 0.42700000000000016, 0.30100000000000016, 0.44799999999999995, 0.381, -0.09699999999999998, 1.443, 0.8820000000000001, 0.2530000000000001, 1.865, -0.14900000000000002, 0.7749999999999999, 1.838, 0.3380000000000001, 0.919, 1.157, 0.938, 0.05800000000000005, 0.9280000000000002, 0.79, 0.33399999999999996, 0.7010000000000001, 0.492, -0.11699999999999999, 0.5960000000000001, 0.6840000000000002, 0.30699999999999994, 0.11599999999999988, 0.44399999999999995, 0.2639999999999999, -0.10899999999999987, 0.42399999999999993, -0.3979999999999999, 0.357, 0.685, 0.3639999999999999, 0.6840000000000002, 0.8999999999999999, 0.681, 0.853, 1.4260000000000002, 0.3819999999999999, -0.31799999999999995, 0.9219999999999999, 1.4979999999999998, 0.484, 0.7969999999999999, 0.41800000000000015, 0.7769999999999999, 0.33699999999999997, 0.9329999999999999, 0.609, 0.32099999999999995, 0.238, 0.369, 0.15399999999999991, 0.29499999999999993, 0.2560000000000002, -0.05700000000000005, 1.771, 0.40600000000000014, 1.611, 0.42399999999999993, 1.919, 0.8089999999999999, 1.8439999999999999, 1.793, 0.877, 0.9180000000000001, 0.8860000000000001, 0.43799999999999994, -0.05700000000000005, 0.478], "episode_lengths": [23, 97, 74, 24, 54, 80, 133, 200, 38, 155, 61, 173, 85, 58, 23, 244, 267, 20, 200, 56, 81, 222, 56, 23, 300, 97, 61, 83, 23, 62, 16, 38, 31, 172, 37, 75, 42, 47, 67, 50, 50, 25, 104, 19, 136, 23, 66, 53, 92, 151, 36, 125, 95, 59, 273, 18, 221, 34, 24, 122, 44, 96, 42, 95, 30, 100, 45, 23, 192, 247, 300, 153, 156, 63, 25, 67, 51, 300, 119, 203, 80, 42, 109, 63, 72, 17, 70, 30, 119, 23, 26, 59, 48, 63, 39, 27, 35, 20, 17, 7], "policy_red_0_reward": [0.929, 1.1960000000000002, 1.2650000000000001, 0.9249999999999999, 1.3319999999999999, 1.2530000000000001, 1.085, 0.871, 1.381, 1.016, 0.494, 0.948, 1.234, 1.3210000000000002, 0.927, 0.733, 0.6629999999999999, 1.436, 0.875, 1.323, 1.242, 0.8059999999999999, 0.83, 1.429, 0.46299999999999997, -0.509, 1.3079999999999998, 1.24, -0.5039999999999999, 1.307, 1.45, -1.002, 0.907, 0.48, 1.3860000000000001, 1.2650000000000001, 0.497, 0.853, 1.289, 0.495, 0.846, 1.4220000000000002, -0.01800000000000001, 1.4409999999999998, 0.5770000000000001, 1.4300000000000002, 1.294, -0.505, 1.2149999999999999, 1.012, 0.89, 1.113, 1.201, 0.8099999999999999, 0.6529999999999999, 1.4449999999999998, -0.529, -1.003, -1.001, 0.622, 0.867, 1.197, 1.37, 1.203, 1.407, 1.192, 1.359, -0.002, 0.9009999999999999, 0.22799999999999998, 0.46199999999999997, 0.476, 1.016, 1.3039999999999998, 1.421, 1.29, 0.841, 0.46499999999999997, 1.131, -0.529, 1.248, 0.871, 1.162, 1.305, 1.2730000000000001, 0.944, 0.492, 0.91, 0.479, 1.427, 0.499, 1.3159999999999998, 0.492, 1.2999999999999998, 1.38, 1.419, 1.3900000000000001, 1.44, -1.005, -1.0], "policy_blue_0_reward": [-0.504, -0.508, -0.51, -1.002, -1.007, -0.518, -0.516, -0.535, -0.502, -0.526, 1.303, -1.021, -0.5149999999999999, -1.013, -0.502, -0.532, -0.537, -1.003, -0.5249999999999999, -0.5069999999999999, -0.5179999999999999, -0.537, -1.007, -1.001, 0.45499999999999996, 1.197, -0.513, -1.011, 0.931, -1.006, -1.002, 1.383, -1.004, 0.963, -0.504, -1.012, 1.3679999999999999, -1.002, -0.5139999999999999, 1.343, -0.508, -0.5029999999999999, 1.1749999999999998, -0.503, -0.519, -0.5019999999999999, -0.504, 0.839, -0.514, -0.52, -1.007, -0.517, -0.517, -0.503, -0.537, -1.001, 0.7929999999999999, 0.894, 1.4249999999999998, -1.0199999999999998, -0.51, -0.512, -1.006, -0.5189999999999999, -0.507, -0.511, -0.506, 1.428, -0.519, -0.5459999999999999, 0.45999999999999996, 1.0219999999999998, -0.532, -0.507, -1.003, -0.513, -0.504, 0.46799999999999997, -0.522, 0.85, -1.01, -0.502, -1.008, -1.01, -1.017, -1.001, 1.279, -0.504, 1.1320000000000001, -1.003, 1.42, -0.507, 1.3519999999999999, 0.493, -0.503, -0.501, -0.504, -1.002, 0.948, 1.478]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.360325235955209, "mean_inference_ms": 7.383552198874047, "mean_action_processing_ms": 0.391468773674813, "mean_env_wait_ms": 0.5127537036765911, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1434077024459839, "StateBufferConnector_ms": 0.009309768676757812, "ViewRequirementAgentConnector_ms": 0.1854327917098999}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.62788922181628, "num_env_steps_trained_throughput_per_sec": 128.62788922181628, "timesteps_total": 156000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 312000, "timers": {"training_iteration_time_ms": 31788.897, "sample_time_ms": 4027.478, "learn_time_ms": 27732.974, "learn_throughput": 144.233, "synch_weights_time_ms": 26.898}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000}, "done": false, "episodes_total": 1219, "training_iteration": 39, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-17-13", "timestamp": 1694837833, "time_this_iter_s": 31.113340854644775, "time_total_s": 1198.5500514507294, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80eda950>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1198.5500514507294, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 24.624444444444453, "ram_util_percent": 56.86888888888889}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.02, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.69, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.69, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.69, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5501922170942029, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08133350549020785, "policy_loss": -0.11368346255815899, "vf_loss": 0.01575619247426706, "vf_explained_var": 0.5895135980720322, "kl": 0.017207544406966566, "entropy": 1.6620970415572325, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 37920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5460543860370914, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08230371963679015, "policy_loss": -0.118207798510169, "vf_loss": 0.022517695344868117, "vf_explained_var": 0.5967813728998105, "kl": 0.017356454533133014, "entropy": 1.7148825501402218, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 37920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "sampler_results": {"episode_reward_max": 1.93, "episode_reward_min": -0.3979999999999999, "episode_reward_mean": 0.6140599999999999, "episode_len_mean": 85.0, "episode_media": {}, "episodes_this_iter": 46, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.0199999999999998}, "policy_reward_max": {"red_0": 1.4449999999999998, "blue_0": 1.478}, "policy_reward_mean": {"red_0": 0.7803, "blue_0": -0.16624000000000003}, "custom_metrics": {"red_0/door_open_done_mean": 0.02, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.69, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.69, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.69, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.79, 0.33399999999999996, 0.7010000000000001, 0.492, -0.11699999999999999, 0.5960000000000001, 0.6840000000000002, 0.30699999999999994, 0.11599999999999988, 0.44399999999999995, 0.2639999999999999, -0.10899999999999987, 0.42399999999999993, -0.3979999999999999, 0.357, 0.685, 0.3639999999999999, 0.6840000000000002, 0.8999999999999999, 0.681, 0.853, 1.4260000000000002, 0.3819999999999999, -0.31799999999999995, 0.9219999999999999, 1.4979999999999998, 0.484, 0.7969999999999999, 0.41800000000000015, 0.7769999999999999, 0.33699999999999997, 0.9329999999999999, 0.609, 0.32099999999999995, 0.238, 0.369, 0.15399999999999991, 0.29499999999999993, 0.2560000000000002, -0.05700000000000005, 1.771, 0.40600000000000014, 1.611, 0.42399999999999993, 1.919, 0.8089999999999999, 1.8439999999999999, 1.793, 0.877, 0.9180000000000001, 0.8860000000000001, 0.43799999999999994, -0.05700000000000005, 0.478, 0.29000000000000004, 0.33000000000000007, 0.4159999999999999, 0.42500000000000004, 1.697, 1.93, 1.482, 0.357, 0.8640000000000001, 0.383, 0.4079999999999999, 0.262, -0.11199999999999988, 1.8399999999999999, 0.20300000000000007, -0.242, -0.052000000000000046, 0.8620000000000001, 0.9390000000000001, 0.34299999999999997, 0.369, 0.867, 0.8839999999999999, 0.44399999999999995, 0.9309999999999999, 1.6019999999999999, -0.08699999999999997, 0.7609999999999999, 0.506, -0.07999999999999996, 0.706, 0.835, -0.127, 1.322, 0.7530000000000001, 0.5089999999999999, 0.2410000000000001, 0.1499999999999999, 0.9149999999999999, 0.17899999999999983, 1.476, 0.913, -0.06999999999999995, 0.4910000000000001, 0.8200000000000001, 0.46099999999999997], "episode_lengths": [66, 53, 92, 151, 36, 125, 95, 59, 273, 18, 221, 34, 24, 122, 44, 96, 42, 95, 30, 100, 45, 23, 192, 247, 300, 153, 156, 63, 25, 67, 51, 300, 119, 203, 80, 42, 109, 63, 72, 17, 70, 30, 119, 23, 26, 59, 48, 63, 39, 27, 35, 20, 17, 7, 217, 51, 26, 23, 93, 22, 160, 45, 42, 36, 29, 73, 33, 49, 92, 75, 17, 42, 20, 49, 41, 41, 35, 17, 300, 123, 26, 73, 148, 25, 91, 51, 41, 55, 75, 151, 79, 259, 300, 252, 163, 27, 21, 156, 58, 12], "policy_red_0_reward": [1.294, -0.505, 1.2149999999999999, 1.012, 0.89, 1.113, 1.201, 0.8099999999999999, 0.6529999999999999, 1.4449999999999998, -0.529, -1.003, -1.001, 0.622, 0.867, 1.197, 1.37, 1.203, 1.407, 1.192, 1.359, -0.002, 0.9009999999999999, 0.22799999999999998, 0.46199999999999997, 0.476, 1.016, 1.3039999999999998, 1.421, 1.29, 0.841, 0.46499999999999997, 1.131, -0.529, 1.248, 0.871, 1.162, 1.305, 1.2730000000000001, 0.944, 0.492, 0.91, 0.479, 1.427, 0.499, 1.3159999999999998, 0.492, 1.2999999999999998, 1.38, 1.419, 1.3900000000000001, 1.44, -1.005, -1.0, 0.824, 0.839, 1.42, 0.929, 0.488, 0.499, 1.004, 1.361, 1.371, 1.389, 1.412, 1.273, 0.896, 0.497, 1.2149999999999999, 0.768, 0.949, -0.5069999999999999, 1.439, -0.503, 0.871, 1.374, 1.389, 0.947, 0.45899999999999996, 0.486, 0.916, -0.51, 1.032, 0.925, 1.218, -0.508, 0.875, -0.010000000000000002, 1.268, 1.029, 1.249, -0.537, 0.45899999999999996, 0.718, 0.482, 1.417, 0.9329999999999999, 1.0070000000000001, 1.323, -0.503], "policy_blue_0_reward": [-0.504, 0.839, -0.514, -0.52, -1.007, -0.517, -0.517, -0.503, -0.537, -1.001, 0.7929999999999999, 0.894, 1.4249999999999998, -1.0199999999999998, -0.51, -0.512, -1.006, -0.5189999999999999, -0.507, -0.511, -0.506, 1.428, -0.519, -0.5459999999999999, 0.45999999999999996, 1.0219999999999998, -0.532, -0.507, -1.003, -0.513, -0.504, 0.46799999999999997, -0.522, 0.85, -1.01, -0.502, -1.008, -1.01, -1.017, -1.001, 1.279, -0.504, 1.1320000000000001, -1.003, 1.42, -0.507, 1.3519999999999999, 0.493, -0.503, -0.501, -0.504, -1.002, 0.948, 1.478, -0.534, -0.509, -1.004, -0.504, 1.209, 1.431, 0.478, -1.004, -0.5069999999999999, -1.006, -1.004, -1.011, -1.0079999999999998, 1.343, -1.0119999999999998, -1.01, -1.001, 1.369, -0.5, 0.846, -0.502, -0.5069999999999999, -0.505, -0.503, 0.472, 1.116, -1.003, 1.271, -0.526, -1.005, -0.5119999999999999, 1.343, -1.002, 1.3319999999999999, -0.515, -0.52, -1.008, 0.6869999999999999, 0.45599999999999996, -0.539, 0.994, -0.504, -1.003, -0.516, -0.503, 0.964]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3583382365541212, "mean_inference_ms": 7.380546988269527, "mean_action_processing_ms": 0.3931174975236471, "mean_env_wait_ms": 0.5115851716250904, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14347565174102783, "StateBufferConnector_ms": 0.00932919979095459, "ViewRequirementAgentConnector_ms": 0.18612194061279297}}, "episode_reward_max": 1.93, "episode_reward_min": -0.3979999999999999, "episode_reward_mean": 0.6140599999999999, "episode_len_mean": 85.0, "episodes_this_iter": 46, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.0199999999999998}, "policy_reward_max": {"red_0": 1.4449999999999998, "blue_0": 1.478}, "policy_reward_mean": {"red_0": 0.7803, "blue_0": -0.16624000000000003}, "hist_stats": {"episode_reward": [0.79, 0.33399999999999996, 0.7010000000000001, 0.492, -0.11699999999999999, 0.5960000000000001, 0.6840000000000002, 0.30699999999999994, 0.11599999999999988, 0.44399999999999995, 0.2639999999999999, -0.10899999999999987, 0.42399999999999993, -0.3979999999999999, 0.357, 0.685, 0.3639999999999999, 0.6840000000000002, 0.8999999999999999, 0.681, 0.853, 1.4260000000000002, 0.3819999999999999, -0.31799999999999995, 0.9219999999999999, 1.4979999999999998, 0.484, 0.7969999999999999, 0.41800000000000015, 0.7769999999999999, 0.33699999999999997, 0.9329999999999999, 0.609, 0.32099999999999995, 0.238, 0.369, 0.15399999999999991, 0.29499999999999993, 0.2560000000000002, -0.05700000000000005, 1.771, 0.40600000000000014, 1.611, 0.42399999999999993, 1.919, 0.8089999999999999, 1.8439999999999999, 1.793, 0.877, 0.9180000000000001, 0.8860000000000001, 0.43799999999999994, -0.05700000000000005, 0.478, 0.29000000000000004, 0.33000000000000007, 0.4159999999999999, 0.42500000000000004, 1.697, 1.93, 1.482, 0.357, 0.8640000000000001, 0.383, 0.4079999999999999, 0.262, -0.11199999999999988, 1.8399999999999999, 0.20300000000000007, -0.242, -0.052000000000000046, 0.8620000000000001, 0.9390000000000001, 0.34299999999999997, 0.369, 0.867, 0.8839999999999999, 0.44399999999999995, 0.9309999999999999, 1.6019999999999999, -0.08699999999999997, 0.7609999999999999, 0.506, -0.07999999999999996, 0.706, 0.835, -0.127, 1.322, 0.7530000000000001, 0.5089999999999999, 0.2410000000000001, 0.1499999999999999, 0.9149999999999999, 0.17899999999999983, 1.476, 0.913, -0.06999999999999995, 0.4910000000000001, 0.8200000000000001, 0.46099999999999997], "episode_lengths": [66, 53, 92, 151, 36, 125, 95, 59, 273, 18, 221, 34, 24, 122, 44, 96, 42, 95, 30, 100, 45, 23, 192, 247, 300, 153, 156, 63, 25, 67, 51, 300, 119, 203, 80, 42, 109, 63, 72, 17, 70, 30, 119, 23, 26, 59, 48, 63, 39, 27, 35, 20, 17, 7, 217, 51, 26, 23, 93, 22, 160, 45, 42, 36, 29, 73, 33, 49, 92, 75, 17, 42, 20, 49, 41, 41, 35, 17, 300, 123, 26, 73, 148, 25, 91, 51, 41, 55, 75, 151, 79, 259, 300, 252, 163, 27, 21, 156, 58, 12], "policy_red_0_reward": [1.294, -0.505, 1.2149999999999999, 1.012, 0.89, 1.113, 1.201, 0.8099999999999999, 0.6529999999999999, 1.4449999999999998, -0.529, -1.003, -1.001, 0.622, 0.867, 1.197, 1.37, 1.203, 1.407, 1.192, 1.359, -0.002, 0.9009999999999999, 0.22799999999999998, 0.46199999999999997, 0.476, 1.016, 1.3039999999999998, 1.421, 1.29, 0.841, 0.46499999999999997, 1.131, -0.529, 1.248, 0.871, 1.162, 1.305, 1.2730000000000001, 0.944, 0.492, 0.91, 0.479, 1.427, 0.499, 1.3159999999999998, 0.492, 1.2999999999999998, 1.38, 1.419, 1.3900000000000001, 1.44, -1.005, -1.0, 0.824, 0.839, 1.42, 0.929, 0.488, 0.499, 1.004, 1.361, 1.371, 1.389, 1.412, 1.273, 0.896, 0.497, 1.2149999999999999, 0.768, 0.949, -0.5069999999999999, 1.439, -0.503, 0.871, 1.374, 1.389, 0.947, 0.45899999999999996, 0.486, 0.916, -0.51, 1.032, 0.925, 1.218, -0.508, 0.875, -0.010000000000000002, 1.268, 1.029, 1.249, -0.537, 0.45899999999999996, 0.718, 0.482, 1.417, 0.9329999999999999, 1.0070000000000001, 1.323, -0.503], "policy_blue_0_reward": [-0.504, 0.839, -0.514, -0.52, -1.007, -0.517, -0.517, -0.503, -0.537, -1.001, 0.7929999999999999, 0.894, 1.4249999999999998, -1.0199999999999998, -0.51, -0.512, -1.006, -0.5189999999999999, -0.507, -0.511, -0.506, 1.428, -0.519, -0.5459999999999999, 0.45999999999999996, 1.0219999999999998, -0.532, -0.507, -1.003, -0.513, -0.504, 0.46799999999999997, -0.522, 0.85, -1.01, -0.502, -1.008, -1.01, -1.017, -1.001, 1.279, -0.504, 1.1320000000000001, -1.003, 1.42, -0.507, 1.3519999999999999, 0.493, -0.503, -0.501, -0.504, -1.002, 0.948, 1.478, -0.534, -0.509, -1.004, -0.504, 1.209, 1.431, 0.478, -1.004, -0.5069999999999999, -1.006, -1.004, -1.011, -1.0079999999999998, 1.343, -1.0119999999999998, -1.01, -1.001, 1.369, -0.5, 0.846, -0.502, -0.5069999999999999, -0.505, -0.503, 0.472, 1.116, -1.003, 1.271, -0.526, -1.005, -0.5119999999999999, 1.343, -1.002, 1.3319999999999999, -0.515, -0.52, -1.008, 0.6869999999999999, 0.45599999999999996, -0.539, 0.994, -0.504, -1.003, -0.516, -0.503, 0.964]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3583382365541212, "mean_inference_ms": 7.380546988269527, "mean_action_processing_ms": 0.3931174975236471, "mean_env_wait_ms": 0.5115851716250904, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14347565174102783, "StateBufferConnector_ms": 0.00932919979095459, "ViewRequirementAgentConnector_ms": 0.18612194061279297}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 122.8432373017939, "num_env_steps_trained_throughput_per_sec": 122.8432373017939, "timesteps_total": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 31896.608, "sample_time_ms": 3982.527, "learn_time_ms": 27885.678, "learn_throughput": 143.443, "synch_weights_time_ms": 26.889}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "episodes_total": 1265, "training_iteration": 40, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-17-46", "timestamp": 1694837866, "time_this_iter_s": 32.57860207557678, "time_total_s": 1231.1286535263062, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80edac20>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1231.1286535263062, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 26.540425531914885, "ram_util_percent": 56.85106382978724}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.02, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.69, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.69, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.69, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5859205362387001, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.0797329501651499, "policy_loss": -0.11542092882203482, "vf_loss": 0.01822433313500369, "vf_explained_var": 0.6121382086227337, "kl": 0.01857592305089304, "entropy": 1.6363699018955231, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 38880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5661375092342495, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08113537820221002, "policy_loss": -0.11832308273054272, "vf_loss": 0.025359915209022196, "vf_explained_var": 0.6509842503815889, "kl": 0.017251780890349146, "entropy": 1.6933943847815196, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 38880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000}, "sampler_results": {"episode_reward_max": 1.93, "episode_reward_min": -0.2469999999999999, "episode_reward_mean": 0.68249, "episode_len_mean": 75.32, "episode_media": {}, "episodes_this_iter": 59, "policy_reward_min": {"red_0": -1.0119999999999998, "blue_0": -1.0119999999999998}, "policy_reward_max": {"red_0": 1.468, "blue_0": 1.431}, "policy_reward_mean": {"red_0": 0.8362599999999999, "blue_0": -0.15377000000000002}, "custom_metrics": {"red_0/door_open_done_mean": 0.02, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.69, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.69, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.69, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.93, 1.482, 0.357, 0.8640000000000001, 0.383, 0.4079999999999999, 0.262, -0.11199999999999988, 1.8399999999999999, 0.20300000000000007, -0.242, -0.052000000000000046, 0.8620000000000001, 0.9390000000000001, 0.34299999999999997, 0.369, 0.867, 0.8839999999999999, 0.44399999999999995, 0.9309999999999999, 1.6019999999999999, -0.08699999999999997, 0.7609999999999999, 0.506, -0.07999999999999996, 0.706, 0.835, -0.127, 1.322, 0.7530000000000001, 0.5089999999999999, 0.2410000000000001, 0.1499999999999999, 0.9149999999999999, 0.17899999999999983, 1.476, 0.913, -0.06999999999999995, 0.4910000000000001, 0.8200000000000001, 0.46099999999999997, 0.21399999999999997, 0.358, 0.349, 0.33999999999999986, -0.038000000000000034, 1.553, 0.46199999999999997, 1.8199999999999998, 0.372, 1.653, 0.45199999999999996, 0.9239999999999999, 1.863, 1.7810000000000001, 0.8999999999999999, 0.7410000000000001, 0.3460000000000001, 0.8119999999999998, 0.7689999999999999, 0.8980000000000001, 0.968, 0.44199999999999995, -0.10199999999999998, 0.04499999999999993, 0.9199999999999999, 0.825, 0.696, 0.8199999999999998, -0.1339999999999999, 0.615, 0.43300000000000005, 1.854, -0.2469999999999999, -0.07000000000000006, 0.669, 0.605, 0.33999999999999986, 0.581, 0.738, 0.7650000000000001, -0.051000000000000045, 0.45100000000000007, 0.33000000000000007, 0.8090000000000002, 0.685, 1.765, 0.69, 0.381, 1.8519999999999999, 1.9209999999999998, 1.589, 1.861, -0.11299999999999999, 0.726, 0.2919999999999998, 0.8540000000000001, 1.873, -0.08299999999999996, -0.15300000000000002], "episode_lengths": [22, 160, 45, 42, 36, 29, 73, 33, 49, 92, 75, 17, 42, 20, 49, 41, 41, 35, 17, 300, 123, 26, 73, 148, 25, 91, 51, 41, 55, 75, 151, 79, 259, 300, 252, 163, 27, 21, 156, 58, 12, 235, 44, 48, 50, 12, 134, 12, 56, 39, 108, 15, 300, 42, 68, 31, 77, 47, 56, 73, 33, 10, 174, 33, 141, 25, 55, 96, 55, 43, 117, 20, 45, 76, 22, 100, 122, 50, 128, 81, 71, 16, 16, 52, 56, 99, 73, 97, 36, 47, 24, 129, 44, 34, 83, 216, 46, 40, 26, 50], "policy_red_0_reward": [0.499, 1.004, 1.361, 1.371, 1.389, 1.412, 1.273, 0.896, 0.497, 1.2149999999999999, 0.768, 0.949, -0.5069999999999999, 1.439, -0.503, 0.871, 1.374, 1.389, 0.947, 0.45899999999999996, 0.486, 0.916, -0.51, 1.032, 0.925, 1.218, -0.508, 0.875, -0.010000000000000002, 1.268, 1.029, 1.249, -0.537, 0.45899999999999996, 0.718, 0.482, 1.417, 0.9329999999999999, 1.0070000000000001, 1.323, -0.503, 0.766, -1.005, 1.35, 1.3479999999999999, 0.963, 0.482, 0.964, 0.493, 0.877, 0.492, 1.455, 0.45999999999999996, 0.494, 0.494, 1.403, 1.266, 0.851, 1.3239999999999998, 1.2759999999999998, 1.4, 1.468, 0.956, 0.899, 0.564, 1.421, 1.331, 1.204, 1.33, -1.003, 1.138, 1.438, 0.493, -1.0119999999999998, 0.9329999999999999, 1.1829999999999998, 1.121, 1.346, -0.515, 1.251, 1.278, 0.952, 1.452, 1.337, 1.326, 1.194, 0.494, 1.199, 0.888, 0.498, 0.495, 0.485, 0.496, 0.891, 1.248, 0.818, 1.359, 1.3780000000000001, 0.919, 0.848], "policy_blue_0_reward": [1.431, 0.478, -1.004, -0.5069999999999999, -1.006, -1.004, -1.011, -1.0079999999999998, 1.343, -1.0119999999999998, -1.01, -1.001, 1.369, -0.5, 0.846, -0.502, -0.5069999999999999, -0.505, -0.503, 0.472, 1.116, -1.003, 1.271, -0.526, -1.005, -0.5119999999999999, 1.343, -1.002, 1.3319999999999999, -0.515, -0.52, -1.008, 0.6869999999999999, 0.45599999999999996, -0.539, 0.994, -0.504, -1.003, -0.516, -0.503, 0.964, -0.552, 1.363, -1.001, -1.008, -1.001, 1.071, -0.502, 1.327, -0.505, 1.161, -1.003, 0.46399999999999997, 1.369, 1.287, -0.503, -0.525, -0.505, -0.512, -0.507, -0.502, -0.5, -0.514, -1.001, -0.519, -0.501, -0.506, -0.508, -0.51, 0.869, -0.523, -1.005, 1.361, 0.765, -1.003, -0.514, -0.516, -1.006, 1.096, -0.513, -0.513, -1.003, -1.001, -1.007, -0.5169999999999999, -0.509, 1.271, -0.509, -0.507, 1.354, 1.426, 1.104, 1.365, -1.004, -0.522, -0.526, -0.505, 0.495, -1.002, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3581303736800026, "mean_inference_ms": 7.390223378183171, "mean_action_processing_ms": 0.3927945687812779, "mean_env_wait_ms": 0.511231372384691, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14408862590789795, "StateBufferConnector_ms": 0.011092543601989746, "ViewRequirementAgentConnector_ms": 0.2049621343612671}}, "episode_reward_max": 1.93, "episode_reward_min": -0.2469999999999999, "episode_reward_mean": 0.68249, "episode_len_mean": 75.32, "episodes_this_iter": 59, "policy_reward_min": {"red_0": -1.0119999999999998, "blue_0": -1.0119999999999998}, "policy_reward_max": {"red_0": 1.468, "blue_0": 1.431}, "policy_reward_mean": {"red_0": 0.8362599999999999, "blue_0": -0.15377000000000002}, "hist_stats": {"episode_reward": [1.93, 1.482, 0.357, 0.8640000000000001, 0.383, 0.4079999999999999, 0.262, -0.11199999999999988, 1.8399999999999999, 0.20300000000000007, -0.242, -0.052000000000000046, 0.8620000000000001, 0.9390000000000001, 0.34299999999999997, 0.369, 0.867, 0.8839999999999999, 0.44399999999999995, 0.9309999999999999, 1.6019999999999999, -0.08699999999999997, 0.7609999999999999, 0.506, -0.07999999999999996, 0.706, 0.835, -0.127, 1.322, 0.7530000000000001, 0.5089999999999999, 0.2410000000000001, 0.1499999999999999, 0.9149999999999999, 0.17899999999999983, 1.476, 0.913, -0.06999999999999995, 0.4910000000000001, 0.8200000000000001, 0.46099999999999997, 0.21399999999999997, 0.358, 0.349, 0.33999999999999986, -0.038000000000000034, 1.553, 0.46199999999999997, 1.8199999999999998, 0.372, 1.653, 0.45199999999999996, 0.9239999999999999, 1.863, 1.7810000000000001, 0.8999999999999999, 0.7410000000000001, 0.3460000000000001, 0.8119999999999998, 0.7689999999999999, 0.8980000000000001, 0.968, 0.44199999999999995, -0.10199999999999998, 0.04499999999999993, 0.9199999999999999, 0.825, 0.696, 0.8199999999999998, -0.1339999999999999, 0.615, 0.43300000000000005, 1.854, -0.2469999999999999, -0.07000000000000006, 0.669, 0.605, 0.33999999999999986, 0.581, 0.738, 0.7650000000000001, -0.051000000000000045, 0.45100000000000007, 0.33000000000000007, 0.8090000000000002, 0.685, 1.765, 0.69, 0.381, 1.8519999999999999, 1.9209999999999998, 1.589, 1.861, -0.11299999999999999, 0.726, 0.2919999999999998, 0.8540000000000001, 1.873, -0.08299999999999996, -0.15300000000000002], "episode_lengths": [22, 160, 45, 42, 36, 29, 73, 33, 49, 92, 75, 17, 42, 20, 49, 41, 41, 35, 17, 300, 123, 26, 73, 148, 25, 91, 51, 41, 55, 75, 151, 79, 259, 300, 252, 163, 27, 21, 156, 58, 12, 235, 44, 48, 50, 12, 134, 12, 56, 39, 108, 15, 300, 42, 68, 31, 77, 47, 56, 73, 33, 10, 174, 33, 141, 25, 55, 96, 55, 43, 117, 20, 45, 76, 22, 100, 122, 50, 128, 81, 71, 16, 16, 52, 56, 99, 73, 97, 36, 47, 24, 129, 44, 34, 83, 216, 46, 40, 26, 50], "policy_red_0_reward": [0.499, 1.004, 1.361, 1.371, 1.389, 1.412, 1.273, 0.896, 0.497, 1.2149999999999999, 0.768, 0.949, -0.5069999999999999, 1.439, -0.503, 0.871, 1.374, 1.389, 0.947, 0.45899999999999996, 0.486, 0.916, -0.51, 1.032, 0.925, 1.218, -0.508, 0.875, -0.010000000000000002, 1.268, 1.029, 1.249, -0.537, 0.45899999999999996, 0.718, 0.482, 1.417, 0.9329999999999999, 1.0070000000000001, 1.323, -0.503, 0.766, -1.005, 1.35, 1.3479999999999999, 0.963, 0.482, 0.964, 0.493, 0.877, 0.492, 1.455, 0.45999999999999996, 0.494, 0.494, 1.403, 1.266, 0.851, 1.3239999999999998, 1.2759999999999998, 1.4, 1.468, 0.956, 0.899, 0.564, 1.421, 1.331, 1.204, 1.33, -1.003, 1.138, 1.438, 0.493, -1.0119999999999998, 0.9329999999999999, 1.1829999999999998, 1.121, 1.346, -0.515, 1.251, 1.278, 0.952, 1.452, 1.337, 1.326, 1.194, 0.494, 1.199, 0.888, 0.498, 0.495, 0.485, 0.496, 0.891, 1.248, 0.818, 1.359, 1.3780000000000001, 0.919, 0.848], "policy_blue_0_reward": [1.431, 0.478, -1.004, -0.5069999999999999, -1.006, -1.004, -1.011, -1.0079999999999998, 1.343, -1.0119999999999998, -1.01, -1.001, 1.369, -0.5, 0.846, -0.502, -0.5069999999999999, -0.505, -0.503, 0.472, 1.116, -1.003, 1.271, -0.526, -1.005, -0.5119999999999999, 1.343, -1.002, 1.3319999999999999, -0.515, -0.52, -1.008, 0.6869999999999999, 0.45599999999999996, -0.539, 0.994, -0.504, -1.003, -0.516, -0.503, 0.964, -0.552, 1.363, -1.001, -1.008, -1.001, 1.071, -0.502, 1.327, -0.505, 1.161, -1.003, 0.46399999999999997, 1.369, 1.287, -0.503, -0.525, -0.505, -0.512, -0.507, -0.502, -0.5, -0.514, -1.001, -0.519, -0.501, -0.506, -0.508, -0.51, 0.869, -0.523, -1.005, 1.361, 0.765, -1.003, -0.514, -0.516, -1.006, 1.096, -0.513, -0.513, -1.003, -1.001, -1.007, -0.5169999999999999, -0.509, 1.271, -0.509, -0.507, 1.354, 1.426, 1.104, 1.365, -1.004, -0.522, -0.526, -0.505, 0.495, -1.002, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3581303736800026, "mean_inference_ms": 7.390223378183171, "mean_action_processing_ms": 0.3927945687812779, "mean_env_wait_ms": 0.511231372384691, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14408862590789795, "StateBufferConnector_ms": 0.011092543601989746, "ViewRequirementAgentConnector_ms": 0.2049621343612671}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 108.42385297674414, "num_env_steps_trained_throughput_per_sec": 108.42385297674414, "timesteps_total": 164000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 328000, "timers": {"training_iteration_time_ms": 32207.258, "sample_time_ms": 4017.762, "learn_time_ms": 28160.911, "learn_throughput": 142.041, "synch_weights_time_ms": 27.058}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000}, "done": false, "episodes_total": 1324, "training_iteration": 41, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-18-24", "timestamp": 1694837904, "time_this_iter_s": 36.910560131073, "time_total_s": 1268.0392136573792, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb72349630>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1268.0392136573792, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 32.45925925925926, "ram_util_percent": 56.946296296296296}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.07, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.67, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.67, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.15, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.67, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5775533793494105, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07888546590305244, "policy_loss": -0.1143706517163082, "vf_loss": 0.016301745043407815, "vf_explained_var": 0.612399556239446, "kl": 0.01906951823862073, "entropy": 1.6275172730286915, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 39840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5629548461486896, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07871511459816247, "policy_loss": -0.11481111278941777, "vf_loss": 0.02349352550615246, "vf_explained_var": 0.6136236408725381, "kl": 0.01715295389163355, "entropy": 1.701812118664384, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 39840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "sampler_results": {"episode_reward_max": 1.9209999999999998, "episode_reward_min": -0.2469999999999999, "episode_reward_mean": 0.7535900000000001, "episode_len_mean": 77.08, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"red_0": -1.0119999999999998, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.468, "blue_0": 1.46}, "policy_reward_mean": {"red_0": 0.8644700000000001, "blue_0": -0.11087999999999998}, "custom_metrics": {"red_0/door_open_done_mean": 0.07, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.67, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.67, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.15, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.67, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.45199999999999996, 0.9239999999999999, 1.863, 1.7810000000000001, 0.8999999999999999, 0.7410000000000001, 0.3460000000000001, 0.8119999999999998, 0.7689999999999999, 0.8980000000000001, 0.968, 0.44199999999999995, -0.10199999999999998, 0.04499999999999993, 0.9199999999999999, 0.825, 0.696, 0.8199999999999998, -0.1339999999999999, 0.615, 0.43300000000000005, 1.854, -0.2469999999999999, -0.07000000000000006, 0.669, 0.605, 0.33999999999999986, 0.581, 0.738, 0.7650000000000001, -0.051000000000000045, 0.45100000000000007, 0.33000000000000007, 0.8090000000000002, 0.685, 1.765, 0.69, 0.381, 1.8519999999999999, 1.9209999999999998, 1.589, 1.861, -0.11299999999999999, 0.726, 0.2919999999999998, 0.8540000000000001, 1.873, -0.08299999999999996, -0.15300000000000002, -0.135, -0.14, 0.40200000000000014, 1.306, 0.052000000000000046, 0.31899999999999995, 0.43799999999999994, 0.44099999999999984, 0.869, 1.626, 0.878, -0.07600000000000007, 0.6629999999999998, 1.38, 0.6459999999999999, 0.5329999999999999, 0.957, 0.776, 1.901, 0.3680000000000001, -0.19300000000000006, 0.26900000000000013, 0.706, 0.72, 0.381, 1.905, 1.2999999999999998, 0.3700000000000001, 0.2729999999999999, 0.9630000000000001, 0.7549999999999999, 0.9269999999999999, 1.7610000000000001, 1.8719999999999999, 0.43299999999999983, 0.762, 1.476, 0.825, 0.07100000000000017, -0.04400000000000004, 1.846, 1.6400000000000001, 0.949, 0.379, 1.549, 0.899, 1.531, 0.43500000000000005, 0.248, 0.403, 0.8159999999999998], "episode_lengths": [15, 300, 42, 68, 31, 77, 47, 56, 73, 33, 10, 174, 33, 141, 25, 55, 96, 55, 43, 117, 20, 45, 76, 22, 100, 122, 50, 128, 81, 71, 16, 16, 52, 56, 99, 73, 97, 36, 47, 24, 129, 44, 34, 83, 216, 46, 40, 26, 50, 197, 43, 30, 61, 134, 58, 20, 174, 40, 120, 39, 22, 106, 190, 108, 142, 13, 70, 30, 40, 60, 71, 92, 87, 193, 30, 213, 42, 69, 12, 77, 300, 74, 40, 22, 72, 161, 55, 134, 14, 47, 110, 16, 194, 139, 31, 141, 20, 80, 29, 56], "policy_red_0_reward": [1.455, 0.45999999999999996, 0.494, 0.494, 1.403, 1.266, 0.851, 1.3239999999999998, 1.2759999999999998, 1.4, 1.468, 0.956, 0.899, 0.564, 1.421, 1.331, 1.204, 1.33, -1.003, 1.138, 1.438, 0.493, -1.0119999999999998, 0.9329999999999999, 1.1829999999999998, 1.121, 1.346, -0.515, 1.251, 1.278, 0.952, 1.452, 1.337, 1.326, 1.194, 0.494, 1.199, 0.888, 0.498, 0.495, 0.485, 0.496, 0.891, 1.248, 0.818, 1.359, 1.3780000000000001, 0.919, 0.848, 0.388, 0.863, 1.405, 0.0, 1.067, 0.8230000000000001, 1.438, 0.971, 1.375, 1.136, -0.501, 0.9299999999999999, 1.1709999999999998, 0.474, 1.158, 1.057, -0.503, -0.505, 1.408, 0.875, 0.817, 1.2810000000000001, 1.2149999999999999, 1.23, -0.514, 1.408, 0.834, 0.871, 1.2799999999999998, 1.463, 1.259, 0.473, 0.494, 1.377, 0.9339999999999999, 1.279, 0.48, 1.331, 0.587, 0.957, 0.493, 0.485, -0.501, 0.899, 1.0659999999999998, 1.4020000000000001, 0.486, 1.438, 0.753, -1.009, 1.325], "policy_blue_0_reward": [-1.003, 0.46399999999999997, 1.369, 1.287, -0.503, -0.525, -0.505, -0.512, -0.507, -0.502, -0.5, -0.514, -1.001, -0.519, -0.501, -0.506, -0.508, -0.51, 0.869, -0.523, -1.005, 1.361, 0.765, -1.003, -0.514, -0.516, -1.006, 1.096, -0.513, -0.513, -1.003, -1.001, -1.007, -0.5169999999999999, -0.509, 1.271, -0.509, -0.507, 1.354, 1.426, 1.104, 1.365, -1.004, -0.522, -0.526, -0.505, 0.495, -1.002, -1.001, -0.523, -1.003, -1.003, 1.306, -1.015, -0.504, -1.0, -0.53, -0.506, 0.49, 1.379, -1.006, -0.508, 0.906, -0.512, -0.524, 1.46, 1.2810000000000001, 0.493, -0.5069999999999999, -1.01, -1.012, -0.509, -0.51, 0.895, 0.497, 0.46599999999999997, -0.501, -1.007, -0.5, -0.504, 0.45399999999999996, 1.267, 0.495, -0.501, -0.5169999999999999, 0.996, -0.506, -0.5159999999999999, -1.001, 1.353, 1.155, 1.45, -0.52, 0.483, -0.503, 1.045, -1.003, -0.505, 1.412, -0.509]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3641194696740604, "mean_inference_ms": 7.4071279384790705, "mean_action_processing_ms": 0.3928579189009332, "mean_env_wait_ms": 0.5128941010599334, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15304124355316162, "StateBufferConnector_ms": 0.011531949043273926, "ViewRequirementAgentConnector_ms": 0.20992732048034668}}, "episode_reward_max": 1.9209999999999998, "episode_reward_min": -0.2469999999999999, "episode_reward_mean": 0.7535900000000001, "episode_len_mean": 77.08, "episodes_this_iter": 51, "policy_reward_min": {"red_0": -1.0119999999999998, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.468, "blue_0": 1.46}, "policy_reward_mean": {"red_0": 0.8644700000000001, "blue_0": -0.11087999999999998}, "hist_stats": {"episode_reward": [0.45199999999999996, 0.9239999999999999, 1.863, 1.7810000000000001, 0.8999999999999999, 0.7410000000000001, 0.3460000000000001, 0.8119999999999998, 0.7689999999999999, 0.8980000000000001, 0.968, 0.44199999999999995, -0.10199999999999998, 0.04499999999999993, 0.9199999999999999, 0.825, 0.696, 0.8199999999999998, -0.1339999999999999, 0.615, 0.43300000000000005, 1.854, -0.2469999999999999, -0.07000000000000006, 0.669, 0.605, 0.33999999999999986, 0.581, 0.738, 0.7650000000000001, -0.051000000000000045, 0.45100000000000007, 0.33000000000000007, 0.8090000000000002, 0.685, 1.765, 0.69, 0.381, 1.8519999999999999, 1.9209999999999998, 1.589, 1.861, -0.11299999999999999, 0.726, 0.2919999999999998, 0.8540000000000001, 1.873, -0.08299999999999996, -0.15300000000000002, -0.135, -0.14, 0.40200000000000014, 1.306, 0.052000000000000046, 0.31899999999999995, 0.43799999999999994, 0.44099999999999984, 0.869, 1.626, 0.878, -0.07600000000000007, 0.6629999999999998, 1.38, 0.6459999999999999, 0.5329999999999999, 0.957, 0.776, 1.901, 0.3680000000000001, -0.19300000000000006, 0.26900000000000013, 0.706, 0.72, 0.381, 1.905, 1.2999999999999998, 0.3700000000000001, 0.2729999999999999, 0.9630000000000001, 0.7549999999999999, 0.9269999999999999, 1.7610000000000001, 1.8719999999999999, 0.43299999999999983, 0.762, 1.476, 0.825, 0.07100000000000017, -0.04400000000000004, 1.846, 1.6400000000000001, 0.949, 0.379, 1.549, 0.899, 1.531, 0.43500000000000005, 0.248, 0.403, 0.8159999999999998], "episode_lengths": [15, 300, 42, 68, 31, 77, 47, 56, 73, 33, 10, 174, 33, 141, 25, 55, 96, 55, 43, 117, 20, 45, 76, 22, 100, 122, 50, 128, 81, 71, 16, 16, 52, 56, 99, 73, 97, 36, 47, 24, 129, 44, 34, 83, 216, 46, 40, 26, 50, 197, 43, 30, 61, 134, 58, 20, 174, 40, 120, 39, 22, 106, 190, 108, 142, 13, 70, 30, 40, 60, 71, 92, 87, 193, 30, 213, 42, 69, 12, 77, 300, 74, 40, 22, 72, 161, 55, 134, 14, 47, 110, 16, 194, 139, 31, 141, 20, 80, 29, 56], "policy_red_0_reward": [1.455, 0.45999999999999996, 0.494, 0.494, 1.403, 1.266, 0.851, 1.3239999999999998, 1.2759999999999998, 1.4, 1.468, 0.956, 0.899, 0.564, 1.421, 1.331, 1.204, 1.33, -1.003, 1.138, 1.438, 0.493, -1.0119999999999998, 0.9329999999999999, 1.1829999999999998, 1.121, 1.346, -0.515, 1.251, 1.278, 0.952, 1.452, 1.337, 1.326, 1.194, 0.494, 1.199, 0.888, 0.498, 0.495, 0.485, 0.496, 0.891, 1.248, 0.818, 1.359, 1.3780000000000001, 0.919, 0.848, 0.388, 0.863, 1.405, 0.0, 1.067, 0.8230000000000001, 1.438, 0.971, 1.375, 1.136, -0.501, 0.9299999999999999, 1.1709999999999998, 0.474, 1.158, 1.057, -0.503, -0.505, 1.408, 0.875, 0.817, 1.2810000000000001, 1.2149999999999999, 1.23, -0.514, 1.408, 0.834, 0.871, 1.2799999999999998, 1.463, 1.259, 0.473, 0.494, 1.377, 0.9339999999999999, 1.279, 0.48, 1.331, 0.587, 0.957, 0.493, 0.485, -0.501, 0.899, 1.0659999999999998, 1.4020000000000001, 0.486, 1.438, 0.753, -1.009, 1.325], "policy_blue_0_reward": [-1.003, 0.46399999999999997, 1.369, 1.287, -0.503, -0.525, -0.505, -0.512, -0.507, -0.502, -0.5, -0.514, -1.001, -0.519, -0.501, -0.506, -0.508, -0.51, 0.869, -0.523, -1.005, 1.361, 0.765, -1.003, -0.514, -0.516, -1.006, 1.096, -0.513, -0.513, -1.003, -1.001, -1.007, -0.5169999999999999, -0.509, 1.271, -0.509, -0.507, 1.354, 1.426, 1.104, 1.365, -1.004, -0.522, -0.526, -0.505, 0.495, -1.002, -1.001, -0.523, -1.003, -1.003, 1.306, -1.015, -0.504, -1.0, -0.53, -0.506, 0.49, 1.379, -1.006, -0.508, 0.906, -0.512, -0.524, 1.46, 1.2810000000000001, 0.493, -0.5069999999999999, -1.01, -1.012, -0.509, -0.51, 0.895, 0.497, 0.46599999999999997, -0.501, -1.007, -0.5, -0.504, 0.45399999999999996, 1.267, 0.495, -0.501, -0.5169999999999999, 0.996, -0.506, -0.5159999999999999, -1.001, 1.353, 1.155, 1.45, -0.52, 0.483, -0.503, 1.045, -1.003, -0.505, 1.412, -0.509]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3641194696740604, "mean_inference_ms": 7.4071279384790705, "mean_action_processing_ms": 0.3928579189009332, "mean_env_wait_ms": 0.5128941010599334, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15304124355316162, "StateBufferConnector_ms": 0.011531949043273926, "ViewRequirementAgentConnector_ms": 0.20992732048034668}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 123.41823366645406, "num_env_steps_trained_throughput_per_sec": 123.41823366645406, "timesteps_total": 168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 32293.432, "sample_time_ms": 4036.925, "learn_time_ms": 28227.824, "learn_throughput": 141.704, "synch_weights_time_ms": 27.151}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "episodes_total": 1375, "training_iteration": 42, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-18-58", "timestamp": 1694837938, "time_this_iter_s": 32.42594790458679, "time_total_s": 1300.465161561966, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a21d090>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1300.465161561966, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 25.54255319148937, "ram_util_percent": 56.965957446808524}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.12, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6061171154491604, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.06684079574673281, "policy_loss": -0.09790712138734912, "vf_loss": 0.012569909935215643, "vf_explained_var": 0.671517510463794, "kl": 0.017384963718964155, "entropy": 1.6220417140672605, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 40800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5535109302960336, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07287740408355603, "policy_loss": -0.10674480120893956, "vf_loss": 0.021392561492636256, "vf_explained_var": 0.5983621479322513, "kl": 0.01638210754336078, "entropy": 1.7092082782338063, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 40800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000}, "sampler_results": {"episode_reward_max": 1.934, "episode_reward_min": -0.406, "episode_reward_mean": 0.77751, "episode_len_mean": 84.21, "episode_media": {}, "episodes_this_iter": 46, "policy_reward_min": {"red_0": -1.009, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.463, "blue_0": 1.46}, "policy_reward_mean": {"red_0": 0.8292899999999999, "blue_0": -0.05177999999999996}, "custom_metrics": {"red_0/door_open_done_mean": 0.12, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.873, -0.08299999999999996, -0.15300000000000002, -0.135, -0.14, 0.40200000000000014, 1.306, 0.052000000000000046, 0.31899999999999995, 0.43799999999999994, 0.44099999999999984, 0.869, 1.626, 0.878, -0.07600000000000007, 0.6629999999999998, 1.38, 0.6459999999999999, 0.5329999999999999, 0.957, 0.776, 1.901, 0.3680000000000001, -0.19300000000000006, 0.26900000000000013, 0.706, 0.72, 0.381, 1.905, 1.2999999999999998, 0.3700000000000001, 0.2729999999999999, 0.9630000000000001, 0.7549999999999999, 0.9269999999999999, 1.7610000000000001, 1.8719999999999999, 0.43299999999999983, 0.762, 1.476, 0.825, 0.07100000000000017, -0.04400000000000004, 1.846, 1.6400000000000001, 0.949, 0.379, 1.549, 0.899, 1.531, 0.43500000000000005, 0.248, 0.403, 0.8159999999999998, 0.9149999999999999, 1.2920000000000003, 1.9140000000000001, 0.9169999999999999, 0.752, 1.853, 0.32899999999999996, 0.45099999999999996, 0.385, 0.8900000000000001, 1.1680000000000001, 0.623, 0.379, 0.7189999999999999, 0.888, -0.07400000000000005, 0.583, 0.07399999999999984, 0.3460000000000001, 0.718, 0.20500000000000007, 0.6219999999999999, 0.879, 1.783, 1.855, 0.6560000000000001, 1.81, -0.05499999999999983, 0.8279999999999998, 1.822, 0.8900000000000001, 1.934, 0.16800000000000004, 0.7690000000000001, -0.1529999999999999, 0.879, 0.20100000000000007, 0.244, 0.933, 0.7909999999999999, 1.741, 0.393, 0.669, 0.42100000000000004, -0.406, 1.682], "episode_lengths": [40, 26, 50, 197, 43, 30, 61, 134, 58, 20, 174, 40, 120, 39, 22, 106, 190, 108, 142, 13, 70, 30, 40, 60, 71, 92, 87, 193, 30, 213, 42, 69, 12, 77, 300, 74, 40, 22, 72, 161, 55, 134, 14, 47, 110, 16, 194, 139, 31, 141, 20, 80, 29, 56, 300, 66, 27, 300, 77, 44, 53, 300, 37, 34, 101, 117, 38, 86, 34, 300, 127, 133, 49, 87, 90, 118, 38, 69, 45, 107, 59, 17, 52, 55, 34, 20, 102, 71, 47, 38, 91, 80, 20, 65, 76, 32, 99, 25, 127, 100], "policy_red_0_reward": [1.3780000000000001, 0.919, 0.848, 0.388, 0.863, 1.405, 0.0, 1.067, 0.8230000000000001, 1.438, 0.971, 1.375, 1.136, -0.501, 0.9299999999999999, 1.1709999999999998, 0.474, 1.158, 1.057, -0.503, -0.505, 1.408, 0.875, 0.817, 1.2810000000000001, 1.2149999999999999, 1.23, -0.514, 1.408, 0.834, 0.871, 1.2799999999999998, 1.463, 1.259, 0.473, 0.494, 1.377, 0.9339999999999999, 1.279, 0.48, 1.331, 0.587, 0.957, 0.493, 0.485, -0.501, 0.899, 1.0659999999999998, 1.4020000000000001, 0.486, 1.438, 0.753, -1.009, 1.325, 0.46699999999999997, 1.299, 0.496, 0.45499999999999996, 1.266, 0.489, 1.3359999999999999, -0.02100000000000001, 0.888, 1.397, 1.1840000000000002, 1.138, 1.3820000000000001, 1.2349999999999999, -0.502, -0.027000000000000017, -0.519, 1.092, 1.3519999999999999, 1.224, 0.719, 1.134, 1.384, 1.2879999999999998, 0.493, 1.169, 0.492, -1.003, 1.3359999999999999, 1.3279999999999998, 1.396, 0.496, -0.5119999999999999, 1.279, 0.855, 1.383, 1.2109999999999999, 0.754, 1.438, 1.2999999999999998, 0.484, 0.9, 1.1869999999999998, 0.924, 0.603, 1.192], "policy_blue_0_reward": [0.495, -1.002, -1.001, -0.523, -1.003, -1.003, 1.306, -1.015, -0.504, -1.0, -0.53, -0.506, 0.49, 1.379, -1.006, -0.508, 0.906, -0.512, -0.524, 1.46, 1.2810000000000001, 0.493, -0.5069999999999999, -1.01, -1.012, -0.509, -0.51, 0.895, 0.497, 0.46599999999999997, -0.501, -1.007, -0.5, -0.504, 0.45399999999999996, 1.267, 0.495, -0.501, -0.5169999999999999, 0.996, -0.506, -0.5159999999999999, -1.001, 1.353, 1.155, 1.45, -0.52, 0.483, -0.503, 1.045, -1.003, -0.505, 1.412, -0.509, 0.44799999999999995, -0.007, 1.4180000000000001, 0.46199999999999997, -0.514, 1.3639999999999999, -1.007, 0.472, -0.503, -0.507, -0.016000000000000007, -0.515, -1.003, -0.516, 1.3900000000000001, -0.047000000000000035, 1.1019999999999999, -1.018, -1.006, -0.506, -0.5139999999999999, -0.512, -0.505, 0.495, 1.362, -0.513, 1.318, 0.948, -0.508, 0.494, -0.506, 1.438, 0.6799999999999999, -0.51, -1.0079999999999998, -0.504, -1.01, -0.51, -0.5049999999999999, -0.509, 1.2570000000000001, -0.507, -0.518, -0.503, -1.009, 0.49]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3670500829592753, "mean_inference_ms": 7.4101422724562305, "mean_action_processing_ms": 0.3939032859362973, "mean_env_wait_ms": 0.5133601921015649, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.151139497756958, "StateBufferConnector_ms": 0.009685397148132324, "ViewRequirementAgentConnector_ms": 0.20169579982757568}}, "episode_reward_max": 1.934, "episode_reward_min": -0.406, "episode_reward_mean": 0.77751, "episode_len_mean": 84.21, "episodes_this_iter": 46, "policy_reward_min": {"red_0": -1.009, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.463, "blue_0": 1.46}, "policy_reward_mean": {"red_0": 0.8292899999999999, "blue_0": -0.05177999999999996}, "hist_stats": {"episode_reward": [1.873, -0.08299999999999996, -0.15300000000000002, -0.135, -0.14, 0.40200000000000014, 1.306, 0.052000000000000046, 0.31899999999999995, 0.43799999999999994, 0.44099999999999984, 0.869, 1.626, 0.878, -0.07600000000000007, 0.6629999999999998, 1.38, 0.6459999999999999, 0.5329999999999999, 0.957, 0.776, 1.901, 0.3680000000000001, -0.19300000000000006, 0.26900000000000013, 0.706, 0.72, 0.381, 1.905, 1.2999999999999998, 0.3700000000000001, 0.2729999999999999, 0.9630000000000001, 0.7549999999999999, 0.9269999999999999, 1.7610000000000001, 1.8719999999999999, 0.43299999999999983, 0.762, 1.476, 0.825, 0.07100000000000017, -0.04400000000000004, 1.846, 1.6400000000000001, 0.949, 0.379, 1.549, 0.899, 1.531, 0.43500000000000005, 0.248, 0.403, 0.8159999999999998, 0.9149999999999999, 1.2920000000000003, 1.9140000000000001, 0.9169999999999999, 0.752, 1.853, 0.32899999999999996, 0.45099999999999996, 0.385, 0.8900000000000001, 1.1680000000000001, 0.623, 0.379, 0.7189999999999999, 0.888, -0.07400000000000005, 0.583, 0.07399999999999984, 0.3460000000000001, 0.718, 0.20500000000000007, 0.6219999999999999, 0.879, 1.783, 1.855, 0.6560000000000001, 1.81, -0.05499999999999983, 0.8279999999999998, 1.822, 0.8900000000000001, 1.934, 0.16800000000000004, 0.7690000000000001, -0.1529999999999999, 0.879, 0.20100000000000007, 0.244, 0.933, 0.7909999999999999, 1.741, 0.393, 0.669, 0.42100000000000004, -0.406, 1.682], "episode_lengths": [40, 26, 50, 197, 43, 30, 61, 134, 58, 20, 174, 40, 120, 39, 22, 106, 190, 108, 142, 13, 70, 30, 40, 60, 71, 92, 87, 193, 30, 213, 42, 69, 12, 77, 300, 74, 40, 22, 72, 161, 55, 134, 14, 47, 110, 16, 194, 139, 31, 141, 20, 80, 29, 56, 300, 66, 27, 300, 77, 44, 53, 300, 37, 34, 101, 117, 38, 86, 34, 300, 127, 133, 49, 87, 90, 118, 38, 69, 45, 107, 59, 17, 52, 55, 34, 20, 102, 71, 47, 38, 91, 80, 20, 65, 76, 32, 99, 25, 127, 100], "policy_red_0_reward": [1.3780000000000001, 0.919, 0.848, 0.388, 0.863, 1.405, 0.0, 1.067, 0.8230000000000001, 1.438, 0.971, 1.375, 1.136, -0.501, 0.9299999999999999, 1.1709999999999998, 0.474, 1.158, 1.057, -0.503, -0.505, 1.408, 0.875, 0.817, 1.2810000000000001, 1.2149999999999999, 1.23, -0.514, 1.408, 0.834, 0.871, 1.2799999999999998, 1.463, 1.259, 0.473, 0.494, 1.377, 0.9339999999999999, 1.279, 0.48, 1.331, 0.587, 0.957, 0.493, 0.485, -0.501, 0.899, 1.0659999999999998, 1.4020000000000001, 0.486, 1.438, 0.753, -1.009, 1.325, 0.46699999999999997, 1.299, 0.496, 0.45499999999999996, 1.266, 0.489, 1.3359999999999999, -0.02100000000000001, 0.888, 1.397, 1.1840000000000002, 1.138, 1.3820000000000001, 1.2349999999999999, -0.502, -0.027000000000000017, -0.519, 1.092, 1.3519999999999999, 1.224, 0.719, 1.134, 1.384, 1.2879999999999998, 0.493, 1.169, 0.492, -1.003, 1.3359999999999999, 1.3279999999999998, 1.396, 0.496, -0.5119999999999999, 1.279, 0.855, 1.383, 1.2109999999999999, 0.754, 1.438, 1.2999999999999998, 0.484, 0.9, 1.1869999999999998, 0.924, 0.603, 1.192], "policy_blue_0_reward": [0.495, -1.002, -1.001, -0.523, -1.003, -1.003, 1.306, -1.015, -0.504, -1.0, -0.53, -0.506, 0.49, 1.379, -1.006, -0.508, 0.906, -0.512, -0.524, 1.46, 1.2810000000000001, 0.493, -0.5069999999999999, -1.01, -1.012, -0.509, -0.51, 0.895, 0.497, 0.46599999999999997, -0.501, -1.007, -0.5, -0.504, 0.45399999999999996, 1.267, 0.495, -0.501, -0.5169999999999999, 0.996, -0.506, -0.5159999999999999, -1.001, 1.353, 1.155, 1.45, -0.52, 0.483, -0.503, 1.045, -1.003, -0.505, 1.412, -0.509, 0.44799999999999995, -0.007, 1.4180000000000001, 0.46199999999999997, -0.514, 1.3639999999999999, -1.007, 0.472, -0.503, -0.507, -0.016000000000000007, -0.515, -1.003, -0.516, 1.3900000000000001, -0.047000000000000035, 1.1019999999999999, -1.018, -1.006, -0.506, -0.5139999999999999, -0.512, -0.505, 0.495, 1.362, -0.513, 1.318, 0.948, -0.508, 0.494, -0.506, 1.438, 0.6799999999999999, -0.51, -1.0079999999999998, -0.504, -1.01, -0.51, -0.5049999999999999, -0.509, 1.2570000000000001, -0.507, -0.518, -0.503, -1.009, 0.49]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3670500829592753, "mean_inference_ms": 7.4101422724562305, "mean_action_processing_ms": 0.3939032859362973, "mean_env_wait_ms": 0.5133601921015649, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.151139497756958, "StateBufferConnector_ms": 0.009685397148132324, "ViewRequirementAgentConnector_ms": 0.20169579982757568}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.59541013118118, "num_env_steps_trained_throughput_per_sec": 128.59541013118118, "timesteps_total": 172000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 344000, "timers": {"training_iteration_time_ms": 32105.946, "sample_time_ms": 3998.516, "learn_time_ms": 28078.988, "learn_throughput": 142.455, "synch_weights_time_ms": 26.835}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000}, "done": false, "episodes_total": 1421, "training_iteration": 43, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-19-30", "timestamp": 1694837970, "time_this_iter_s": 31.121893167495728, "time_total_s": 1331.5870547294617, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80eb91b0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1331.5870547294617, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 25.191111111111113, "ram_util_percent": 56.90222222222223}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.07, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.66, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.66, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.08, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.66, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5666433958647151, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.0745856238194392, "policy_loss": -0.11200053783153029, "vf_loss": 0.024388567056060614, "vf_explained_var": 0.5679573512946566, "kl": 0.017672480556742205, "entropy": 1.6194480386873087, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 41760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5468137703525523, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.0801480469769255, "policy_loss": -0.12011399923503632, "vf_loss": 0.027914699454170962, "vf_explained_var": 0.6160784907639026, "kl": 0.0182384596367341, "entropy": 1.6910568966219823, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 41760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "sampler_results": {"episode_reward_max": 1.934, "episode_reward_min": -0.406, "episode_reward_mean": 0.63057, "episode_len_mean": 73.0, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.76717, "blue_0": -0.13659999999999997}, "custom_metrics": {"red_0/door_open_done_mean": 0.07, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.66, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.66, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.08, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.66, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.32899999999999996, 0.45099999999999996, 0.385, 0.8900000000000001, 1.1680000000000001, 0.623, 0.379, 0.7189999999999999, 0.888, -0.07400000000000005, 0.583, 0.07399999999999984, 0.3460000000000001, 0.718, 0.20500000000000007, 0.6219999999999999, 0.879, 1.783, 1.855, 0.6560000000000001, 1.81, -0.05499999999999983, 0.8279999999999998, 1.822, 0.8900000000000001, 1.934, 0.16800000000000004, 0.7690000000000001, -0.1529999999999999, 0.879, 0.20100000000000007, 0.244, 0.933, 0.7909999999999999, 1.741, 0.393, 0.669, 0.42100000000000004, -0.406, 1.682, 0.3620000000000001, 0.42000000000000004, 0.8199999999999998, 0.8180000000000001, 0.615, 1.4249999999999998, 0.69, 0.43199999999999994, 0.367, 0.5529999999999999, 0.43599999999999994, 0.15300000000000002, 0.883, 1.192, 0.21099999999999985, 0.8460000000000001, -0.02100000000000002, 0.28, -0.06900000000000006, 0.5529999999999999, 0.31999999999999984, 0.16800000000000015, 0.359, 0.875, 0.2799999999999998, 0.742, 0.9289999999999998, -0.04800000000000004, 0.1479999999999999, 0.45999999999999996, 0.3700000000000001, 0.8999999999999999, 0.248, 0.91, 0.121, 0.8119999999999999, -0.061999999999999944, -0.09999999999999987, 0.76, 0.8780000000000001, 0.27700000000000014, 0.2610000000000001, 1.6749999999999998, 0.9590000000000001, -0.06400000000000006, 0.519, 0.45999999999999996, 1.93, 1.781, 0.8680000000000001, 1.4000000000000001, -0.14800000000000002, 0.29400000000000004, -0.129, 0.8700000000000001, 0.355, 1.919, 0.2849999999999999, 0.8439999999999999, -0.375], "episode_lengths": [53, 300, 37, 34, 101, 117, 38, 86, 34, 300, 127, 133, 49, 87, 90, 118, 38, 69, 45, 107, 59, 17, 52, 55, 34, 20, 102, 71, 47, 38, 91, 80, 20, 65, 76, 32, 99, 25, 127, 100, 43, 26, 56, 55, 121, 24, 95, 22, 40, 139, 20, 108, 35, 93, 90, 46, 7, 69, 22, 134, 56, 101, 43, 41, 69, 77, 22, 15, 112, 167, 40, 300, 78, 29, 269, 60, 19, 33, 76, 38, 70, 75, 99, 13, 20, 151, 12, 22, 67, 39, 30, 46, 62, 38, 39, 45, 26, 218, 48, 117], "policy_red_0_reward": [1.3359999999999999, -0.02100000000000001, 0.888, 1.397, 1.1840000000000002, 1.138, 1.3820000000000001, 1.2349999999999999, -0.502, -0.027000000000000017, -0.519, 1.092, 1.3519999999999999, 1.224, 0.719, 1.134, 1.384, 1.2879999999999998, 0.493, 1.169, 0.492, -1.003, 1.3359999999999999, 1.3279999999999998, 1.396, 0.496, -0.5119999999999999, 1.279, 0.855, 1.383, 1.2109999999999999, 0.754, 1.438, 1.2999999999999998, 0.484, 0.9, 1.1869999999999998, 0.924, 0.603, 1.192, 1.366, -0.5, 1.3279999999999998, 1.322, 1.127, -0.001, 1.203, 1.434, 0.873, 1.068, -1.002, 1.164, 1.387, 1.205, 1.226, 1.353, -1.0, 1.286, 0.9329999999999999, -0.516, 0.827, 0.685, 1.365, -0.501, 0.7839999999999999, 1.2570000000000001, 1.43, 0.954, 1.156, 0.986, 0.875, 0.45699999999999996, 1.259, -0.503, 0.658, -0.502, -1.002, 0.901, 1.263, 1.381, 0.784, 1.2690000000000001, 0.491, 1.4609999999999999, 0.938, -0.517, -1.001, 0.499, 1.29, -0.5049999999999999, 1.4060000000000001, -1.004, 1.306, 0.879, 1.377, 1.3639999999999999, 0.499, 0.818, 1.35, 0.638], "policy_blue_0_reward": [-1.007, 0.472, -0.503, -0.507, -0.016000000000000007, -0.515, -1.003, -0.516, 1.3900000000000001, -0.047000000000000035, 1.1019999999999999, -1.018, -1.006, -0.506, -0.5139999999999999, -0.512, -0.505, 0.495, 1.362, -0.513, 1.318, 0.948, -0.508, 0.494, -0.506, 1.438, 0.6799999999999999, -0.51, -1.0079999999999998, -0.504, -1.01, -0.51, -0.5049999999999999, -0.509, 1.2570000000000001, -0.507, -0.518, -0.503, -1.009, 0.49, -1.004, 0.92, -0.508, -0.5039999999999999, -0.512, 1.426, -0.513, -1.002, -0.506, -0.5149999999999999, 1.438, -1.011, -0.504, -0.013000000000000005, -1.015, -0.5069999999999999, 0.979, -1.0059999999999998, -1.002, 1.069, -0.507, -0.517, -1.0059999999999998, 1.376, -0.504, -0.5149999999999999, -0.501, -1.002, -1.008, -0.526, -0.505, 0.44299999999999995, -1.011, 1.413, -0.5369999999999999, 1.314, 0.94, -1.001, -0.503, -0.503, -0.507, -1.008, 1.184, -0.502, -1.002, 1.036, 1.4609999999999999, 1.431, 0.491, 1.373, -0.006, 0.856, -1.012, -1.008, -0.507, -1.009, 1.42, -0.533, -0.506, -1.013]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3685175285843036, "mean_inference_ms": 7.416873566527838, "mean_action_processing_ms": 0.3930667973045121, "mean_env_wait_ms": 0.5134596017415336, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15143334865570068, "StateBufferConnector_ms": 0.01046764850616455, "ViewRequirementAgentConnector_ms": 0.2123943567276001}}, "episode_reward_max": 1.934, "episode_reward_min": -0.406, "episode_reward_mean": 0.63057, "episode_len_mean": 73.0, "episodes_this_iter": 60, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.76717, "blue_0": -0.13659999999999997}, "hist_stats": {"episode_reward": [0.32899999999999996, 0.45099999999999996, 0.385, 0.8900000000000001, 1.1680000000000001, 0.623, 0.379, 0.7189999999999999, 0.888, -0.07400000000000005, 0.583, 0.07399999999999984, 0.3460000000000001, 0.718, 0.20500000000000007, 0.6219999999999999, 0.879, 1.783, 1.855, 0.6560000000000001, 1.81, -0.05499999999999983, 0.8279999999999998, 1.822, 0.8900000000000001, 1.934, 0.16800000000000004, 0.7690000000000001, -0.1529999999999999, 0.879, 0.20100000000000007, 0.244, 0.933, 0.7909999999999999, 1.741, 0.393, 0.669, 0.42100000000000004, -0.406, 1.682, 0.3620000000000001, 0.42000000000000004, 0.8199999999999998, 0.8180000000000001, 0.615, 1.4249999999999998, 0.69, 0.43199999999999994, 0.367, 0.5529999999999999, 0.43599999999999994, 0.15300000000000002, 0.883, 1.192, 0.21099999999999985, 0.8460000000000001, -0.02100000000000002, 0.28, -0.06900000000000006, 0.5529999999999999, 0.31999999999999984, 0.16800000000000015, 0.359, 0.875, 0.2799999999999998, 0.742, 0.9289999999999998, -0.04800000000000004, 0.1479999999999999, 0.45999999999999996, 0.3700000000000001, 0.8999999999999999, 0.248, 0.91, 0.121, 0.8119999999999999, -0.061999999999999944, -0.09999999999999987, 0.76, 0.8780000000000001, 0.27700000000000014, 0.2610000000000001, 1.6749999999999998, 0.9590000000000001, -0.06400000000000006, 0.519, 0.45999999999999996, 1.93, 1.781, 0.8680000000000001, 1.4000000000000001, -0.14800000000000002, 0.29400000000000004, -0.129, 0.8700000000000001, 0.355, 1.919, 0.2849999999999999, 0.8439999999999999, -0.375], "episode_lengths": [53, 300, 37, 34, 101, 117, 38, 86, 34, 300, 127, 133, 49, 87, 90, 118, 38, 69, 45, 107, 59, 17, 52, 55, 34, 20, 102, 71, 47, 38, 91, 80, 20, 65, 76, 32, 99, 25, 127, 100, 43, 26, 56, 55, 121, 24, 95, 22, 40, 139, 20, 108, 35, 93, 90, 46, 7, 69, 22, 134, 56, 101, 43, 41, 69, 77, 22, 15, 112, 167, 40, 300, 78, 29, 269, 60, 19, 33, 76, 38, 70, 75, 99, 13, 20, 151, 12, 22, 67, 39, 30, 46, 62, 38, 39, 45, 26, 218, 48, 117], "policy_red_0_reward": [1.3359999999999999, -0.02100000000000001, 0.888, 1.397, 1.1840000000000002, 1.138, 1.3820000000000001, 1.2349999999999999, -0.502, -0.027000000000000017, -0.519, 1.092, 1.3519999999999999, 1.224, 0.719, 1.134, 1.384, 1.2879999999999998, 0.493, 1.169, 0.492, -1.003, 1.3359999999999999, 1.3279999999999998, 1.396, 0.496, -0.5119999999999999, 1.279, 0.855, 1.383, 1.2109999999999999, 0.754, 1.438, 1.2999999999999998, 0.484, 0.9, 1.1869999999999998, 0.924, 0.603, 1.192, 1.366, -0.5, 1.3279999999999998, 1.322, 1.127, -0.001, 1.203, 1.434, 0.873, 1.068, -1.002, 1.164, 1.387, 1.205, 1.226, 1.353, -1.0, 1.286, 0.9329999999999999, -0.516, 0.827, 0.685, 1.365, -0.501, 0.7839999999999999, 1.2570000000000001, 1.43, 0.954, 1.156, 0.986, 0.875, 0.45699999999999996, 1.259, -0.503, 0.658, -0.502, -1.002, 0.901, 1.263, 1.381, 0.784, 1.2690000000000001, 0.491, 1.4609999999999999, 0.938, -0.517, -1.001, 0.499, 1.29, -0.5049999999999999, 1.4060000000000001, -1.004, 1.306, 0.879, 1.377, 1.3639999999999999, 0.499, 0.818, 1.35, 0.638], "policy_blue_0_reward": [-1.007, 0.472, -0.503, -0.507, -0.016000000000000007, -0.515, -1.003, -0.516, 1.3900000000000001, -0.047000000000000035, 1.1019999999999999, -1.018, -1.006, -0.506, -0.5139999999999999, -0.512, -0.505, 0.495, 1.362, -0.513, 1.318, 0.948, -0.508, 0.494, -0.506, 1.438, 0.6799999999999999, -0.51, -1.0079999999999998, -0.504, -1.01, -0.51, -0.5049999999999999, -0.509, 1.2570000000000001, -0.507, -0.518, -0.503, -1.009, 0.49, -1.004, 0.92, -0.508, -0.5039999999999999, -0.512, 1.426, -0.513, -1.002, -0.506, -0.5149999999999999, 1.438, -1.011, -0.504, -0.013000000000000005, -1.015, -0.5069999999999999, 0.979, -1.0059999999999998, -1.002, 1.069, -0.507, -0.517, -1.0059999999999998, 1.376, -0.504, -0.5149999999999999, -0.501, -1.002, -1.008, -0.526, -0.505, 0.44299999999999995, -1.011, 1.413, -0.5369999999999999, 1.314, 0.94, -1.001, -0.503, -0.503, -0.507, -1.008, 1.184, -0.502, -1.002, 1.036, 1.4609999999999999, 1.431, 0.491, 1.373, -0.006, 0.856, -1.012, -1.008, -0.507, -1.009, 1.42, -0.533, -0.506, -1.013]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3685175285843036, "mean_inference_ms": 7.416873566527838, "mean_action_processing_ms": 0.3930667973045121, "mean_env_wait_ms": 0.5134596017415336, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15143334865570068, "StateBufferConnector_ms": 0.01046764850616455, "ViewRequirementAgentConnector_ms": 0.2123943567276001}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 122.94420743223743, "num_env_steps_trained_throughput_per_sec": 122.94420743223743, "timesteps_total": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 32186.109, "sample_time_ms": 4033.146, "learn_time_ms": 28124.66, "learn_throughput": 142.224, "synch_weights_time_ms": 26.685}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "episodes_total": 1481, "training_iteration": 44, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-20-04", "timestamp": 1694838004, "time_this_iter_s": 32.550490856170654, "time_total_s": 1364.1375455856323, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a21c940>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1364.1375455856323, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 26.108333333333338, "ram_util_percent": 57.00416666666666}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.06, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.62, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.19, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.62, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.19, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.62, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.19, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5862262105879684, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07433801214356209, "policy_loss": -0.10907164439777262, "vf_loss": 0.016206048335394976, "vf_explained_var": 0.6002203323567907, "kl": 0.01860505022914128, "entropy": 1.6258099667727948, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 42720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5842386833392084, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08340772902301978, "policy_loss": -0.12233765613103363, "vf_loss": 0.023607937229583816, "vf_explained_var": 0.5835019841790199, "kl": 0.018968200034323215, "entropy": 1.6819948377708593, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 42720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000}, "sampler_results": {"episode_reward_max": 1.93, "episode_reward_min": -0.375, "episode_reward_mean": 0.6719600000000001, "episode_len_mean": 76.07, "episode_media": {}, "episodes_this_iter": 46, "policy_reward_min": {"red_0": -1.016, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 0.7092400000000002, "blue_0": -0.03728}, "custom_metrics": {"red_0/door_open_done_mean": 0.06, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.62, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.19, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.62, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.19, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.62, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.19, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.69, 0.43199999999999994, 0.367, 0.5529999999999999, 0.43599999999999994, 0.15300000000000002, 0.883, 1.192, 0.21099999999999985, 0.8460000000000001, -0.02100000000000002, 0.28, -0.06900000000000006, 0.5529999999999999, 0.31999999999999984, 0.16800000000000015, 0.359, 0.875, 0.2799999999999998, 0.742, 0.9289999999999998, -0.04800000000000004, 0.1479999999999999, 0.45999999999999996, 0.3700000000000001, 0.8999999999999999, 0.248, 0.91, 0.121, 0.8119999999999999, -0.061999999999999944, -0.09999999999999987, 0.76, 0.8780000000000001, 0.27700000000000014, 0.2610000000000001, 1.6749999999999998, 0.9590000000000001, -0.06400000000000006, 0.519, 0.45999999999999996, 1.93, 1.781, 0.8680000000000001, 1.4000000000000001, -0.14800000000000002, 0.29400000000000004, -0.129, 0.8700000000000001, 0.355, 1.919, 0.2849999999999999, 0.8439999999999999, -0.375, -0.0010000000000000009, 0.9420000000000002, 1.671, 1.427, 0.815, 1.0299999999999998, -0.07199999999999995, 1.8599999999999999, 0.706, 0.245, 0.749, 0.746, 0.42599999999999993, 0.704, 0.895, 1.9220000000000002, 0.954, 0.17799999999999994, 0.969, 0.46099999999999985, 0.82, 0.14200000000000013, -0.02400000000000002, 0.7429999999999999, -0.08499999999999996, 1.7469999999999999, 0.355, 1.797, 1.9289999999999998, 0.5329999999999999, 1.722, 1.319, 0.7970000000000002, 0.874, 0.1200000000000001, 0.718, 0.734, 0.30299999999999994, 1.807, 0.909, 0.256, 0.782, 0.42999999999999994, 0.4119999999999999, 0.41800000000000015, 1.4539999999999997], "episode_lengths": [95, 22, 40, 139, 20, 108, 35, 93, 90, 46, 7, 69, 22, 134, 56, 101, 43, 41, 69, 77, 22, 15, 112, 167, 40, 300, 78, 29, 269, 60, 19, 33, 76, 38, 70, 75, 99, 13, 20, 151, 12, 22, 67, 39, 30, 46, 62, 38, 39, 45, 26, 218, 48, 117, 150, 18, 101, 180, 55, 293, 22, 43, 90, 78, 78, 79, 174, 92, 33, 25, 15, 101, 10, 168, 56, 110, 8, 82, 27, 77, 45, 61, 22, 146, 87, 57, 62, 38, 269, 86, 81, 62, 60, 28, 75, 67, 177, 27, 25, 165], "policy_red_0_reward": [1.203, 1.434, 0.873, 1.068, -1.002, 1.164, 1.387, 1.205, 1.226, 1.353, -1.0, 1.286, 0.9329999999999999, -0.516, 0.827, 0.685, 1.365, -0.501, 0.7839999999999999, 1.2570000000000001, 1.43, 0.954, 1.156, 0.986, 0.875, 0.45699999999999996, 1.259, -0.503, 0.658, -0.502, -1.002, 0.901, 1.263, 1.381, 0.784, 1.2690000000000001, 0.491, 1.4609999999999999, 0.938, -0.517, -1.001, 0.499, 1.29, -0.5049999999999999, 1.4060000000000001, -1.004, 1.306, 0.879, 1.377, 1.3639999999999999, 0.499, 0.818, 1.35, 0.638, 1.02, 1.4449999999999998, 0.491, 0.478, 1.326, 0.45299999999999996, 0.9329999999999999, 0.494, 1.218, -1.016, -0.508, 1.255, 0.958, 1.216, 1.399, 0.498, 1.455, 1.186, -0.5, 0.9799999999999999, -0.506, 1.158, 0.976, 1.249, 0.915, 0.494, 1.359, 0.493, 0.498, 1.049, 1.2349999999999999, 1.326, 1.308, -0.508, 0.662, -0.511, -0.513, 1.308, 0.493, 1.412, -0.508, 1.295, 0.956, 0.917, 0.921, 0.9789999999999999], "policy_blue_0_reward": [-0.513, -1.002, -0.506, -0.5149999999999999, 1.438, -1.011, -0.504, -0.013000000000000005, -1.015, -0.5069999999999999, 0.979, -1.0059999999999998, -1.002, 1.069, -0.507, -0.517, -1.0059999999999998, 1.376, -0.504, -0.5149999999999999, -0.501, -1.002, -1.008, -0.526, -0.505, 0.44299999999999995, -1.011, 1.413, -0.5369999999999999, 1.314, 0.94, -1.001, -0.503, -0.503, -0.507, -1.008, 1.184, -0.502, -1.002, 1.036, 1.4609999999999999, 1.431, 0.491, 1.373, -0.006, 0.856, -1.012, -1.008, -0.507, -1.009, 1.42, -0.533, -0.506, -1.013, -1.021, -0.5029999999999999, 1.1800000000000002, 0.949, -0.511, 0.577, -1.005, 1.366, -0.512, 1.2610000000000001, 1.2570000000000001, -0.5089999999999999, -0.532, -0.512, -0.504, 1.424, -0.501, -1.008, 1.4689999999999999, -0.519, 1.326, -1.0159999999999998, -1.0, -0.506, -1.0, 1.2530000000000001, -1.004, 1.3039999999999998, 1.431, -0.5159999999999999, 0.487, -0.007, -0.5109999999999999, 1.3820000000000001, -0.542, 1.229, 1.2469999999999999, -1.005, 1.314, -0.503, 0.764, -0.513, -0.526, -0.505, -0.5029999999999999, 0.475]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3694021486979842, "mean_inference_ms": 7.427977750176626, "mean_action_processing_ms": 0.39361575445509317, "mean_env_wait_ms": 0.5143605272183281, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15206551551818848, "StateBufferConnector_ms": 0.010534405708312988, "ViewRequirementAgentConnector_ms": 0.21215617656707764}}, "episode_reward_max": 1.93, "episode_reward_min": -0.375, "episode_reward_mean": 0.6719600000000001, "episode_len_mean": 76.07, "episodes_this_iter": 46, "policy_reward_min": {"red_0": -1.016, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 0.7092400000000002, "blue_0": -0.03728}, "hist_stats": {"episode_reward": [0.69, 0.43199999999999994, 0.367, 0.5529999999999999, 0.43599999999999994, 0.15300000000000002, 0.883, 1.192, 0.21099999999999985, 0.8460000000000001, -0.02100000000000002, 0.28, -0.06900000000000006, 0.5529999999999999, 0.31999999999999984, 0.16800000000000015, 0.359, 0.875, 0.2799999999999998, 0.742, 0.9289999999999998, -0.04800000000000004, 0.1479999999999999, 0.45999999999999996, 0.3700000000000001, 0.8999999999999999, 0.248, 0.91, 0.121, 0.8119999999999999, -0.061999999999999944, -0.09999999999999987, 0.76, 0.8780000000000001, 0.27700000000000014, 0.2610000000000001, 1.6749999999999998, 0.9590000000000001, -0.06400000000000006, 0.519, 0.45999999999999996, 1.93, 1.781, 0.8680000000000001, 1.4000000000000001, -0.14800000000000002, 0.29400000000000004, -0.129, 0.8700000000000001, 0.355, 1.919, 0.2849999999999999, 0.8439999999999999, -0.375, -0.0010000000000000009, 0.9420000000000002, 1.671, 1.427, 0.815, 1.0299999999999998, -0.07199999999999995, 1.8599999999999999, 0.706, 0.245, 0.749, 0.746, 0.42599999999999993, 0.704, 0.895, 1.9220000000000002, 0.954, 0.17799999999999994, 0.969, 0.46099999999999985, 0.82, 0.14200000000000013, -0.02400000000000002, 0.7429999999999999, -0.08499999999999996, 1.7469999999999999, 0.355, 1.797, 1.9289999999999998, 0.5329999999999999, 1.722, 1.319, 0.7970000000000002, 0.874, 0.1200000000000001, 0.718, 0.734, 0.30299999999999994, 1.807, 0.909, 0.256, 0.782, 0.42999999999999994, 0.4119999999999999, 0.41800000000000015, 1.4539999999999997], "episode_lengths": [95, 22, 40, 139, 20, 108, 35, 93, 90, 46, 7, 69, 22, 134, 56, 101, 43, 41, 69, 77, 22, 15, 112, 167, 40, 300, 78, 29, 269, 60, 19, 33, 76, 38, 70, 75, 99, 13, 20, 151, 12, 22, 67, 39, 30, 46, 62, 38, 39, 45, 26, 218, 48, 117, 150, 18, 101, 180, 55, 293, 22, 43, 90, 78, 78, 79, 174, 92, 33, 25, 15, 101, 10, 168, 56, 110, 8, 82, 27, 77, 45, 61, 22, 146, 87, 57, 62, 38, 269, 86, 81, 62, 60, 28, 75, 67, 177, 27, 25, 165], "policy_red_0_reward": [1.203, 1.434, 0.873, 1.068, -1.002, 1.164, 1.387, 1.205, 1.226, 1.353, -1.0, 1.286, 0.9329999999999999, -0.516, 0.827, 0.685, 1.365, -0.501, 0.7839999999999999, 1.2570000000000001, 1.43, 0.954, 1.156, 0.986, 0.875, 0.45699999999999996, 1.259, -0.503, 0.658, -0.502, -1.002, 0.901, 1.263, 1.381, 0.784, 1.2690000000000001, 0.491, 1.4609999999999999, 0.938, -0.517, -1.001, 0.499, 1.29, -0.5049999999999999, 1.4060000000000001, -1.004, 1.306, 0.879, 1.377, 1.3639999999999999, 0.499, 0.818, 1.35, 0.638, 1.02, 1.4449999999999998, 0.491, 0.478, 1.326, 0.45299999999999996, 0.9329999999999999, 0.494, 1.218, -1.016, -0.508, 1.255, 0.958, 1.216, 1.399, 0.498, 1.455, 1.186, -0.5, 0.9799999999999999, -0.506, 1.158, 0.976, 1.249, 0.915, 0.494, 1.359, 0.493, 0.498, 1.049, 1.2349999999999999, 1.326, 1.308, -0.508, 0.662, -0.511, -0.513, 1.308, 0.493, 1.412, -0.508, 1.295, 0.956, 0.917, 0.921, 0.9789999999999999], "policy_blue_0_reward": [-0.513, -1.002, -0.506, -0.5149999999999999, 1.438, -1.011, -0.504, -0.013000000000000005, -1.015, -0.5069999999999999, 0.979, -1.0059999999999998, -1.002, 1.069, -0.507, -0.517, -1.0059999999999998, 1.376, -0.504, -0.5149999999999999, -0.501, -1.002, -1.008, -0.526, -0.505, 0.44299999999999995, -1.011, 1.413, -0.5369999999999999, 1.314, 0.94, -1.001, -0.503, -0.503, -0.507, -1.008, 1.184, -0.502, -1.002, 1.036, 1.4609999999999999, 1.431, 0.491, 1.373, -0.006, 0.856, -1.012, -1.008, -0.507, -1.009, 1.42, -0.533, -0.506, -1.013, -1.021, -0.5029999999999999, 1.1800000000000002, 0.949, -0.511, 0.577, -1.005, 1.366, -0.512, 1.2610000000000001, 1.2570000000000001, -0.5089999999999999, -0.532, -0.512, -0.504, 1.424, -0.501, -1.008, 1.4689999999999999, -0.519, 1.326, -1.0159999999999998, -1.0, -0.506, -1.0, 1.2530000000000001, -1.004, 1.3039999999999998, 1.431, -0.5159999999999999, 0.487, -0.007, -0.5109999999999999, 1.3820000000000001, -0.542, 1.229, 1.2469999999999999, -1.005, 1.314, -0.503, 0.764, -0.513, -0.526, -0.505, -0.5029999999999999, 0.475]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3694021486979842, "mean_inference_ms": 7.427977750176626, "mean_action_processing_ms": 0.39361575445509317, "mean_env_wait_ms": 0.5143605272183281, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15206551551818848, "StateBufferConnector_ms": 0.010534405708312988, "ViewRequirementAgentConnector_ms": 0.21215617656707764}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.92937882892954, "num_env_steps_trained_throughput_per_sec": 127.92937882892954, "timesteps_total": 180000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 360000, "timers": {"training_iteration_time_ms": 32182.633, "sample_time_ms": 4015.065, "learn_time_ms": 28138.957, "learn_throughput": 142.152, "synch_weights_time_ms": 27.006}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000}, "done": false, "episodes_total": 1527, "training_iteration": 45, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-20-36", "timestamp": 1694838036, "time_this_iter_s": 31.28268003463745, "time_total_s": 1395.4202256202698, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80eb95a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1395.4202256202698, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 26.23777777777778, "ram_util_percent": 57.0111111111111}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.06, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.67, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.67, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.67, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6027749551149706, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08033312978271473, "policy_loss": -0.11917063871223946, "vf_loss": 0.019887461328471544, "vf_explained_var": 0.5725045078744491, "kl": 0.020072427991665944, "entropy": 1.5912213288247585, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 43680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5599813044071198, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08301878181437132, "policy_loss": -0.12095597645578285, "vf_loss": 0.02663783497409895, "vf_explained_var": 0.5938558643062909, "kl": 0.017329788837502566, "entropy": 1.7013394021739563, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 43680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "sampler_results": {"episode_reward_max": 1.9289999999999998, "episode_reward_min": -0.375, "episode_reward_mean": 0.7299599999999999, "episode_len_mean": 79.93, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"red_0": -1.016, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.455, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 0.8249799999999999, "blue_0": -0.09501999999999997}, "custom_metrics": {"red_0/door_open_done_mean": 0.06, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.67, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.67, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.67, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.375, -0.0010000000000000009, 0.9420000000000002, 1.671, 1.427, 0.815, 1.0299999999999998, -0.07199999999999995, 1.8599999999999999, 0.706, 0.245, 0.749, 0.746, 0.42599999999999993, 0.704, 0.895, 1.9220000000000002, 0.954, 0.17799999999999994, 0.969, 0.46099999999999985, 0.82, 0.14200000000000013, -0.02400000000000002, 0.7429999999999999, -0.08499999999999996, 1.7469999999999999, 0.355, 1.797, 1.9289999999999998, 0.5329999999999999, 1.722, 1.319, 0.7970000000000002, 0.874, 0.1200000000000001, 0.718, 0.734, 0.30299999999999994, 1.807, 0.909, 0.256, 0.782, 0.42999999999999994, 0.4119999999999999, 0.41800000000000015, 1.4539999999999997, 0.6190000000000002, 0.8600000000000001, 0.7850000000000001, 0.469, 0.8300000000000001, 0.7989999999999999, 1.7930000000000001, 0.391, 0.44100000000000006, 0.31600000000000006, 0.28900000000000015, 0.06199999999999983, 0.05699999999999994, 0.7669999999999999, 0.41600000000000015, 0.4790000000000001, 0.9349999999999999, -0.03400000000000003, 1.831, -0.039000000000000035, 0.6339999999999999, 1.384, -0.18700000000000006, 0.2959999999999998, 0.2849999999999999, 0.9140000000000001, 0.7669999999999999, 0.8799999999999999, 0.5609999999999999, 0.5720000000000001, 1.846, 0.872, 0.44399999999999995, 0.6559999999999999, 0.7370000000000001, 0.9020000000000001, -0.050000000000000044, 0.39400000000000013, 0.30500000000000016, 0.81, 0.8300000000000001, 0.7869999999999999, 0.7730000000000001, 1.819, 1.1749999999999998, 0.823, 0.08299999999999996, 0.349, 0.845, 0.29700000000000015, 1.6430000000000002, 0.8159999999999998, 0.4039999999999999], "episode_lengths": [117, 150, 18, 101, 180, 55, 293, 22, 43, 90, 78, 78, 79, 174, 92, 33, 25, 15, 101, 10, 168, 56, 110, 8, 82, 27, 77, 45, 61, 22, 146, 87, 57, 62, 38, 269, 86, 81, 62, 60, 28, 75, 67, 177, 27, 25, 165, 119, 42, 68, 162, 54, 59, 64, 34, 18, 58, 66, 135, 288, 71, 27, 156, 20, 10, 53, 12, 108, 37, 213, 214, 67, 25, 70, 39, 136, 130, 47, 40, 169, 104, 83, 31, 16, 33, 59, 58, 50, 65, 71, 54, 98, 56, 128, 45, 49, 64, 109, 56, 31], "policy_red_0_reward": [0.638, 1.02, 1.4449999999999998, 0.491, 0.478, 1.326, 0.45299999999999996, 0.9329999999999999, 0.494, 1.218, -1.016, -0.508, 1.255, 0.958, 1.216, 1.399, 0.498, 1.455, 1.186, -0.5, 0.9799999999999999, -0.506, 1.158, 0.976, 1.249, 0.915, 0.494, 1.359, 0.493, 0.498, 1.049, 1.2349999999999999, 1.326, 1.308, -0.508, 0.662, -0.511, -0.513, 1.308, 0.493, 1.412, -0.508, 1.295, 0.956, 0.917, 0.921, 0.9789999999999999, 1.131, 1.369, 1.2890000000000001, -0.521, 1.333, 1.311, 0.49, 0.893, 1.4449999999999998, 1.322, 1.294, 1.073, 0.594, 1.282, -0.5009999999999999, 0.999, -0.503, 0.969, 1.333, 0.963, 1.164, -0.002, 0.33999999999999997, 0.829, -0.507, 1.42, 1.278, 1.383, 1.0790000000000002, 1.088, 0.496, -0.503, 0.971, 1.18, 1.242, 1.403, 0.951, 0.9, 1.313, 1.322, 1.341, 1.298, 1.284, 1.33, -0.022000000000000013, 1.33, 1.104, 1.358, -0.504, 1.3010000000000002, 1.161, 1.3239999999999998, 1.405], "policy_blue_0_reward": [-1.013, -1.021, -0.5029999999999999, 1.1800000000000002, 0.949, -0.511, 0.577, -1.005, 1.366, -0.512, 1.2610000000000001, 1.2570000000000001, -0.5089999999999999, -0.532, -0.512, -0.504, 1.424, -0.501, -1.008, 1.4689999999999999, -0.519, 1.326, -1.0159999999999998, -1.0, -0.506, -1.0, 1.2530000000000001, -1.004, 1.3039999999999998, 1.431, -0.5159999999999999, 0.487, -0.007, -0.5109999999999999, 1.3820000000000001, -0.542, 1.229, 1.2469999999999999, -1.005, 1.314, -0.503, 0.764, -0.513, -0.526, -0.505, -0.5029999999999999, 0.475, -0.5119999999999999, -0.5089999999999999, -0.504, 0.99, -0.503, -0.512, 1.303, -0.502, -1.0039999999999998, -1.006, -1.005, -1.011, -0.537, -0.515, 0.917, -0.52, 1.438, -1.003, 0.498, -1.002, -0.53, 1.3860000000000001, -0.527, -0.533, 0.7919999999999999, -0.506, -0.511, -0.503, -0.518, -0.516, 1.35, 1.375, -0.527, -0.524, -0.505, -0.501, -1.001, -0.5059999999999999, -1.0079999999999998, -0.512, -0.511, -0.511, -0.511, 0.489, 1.197, -0.507, -1.021, -1.009, 1.349, -1.004, 0.482, -0.508, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3700228431491308, "mean_inference_ms": 7.424394468445269, "mean_action_processing_ms": 0.3937527450467402, "mean_env_wait_ms": 0.514340637616504, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14781475067138672, "StateBufferConnector_ms": 0.00948953628540039, "ViewRequirementAgentConnector_ms": 0.18786156177520752}}, "episode_reward_max": 1.9289999999999998, "episode_reward_min": -0.375, "episode_reward_mean": 0.7299599999999999, "episode_len_mean": 79.93, "episodes_this_iter": 53, "policy_reward_min": {"red_0": -1.016, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.455, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 0.8249799999999999, "blue_0": -0.09501999999999997}, "hist_stats": {"episode_reward": [-0.375, -0.0010000000000000009, 0.9420000000000002, 1.671, 1.427, 0.815, 1.0299999999999998, -0.07199999999999995, 1.8599999999999999, 0.706, 0.245, 0.749, 0.746, 0.42599999999999993, 0.704, 0.895, 1.9220000000000002, 0.954, 0.17799999999999994, 0.969, 0.46099999999999985, 0.82, 0.14200000000000013, -0.02400000000000002, 0.7429999999999999, -0.08499999999999996, 1.7469999999999999, 0.355, 1.797, 1.9289999999999998, 0.5329999999999999, 1.722, 1.319, 0.7970000000000002, 0.874, 0.1200000000000001, 0.718, 0.734, 0.30299999999999994, 1.807, 0.909, 0.256, 0.782, 0.42999999999999994, 0.4119999999999999, 0.41800000000000015, 1.4539999999999997, 0.6190000000000002, 0.8600000000000001, 0.7850000000000001, 0.469, 0.8300000000000001, 0.7989999999999999, 1.7930000000000001, 0.391, 0.44100000000000006, 0.31600000000000006, 0.28900000000000015, 0.06199999999999983, 0.05699999999999994, 0.7669999999999999, 0.41600000000000015, 0.4790000000000001, 0.9349999999999999, -0.03400000000000003, 1.831, -0.039000000000000035, 0.6339999999999999, 1.384, -0.18700000000000006, 0.2959999999999998, 0.2849999999999999, 0.9140000000000001, 0.7669999999999999, 0.8799999999999999, 0.5609999999999999, 0.5720000000000001, 1.846, 0.872, 0.44399999999999995, 0.6559999999999999, 0.7370000000000001, 0.9020000000000001, -0.050000000000000044, 0.39400000000000013, 0.30500000000000016, 0.81, 0.8300000000000001, 0.7869999999999999, 0.7730000000000001, 1.819, 1.1749999999999998, 0.823, 0.08299999999999996, 0.349, 0.845, 0.29700000000000015, 1.6430000000000002, 0.8159999999999998, 0.4039999999999999], "episode_lengths": [117, 150, 18, 101, 180, 55, 293, 22, 43, 90, 78, 78, 79, 174, 92, 33, 25, 15, 101, 10, 168, 56, 110, 8, 82, 27, 77, 45, 61, 22, 146, 87, 57, 62, 38, 269, 86, 81, 62, 60, 28, 75, 67, 177, 27, 25, 165, 119, 42, 68, 162, 54, 59, 64, 34, 18, 58, 66, 135, 288, 71, 27, 156, 20, 10, 53, 12, 108, 37, 213, 214, 67, 25, 70, 39, 136, 130, 47, 40, 169, 104, 83, 31, 16, 33, 59, 58, 50, 65, 71, 54, 98, 56, 128, 45, 49, 64, 109, 56, 31], "policy_red_0_reward": [0.638, 1.02, 1.4449999999999998, 0.491, 0.478, 1.326, 0.45299999999999996, 0.9329999999999999, 0.494, 1.218, -1.016, -0.508, 1.255, 0.958, 1.216, 1.399, 0.498, 1.455, 1.186, -0.5, 0.9799999999999999, -0.506, 1.158, 0.976, 1.249, 0.915, 0.494, 1.359, 0.493, 0.498, 1.049, 1.2349999999999999, 1.326, 1.308, -0.508, 0.662, -0.511, -0.513, 1.308, 0.493, 1.412, -0.508, 1.295, 0.956, 0.917, 0.921, 0.9789999999999999, 1.131, 1.369, 1.2890000000000001, -0.521, 1.333, 1.311, 0.49, 0.893, 1.4449999999999998, 1.322, 1.294, 1.073, 0.594, 1.282, -0.5009999999999999, 0.999, -0.503, 0.969, 1.333, 0.963, 1.164, -0.002, 0.33999999999999997, 0.829, -0.507, 1.42, 1.278, 1.383, 1.0790000000000002, 1.088, 0.496, -0.503, 0.971, 1.18, 1.242, 1.403, 0.951, 0.9, 1.313, 1.322, 1.341, 1.298, 1.284, 1.33, -0.022000000000000013, 1.33, 1.104, 1.358, -0.504, 1.3010000000000002, 1.161, 1.3239999999999998, 1.405], "policy_blue_0_reward": [-1.013, -1.021, -0.5029999999999999, 1.1800000000000002, 0.949, -0.511, 0.577, -1.005, 1.366, -0.512, 1.2610000000000001, 1.2570000000000001, -0.5089999999999999, -0.532, -0.512, -0.504, 1.424, -0.501, -1.008, 1.4689999999999999, -0.519, 1.326, -1.0159999999999998, -1.0, -0.506, -1.0, 1.2530000000000001, -1.004, 1.3039999999999998, 1.431, -0.5159999999999999, 0.487, -0.007, -0.5109999999999999, 1.3820000000000001, -0.542, 1.229, 1.2469999999999999, -1.005, 1.314, -0.503, 0.764, -0.513, -0.526, -0.505, -0.5029999999999999, 0.475, -0.5119999999999999, -0.5089999999999999, -0.504, 0.99, -0.503, -0.512, 1.303, -0.502, -1.0039999999999998, -1.006, -1.005, -1.011, -0.537, -0.515, 0.917, -0.52, 1.438, -1.003, 0.498, -1.002, -0.53, 1.3860000000000001, -0.527, -0.533, 0.7919999999999999, -0.506, -0.511, -0.503, -0.518, -0.516, 1.35, 1.375, -0.527, -0.524, -0.505, -0.501, -1.001, -0.5059999999999999, -1.0079999999999998, -0.512, -0.511, -0.511, -0.511, 0.489, 1.197, -0.507, -1.021, -1.009, 1.349, -1.004, 0.482, -0.508, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3700228431491308, "mean_inference_ms": 7.424394468445269, "mean_action_processing_ms": 0.3937527450467402, "mean_env_wait_ms": 0.514340637616504, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14781475067138672, "StateBufferConnector_ms": 0.00948953628540039, "ViewRequirementAgentConnector_ms": 0.18786156177520752}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.88704130793283, "num_env_steps_trained_throughput_per_sec": 131.88704130793283, "timesteps_total": 184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 32092.332, "sample_time_ms": 4009.106, "learn_time_ms": 28054.49, "learn_throughput": 142.58, "synch_weights_time_ms": 27.109}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "episodes_total": 1580, "training_iteration": 46, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-21-07", "timestamp": 1694838067, "time_this_iter_s": 30.344310998916626, "time_total_s": 1425.7645366191864, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a21e830>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1425.7645366191864, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 23.306818181818183, "ram_util_percent": 56.95}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.09, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.66, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.18, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.66, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.06, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.18, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.66, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.18, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5804143707578381, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.058762448517760885, "policy_loss": -0.10134622110635974, "vf_loss": 0.024648773439306146, "vf_explained_var": 0.5956973489373922, "kl": 0.013978896436746813, "entropy": 1.586289290462931, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 44640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6011353771512707, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07356739591826529, "policy_loss": -0.1156841325161319, "vf_loss": 0.03197608581879952, "vf_explained_var": 0.5368637854233385, "kl": 0.018303228392778693, "entropy": 1.6693333509067694, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 44640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000}, "sampler_results": {"episode_reward_max": 1.9180000000000001, "episode_reward_min": -0.3360000000000001, "episode_reward_mean": 0.68991, "episode_len_mean": 71.88, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"red_0": -1.009, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.454, "blue_0": 1.467}, "policy_reward_mean": {"red_0": 0.8048700000000001, "blue_0": -0.11495999999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.09, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.66, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.18, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.66, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.06, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.18, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.66, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.18, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.06199999999999983, 0.05699999999999994, 0.7669999999999999, 0.41600000000000015, 0.4790000000000001, 0.9349999999999999, -0.03400000000000003, 1.831, -0.039000000000000035, 0.6339999999999999, 1.384, -0.18700000000000006, 0.2959999999999998, 0.2849999999999999, 0.9140000000000001, 0.7669999999999999, 0.8799999999999999, 0.5609999999999999, 0.5720000000000001, 1.846, 0.872, 0.44399999999999995, 0.6559999999999999, 0.7370000000000001, 0.9020000000000001, -0.050000000000000044, 0.39400000000000013, 0.30500000000000016, 0.81, 0.8300000000000001, 0.7869999999999999, 0.7730000000000001, 1.819, 1.1749999999999998, 0.823, 0.08299999999999996, 0.349, 0.845, 0.29700000000000015, 1.6430000000000002, 0.8159999999999998, 0.4039999999999999, 0.873, 0.849, -0.049000000000000044, 0.45299999999999985, 0.7549999999999999, 0.42799999999999994, 0.835, 1.8820000000000001, 0.9359999999999999, 0.3500000000000001, 0.7639999999999998, 0.3610000000000002, 0.387, 1.733, 0.825, 0.9140000000000001, 0.32200000000000006, 0.7930000000000001, 0.7309999999999999, 0.5489999999999999, 1.9180000000000001, 1.787, -0.3360000000000001, 0.46699999999999997, 0.43199999999999994, -0.05399999999999994, 0.8500000000000001, 1.857, 0.33099999999999996, -0.05300000000000005, 0.387, 1.847, 1.698, 0.22100000000000009, 0.45299999999999985, 0.8160000000000001, 0.365, 0.919, 0.20000000000000007, 0.6299999999999999, 0.8799999999999999, 0.9249999999999999, 0.7450000000000001, -0.279, 0.7879999999999998, 0.365, -0.1110000000000001, 0.8710000000000001, -0.20200000000000007, 0.373, 0.52, 0.43799999999999994, 0.29800000000000004, 0.4810000000000001, 1.859, 1.911, 0.7579999999999999, 0.8049999999999999], "episode_lengths": [135, 288, 71, 27, 156, 20, 10, 53, 12, 108, 37, 213, 214, 67, 25, 70, 39, 136, 130, 47, 40, 169, 104, 83, 31, 16, 33, 59, 58, 50, 65, 71, 54, 98, 56, 128, 45, 49, 64, 109, 56, 31, 38, 47, 15, 166, 76, 300, 50, 37, 19, 45, 73, 44, 34, 84, 55, 27, 53, 64, 84, 139, 26, 67, 106, 11, 19, 16, 47, 45, 53, 17, 34, 48, 93, 238, 15, 56, 42, 25, 95, 112, 37, 24, 78, 87, 65, 40, 186, 41, 63, 38, 146, 19, 63, 156, 43, 28, 73, 59], "policy_red_0_reward": [1.073, 0.594, 1.282, -0.5009999999999999, 0.999, -0.503, 0.969, 1.333, 0.963, 1.164, -0.002, 0.33999999999999997, 0.829, -0.507, 1.42, 1.278, 1.383, 1.0790000000000002, 1.088, 0.496, -0.503, 0.971, 1.18, 1.242, 1.403, 0.951, 0.9, 1.313, 1.322, 1.341, 1.298, 1.284, 1.33, -0.022000000000000013, 1.33, 1.104, 1.358, -0.504, 1.3010000000000002, 1.161, 1.3239999999999998, 1.405, 1.383, -0.504, 0.954, 0.975, 1.263, 0.44999999999999996, 1.342, 1.3860000000000001, 1.44, 0.857, 1.2759999999999998, 1.365, 1.391, 1.24, -0.502, 1.417, 0.835, 1.302, 1.24, 1.0659999999999998, 1.421, 1.295, 0.6709999999999999, -1.0, 1.438, 0.95, 1.357, 1.3599999999999999, 0.836, -1.0, -0.503, 0.498, 1.209, 0.754, 1.454, -0.5059999999999999, 1.37, 1.4220000000000002, -1.009, -0.516, 1.385, -0.5, 1.2530000000000001, -1.006, 1.295, 1.373, -0.537, -0.5019999999999999, 0.8049999999999999, 1.379, 1.039, 1.443, 1.306, 1.0150000000000001, 0.491, 0.498, -0.508, 1.315], "policy_blue_0_reward": [-1.011, -0.537, -0.515, 0.917, -0.52, 1.438, -1.003, 0.498, -1.002, -0.53, 1.3860000000000001, -0.527, -0.533, 0.7919999999999999, -0.506, -0.511, -0.503, -0.518, -0.516, 1.35, 1.375, -0.527, -0.524, -0.505, -0.501, -1.001, -0.5059999999999999, -1.0079999999999998, -0.512, -0.511, -0.511, -0.511, 0.489, 1.197, -0.507, -1.021, -1.009, 1.349, -1.004, 0.482, -0.508, -1.001, -0.51, 1.353, -1.003, -0.522, -0.508, -0.022000000000000013, -0.5069999999999999, 0.496, -0.504, -0.507, -0.512, -1.0039999999999998, -1.004, 0.493, 1.327, -0.503, -0.513, -0.5089999999999999, -0.509, -0.517, 0.497, 0.492, -1.007, 1.467, -1.006, -1.0039999999999998, -0.507, 0.497, -0.505, 0.947, 0.89, 1.349, 0.489, -0.533, -1.001, 1.322, -1.005, -0.503, 1.209, 1.146, -0.505, 1.4249999999999998, -0.508, 0.727, -0.507, -1.008, 0.42599999999999993, 1.373, -1.007, -1.006, -0.519, -1.005, -1.008, -0.5339999999999999, 1.3679999999999999, 1.413, 1.266, -0.51]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3691483578722197, "mean_inference_ms": 7.423502744607233, "mean_action_processing_ms": 0.39254753017511634, "mean_env_wait_ms": 0.5146972815692531, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1453862190246582, "StateBufferConnector_ms": 0.009137749671936035, "ViewRequirementAgentConnector_ms": 0.18352043628692627}}, "episode_reward_max": 1.9180000000000001, "episode_reward_min": -0.3360000000000001, "episode_reward_mean": 0.68991, "episode_len_mean": 71.88, "episodes_this_iter": 58, "policy_reward_min": {"red_0": -1.009, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.454, "blue_0": 1.467}, "policy_reward_mean": {"red_0": 0.8048700000000001, "blue_0": -0.11495999999999999}, "hist_stats": {"episode_reward": [0.06199999999999983, 0.05699999999999994, 0.7669999999999999, 0.41600000000000015, 0.4790000000000001, 0.9349999999999999, -0.03400000000000003, 1.831, -0.039000000000000035, 0.6339999999999999, 1.384, -0.18700000000000006, 0.2959999999999998, 0.2849999999999999, 0.9140000000000001, 0.7669999999999999, 0.8799999999999999, 0.5609999999999999, 0.5720000000000001, 1.846, 0.872, 0.44399999999999995, 0.6559999999999999, 0.7370000000000001, 0.9020000000000001, -0.050000000000000044, 0.39400000000000013, 0.30500000000000016, 0.81, 0.8300000000000001, 0.7869999999999999, 0.7730000000000001, 1.819, 1.1749999999999998, 0.823, 0.08299999999999996, 0.349, 0.845, 0.29700000000000015, 1.6430000000000002, 0.8159999999999998, 0.4039999999999999, 0.873, 0.849, -0.049000000000000044, 0.45299999999999985, 0.7549999999999999, 0.42799999999999994, 0.835, 1.8820000000000001, 0.9359999999999999, 0.3500000000000001, 0.7639999999999998, 0.3610000000000002, 0.387, 1.733, 0.825, 0.9140000000000001, 0.32200000000000006, 0.7930000000000001, 0.7309999999999999, 0.5489999999999999, 1.9180000000000001, 1.787, -0.3360000000000001, 0.46699999999999997, 0.43199999999999994, -0.05399999999999994, 0.8500000000000001, 1.857, 0.33099999999999996, -0.05300000000000005, 0.387, 1.847, 1.698, 0.22100000000000009, 0.45299999999999985, 0.8160000000000001, 0.365, 0.919, 0.20000000000000007, 0.6299999999999999, 0.8799999999999999, 0.9249999999999999, 0.7450000000000001, -0.279, 0.7879999999999998, 0.365, -0.1110000000000001, 0.8710000000000001, -0.20200000000000007, 0.373, 0.52, 0.43799999999999994, 0.29800000000000004, 0.4810000000000001, 1.859, 1.911, 0.7579999999999999, 0.8049999999999999], "episode_lengths": [135, 288, 71, 27, 156, 20, 10, 53, 12, 108, 37, 213, 214, 67, 25, 70, 39, 136, 130, 47, 40, 169, 104, 83, 31, 16, 33, 59, 58, 50, 65, 71, 54, 98, 56, 128, 45, 49, 64, 109, 56, 31, 38, 47, 15, 166, 76, 300, 50, 37, 19, 45, 73, 44, 34, 84, 55, 27, 53, 64, 84, 139, 26, 67, 106, 11, 19, 16, 47, 45, 53, 17, 34, 48, 93, 238, 15, 56, 42, 25, 95, 112, 37, 24, 78, 87, 65, 40, 186, 41, 63, 38, 146, 19, 63, 156, 43, 28, 73, 59], "policy_red_0_reward": [1.073, 0.594, 1.282, -0.5009999999999999, 0.999, -0.503, 0.969, 1.333, 0.963, 1.164, -0.002, 0.33999999999999997, 0.829, -0.507, 1.42, 1.278, 1.383, 1.0790000000000002, 1.088, 0.496, -0.503, 0.971, 1.18, 1.242, 1.403, 0.951, 0.9, 1.313, 1.322, 1.341, 1.298, 1.284, 1.33, -0.022000000000000013, 1.33, 1.104, 1.358, -0.504, 1.3010000000000002, 1.161, 1.3239999999999998, 1.405, 1.383, -0.504, 0.954, 0.975, 1.263, 0.44999999999999996, 1.342, 1.3860000000000001, 1.44, 0.857, 1.2759999999999998, 1.365, 1.391, 1.24, -0.502, 1.417, 0.835, 1.302, 1.24, 1.0659999999999998, 1.421, 1.295, 0.6709999999999999, -1.0, 1.438, 0.95, 1.357, 1.3599999999999999, 0.836, -1.0, -0.503, 0.498, 1.209, 0.754, 1.454, -0.5059999999999999, 1.37, 1.4220000000000002, -1.009, -0.516, 1.385, -0.5, 1.2530000000000001, -1.006, 1.295, 1.373, -0.537, -0.5019999999999999, 0.8049999999999999, 1.379, 1.039, 1.443, 1.306, 1.0150000000000001, 0.491, 0.498, -0.508, 1.315], "policy_blue_0_reward": [-1.011, -0.537, -0.515, 0.917, -0.52, 1.438, -1.003, 0.498, -1.002, -0.53, 1.3860000000000001, -0.527, -0.533, 0.7919999999999999, -0.506, -0.511, -0.503, -0.518, -0.516, 1.35, 1.375, -0.527, -0.524, -0.505, -0.501, -1.001, -0.5059999999999999, -1.0079999999999998, -0.512, -0.511, -0.511, -0.511, 0.489, 1.197, -0.507, -1.021, -1.009, 1.349, -1.004, 0.482, -0.508, -1.001, -0.51, 1.353, -1.003, -0.522, -0.508, -0.022000000000000013, -0.5069999999999999, 0.496, -0.504, -0.507, -0.512, -1.0039999999999998, -1.004, 0.493, 1.327, -0.503, -0.513, -0.5089999999999999, -0.509, -0.517, 0.497, 0.492, -1.007, 1.467, -1.006, -1.0039999999999998, -0.507, 0.497, -0.505, 0.947, 0.89, 1.349, 0.489, -0.533, -1.001, 1.322, -1.005, -0.503, 1.209, 1.146, -0.505, 1.4249999999999998, -0.508, 0.727, -0.507, -1.008, 0.42599999999999993, 1.373, -1.007, -1.006, -0.519, -1.005, -1.008, -0.5339999999999999, 1.3679999999999999, 1.413, 1.266, -0.51]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3691483578722197, "mean_inference_ms": 7.423502744607233, "mean_action_processing_ms": 0.39254753017511634, "mean_env_wait_ms": 0.5146972815692531, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1453862190246582, "StateBufferConnector_ms": 0.009137749671936035, "ViewRequirementAgentConnector_ms": 0.18352043628692627}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.14867279283152, "num_env_steps_trained_throughput_per_sec": 131.14867279283152, "timesteps_total": 188000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 376000, "timers": {"training_iteration_time_ms": 32047.304, "sample_time_ms": 4013.383, "learn_time_ms": 28005.161, "learn_throughput": 142.831, "synch_weights_time_ms": 27.162}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000}, "done": false, "episodes_total": 1638, "training_iteration": 47, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-21-38", "timestamp": 1694838098, "time_this_iter_s": 30.514413118362427, "time_total_s": 1456.2789497375488, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80eb8b80>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1456.2789497375488, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 24.84090909090909, "ram_util_percent": 56.96136363636364}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.08, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.65, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.65, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.65, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6285152273563047, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06291629745198103, "policy_loss": -0.10662881435928284, "vf_loss": 0.02655854835077965, "vf_explained_var": 0.5506601348519325, "kl": 0.014041456357169106, "entropy": 1.5549511073778073, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 45600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5921366406604648, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07329629413870861, "policy_loss": -0.11852505038683982, "vf_loss": 0.03746949456787358, "vf_explained_var": 0.6022324611743292, "kl": 0.018528716641213805, "entropy": 1.6464788808176916, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 45600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "sampler_results": {"episode_reward_max": 1.951, "episode_reward_min": -0.279, "episode_reward_mean": 0.7641399999999998, "episode_len_mean": 58.85, "episode_media": {}, "episodes_this_iter": 78, "policy_reward_min": {"red_0": -1.017, "blue_0": -1.012}, "policy_reward_max": {"red_0": 1.467, "blue_0": 1.455}, "policy_reward_mean": {"red_0": 0.83603, "blue_0": -0.07188999999999998}, "custom_metrics": {"red_0/door_open_done_mean": 0.08, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.65, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.65, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.65, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.365, 0.919, 0.20000000000000007, 0.6299999999999999, 0.8799999999999999, 0.9249999999999999, 0.7450000000000001, -0.279, 0.7879999999999998, 0.365, -0.1110000000000001, 0.8710000000000001, -0.20200000000000007, 0.373, 0.52, 0.43799999999999994, 0.29800000000000004, 0.4810000000000001, 1.859, 1.911, 0.7579999999999999, 0.8049999999999999, 0.6739999999999999, 0.6800000000000002, 0.7679999999999998, 1.81, -0.08099999999999996, 0.8380000000000001, 0.42399999999999993, 1.282, 1.276, -0.08199999999999996, 0.857, 0.9219999999999999, 0.5549999999999999, 0.347, 0.371, 0.43900000000000006, 1.9, 0.42199999999999993, 0.7400000000000002, 0.772, -0.18600000000000005, 1.901, 0.8980000000000001, -0.04799999999999993, 0.8759999999999999, 0.74, 0.44700000000000006, 1.854, 0.41999999999999993, 0.32899999999999996, 1.4, 0.9670000000000001, 1.351, 0.6699999999999999, -0.06700000000000006, 0.915, 0.9359999999999999, 0.385, 0.9039999999999999, 0.29300000000000015, 0.81, 1.756, 0.8180000000000001, 0.1459999999999999, 0.29499999999999993, 1.121, 0.345, 0.8919999999999999, 0.7869999999999999, 0.4670000000000001, -0.20599999999999996, 1.838, 1.9060000000000001, 0.387, 0.7069999999999999, -0.031000000000000028, 0.8119999999999999, 0.42600000000000016, 0.744, 0.7400000000000002, 1.8479999999999999, 0.278, 0.7600000000000002, 1.951, -0.14400000000000002, 0.835, 1.858, 0.8410000000000002, 0.742, 1.881, -0.09400000000000008, 1.814, 1.917, 1.7610000000000001, 0.8180000000000001, 0.40700000000000003, 0.32699999999999996, 0.4159999999999999], "episode_lengths": [42, 25, 95, 112, 37, 24, 78, 87, 65, 40, 186, 41, 63, 38, 146, 19, 63, 156, 43, 28, 73, 59, 100, 97, 69, 58, 26, 51, 24, 218, 68, 26, 45, 24, 138, 48, 40, 18, 31, 24, 79, 72, 55, 32, 32, 15, 39, 79, 16, 45, 26, 51, 31, 11, 47, 102, 20, 26, 20, 36, 29, 66, 60, 76, 56, 110, 217, 121, 49, 34, 65, 11, 61, 51, 30, 36, 91, 10, 57, 23, 78, 81, 47, 70, 72, 15, 43, 52, 44, 50, 80, 36, 183, 58, 26, 74, 56, 29, 54, 25], "policy_red_0_reward": [1.37, 1.4220000000000002, -1.009, -0.516, 1.385, -0.5, 1.2530000000000001, -1.006, 1.295, 1.373, -0.537, -0.5019999999999999, 0.8049999999999999, 1.379, 1.039, 1.443, 1.306, 1.0150000000000001, 0.491, 0.498, -0.508, 1.315, 1.184, 1.197, 1.282, 0.494, 0.921, 1.345, 1.426, 0.814, -0.009000000000000001, 0.92, 1.361, 1.426, 1.075, -1.008, 1.377, 0.941, 1.404, 0.9259999999999999, 1.2530000000000001, 1.279, 0.821, 0.498, 1.403, -1.0, 1.38, 1.25, 1.45, 0.498, 1.421, 1.337, -0.003, 1.467, 1.355, -0.51, 0.9349999999999999, -0.502, 1.4369999999999998, -1.003, 1.409, 0.797, 1.317, 1.2650000000000001, 1.325, 1.158, 0.815, 1.127, 1.349, 1.396, 1.298, 0.967, -1.017, 1.3439999999999999, 0.498, 0.89, 1.216, 0.969, -0.508, 0.929, 1.2570000000000001, 1.251, 0.495, 1.283, 1.271, 0.496, 0.865, 1.343, 0.495, 1.345, 1.249, 1.385, 0.42799999999999994, 0.491, 0.499, 1.268, 1.3279999999999998, 1.409, 1.33, 0.918], "policy_blue_0_reward": [-1.005, -0.503, 1.209, 1.146, -0.505, 1.4249999999999998, -0.508, 0.727, -0.507, -1.008, 0.42599999999999993, 1.373, -1.007, -1.006, -0.519, -1.005, -1.008, -0.5339999999999999, 1.3679999999999999, 1.413, 1.266, -0.51, -0.5099999999999999, -0.517, -0.514, 1.316, -1.002, -0.507, -1.002, 0.46799999999999997, 1.2850000000000001, -1.002, -0.504, -0.504, -0.52, 1.355, -1.006, -0.5019999999999999, 0.496, -0.504, -0.5129999999999999, -0.507, -1.007, 1.403, -0.505, 0.952, -0.504, -0.51, -1.003, 1.3559999999999999, -1.001, -1.008, 1.403, -0.5, -0.004, 1.18, -1.002, 1.417, -0.501, 1.388, -0.505, -0.504, -0.5069999999999999, 0.491, -0.507, -1.012, -0.5199999999999999, -0.006, -1.004, -0.504, -0.511, -0.5, 0.8109999999999999, 0.494, 1.408, -0.503, -0.509, -1.0, 1.3199999999999998, -0.503, -0.513, -0.5109999999999999, 1.353, -1.005, -0.5109999999999999, 1.455, -1.009, -0.508, 1.363, -0.5039999999999999, -0.507, 0.496, -0.522, 1.323, 1.4180000000000001, 0.493, -0.51, -1.002, -1.003, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3715160825415773, "mean_inference_ms": 7.411470156386794, "mean_action_processing_ms": 0.39165675619329476, "mean_env_wait_ms": 0.5140268421505795, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.18963193893432617, "StateBufferConnector_ms": 0.008870482444763184, "ViewRequirementAgentConnector_ms": 0.18098127841949463}}, "episode_reward_max": 1.951, "episode_reward_min": -0.279, "episode_reward_mean": 0.7641399999999998, "episode_len_mean": 58.85, "episodes_this_iter": 78, "policy_reward_min": {"red_0": -1.017, "blue_0": -1.012}, "policy_reward_max": {"red_0": 1.467, "blue_0": 1.455}, "policy_reward_mean": {"red_0": 0.83603, "blue_0": -0.07188999999999998}, "hist_stats": {"episode_reward": [0.365, 0.919, 0.20000000000000007, 0.6299999999999999, 0.8799999999999999, 0.9249999999999999, 0.7450000000000001, -0.279, 0.7879999999999998, 0.365, -0.1110000000000001, 0.8710000000000001, -0.20200000000000007, 0.373, 0.52, 0.43799999999999994, 0.29800000000000004, 0.4810000000000001, 1.859, 1.911, 0.7579999999999999, 0.8049999999999999, 0.6739999999999999, 0.6800000000000002, 0.7679999999999998, 1.81, -0.08099999999999996, 0.8380000000000001, 0.42399999999999993, 1.282, 1.276, -0.08199999999999996, 0.857, 0.9219999999999999, 0.5549999999999999, 0.347, 0.371, 0.43900000000000006, 1.9, 0.42199999999999993, 0.7400000000000002, 0.772, -0.18600000000000005, 1.901, 0.8980000000000001, -0.04799999999999993, 0.8759999999999999, 0.74, 0.44700000000000006, 1.854, 0.41999999999999993, 0.32899999999999996, 1.4, 0.9670000000000001, 1.351, 0.6699999999999999, -0.06700000000000006, 0.915, 0.9359999999999999, 0.385, 0.9039999999999999, 0.29300000000000015, 0.81, 1.756, 0.8180000000000001, 0.1459999999999999, 0.29499999999999993, 1.121, 0.345, 0.8919999999999999, 0.7869999999999999, 0.4670000000000001, -0.20599999999999996, 1.838, 1.9060000000000001, 0.387, 0.7069999999999999, -0.031000000000000028, 0.8119999999999999, 0.42600000000000016, 0.744, 0.7400000000000002, 1.8479999999999999, 0.278, 0.7600000000000002, 1.951, -0.14400000000000002, 0.835, 1.858, 0.8410000000000002, 0.742, 1.881, -0.09400000000000008, 1.814, 1.917, 1.7610000000000001, 0.8180000000000001, 0.40700000000000003, 0.32699999999999996, 0.4159999999999999], "episode_lengths": [42, 25, 95, 112, 37, 24, 78, 87, 65, 40, 186, 41, 63, 38, 146, 19, 63, 156, 43, 28, 73, 59, 100, 97, 69, 58, 26, 51, 24, 218, 68, 26, 45, 24, 138, 48, 40, 18, 31, 24, 79, 72, 55, 32, 32, 15, 39, 79, 16, 45, 26, 51, 31, 11, 47, 102, 20, 26, 20, 36, 29, 66, 60, 76, 56, 110, 217, 121, 49, 34, 65, 11, 61, 51, 30, 36, 91, 10, 57, 23, 78, 81, 47, 70, 72, 15, 43, 52, 44, 50, 80, 36, 183, 58, 26, 74, 56, 29, 54, 25], "policy_red_0_reward": [1.37, 1.4220000000000002, -1.009, -0.516, 1.385, -0.5, 1.2530000000000001, -1.006, 1.295, 1.373, -0.537, -0.5019999999999999, 0.8049999999999999, 1.379, 1.039, 1.443, 1.306, 1.0150000000000001, 0.491, 0.498, -0.508, 1.315, 1.184, 1.197, 1.282, 0.494, 0.921, 1.345, 1.426, 0.814, -0.009000000000000001, 0.92, 1.361, 1.426, 1.075, -1.008, 1.377, 0.941, 1.404, 0.9259999999999999, 1.2530000000000001, 1.279, 0.821, 0.498, 1.403, -1.0, 1.38, 1.25, 1.45, 0.498, 1.421, 1.337, -0.003, 1.467, 1.355, -0.51, 0.9349999999999999, -0.502, 1.4369999999999998, -1.003, 1.409, 0.797, 1.317, 1.2650000000000001, 1.325, 1.158, 0.815, 1.127, 1.349, 1.396, 1.298, 0.967, -1.017, 1.3439999999999999, 0.498, 0.89, 1.216, 0.969, -0.508, 0.929, 1.2570000000000001, 1.251, 0.495, 1.283, 1.271, 0.496, 0.865, 1.343, 0.495, 1.345, 1.249, 1.385, 0.42799999999999994, 0.491, 0.499, 1.268, 1.3279999999999998, 1.409, 1.33, 0.918], "policy_blue_0_reward": [-1.005, -0.503, 1.209, 1.146, -0.505, 1.4249999999999998, -0.508, 0.727, -0.507, -1.008, 0.42599999999999993, 1.373, -1.007, -1.006, -0.519, -1.005, -1.008, -0.5339999999999999, 1.3679999999999999, 1.413, 1.266, -0.51, -0.5099999999999999, -0.517, -0.514, 1.316, -1.002, -0.507, -1.002, 0.46799999999999997, 1.2850000000000001, -1.002, -0.504, -0.504, -0.52, 1.355, -1.006, -0.5019999999999999, 0.496, -0.504, -0.5129999999999999, -0.507, -1.007, 1.403, -0.505, 0.952, -0.504, -0.51, -1.003, 1.3559999999999999, -1.001, -1.008, 1.403, -0.5, -0.004, 1.18, -1.002, 1.417, -0.501, 1.388, -0.505, -0.504, -0.5069999999999999, 0.491, -0.507, -1.012, -0.5199999999999999, -0.006, -1.004, -0.504, -0.511, -0.5, 0.8109999999999999, 0.494, 1.408, -0.503, -0.509, -1.0, 1.3199999999999998, -0.503, -0.513, -0.5109999999999999, 1.353, -1.005, -0.5109999999999999, 1.455, -1.009, -0.508, 1.363, -0.5039999999999999, -0.507, 0.496, -0.522, 1.323, 1.4180000000000001, 0.493, -0.51, -1.002, -1.003, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3715160825415773, "mean_inference_ms": 7.411470156386794, "mean_action_processing_ms": 0.39165675619329476, "mean_env_wait_ms": 0.5140268421505795, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.18963193893432617, "StateBufferConnector_ms": 0.008870482444763184, "ViewRequirementAgentConnector_ms": 0.18098127841949463}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.1241269625038, "num_env_steps_trained_throughput_per_sec": 131.1241269625038, "timesteps_total": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 31920.315, "sample_time_ms": 4024.209, "learn_time_ms": 27867.204, "learn_throughput": 143.538, "synch_weights_time_ms": 27.256}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "episodes_total": 1716, "training_iteration": 48, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-22-10", "timestamp": 1694838130, "time_this_iter_s": 30.52322220802307, "time_total_s": 1486.802171945572, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a21edd0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1486.802171945572, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 24.197727272727274, "ram_util_percent": 56.99545454545455}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.14, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.57, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.57, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.57, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6339006529810528, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06666990854137111, "policy_loss": -0.11063978267629863, "vf_loss": 0.02435518419370055, "vf_explained_var": 0.5554100432743628, "kl": 0.01465106989864189, "entropy": 1.5846869946767888, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 46560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6045172783235709, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.08137902045540008, "policy_loss": -0.12103153315692908, "vf_loss": 0.027331275240673372, "vf_explained_var": 0.5693922075132529, "kl": 0.018211618255451655, "entropy": 1.672019085412224, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 46560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000}, "sampler_results": {"episode_reward_max": 1.951, "episode_reward_min": -0.2440000000000001, "episode_reward_mean": 0.8822200000000002, "episode_len_mean": 62.13, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"red_0": -1.017, "blue_0": -1.012}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.455}, "policy_reward_mean": {"red_0": 0.84016, "blue_0": 0.042060000000000014}, "custom_metrics": {"red_0/door_open_done_mean": 0.14, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.57, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.57, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.57, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9359999999999999, 0.385, 0.9039999999999999, 0.29300000000000015, 0.81, 1.756, 0.8180000000000001, 0.1459999999999999, 0.29499999999999993, 1.121, 0.345, 0.8919999999999999, 0.7869999999999999, 0.4670000000000001, -0.20599999999999996, 1.838, 1.9060000000000001, 0.387, 0.7069999999999999, -0.031000000000000028, 0.8119999999999999, 0.42600000000000016, 0.744, 0.7400000000000002, 1.8479999999999999, 0.278, 0.7600000000000002, 1.951, -0.14400000000000002, 0.835, 1.858, 0.8410000000000002, 0.742, 1.881, -0.09400000000000008, 1.814, 1.917, 1.7610000000000001, 0.8180000000000001, 0.40700000000000003, 0.32699999999999996, 0.4159999999999999, 0.8989999999999999, 0.3700000000000001, 0.34299999999999997, 1.9140000000000001, 0.909, 0.258, 0.3580000000000001, 0.819, 1.658, 0.938, 0.7690000000000001, 1.626, 1.375, 0.858, 1.9140000000000001, 0.7719999999999998, 0.885, 0.41700000000000004, 0.40700000000000003, 1.877, 0.355, -0.02100000000000002, 1.921, 0.21399999999999997, 1.238, 0.45599999999999996, 0.968, 1.6909999999999998, -0.2440000000000001, 1.901, 0.403, 1.881, 1.603, 1.759, 0.5429999999999999, 0.30900000000000016, 1.702, 0.42300000000000004, 0.917, 1.899, 1.8559999999999999, 0.41700000000000004, 0.585, 1.8319999999999999, 0.841, 0.7490000000000001, 0.746, 0.7030000000000001, 0.3599999999999999, 0.6200000000000001, 0.44999999999999996, 0.97, 0.5390000000000001, 0.7650000000000001, 0.762, 0.381, 0.45299999999999985, 0.41500000000000004], "episode_lengths": [20, 36, 29, 66, 60, 76, 56, 110, 217, 121, 49, 34, 65, 11, 61, 51, 30, 36, 91, 10, 57, 23, 78, 81, 47, 70, 72, 15, 43, 52, 44, 50, 80, 36, 183, 58, 26, 74, 56, 29, 54, 25, 300, 39, 48, 26, 28, 229, 43, 54, 104, 19, 71, 113, 37, 44, 27, 69, 36, 26, 29, 38, 45, 7, 25, 87, 81, 14, 10, 96, 73, 32, 31, 36, 121, 73, 141, 59, 91, 24, 26, 30, 46, 25, 125, 54, 49, 80, 80, 86, 45, 117, 16, 10, 144, 70, 71, 190, 15, 26], "policy_red_0_reward": [1.4369999999999998, -1.003, 1.409, 0.797, 1.317, 1.2650000000000001, 1.325, 1.158, 0.815, 1.127, 1.349, 1.396, 1.298, 0.967, -1.017, 1.3439999999999999, 0.498, 0.89, 1.216, 0.969, -0.508, 0.929, 1.2570000000000001, 1.251, 0.495, 1.283, 1.271, 0.496, 0.865, 1.343, 0.495, 1.345, 1.249, 1.385, 0.42799999999999994, 0.491, 0.499, 1.268, 1.3279999999999998, 1.409, 1.33, 0.918, 0.45399999999999996, 0.878, -0.509, 1.421, 1.413, -0.523, -1.005, 1.326, 0.482, 1.4409999999999998, 1.272, 0.477, -0.006, -0.505, 1.415, 1.283, -0.503, 1.42, 1.4100000000000001, 1.384, 1.358, -1.0, 0.497, -1.01, 1.2469999999999999, -0.501, 1.4689999999999999, 1.2029999999999998, 0.7639999999999999, 0.499, -0.502, 1.385, 1.121, 1.27, 1.0579999999999998, 1.317, 0.491, 1.426, 1.421, 1.4060000000000001, 0.498, -0.505, 1.1099999999999999, 0.497, 1.3439999999999999, 1.256, 1.254, 1.22, 1.362, 1.1360000000000001, 0.952, 1.47, 1.0550000000000002, 1.275, -0.511, 0.902, 0.954, 1.419], "policy_blue_0_reward": [-0.501, 1.388, -0.505, -0.504, -0.5069999999999999, 0.491, -0.507, -1.012, -0.5199999999999999, -0.006, -1.004, -0.504, -0.511, -0.5, 0.8109999999999999, 0.494, 1.408, -0.503, -0.509, -1.0, 1.3199999999999998, -0.503, -0.513, -0.5109999999999999, 1.353, -1.005, -0.5109999999999999, 1.455, -1.009, -0.508, 1.363, -0.5039999999999999, -0.507, 0.496, -0.522, 1.323, 1.4180000000000001, 0.493, -0.51, -1.002, -1.003, -0.502, 0.44499999999999995, -0.508, 0.852, 0.493, -0.504, 0.781, 1.363, -0.507, 1.176, -0.503, -0.503, 1.149, 1.381, 1.363, 0.499, -0.511, 1.388, -1.003, -1.003, 0.493, -1.003, 0.979, 1.424, 1.224, -0.009000000000000001, 0.957, -0.501, 0.488, -1.008, 1.4020000000000001, 0.905, 0.496, 0.482, 0.489, -0.515, -1.0079999999999998, 1.2109999999999999, -1.003, -0.504, 0.493, 1.358, 0.922, -0.5249999999999999, 1.335, -0.503, -0.5069999999999999, -0.508, -0.5169999999999999, -1.002, -0.516, -0.502, -0.5, -0.516, -0.51, 1.2730000000000001, -0.521, -0.501, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3711224748530202, "mean_inference_ms": 7.408400857620491, "mean_action_processing_ms": 0.3906403024174932, "mean_env_wait_ms": 0.5143079059027985, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1529325246810913, "StateBufferConnector_ms": 0.008796215057373047, "ViewRequirementAgentConnector_ms": 0.17576360702514648}}, "episode_reward_max": 1.951, "episode_reward_min": -0.2440000000000001, "episode_reward_mean": 0.8822200000000002, "episode_len_mean": 62.13, "episodes_this_iter": 58, "policy_reward_min": {"red_0": -1.017, "blue_0": -1.012}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.455}, "policy_reward_mean": {"red_0": 0.84016, "blue_0": 0.042060000000000014}, "hist_stats": {"episode_reward": [0.9359999999999999, 0.385, 0.9039999999999999, 0.29300000000000015, 0.81, 1.756, 0.8180000000000001, 0.1459999999999999, 0.29499999999999993, 1.121, 0.345, 0.8919999999999999, 0.7869999999999999, 0.4670000000000001, -0.20599999999999996, 1.838, 1.9060000000000001, 0.387, 0.7069999999999999, -0.031000000000000028, 0.8119999999999999, 0.42600000000000016, 0.744, 0.7400000000000002, 1.8479999999999999, 0.278, 0.7600000000000002, 1.951, -0.14400000000000002, 0.835, 1.858, 0.8410000000000002, 0.742, 1.881, -0.09400000000000008, 1.814, 1.917, 1.7610000000000001, 0.8180000000000001, 0.40700000000000003, 0.32699999999999996, 0.4159999999999999, 0.8989999999999999, 0.3700000000000001, 0.34299999999999997, 1.9140000000000001, 0.909, 0.258, 0.3580000000000001, 0.819, 1.658, 0.938, 0.7690000000000001, 1.626, 1.375, 0.858, 1.9140000000000001, 0.7719999999999998, 0.885, 0.41700000000000004, 0.40700000000000003, 1.877, 0.355, -0.02100000000000002, 1.921, 0.21399999999999997, 1.238, 0.45599999999999996, 0.968, 1.6909999999999998, -0.2440000000000001, 1.901, 0.403, 1.881, 1.603, 1.759, 0.5429999999999999, 0.30900000000000016, 1.702, 0.42300000000000004, 0.917, 1.899, 1.8559999999999999, 0.41700000000000004, 0.585, 1.8319999999999999, 0.841, 0.7490000000000001, 0.746, 0.7030000000000001, 0.3599999999999999, 0.6200000000000001, 0.44999999999999996, 0.97, 0.5390000000000001, 0.7650000000000001, 0.762, 0.381, 0.45299999999999985, 0.41500000000000004], "episode_lengths": [20, 36, 29, 66, 60, 76, 56, 110, 217, 121, 49, 34, 65, 11, 61, 51, 30, 36, 91, 10, 57, 23, 78, 81, 47, 70, 72, 15, 43, 52, 44, 50, 80, 36, 183, 58, 26, 74, 56, 29, 54, 25, 300, 39, 48, 26, 28, 229, 43, 54, 104, 19, 71, 113, 37, 44, 27, 69, 36, 26, 29, 38, 45, 7, 25, 87, 81, 14, 10, 96, 73, 32, 31, 36, 121, 73, 141, 59, 91, 24, 26, 30, 46, 25, 125, 54, 49, 80, 80, 86, 45, 117, 16, 10, 144, 70, 71, 190, 15, 26], "policy_red_0_reward": [1.4369999999999998, -1.003, 1.409, 0.797, 1.317, 1.2650000000000001, 1.325, 1.158, 0.815, 1.127, 1.349, 1.396, 1.298, 0.967, -1.017, 1.3439999999999999, 0.498, 0.89, 1.216, 0.969, -0.508, 0.929, 1.2570000000000001, 1.251, 0.495, 1.283, 1.271, 0.496, 0.865, 1.343, 0.495, 1.345, 1.249, 1.385, 0.42799999999999994, 0.491, 0.499, 1.268, 1.3279999999999998, 1.409, 1.33, 0.918, 0.45399999999999996, 0.878, -0.509, 1.421, 1.413, -0.523, -1.005, 1.326, 0.482, 1.4409999999999998, 1.272, 0.477, -0.006, -0.505, 1.415, 1.283, -0.503, 1.42, 1.4100000000000001, 1.384, 1.358, -1.0, 0.497, -1.01, 1.2469999999999999, -0.501, 1.4689999999999999, 1.2029999999999998, 0.7639999999999999, 0.499, -0.502, 1.385, 1.121, 1.27, 1.0579999999999998, 1.317, 0.491, 1.426, 1.421, 1.4060000000000001, 0.498, -0.505, 1.1099999999999999, 0.497, 1.3439999999999999, 1.256, 1.254, 1.22, 1.362, 1.1360000000000001, 0.952, 1.47, 1.0550000000000002, 1.275, -0.511, 0.902, 0.954, 1.419], "policy_blue_0_reward": [-0.501, 1.388, -0.505, -0.504, -0.5069999999999999, 0.491, -0.507, -1.012, -0.5199999999999999, -0.006, -1.004, -0.504, -0.511, -0.5, 0.8109999999999999, 0.494, 1.408, -0.503, -0.509, -1.0, 1.3199999999999998, -0.503, -0.513, -0.5109999999999999, 1.353, -1.005, -0.5109999999999999, 1.455, -1.009, -0.508, 1.363, -0.5039999999999999, -0.507, 0.496, -0.522, 1.323, 1.4180000000000001, 0.493, -0.51, -1.002, -1.003, -0.502, 0.44499999999999995, -0.508, 0.852, 0.493, -0.504, 0.781, 1.363, -0.507, 1.176, -0.503, -0.503, 1.149, 1.381, 1.363, 0.499, -0.511, 1.388, -1.003, -1.003, 0.493, -1.003, 0.979, 1.424, 1.224, -0.009000000000000001, 0.957, -0.501, 0.488, -1.008, 1.4020000000000001, 0.905, 0.496, 0.482, 0.489, -0.515, -1.0079999999999998, 1.2109999999999999, -1.003, -0.504, 0.493, 1.358, 0.922, -0.5249999999999999, 1.335, -0.503, -0.5069999999999999, -0.508, -0.5169999999999999, -1.002, -0.516, -0.502, -0.5, -0.516, -0.51, 1.2730000000000001, -0.521, -0.501, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3711224748530202, "mean_inference_ms": 7.408400857620491, "mean_action_processing_ms": 0.3906403024174932, "mean_env_wait_ms": 0.5143079059027985, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1529325246810913, "StateBufferConnector_ms": 0.008796215057373047, "ViewRequirementAgentConnector_ms": 0.17576360702514648}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.15863130065088, "num_env_steps_trained_throughput_per_sec": 131.15863130065088, "timesteps_total": 196000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 392000, "timers": {"training_iteration_time_ms": 31860.311, "sample_time_ms": 3994.456, "learn_time_ms": 27837.065, "learn_throughput": 143.693, "synch_weights_time_ms": 27.159}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000}, "done": false, "episodes_total": 1774, "training_iteration": 49, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-22-41", "timestamp": 1694838161, "time_this_iter_s": 30.51227378845215, "time_total_s": 1517.314445734024, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80eb8f70>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1517.314445734024, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 23.971111111111114, "ram_util_percent": 56.964444444444446}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.14, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.57, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.17, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.57, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.17, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.57, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.17, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.627029086711506, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.057922162077738905, "policy_loss": -0.100145449230331, "vf_loss": 0.025753562650061214, "vf_explained_var": 0.5949524031331141, "kl": 0.013569254129068516, "entropy": 1.5659512728452682, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 47520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5814751616989573, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07135696782085385, "policy_loss": -0.11002041030127051, "vf_loss": 0.028857369614706842, "vf_explained_var": 0.6134795016298692, "kl": 0.01706025707506266, "entropy": 1.6755068561683097, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 47520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "sampler_results": {"episode_reward_max": 1.9289999999999998, "episode_reward_min": -0.361, "episode_reward_mean": 0.7954300000000001, "episode_len_mean": 62.97, "episode_media": {}, "episodes_this_iter": 64, "policy_reward_min": {"red_0": -1.01, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.7943499999999999, "blue_0": 0.0010799999999999998}, "custom_metrics": {"red_0/door_open_done_mean": 0.14, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.57, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.17, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.57, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.17, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.57, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.17, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.921, 0.21399999999999997, 1.238, 0.45599999999999996, 0.968, 1.6909999999999998, -0.2440000000000001, 1.901, 0.403, 1.881, 1.603, 1.759, 0.5429999999999999, 0.30900000000000016, 1.702, 0.42300000000000004, 0.917, 1.899, 1.8559999999999999, 0.41700000000000004, 0.585, 1.8319999999999999, 0.841, 0.7490000000000001, 0.746, 0.7030000000000001, 0.3599999999999999, 0.6200000000000001, 0.44999999999999996, 0.97, 0.5390000000000001, 0.7650000000000001, 0.762, 0.381, 0.45299999999999985, 0.41500000000000004, 1.841, 0.394, 1.915, 1.432, 0.76, -0.11499999999999988, 0.18300000000000005, 1.9289999999999998, 0.829, 1.377, 0.44599999999999995, -0.09999999999999998, 0.3999999999999999, 0.47, 0.3610000000000002, 0.8820000000000001, 0.887, 0.42300000000000004, -0.07999999999999996, 1.021, 1.8599999999999999, 0.32699999999999996, 0.7309999999999999, 0.45099999999999996, 0.897, 1.387, 0.5269999999999999, 0.8340000000000001, 0.5640000000000001, 1.799, 0.42399999999999993, 0.43399999999999994, 0.41800000000000004, 0.6539999999999999, 0.859, 0.9409999999999998, 0.40600000000000014, 0.5059999999999999, 0.689, 0.6679999999999999, 0.35599999999999987, 0.17499999999999982, 0.41400000000000003, 0.7210000000000001, 0.3919999999999999, 1.871, 0.953, -0.131, 0.3500000000000001, -0.09699999999999998, 0.365, 0.45799999999999996, 1.2559999999999998, 0.788, 0.41500000000000004, 1.857, 0.942, 1.7999999999999998, 0.34799999999999986, 0.698, 1.444, 0.41400000000000003, -0.361, 0.45599999999999996], "episode_lengths": [25, 87, 81, 14, 10, 96, 73, 32, 31, 36, 121, 73, 141, 59, 91, 24, 26, 30, 46, 25, 125, 54, 49, 80, 80, 86, 45, 117, 16, 10, 144, 70, 71, 190, 15, 26, 49, 33, 26, 21, 76, 34, 95, 22, 53, 38, 17, 32, 30, 10, 39, 37, 35, 24, 25, 300, 41, 52, 80, 16, 31, 36, 145, 50, 136, 62, 24, 20, 26, 104, 43, 19, 30, 152, 96, 104, 200, 257, 26, 86, 34, 38, 166, 41, 48, 29, 42, 13, 227, 64, 27, 45, 18, 63, 47, 92, 18, 26, 114, 14], "policy_red_0_reward": [0.497, -1.01, 1.2469999999999999, -0.501, 1.4689999999999999, 1.2029999999999998, 0.7639999999999999, 0.499, -0.502, 1.385, 1.121, 1.27, 1.0579999999999998, 1.317, 0.491, 1.426, 1.421, 1.4060000000000001, 0.498, -0.505, 1.1099999999999999, 0.497, 1.3439999999999999, 1.256, 1.254, 1.22, 1.362, 1.1360000000000001, 0.952, 1.47, 1.0550000000000002, 1.275, -0.511, 0.902, 0.954, 1.419, 1.347, -0.502, 0.496, 1.436, 1.2650000000000001, 0.893, 1.202, 0.496, 1.337, 1.383, 0.948, 0.902, 1.407, 0.97, 1.375, 1.389, 1.392, 1.426, 0.923, 0.45999999999999996, 1.3719999999999999, 1.338, 1.249, -0.5, -0.504, -0.002, -0.523, 1.3439999999999999, 1.081, 0.496, 0.9269999999999999, 1.4369999999999998, -0.502, 1.178, 1.362, 1.442, 0.908, -0.521, -0.506, 1.176, 0.881, 0.702, -1.004, 1.233, 1.393, 1.38, 0.981, 0.875, 1.354, 0.908, 1.3719999999999999, -1.003, 0.7869999999999999, 1.299, 1.417, 0.497, -0.502, 1.303, 0.855, 1.213, -0.001, -0.503, -1.006, 0.958], "policy_blue_0_reward": [1.424, 1.224, -0.009000000000000001, 0.957, -0.501, 0.488, -1.008, 1.4020000000000001, 0.905, 0.496, 0.482, 0.489, -0.515, -1.0079999999999998, 1.2109999999999999, -1.003, -0.504, 0.493, 1.358, 0.922, -0.5249999999999999, 1.335, -0.503, -0.5069999999999999, -0.508, -0.5169999999999999, -1.002, -0.516, -0.502, -0.5, -0.516, -0.51, 1.2730000000000001, -0.521, -0.501, -1.004, 0.494, 0.896, 1.419, -0.004, -0.505, -1.0079999999999998, -1.019, 1.4329999999999998, -0.508, -0.006, -0.502, -1.002, -1.007, -0.5, -1.0139999999999998, -0.507, -0.505, -1.003, -1.003, 0.5609999999999999, 0.488, -1.011, -0.518, 0.951, 1.401, 1.389, 1.0499999999999998, -0.51, -0.517, 1.303, -0.503, -1.003, 0.92, -0.524, -0.503, -0.501, -0.502, 1.027, 1.1949999999999998, -0.508, -0.525, -0.527, 1.4180000000000001, -0.512, -1.001, 0.491, -0.028000000000000018, -1.006, -1.004, -1.005, -1.007, 1.4609999999999999, 0.469, -0.511, -1.002, 1.3599999999999999, 1.444, 0.497, -0.507, -0.5149999999999999, 1.4449999999999998, 0.917, 0.6449999999999999, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3677953947129173, "mean_inference_ms": 7.39914855776473, "mean_action_processing_ms": 0.3907777349531123, "mean_env_wait_ms": 0.5134765202315268, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.135550856590271, "StateBufferConnector_ms": 0.008799433708190918, "ViewRequirementAgentConnector_ms": 0.17612099647521973}}, "episode_reward_max": 1.9289999999999998, "episode_reward_min": -0.361, "episode_reward_mean": 0.7954300000000001, "episode_len_mean": 62.97, "episodes_this_iter": 64, "policy_reward_min": {"red_0": -1.01, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.7943499999999999, "blue_0": 0.0010799999999999998}, "hist_stats": {"episode_reward": [1.921, 0.21399999999999997, 1.238, 0.45599999999999996, 0.968, 1.6909999999999998, -0.2440000000000001, 1.901, 0.403, 1.881, 1.603, 1.759, 0.5429999999999999, 0.30900000000000016, 1.702, 0.42300000000000004, 0.917, 1.899, 1.8559999999999999, 0.41700000000000004, 0.585, 1.8319999999999999, 0.841, 0.7490000000000001, 0.746, 0.7030000000000001, 0.3599999999999999, 0.6200000000000001, 0.44999999999999996, 0.97, 0.5390000000000001, 0.7650000000000001, 0.762, 0.381, 0.45299999999999985, 0.41500000000000004, 1.841, 0.394, 1.915, 1.432, 0.76, -0.11499999999999988, 0.18300000000000005, 1.9289999999999998, 0.829, 1.377, 0.44599999999999995, -0.09999999999999998, 0.3999999999999999, 0.47, 0.3610000000000002, 0.8820000000000001, 0.887, 0.42300000000000004, -0.07999999999999996, 1.021, 1.8599999999999999, 0.32699999999999996, 0.7309999999999999, 0.45099999999999996, 0.897, 1.387, 0.5269999999999999, 0.8340000000000001, 0.5640000000000001, 1.799, 0.42399999999999993, 0.43399999999999994, 0.41800000000000004, 0.6539999999999999, 0.859, 0.9409999999999998, 0.40600000000000014, 0.5059999999999999, 0.689, 0.6679999999999999, 0.35599999999999987, 0.17499999999999982, 0.41400000000000003, 0.7210000000000001, 0.3919999999999999, 1.871, 0.953, -0.131, 0.3500000000000001, -0.09699999999999998, 0.365, 0.45799999999999996, 1.2559999999999998, 0.788, 0.41500000000000004, 1.857, 0.942, 1.7999999999999998, 0.34799999999999986, 0.698, 1.444, 0.41400000000000003, -0.361, 0.45599999999999996], "episode_lengths": [25, 87, 81, 14, 10, 96, 73, 32, 31, 36, 121, 73, 141, 59, 91, 24, 26, 30, 46, 25, 125, 54, 49, 80, 80, 86, 45, 117, 16, 10, 144, 70, 71, 190, 15, 26, 49, 33, 26, 21, 76, 34, 95, 22, 53, 38, 17, 32, 30, 10, 39, 37, 35, 24, 25, 300, 41, 52, 80, 16, 31, 36, 145, 50, 136, 62, 24, 20, 26, 104, 43, 19, 30, 152, 96, 104, 200, 257, 26, 86, 34, 38, 166, 41, 48, 29, 42, 13, 227, 64, 27, 45, 18, 63, 47, 92, 18, 26, 114, 14], "policy_red_0_reward": [0.497, -1.01, 1.2469999999999999, -0.501, 1.4689999999999999, 1.2029999999999998, 0.7639999999999999, 0.499, -0.502, 1.385, 1.121, 1.27, 1.0579999999999998, 1.317, 0.491, 1.426, 1.421, 1.4060000000000001, 0.498, -0.505, 1.1099999999999999, 0.497, 1.3439999999999999, 1.256, 1.254, 1.22, 1.362, 1.1360000000000001, 0.952, 1.47, 1.0550000000000002, 1.275, -0.511, 0.902, 0.954, 1.419, 1.347, -0.502, 0.496, 1.436, 1.2650000000000001, 0.893, 1.202, 0.496, 1.337, 1.383, 0.948, 0.902, 1.407, 0.97, 1.375, 1.389, 1.392, 1.426, 0.923, 0.45999999999999996, 1.3719999999999999, 1.338, 1.249, -0.5, -0.504, -0.002, -0.523, 1.3439999999999999, 1.081, 0.496, 0.9269999999999999, 1.4369999999999998, -0.502, 1.178, 1.362, 1.442, 0.908, -0.521, -0.506, 1.176, 0.881, 0.702, -1.004, 1.233, 1.393, 1.38, 0.981, 0.875, 1.354, 0.908, 1.3719999999999999, -1.003, 0.7869999999999999, 1.299, 1.417, 0.497, -0.502, 1.303, 0.855, 1.213, -0.001, -0.503, -1.006, 0.958], "policy_blue_0_reward": [1.424, 1.224, -0.009000000000000001, 0.957, -0.501, 0.488, -1.008, 1.4020000000000001, 0.905, 0.496, 0.482, 0.489, -0.515, -1.0079999999999998, 1.2109999999999999, -1.003, -0.504, 0.493, 1.358, 0.922, -0.5249999999999999, 1.335, -0.503, -0.5069999999999999, -0.508, -0.5169999999999999, -1.002, -0.516, -0.502, -0.5, -0.516, -0.51, 1.2730000000000001, -0.521, -0.501, -1.004, 0.494, 0.896, 1.419, -0.004, -0.505, -1.0079999999999998, -1.019, 1.4329999999999998, -0.508, -0.006, -0.502, -1.002, -1.007, -0.5, -1.0139999999999998, -0.507, -0.505, -1.003, -1.003, 0.5609999999999999, 0.488, -1.011, -0.518, 0.951, 1.401, 1.389, 1.0499999999999998, -0.51, -0.517, 1.303, -0.503, -1.003, 0.92, -0.524, -0.503, -0.501, -0.502, 1.027, 1.1949999999999998, -0.508, -0.525, -0.527, 1.4180000000000001, -0.512, -1.001, 0.491, -0.028000000000000018, -1.006, -1.004, -1.005, -1.007, 1.4609999999999999, 0.469, -0.511, -1.002, 1.3599999999999999, 1.444, 0.497, -0.507, -0.5149999999999999, 1.4449999999999998, 0.917, 0.6449999999999999, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3677953947129173, "mean_inference_ms": 7.39914855776473, "mean_action_processing_ms": 0.3907777349531123, "mean_env_wait_ms": 0.5134765202315268, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.135550856590271, "StateBufferConnector_ms": 0.008799433708190918, "ViewRequirementAgentConnector_ms": 0.17612099647521973}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 134.02223887366722, "num_env_steps_trained_throughput_per_sec": 134.02223887366722, "timesteps_total": 200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 31588.708, "sample_time_ms": 3992.845, "learn_time_ms": 27567.302, "learn_throughput": 145.099, "synch_weights_time_ms": 26.95}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "episodes_total": 1838, "training_iteration": 50, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-23-12", "timestamp": 1694838192, "time_this_iter_s": 29.860610008239746, "time_total_s": 1547.1750557422638, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a21d870>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1547.1750557422638, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 19.972093023255812, "ram_util_percent": 56.94186046511629}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.09, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.59, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.18, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.59, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.18, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.59, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.18, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6265085240205129, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06337588110909564, "policy_loss": -0.10413334009390382, "vf_loss": 0.01771816662173175, "vf_explained_var": 0.5949266510084271, "kl": 0.014692995529888545, "entropy": 1.574105796466271, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 48480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.58581678836296, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07387104365140355, "policy_loss": -0.11240294809103943, "vf_loss": 0.027559823469103625, "vf_explained_var": 0.592741799975435, "kl": 0.017389444379425932, "entropy": 1.6582249647627274, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 48480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000}, "sampler_results": {"episode_reward_max": 1.928, "episode_reward_min": -0.361, "episode_reward_mean": 0.7109500000000001, "episode_len_mean": 73.12, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"red_0": -1.006, "blue_0": -1.012}, "policy_reward_max": {"red_0": 1.446, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.72556, "blue_0": -0.01460999999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.09, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.59, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.18, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.59, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.18, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.59, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.18, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.021, 1.8599999999999999, 0.32699999999999996, 0.7309999999999999, 0.45099999999999996, 0.897, 1.387, 0.5269999999999999, 0.8340000000000001, 0.5640000000000001, 1.799, 0.42399999999999993, 0.43399999999999994, 0.41800000000000004, 0.6539999999999999, 0.859, 0.9409999999999998, 0.40600000000000014, 0.5059999999999999, 0.689, 0.6679999999999999, 0.35599999999999987, 0.17499999999999982, 0.41400000000000003, 0.7210000000000001, 0.3919999999999999, 1.871, 0.953, -0.131, 0.3500000000000001, -0.09699999999999998, 0.365, 0.45799999999999996, 1.2559999999999998, 0.788, 0.41500000000000004, 1.857, 0.942, 1.7999999999999998, 0.34799999999999986, 0.698, 1.444, 0.41400000000000003, -0.361, 0.45599999999999996, 1.7710000000000001, 0.3340000000000001, 0.30899999999999994, 1.361, 1.27, 0.09699999999999998, 0.8979999999999999, 0.33599999999999997, 0.7, 0.9220000000000002, 0.6970000000000001, 0.6759999999999999, 0.18100000000000005, -0.06599999999999995, 0.935, 0.32299999999999995, 0.44599999999999995, 1.342, 0.601, 0.469, 0.44099999999999984, 0.9079999999999999, 0.252, 1.823, 1.916, -0.17600000000000005, 1.454, -0.11299999999999999, 0.43500000000000005, 0.859, 1.6800000000000002, 0.7769999999999999, 0.691, 0.34299999999999997, 0.43699999999999994, -0.07999999999999996, 0.34299999999999997, 0.7389999999999999, 0.397, 0.52, 1.698, 1.865, 1.792, 0.403, 0.7200000000000002, 0.16599999999999993, -0.1299999999999999, 0.8480000000000001, 0.911, 0.9369999999999998, -0.07599999999999996, 1.928, 0.3420000000000001, 0.2120000000000002, -0.050000000000000044], "episode_lengths": [300, 41, 52, 80, 16, 31, 36, 145, 50, 136, 62, 24, 20, 26, 104, 43, 19, 30, 152, 96, 104, 200, 257, 26, 86, 34, 38, 166, 41, 48, 29, 42, 13, 227, 64, 27, 45, 18, 63, 47, 92, 18, 26, 114, 14, 70, 51, 59, 44, 72, 125, 300, 52, 93, 23, 90, 98, 101, 20, 20, 55, 18, 48, 121, 10, 19, 28, 76, 55, 25, 55, 167, 35, 21, 43, 97, 69, 96, 50, 20, 25, 47, 77, 30, 147, 93, 43, 64, 184, 81, 258, 40, 47, 28, 20, 23, 23, 200, 238, 16], "policy_red_0_reward": [0.45999999999999996, 1.3719999999999999, 1.338, 1.249, -0.5, -0.504, -0.002, -0.523, 1.3439999999999999, 1.081, 0.496, 0.9269999999999999, 1.4369999999999998, -0.502, 1.178, 1.362, 1.442, 0.908, -0.521, -0.506, 1.176, 0.881, 0.702, -1.004, 1.233, 1.393, 1.38, 0.981, 0.875, 1.354, 0.908, 1.3719999999999999, -1.003, 0.7869999999999999, 1.299, 1.417, 0.497, -0.502, 1.303, 0.855, 1.213, -0.001, -0.503, -1.006, 0.958, 1.2770000000000001, 1.341, 1.318, 1.366, -0.003, 0.617, 0.43899999999999995, -0.504, 1.2109999999999999, 1.429, 1.221, 1.192, 0.6880000000000001, 0.938, -0.5029999999999999, 1.326, 1.446, -0.008, 1.1179999999999999, -0.501, 0.942, 1.411, 1.264, 1.3319999999999999, 0.496, 0.826, 0.476, 0.89, 1.4369999999999998, 1.366, 0.484, -0.505, -0.513, 1.3479999999999999, -0.502, 0.923, 1.3519999999999999, 1.259, 1.404, 1.044, 0.488, 0.496, 1.303, 0.926, 1.236, 0.689, 0.879, 1.3559999999999999, -0.503, 1.439, 0.93, 0.5, 0.87, 0.752, 0.952], "policy_blue_0_reward": [0.5609999999999999, 0.488, -1.011, -0.518, 0.951, 1.401, 1.389, 1.0499999999999998, -0.51, -0.517, 1.303, -0.503, -1.003, 0.92, -0.524, -0.503, -0.501, -0.502, 1.027, 1.1949999999999998, -0.508, -0.525, -0.527, 1.4180000000000001, -0.512, -1.001, 0.491, -0.028000000000000018, -1.006, -1.004, -1.005, -1.007, 1.4609999999999999, 0.469, -0.511, -1.002, 1.3599999999999999, 1.444, 0.497, -0.507, -0.5149999999999999, 1.4449999999999998, 0.917, 0.6449999999999999, -0.502, 0.494, -1.007, -1.009, -0.005, 1.2730000000000001, -0.52, 0.45899999999999996, 0.84, -0.511, -0.507, -0.524, -0.516, -0.507, -1.0039999999999998, 1.438, -1.003, -1.0, 1.35, -0.517, 0.97, -0.501, -0.503, -1.012, 0.491, 1.42, -1.002, 0.978, -1.003, -1.002, -0.507, 1.1960000000000002, 1.282, 1.204, -1.005, 0.939, -1.003, -1.009, -0.52, -1.007, -0.524, 1.21, 1.369, 0.489, -0.523, -0.5159999999999999, -0.523, -1.009, -0.5079999999999999, 1.4140000000000001, -0.502, -1.006, 1.428, -0.528, -0.5399999999999999, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3677542721566374, "mean_inference_ms": 7.3983884452090765, "mean_action_processing_ms": 0.39080672822116197, "mean_env_wait_ms": 0.5124680058953287, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15006983280181885, "StateBufferConnector_ms": 0.009445905685424805, "ViewRequirementAgentConnector_ms": 0.19200634956359863}}, "episode_reward_max": 1.928, "episode_reward_min": -0.361, "episode_reward_mean": 0.7109500000000001, "episode_len_mean": 73.12, "episodes_this_iter": 55, "policy_reward_min": {"red_0": -1.006, "blue_0": -1.012}, "policy_reward_max": {"red_0": 1.446, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.72556, "blue_0": -0.01460999999999999}, "hist_stats": {"episode_reward": [1.021, 1.8599999999999999, 0.32699999999999996, 0.7309999999999999, 0.45099999999999996, 0.897, 1.387, 0.5269999999999999, 0.8340000000000001, 0.5640000000000001, 1.799, 0.42399999999999993, 0.43399999999999994, 0.41800000000000004, 0.6539999999999999, 0.859, 0.9409999999999998, 0.40600000000000014, 0.5059999999999999, 0.689, 0.6679999999999999, 0.35599999999999987, 0.17499999999999982, 0.41400000000000003, 0.7210000000000001, 0.3919999999999999, 1.871, 0.953, -0.131, 0.3500000000000001, -0.09699999999999998, 0.365, 0.45799999999999996, 1.2559999999999998, 0.788, 0.41500000000000004, 1.857, 0.942, 1.7999999999999998, 0.34799999999999986, 0.698, 1.444, 0.41400000000000003, -0.361, 0.45599999999999996, 1.7710000000000001, 0.3340000000000001, 0.30899999999999994, 1.361, 1.27, 0.09699999999999998, 0.8979999999999999, 0.33599999999999997, 0.7, 0.9220000000000002, 0.6970000000000001, 0.6759999999999999, 0.18100000000000005, -0.06599999999999995, 0.935, 0.32299999999999995, 0.44599999999999995, 1.342, 0.601, 0.469, 0.44099999999999984, 0.9079999999999999, 0.252, 1.823, 1.916, -0.17600000000000005, 1.454, -0.11299999999999999, 0.43500000000000005, 0.859, 1.6800000000000002, 0.7769999999999999, 0.691, 0.34299999999999997, 0.43699999999999994, -0.07999999999999996, 0.34299999999999997, 0.7389999999999999, 0.397, 0.52, 1.698, 1.865, 1.792, 0.403, 0.7200000000000002, 0.16599999999999993, -0.1299999999999999, 0.8480000000000001, 0.911, 0.9369999999999998, -0.07599999999999996, 1.928, 0.3420000000000001, 0.2120000000000002, -0.050000000000000044], "episode_lengths": [300, 41, 52, 80, 16, 31, 36, 145, 50, 136, 62, 24, 20, 26, 104, 43, 19, 30, 152, 96, 104, 200, 257, 26, 86, 34, 38, 166, 41, 48, 29, 42, 13, 227, 64, 27, 45, 18, 63, 47, 92, 18, 26, 114, 14, 70, 51, 59, 44, 72, 125, 300, 52, 93, 23, 90, 98, 101, 20, 20, 55, 18, 48, 121, 10, 19, 28, 76, 55, 25, 55, 167, 35, 21, 43, 97, 69, 96, 50, 20, 25, 47, 77, 30, 147, 93, 43, 64, 184, 81, 258, 40, 47, 28, 20, 23, 23, 200, 238, 16], "policy_red_0_reward": [0.45999999999999996, 1.3719999999999999, 1.338, 1.249, -0.5, -0.504, -0.002, -0.523, 1.3439999999999999, 1.081, 0.496, 0.9269999999999999, 1.4369999999999998, -0.502, 1.178, 1.362, 1.442, 0.908, -0.521, -0.506, 1.176, 0.881, 0.702, -1.004, 1.233, 1.393, 1.38, 0.981, 0.875, 1.354, 0.908, 1.3719999999999999, -1.003, 0.7869999999999999, 1.299, 1.417, 0.497, -0.502, 1.303, 0.855, 1.213, -0.001, -0.503, -1.006, 0.958, 1.2770000000000001, 1.341, 1.318, 1.366, -0.003, 0.617, 0.43899999999999995, -0.504, 1.2109999999999999, 1.429, 1.221, 1.192, 0.6880000000000001, 0.938, -0.5029999999999999, 1.326, 1.446, -0.008, 1.1179999999999999, -0.501, 0.942, 1.411, 1.264, 1.3319999999999999, 0.496, 0.826, 0.476, 0.89, 1.4369999999999998, 1.366, 0.484, -0.505, -0.513, 1.3479999999999999, -0.502, 0.923, 1.3519999999999999, 1.259, 1.404, 1.044, 0.488, 0.496, 1.303, 0.926, 1.236, 0.689, 0.879, 1.3559999999999999, -0.503, 1.439, 0.93, 0.5, 0.87, 0.752, 0.952], "policy_blue_0_reward": [0.5609999999999999, 0.488, -1.011, -0.518, 0.951, 1.401, 1.389, 1.0499999999999998, -0.51, -0.517, 1.303, -0.503, -1.003, 0.92, -0.524, -0.503, -0.501, -0.502, 1.027, 1.1949999999999998, -0.508, -0.525, -0.527, 1.4180000000000001, -0.512, -1.001, 0.491, -0.028000000000000018, -1.006, -1.004, -1.005, -1.007, 1.4609999999999999, 0.469, -0.511, -1.002, 1.3599999999999999, 1.444, 0.497, -0.507, -0.5149999999999999, 1.4449999999999998, 0.917, 0.6449999999999999, -0.502, 0.494, -1.007, -1.009, -0.005, 1.2730000000000001, -0.52, 0.45899999999999996, 0.84, -0.511, -0.507, -0.524, -0.516, -0.507, -1.0039999999999998, 1.438, -1.003, -1.0, 1.35, -0.517, 0.97, -0.501, -0.503, -1.012, 0.491, 1.42, -1.002, 0.978, -1.003, -1.002, -0.507, 1.1960000000000002, 1.282, 1.204, -1.005, 0.939, -1.003, -1.009, -0.52, -1.007, -0.524, 1.21, 1.369, 0.489, -0.523, -0.5159999999999999, -0.523, -1.009, -0.5079999999999999, 1.4140000000000001, -0.502, -1.006, 1.428, -0.528, -0.5399999999999999, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3677542721566374, "mean_inference_ms": 7.3983884452090765, "mean_action_processing_ms": 0.39080672822116197, "mean_env_wait_ms": 0.5124680058953287, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15006983280181885, "StateBufferConnector_ms": 0.009445905685424805, "ViewRequirementAgentConnector_ms": 0.19200634956359863}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 114.32022280034305, "num_env_steps_trained_throughput_per_sec": 114.32022280034305, "timesteps_total": 204000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 408000, "timers": {"training_iteration_time_ms": 31398.427, "sample_time_ms": 3982.553, "learn_time_ms": 27387.364, "learn_throughput": 146.053, "synch_weights_time_ms": 26.901}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000}, "done": false, "episodes_total": 1893, "training_iteration": 51, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-23-48", "timestamp": 1694838228, "time_this_iter_s": 35.00729298591614, "time_total_s": 1582.18234872818, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7239c8b0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1582.18234872818, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 32.001960784313724, "ram_util_percent": 57.01568627450981}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.06, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.65, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.15, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.65, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.15, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.65, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.15, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6122741457695763, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06271444141942387, "policy_loss": -0.10576876909083997, "vf_loss": 0.02713579239352839, "vf_explained_var": 0.5752125324681401, "kl": 0.013621904232654377, "entropy": 1.545969803755482, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 49440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5709802504628897, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07215533948716862, "policy_loss": -0.11344990899815457, "vf_loss": 0.034453849298491455, "vf_explained_var": 0.5947171455870072, "kl": 0.016930686709633845, "entropy": 1.6458338860422372, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 49440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "sampler_results": {"episode_reward_max": 1.9409999999999998, "episode_reward_min": -0.17600000000000005, "episode_reward_mean": 0.75362, "episode_len_mean": 63.19, "episode_media": {}, "episodes_this_iter": 66, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.0199999999999998}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 0.82081, "blue_0": -0.06719000000000001}, "custom_metrics": {"red_0/door_open_done_mean": 0.06, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.65, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.15, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.65, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.15, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.65, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.15, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9079999999999999, 0.252, 1.823, 1.916, -0.17600000000000005, 1.454, -0.11299999999999999, 0.43500000000000005, 0.859, 1.6800000000000002, 0.7769999999999999, 0.691, 0.34299999999999997, 0.43699999999999994, -0.07999999999999996, 0.34299999999999997, 0.7389999999999999, 0.397, 0.52, 1.698, 1.865, 1.792, 0.403, 0.7200000000000002, 0.16599999999999993, -0.1299999999999999, 0.8480000000000001, 0.911, 0.9369999999999998, -0.07599999999999996, 1.928, 0.3420000000000001, 0.2120000000000002, -0.050000000000000044, 0.7809999999999999, 1.9409999999999998, 0.5409999999999999, 1.897, 0.472, 0.347, 0.75, 0.42100000000000004, 0.9119999999999999, -0.10499999999999998, 0.605, 0.2929999999999999, 0.877, 0.8380000000000001, 1.8399999999999999, 0.879, 0.44399999999999995, 0.8009999999999999, 0.42700000000000005, 0.6219999999999999, 1.831, 0.28400000000000003, 0.7869999999999999, 0.42600000000000005, 0.9319999999999999, 0.39800000000000013, 0.33699999999999997, 0.878, 0.97, 0.9409999999999998, 0.871, 0.9319999999999999, 0.8740000000000001, 1.585, 0.8740000000000001, 0.6629999999999998, 0.399, 0.9139999999999999, 0.905, 1.781, 1.9329999999999998, 0.46199999999999997, -0.038999999999999924, 0.44999999999999996, 0.31199999999999983, 0.5259999999999998, 1.548, 0.29499999999999993, 0.26900000000000013, 0.54, 1.585, 0.9279999999999999, 0.401, 0.40600000000000014, 0.847, 0.3799999999999999, 0.4630000000000001, 1.889, 1.8900000000000001, 0.14300000000000024, 0.44999999999999996, 0.902, 0.43100000000000005, 0.251, -0.07799999999999996, 0.242], "episode_lengths": [28, 76, 55, 25, 55, 167, 35, 21, 43, 97, 69, 96, 50, 20, 25, 47, 77, 30, 147, 93, 43, 64, 184, 81, 258, 40, 47, 28, 20, 23, 23, 200, 238, 16, 69, 19, 141, 31, 9, 47, 74, 25, 27, 33, 121, 65, 39, 51, 47, 39, 17, 60, 22, 116, 53, 68, 65, 23, 22, 32, 52, 39, 10, 18, 42, 22, 38, 126, 40, 106, 32, 300, 28, 69, 21, 12, 12, 16, 57, 146, 137, 63, 72, 138, 128, 21, 31, 30, 48, 37, 12, 34, 34, 107, 16, 31, 22, 229, 25, 82], "policy_red_0_reward": [1.411, 1.264, 1.3319999999999999, 0.496, 0.826, 0.476, 0.89, 1.4369999999999998, 1.366, 0.484, -0.505, -0.513, 1.3479999999999999, -0.502, 0.923, 1.3519999999999999, 1.259, 1.404, 1.044, 0.488, 0.496, 1.303, 0.926, 1.236, 0.689, 0.879, 1.3559999999999999, -0.503, 1.439, 0.93, 0.5, 0.87, 0.752, 0.952, 1.287, 1.443, 1.059, 0.498, 1.4729999999999999, 1.353, 1.264, -1.002, 1.413, -1.003, 1.1219999999999999, 0.8009999999999999, 1.3820000000000001, 1.346, 0.493, 1.381, 1.448, 1.311, 1.431, 1.137, 1.3359999999999999, 0.791, 1.298, -0.504, 1.4329999999999998, 1.404, 1.339, -0.502, -0.5, 1.443, -0.501, -0.501, 1.381, 1.097, 1.3780000000000001, 1.169, 0.9, 0.46499999999999997, -0.507, 0.497, 0.498, 0.962, 0.963, 1.451, 1.3239999999999998, 1.043, 0.477, 0.8029999999999999, 0.775, 1.068, 0.488, 1.432, 0.905, 1.409, 1.3519999999999999, 0.885, 0.964, 1.3940000000000001, 0.494, 1.163, -0.502, -0.502, 1.434, -0.531, 0.924, 0.75], "policy_blue_0_reward": [-0.503, -1.012, 0.491, 1.42, -1.002, 0.978, -1.003, -1.002, -0.507, 1.1960000000000002, 1.282, 1.204, -1.005, 0.939, -1.003, -1.009, -0.52, -1.007, -0.524, 1.21, 1.369, 0.489, -0.523, -0.5159999999999999, -0.523, -1.009, -0.5079999999999999, 1.4140000000000001, -0.502, -1.006, 1.428, -0.528, -0.5399999999999999, -1.002, -0.506, 0.498, -0.518, 1.399, -1.001, -1.006, -0.514, 1.423, -0.501, 0.898, -0.517, -0.508, -0.505, -0.508, 1.347, -0.502, -1.0039999999999998, -0.51, -1.004, -0.515, 0.495, -0.507, -0.511, 0.93, -0.501, -1.0059999999999998, -1.002, 1.38, 1.47, -0.502, 1.3719999999999999, 1.4329999999999998, -0.507, 0.488, -0.504, -0.506, -0.501, 0.44899999999999995, 1.412, 1.2839999999999998, 1.435, -0.5, -1.0019999999999998, -1.001, -1.012, -0.517, 1.071, -0.508, -0.506, -0.528, 1.097, -0.504, -0.504, -1.003, -0.505, -0.505, -0.501, 0.495, 1.396, -1.0199999999999998, 0.952, 1.404, -1.003, 0.782, -1.002, -0.508]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.37055100397067, "mean_inference_ms": 7.404036714527467, "mean_action_processing_ms": 0.39130973104511546, "mean_env_wait_ms": 0.5133246808422454, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15525388717651367, "StateBufferConnector_ms": 0.009766101837158203, "ViewRequirementAgentConnector_ms": 0.20312178134918213}}, "episode_reward_max": 1.9409999999999998, "episode_reward_min": -0.17600000000000005, "episode_reward_mean": 0.75362, "episode_len_mean": 63.19, "episodes_this_iter": 66, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.0199999999999998}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 0.82081, "blue_0": -0.06719000000000001}, "hist_stats": {"episode_reward": [0.9079999999999999, 0.252, 1.823, 1.916, -0.17600000000000005, 1.454, -0.11299999999999999, 0.43500000000000005, 0.859, 1.6800000000000002, 0.7769999999999999, 0.691, 0.34299999999999997, 0.43699999999999994, -0.07999999999999996, 0.34299999999999997, 0.7389999999999999, 0.397, 0.52, 1.698, 1.865, 1.792, 0.403, 0.7200000000000002, 0.16599999999999993, -0.1299999999999999, 0.8480000000000001, 0.911, 0.9369999999999998, -0.07599999999999996, 1.928, 0.3420000000000001, 0.2120000000000002, -0.050000000000000044, 0.7809999999999999, 1.9409999999999998, 0.5409999999999999, 1.897, 0.472, 0.347, 0.75, 0.42100000000000004, 0.9119999999999999, -0.10499999999999998, 0.605, 0.2929999999999999, 0.877, 0.8380000000000001, 1.8399999999999999, 0.879, 0.44399999999999995, 0.8009999999999999, 0.42700000000000005, 0.6219999999999999, 1.831, 0.28400000000000003, 0.7869999999999999, 0.42600000000000005, 0.9319999999999999, 0.39800000000000013, 0.33699999999999997, 0.878, 0.97, 0.9409999999999998, 0.871, 0.9319999999999999, 0.8740000000000001, 1.585, 0.8740000000000001, 0.6629999999999998, 0.399, 0.9139999999999999, 0.905, 1.781, 1.9329999999999998, 0.46199999999999997, -0.038999999999999924, 0.44999999999999996, 0.31199999999999983, 0.5259999999999998, 1.548, 0.29499999999999993, 0.26900000000000013, 0.54, 1.585, 0.9279999999999999, 0.401, 0.40600000000000014, 0.847, 0.3799999999999999, 0.4630000000000001, 1.889, 1.8900000000000001, 0.14300000000000024, 0.44999999999999996, 0.902, 0.43100000000000005, 0.251, -0.07799999999999996, 0.242], "episode_lengths": [28, 76, 55, 25, 55, 167, 35, 21, 43, 97, 69, 96, 50, 20, 25, 47, 77, 30, 147, 93, 43, 64, 184, 81, 258, 40, 47, 28, 20, 23, 23, 200, 238, 16, 69, 19, 141, 31, 9, 47, 74, 25, 27, 33, 121, 65, 39, 51, 47, 39, 17, 60, 22, 116, 53, 68, 65, 23, 22, 32, 52, 39, 10, 18, 42, 22, 38, 126, 40, 106, 32, 300, 28, 69, 21, 12, 12, 16, 57, 146, 137, 63, 72, 138, 128, 21, 31, 30, 48, 37, 12, 34, 34, 107, 16, 31, 22, 229, 25, 82], "policy_red_0_reward": [1.411, 1.264, 1.3319999999999999, 0.496, 0.826, 0.476, 0.89, 1.4369999999999998, 1.366, 0.484, -0.505, -0.513, 1.3479999999999999, -0.502, 0.923, 1.3519999999999999, 1.259, 1.404, 1.044, 0.488, 0.496, 1.303, 0.926, 1.236, 0.689, 0.879, 1.3559999999999999, -0.503, 1.439, 0.93, 0.5, 0.87, 0.752, 0.952, 1.287, 1.443, 1.059, 0.498, 1.4729999999999999, 1.353, 1.264, -1.002, 1.413, -1.003, 1.1219999999999999, 0.8009999999999999, 1.3820000000000001, 1.346, 0.493, 1.381, 1.448, 1.311, 1.431, 1.137, 1.3359999999999999, 0.791, 1.298, -0.504, 1.4329999999999998, 1.404, 1.339, -0.502, -0.5, 1.443, -0.501, -0.501, 1.381, 1.097, 1.3780000000000001, 1.169, 0.9, 0.46499999999999997, -0.507, 0.497, 0.498, 0.962, 0.963, 1.451, 1.3239999999999998, 1.043, 0.477, 0.8029999999999999, 0.775, 1.068, 0.488, 1.432, 0.905, 1.409, 1.3519999999999999, 0.885, 0.964, 1.3940000000000001, 0.494, 1.163, -0.502, -0.502, 1.434, -0.531, 0.924, 0.75], "policy_blue_0_reward": [-0.503, -1.012, 0.491, 1.42, -1.002, 0.978, -1.003, -1.002, -0.507, 1.1960000000000002, 1.282, 1.204, -1.005, 0.939, -1.003, -1.009, -0.52, -1.007, -0.524, 1.21, 1.369, 0.489, -0.523, -0.5159999999999999, -0.523, -1.009, -0.5079999999999999, 1.4140000000000001, -0.502, -1.006, 1.428, -0.528, -0.5399999999999999, -1.002, -0.506, 0.498, -0.518, 1.399, -1.001, -1.006, -0.514, 1.423, -0.501, 0.898, -0.517, -0.508, -0.505, -0.508, 1.347, -0.502, -1.0039999999999998, -0.51, -1.004, -0.515, 0.495, -0.507, -0.511, 0.93, -0.501, -1.0059999999999998, -1.002, 1.38, 1.47, -0.502, 1.3719999999999999, 1.4329999999999998, -0.507, 0.488, -0.504, -0.506, -0.501, 0.44899999999999995, 1.412, 1.2839999999999998, 1.435, -0.5, -1.0019999999999998, -1.001, -1.012, -0.517, 1.071, -0.508, -0.506, -0.528, 1.097, -0.504, -0.504, -1.003, -0.505, -0.505, -0.501, 0.495, 1.396, -1.0199999999999998, 0.952, 1.404, -1.003, 0.782, -1.002, -0.508]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.37055100397067, "mean_inference_ms": 7.404036714527467, "mean_action_processing_ms": 0.39130973104511546, "mean_env_wait_ms": 0.5133246808422454, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15525388717651367, "StateBufferConnector_ms": 0.009766101837158203, "ViewRequirementAgentConnector_ms": 0.20312178134918213}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.47278245173075, "num_env_steps_trained_throughput_per_sec": 131.47278245173075, "timesteps_total": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 31199.869, "sample_time_ms": 3946.758, "learn_time_ms": 27224.592, "learn_throughput": 146.926, "synch_weights_time_ms": 26.95}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "episodes_total": 1959, "training_iteration": 52, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-24-19", "timestamp": 1694838259, "time_this_iter_s": 30.440645217895508, "time_total_s": 1612.6229939460754, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a21e830>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1612.6229939460754, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 25.843181818181822, "ram_util_percent": 57.01363636363637}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.08, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.15, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.616612835911413, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06218539046143026, "policy_loss": -0.10659420322093259, "vf_loss": 0.02975679567171028, "vf_explained_var": 0.5842555437237025, "kl": 0.013630246867101192, "entropy": 1.520991692567865, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 50400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6220136199146509, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": -0.07741465128541071, "policy_loss": -0.12458815855886012, "vf_loss": 0.03681088678907448, "vf_explained_var": 0.6076089375962813, "kl": 0.020019404677079626, "entropy": 1.6364065172771614, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 50400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000}, "sampler_results": {"episode_reward_max": 1.9369999999999998, "episode_reward_min": -0.19999999999999996, "episode_reward_mean": 0.79184, "episode_len_mean": 56.12, "episode_media": {}, "episodes_this_iter": 77, "policy_reward_min": {"red_0": -1.013, "blue_0": -1.0199999999999998}, "policy_reward_max": {"red_0": 1.466, "blue_0": 1.4409999999999998}, "policy_reward_mean": {"red_0": 0.7797799999999999, "blue_0": 0.012060000000000013}, "custom_metrics": {"red_0/door_open_done_mean": 0.08, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.15, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.44999999999999996, 0.31199999999999983, 0.5259999999999998, 1.548, 0.29499999999999993, 0.26900000000000013, 0.54, 1.585, 0.9279999999999999, 0.401, 0.40600000000000014, 0.847, 0.3799999999999999, 0.4630000000000001, 1.889, 1.8900000000000001, 0.14300000000000024, 0.44999999999999996, 0.902, 0.43100000000000005, 0.251, -0.07799999999999996, 0.242, 0.373, 0.35199999999999987, 1.8279999999999998, 0.42599999999999993, 0.74, 0.8240000000000001, 1.287, 1.5259999999999998, 0.718, 0.43500000000000005, 1.6139999999999999, 0.246, 0.43399999999999994, 1.871, 0.6719999999999999, 1.8479999999999999, 0.857, 0.8519999999999999, 1.911, 0.387, 0.8319999999999999, 0.8679999999999999, 1.342, 0.46599999999999997, 1.922, 1.818, 0.356, 0.3610000000000002, 0.8519999999999999, 0.9060000000000001, 0.755, -0.17200000000000004, -0.10799999999999998, 0.868, 0.9650000000000001, 0.9119999999999999, 0.746, -0.19999999999999996, 0.391, 0.44599999999999995, 0.4209999999999998, 0.40700000000000003, 1.421, 0.6949999999999998, 0.29500000000000004, 0.43100000000000005, 0.621, 0.29499999999999993, -0.051000000000000045, 0.88, 1.857, 0.909, -0.05800000000000005, 0.236, 0.821, 1.25, 0.41000000000000014, 0.924, 0.939, 0.363, 0.381, -0.05800000000000005, 1.854, 0.32499999999999996, 1.1320000000000001, 0.9239999999999999, 0.827, 0.948, 0.44499999999999984, 0.8959999999999999, 1.853, 0.966, 1.9369999999999998, 0.802, 0.9420000000000002, 1.423, 1.924], "episode_lengths": [16, 57, 146, 137, 63, 72, 138, 128, 21, 31, 30, 48, 37, 12, 34, 34, 107, 16, 31, 22, 229, 25, 82, 39, 47, 55, 24, 78, 54, 223, 143, 87, 21, 120, 77, 21, 40, 102, 46, 45, 45, 28, 35, 51, 40, 48, 164, 24, 55, 44, 42, 45, 29, 76, 53, 33, 42, 11, 27, 80, 62, 34, 17, 24, 29, 25, 92, 62, 22, 119, 61, 16, 36, 43, 29, 18, 80, 55, 76, 28, 23, 19, 42, 36, 18, 44, 55, 112, 300, 53, 17, 18, 32, 46, 11, 20, 61, 19, 24, 24], "policy_red_0_reward": [1.451, 1.3239999999999998, 1.043, 0.477, 0.8029999999999999, 0.775, 1.068, 0.488, 1.432, 0.905, 1.409, 1.3519999999999999, 0.885, 0.964, 1.3940000000000001, 0.494, 1.163, -0.502, -0.502, 1.434, -0.531, 0.924, 0.75, 0.878, 1.354, 1.331, 1.428, 1.256, -0.5079999999999999, 0.8180000000000001, 0.477, 1.2309999999999999, 0.9369999999999999, 0.486, 1.26, -0.5, 0.5, -0.514, 1.354, 1.362, 1.359, 0.497, 1.391, 1.339, 1.3719999999999999, 1.35, 0.988, 0.496, 0.491, -0.504, 0.866, 1.3559999999999999, 1.411, -0.51, 0.835, 0.897, -0.501, 1.466, 1.417, 1.2530000000000001, 0.807, 1.396, 1.448, 0.9249999999999999, 0.91, -0.002, 1.209, -1.01, 0.9329999999999999, 1.129, 0.813, 0.95, -0.505, 0.494, -0.502, -1.001, -1.013, 1.325, -0.008, 0.916, -0.503, -0.502, 1.3679999999999999, 1.3860000000000001, 0.945, 0.493, 1.329, 1.156, 0.46399999999999997, 1.335, 1.4489999999999998, 1.4449999999999998, 1.4, 0.497, 1.466, 1.439, 1.311, 1.443, -0.002, 1.426], "policy_blue_0_reward": [-1.001, -1.012, -0.517, 1.071, -0.508, -0.506, -0.528, 1.097, -0.504, -0.504, -1.003, -0.505, -0.505, -0.501, 0.495, 1.396, -1.0199999999999998, 0.952, 1.404, -1.003, 0.782, -1.002, -0.508, -0.505, -1.002, 0.497, -1.002, -0.516, 1.3319999999999999, 0.469, 1.049, -0.513, -0.502, 1.128, -1.014, 0.9339999999999999, 1.371, 1.186, 0.494, -0.505, -0.507, 1.4140000000000001, -1.004, -0.507, -0.504, -0.008, -0.522, 1.426, 1.327, 0.86, -0.5049999999999999, -0.504, -0.505, 1.2650000000000001, -1.007, -1.005, 1.369, -0.5009999999999999, -0.505, -0.5069999999999999, -1.007, -1.005, -1.002, -0.504, -0.503, 1.423, -0.514, 1.3050000000000002, -0.502, -0.508, -0.5179999999999999, -1.001, 1.385, 1.363, 1.411, 0.943, 1.249, -0.504, 1.258, -0.506, 1.427, 1.4409999999999998, -1.005, -1.005, -1.003, 1.361, -1.004, -0.024000000000000014, 0.45999999999999996, -0.508, -0.5009999999999999, -1.0, -0.504, 1.3559999999999999, -0.5, 0.498, -0.509, -0.5009999999999999, 1.4249999999999998, 0.498]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3740587301695124, "mean_inference_ms": 7.396699887828979, "mean_action_processing_ms": 0.3895514116659482, "mean_env_wait_ms": 0.5147208696343728, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15381038188934326, "StateBufferConnector_ms": 0.00927591323852539, "ViewRequirementAgentConnector_ms": 0.18840086460113525}}, "episode_reward_max": 1.9369999999999998, "episode_reward_min": -0.19999999999999996, "episode_reward_mean": 0.79184, "episode_len_mean": 56.12, "episodes_this_iter": 77, "policy_reward_min": {"red_0": -1.013, "blue_0": -1.0199999999999998}, "policy_reward_max": {"red_0": 1.466, "blue_0": 1.4409999999999998}, "policy_reward_mean": {"red_0": 0.7797799999999999, "blue_0": 0.012060000000000013}, "hist_stats": {"episode_reward": [0.44999999999999996, 0.31199999999999983, 0.5259999999999998, 1.548, 0.29499999999999993, 0.26900000000000013, 0.54, 1.585, 0.9279999999999999, 0.401, 0.40600000000000014, 0.847, 0.3799999999999999, 0.4630000000000001, 1.889, 1.8900000000000001, 0.14300000000000024, 0.44999999999999996, 0.902, 0.43100000000000005, 0.251, -0.07799999999999996, 0.242, 0.373, 0.35199999999999987, 1.8279999999999998, 0.42599999999999993, 0.74, 0.8240000000000001, 1.287, 1.5259999999999998, 0.718, 0.43500000000000005, 1.6139999999999999, 0.246, 0.43399999999999994, 1.871, 0.6719999999999999, 1.8479999999999999, 0.857, 0.8519999999999999, 1.911, 0.387, 0.8319999999999999, 0.8679999999999999, 1.342, 0.46599999999999997, 1.922, 1.818, 0.356, 0.3610000000000002, 0.8519999999999999, 0.9060000000000001, 0.755, -0.17200000000000004, -0.10799999999999998, 0.868, 0.9650000000000001, 0.9119999999999999, 0.746, -0.19999999999999996, 0.391, 0.44599999999999995, 0.4209999999999998, 0.40700000000000003, 1.421, 0.6949999999999998, 0.29500000000000004, 0.43100000000000005, 0.621, 0.29499999999999993, -0.051000000000000045, 0.88, 1.857, 0.909, -0.05800000000000005, 0.236, 0.821, 1.25, 0.41000000000000014, 0.924, 0.939, 0.363, 0.381, -0.05800000000000005, 1.854, 0.32499999999999996, 1.1320000000000001, 0.9239999999999999, 0.827, 0.948, 0.44499999999999984, 0.8959999999999999, 1.853, 0.966, 1.9369999999999998, 0.802, 0.9420000000000002, 1.423, 1.924], "episode_lengths": [16, 57, 146, 137, 63, 72, 138, 128, 21, 31, 30, 48, 37, 12, 34, 34, 107, 16, 31, 22, 229, 25, 82, 39, 47, 55, 24, 78, 54, 223, 143, 87, 21, 120, 77, 21, 40, 102, 46, 45, 45, 28, 35, 51, 40, 48, 164, 24, 55, 44, 42, 45, 29, 76, 53, 33, 42, 11, 27, 80, 62, 34, 17, 24, 29, 25, 92, 62, 22, 119, 61, 16, 36, 43, 29, 18, 80, 55, 76, 28, 23, 19, 42, 36, 18, 44, 55, 112, 300, 53, 17, 18, 32, 46, 11, 20, 61, 19, 24, 24], "policy_red_0_reward": [1.451, 1.3239999999999998, 1.043, 0.477, 0.8029999999999999, 0.775, 1.068, 0.488, 1.432, 0.905, 1.409, 1.3519999999999999, 0.885, 0.964, 1.3940000000000001, 0.494, 1.163, -0.502, -0.502, 1.434, -0.531, 0.924, 0.75, 0.878, 1.354, 1.331, 1.428, 1.256, -0.5079999999999999, 0.8180000000000001, 0.477, 1.2309999999999999, 0.9369999999999999, 0.486, 1.26, -0.5, 0.5, -0.514, 1.354, 1.362, 1.359, 0.497, 1.391, 1.339, 1.3719999999999999, 1.35, 0.988, 0.496, 0.491, -0.504, 0.866, 1.3559999999999999, 1.411, -0.51, 0.835, 0.897, -0.501, 1.466, 1.417, 1.2530000000000001, 0.807, 1.396, 1.448, 0.9249999999999999, 0.91, -0.002, 1.209, -1.01, 0.9329999999999999, 1.129, 0.813, 0.95, -0.505, 0.494, -0.502, -1.001, -1.013, 1.325, -0.008, 0.916, -0.503, -0.502, 1.3679999999999999, 1.3860000000000001, 0.945, 0.493, 1.329, 1.156, 0.46399999999999997, 1.335, 1.4489999999999998, 1.4449999999999998, 1.4, 0.497, 1.466, 1.439, 1.311, 1.443, -0.002, 1.426], "policy_blue_0_reward": [-1.001, -1.012, -0.517, 1.071, -0.508, -0.506, -0.528, 1.097, -0.504, -0.504, -1.003, -0.505, -0.505, -0.501, 0.495, 1.396, -1.0199999999999998, 0.952, 1.404, -1.003, 0.782, -1.002, -0.508, -0.505, -1.002, 0.497, -1.002, -0.516, 1.3319999999999999, 0.469, 1.049, -0.513, -0.502, 1.128, -1.014, 0.9339999999999999, 1.371, 1.186, 0.494, -0.505, -0.507, 1.4140000000000001, -1.004, -0.507, -0.504, -0.008, -0.522, 1.426, 1.327, 0.86, -0.5049999999999999, -0.504, -0.505, 1.2650000000000001, -1.007, -1.005, 1.369, -0.5009999999999999, -0.505, -0.5069999999999999, -1.007, -1.005, -1.002, -0.504, -0.503, 1.423, -0.514, 1.3050000000000002, -0.502, -0.508, -0.5179999999999999, -1.001, 1.385, 1.363, 1.411, 0.943, 1.249, -0.504, 1.258, -0.506, 1.427, 1.4409999999999998, -1.005, -1.005, -1.003, 1.361, -1.004, -0.024000000000000014, 0.45999999999999996, -0.508, -0.5009999999999999, -1.0, -0.504, 1.3559999999999999, -0.5, 0.498, -0.509, -0.5009999999999999, 1.4249999999999998, 0.498]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3740587301695124, "mean_inference_ms": 7.396699887828979, "mean_action_processing_ms": 0.3895514116659482, "mean_env_wait_ms": 0.5147208696343728, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15381038188934326, "StateBufferConnector_ms": 0.00927591323852539, "ViewRequirementAgentConnector_ms": 0.18840086460113525}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 133.5433479812031, "num_env_steps_trained_throughput_per_sec": 133.5433479812031, "timesteps_total": 212000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 424000, "timers": {"training_iteration_time_ms": 31084.62, "sample_time_ms": 3950.134, "learn_time_ms": 27105.936, "learn_throughput": 147.569, "synch_weights_time_ms": 27.058}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000}, "done": false, "episodes_total": 2036, "training_iteration": 53, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-24-50", "timestamp": 1694838290, "time_this_iter_s": 29.968090772628784, "time_total_s": 1642.5910847187042, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a254c10>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1642.5910847187042, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 23.78604651162791, "ram_util_percent": 57.0}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.09, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.15, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.15, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.15, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6272235748978953, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.07091597904654919, "policy_loss": -0.11415643310610904, "vf_loss": 0.02550443320942577, "vf_explained_var": 0.5890193534394105, "kl": 0.014063866296769622, "entropy": 1.5510082664589087, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 51360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.647098257423689, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06329272540121261, "policy_loss": -0.11026796564692631, "vf_loss": 0.03522552095237188, "vf_explained_var": 0.5767357672875126, "kl": 0.013623176553954845, "entropy": 1.67281926125288, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 51360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "sampler_results": {"episode_reward_max": 1.94, "episode_reward_min": -0.264, "episode_reward_mean": 0.7946599999999999, "episode_len_mean": 56.3, "episode_media": {}, "episodes_this_iter": 72, "policy_reward_min": {"red_0": -1.015, "blue_0": -1.011}, "policy_reward_max": {"red_0": 1.466, "blue_0": 1.4649999999999999}, "policy_reward_mean": {"red_0": 0.7993600000000001, "blue_0": -0.004699999999999982}, "custom_metrics": {"red_0/door_open_done_mean": 0.09, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.15, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.15, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.15, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.88, 1.857, 0.909, -0.05800000000000005, 0.236, 0.821, 1.25, 0.41000000000000014, 0.924, 0.939, 0.363, 0.381, -0.05800000000000005, 1.854, 0.32499999999999996, 1.1320000000000001, 0.9239999999999999, 0.827, 0.948, 0.44499999999999984, 0.8959999999999999, 1.853, 0.966, 1.9369999999999998, 0.802, 0.9420000000000002, 1.423, 1.924, 0.18299999999999983, 0.44799999999999995, 1.821, -0.03499999999999992, 0.358, 0.45699999999999985, 1.9, 1.408, 0.859, 0.4690000000000001, 1.746, 0.9289999999999998, -0.029000000000000026, 0.8719999999999999, 1.267, 0.768, 1.9060000000000001, 1.887, 0.879, 0.918, 0.927, 0.31899999999999995, -0.049000000000000044, 0.040999999999999925, 1.709, 0.42700000000000005, 0.637, 0.45299999999999985, 1.94, 0.32899999999999996, 0.9299999999999999, 1.877, -0.08599999999999997, 0.46099999999999985, 1.54, 0.6059999999999999, 0.726, 0.472, 0.5940000000000001, 0.885, 0.4620000000000002, 0.46499999999999986, 0.6840000000000002, 0.8940000000000001, 0.46399999999999997, 0.3879999999999999, 0.9359999999999999, 0.387, 0.8570000000000002, 0.44099999999999984, 1.932, 0.819, 0.30899999999999994, -0.20300000000000007, 0.891, 0.42700000000000005, -0.04700000000000004, 1.865, 0.89, 0.6139999999999999, 1.903, 0.369, -0.264, 0.869, 0.44199999999999995, 0.10999999999999999, -0.05600000000000005, 0.30200000000000005, 1.845, -0.041999999999999926, 0.34299999999999997, 0.369], "episode_lengths": [36, 43, 29, 18, 80, 55, 76, 28, 23, 19, 42, 36, 18, 44, 55, 112, 300, 53, 17, 18, 32, 46, 11, 20, 61, 19, 24, 24, 252, 16, 55, 10, 44, 14, 31, 29, 44, 10, 79, 22, 162, 40, 69, 72, 29, 35, 36, 26, 23, 203, 15, 292, 91, 23, 111, 15, 19, 54, 300, 37, 26, 169, 137, 121, 82, 9, 122, 36, 11, 11, 95, 33, 11, 35, 18, 34, 44, 19, 22, 55, 56, 61, 33, 20, 15, 43, 34, 117, 30, 40, 80, 41, 19, 123, 18, 62, 49, 13, 48, 41], "policy_red_0_reward": [-0.505, 0.494, -0.502, -1.001, -1.013, 1.325, -0.008, 0.916, -0.503, -0.502, 1.3679999999999999, 1.3860000000000001, 0.945, 0.493, 1.329, 1.156, 0.46399999999999997, 1.335, 1.4489999999999998, 1.4449999999999998, 1.4, 0.497, 1.466, 1.439, 1.311, 1.443, -0.002, 1.426, 0.717, 1.452, 0.494, 0.968, -0.506, 0.957, 0.497, -0.001, 1.366, 0.97, 1.251, 1.432, 0.485, 1.377, -0.016000000000000007, 1.278, 1.409, 1.3900000000000001, 1.387, -0.503, 1.4300000000000002, 0.853, 0.953, 0.5899999999999999, 1.221, 1.428, 1.1560000000000001, 1.455, 0.499, 1.333, 0.474, 0.491, 0.918, 0.983, 0.48, 1.125, 1.244, -0.5, 1.12, 1.3900000000000001, 1.4649999999999999, 0.966, 1.201, 1.397, -1.001, 1.393, 1.4409999999999998, 1.393, 1.3639999999999999, 1.4409999999999998, 0.5, 1.329, 1.319, -1.015, 1.3980000000000001, 0.9339999999999999, 0.954, 1.369, -0.503, 1.124, 0.497, 1.3719999999999999, 0.747, -0.504, 1.443, -0.512, 0.945, 0.8130000000000001, 1.3479999999999999, -1.002, 1.349, 0.873], "policy_blue_0_reward": [1.385, 1.363, 1.411, 0.943, 1.249, -0.504, 1.258, -0.506, 1.427, 1.4409999999999998, -1.005, -1.005, -1.003, 1.361, -1.004, -0.024000000000000014, 0.45999999999999996, -0.508, -0.5009999999999999, -1.0, -0.504, 1.3559999999999999, -0.5, 0.498, -0.509, -0.5009999999999999, 1.4249999999999998, 0.498, -0.534, -1.004, 1.327, -1.003, 0.864, -0.5, 1.403, 1.409, -0.507, -0.5009999999999999, 0.495, -0.503, -0.514, -0.505, 1.283, -0.51, 0.497, 0.497, -0.508, 1.421, -0.503, -0.534, -1.002, -0.549, 0.488, -1.001, -0.519, -1.002, 1.4409999999999998, -1.004, 0.45599999999999996, 1.3860000000000001, -1.004, -0.522, 1.06, -0.519, -0.518, 0.972, -0.5259999999999999, -0.505, -1.003, -0.501, -0.517, -0.503, 1.4649999999999999, -1.005, -0.505, -1.006, -0.5069999999999999, -1.0, 1.432, -0.51, -1.01, 0.8119999999999999, -0.507, -0.5069999999999999, -1.001, 0.496, 1.393, -0.51, 1.4060000000000001, -1.003, -1.011, 1.373, -1.001, 0.622, -1.001, -0.511, 0.497, 0.96, -1.006, -0.504]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3753429226785823, "mean_inference_ms": 7.401596858344753, "mean_action_processing_ms": 0.39043194219620775, "mean_env_wait_ms": 0.5148033567317152, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1481539011001587, "StateBufferConnector_ms": 0.009220480918884277, "ViewRequirementAgentConnector_ms": 0.1987839937210083}}, "episode_reward_max": 1.94, "episode_reward_min": -0.264, "episode_reward_mean": 0.7946599999999999, "episode_len_mean": 56.3, "episodes_this_iter": 72, "policy_reward_min": {"red_0": -1.015, "blue_0": -1.011}, "policy_reward_max": {"red_0": 1.466, "blue_0": 1.4649999999999999}, "policy_reward_mean": {"red_0": 0.7993600000000001, "blue_0": -0.004699999999999982}, "hist_stats": {"episode_reward": [0.88, 1.857, 0.909, -0.05800000000000005, 0.236, 0.821, 1.25, 0.41000000000000014, 0.924, 0.939, 0.363, 0.381, -0.05800000000000005, 1.854, 0.32499999999999996, 1.1320000000000001, 0.9239999999999999, 0.827, 0.948, 0.44499999999999984, 0.8959999999999999, 1.853, 0.966, 1.9369999999999998, 0.802, 0.9420000000000002, 1.423, 1.924, 0.18299999999999983, 0.44799999999999995, 1.821, -0.03499999999999992, 0.358, 0.45699999999999985, 1.9, 1.408, 0.859, 0.4690000000000001, 1.746, 0.9289999999999998, -0.029000000000000026, 0.8719999999999999, 1.267, 0.768, 1.9060000000000001, 1.887, 0.879, 0.918, 0.927, 0.31899999999999995, -0.049000000000000044, 0.040999999999999925, 1.709, 0.42700000000000005, 0.637, 0.45299999999999985, 1.94, 0.32899999999999996, 0.9299999999999999, 1.877, -0.08599999999999997, 0.46099999999999985, 1.54, 0.6059999999999999, 0.726, 0.472, 0.5940000000000001, 0.885, 0.4620000000000002, 0.46499999999999986, 0.6840000000000002, 0.8940000000000001, 0.46399999999999997, 0.3879999999999999, 0.9359999999999999, 0.387, 0.8570000000000002, 0.44099999999999984, 1.932, 0.819, 0.30899999999999994, -0.20300000000000007, 0.891, 0.42700000000000005, -0.04700000000000004, 1.865, 0.89, 0.6139999999999999, 1.903, 0.369, -0.264, 0.869, 0.44199999999999995, 0.10999999999999999, -0.05600000000000005, 0.30200000000000005, 1.845, -0.041999999999999926, 0.34299999999999997, 0.369], "episode_lengths": [36, 43, 29, 18, 80, 55, 76, 28, 23, 19, 42, 36, 18, 44, 55, 112, 300, 53, 17, 18, 32, 46, 11, 20, 61, 19, 24, 24, 252, 16, 55, 10, 44, 14, 31, 29, 44, 10, 79, 22, 162, 40, 69, 72, 29, 35, 36, 26, 23, 203, 15, 292, 91, 23, 111, 15, 19, 54, 300, 37, 26, 169, 137, 121, 82, 9, 122, 36, 11, 11, 95, 33, 11, 35, 18, 34, 44, 19, 22, 55, 56, 61, 33, 20, 15, 43, 34, 117, 30, 40, 80, 41, 19, 123, 18, 62, 49, 13, 48, 41], "policy_red_0_reward": [-0.505, 0.494, -0.502, -1.001, -1.013, 1.325, -0.008, 0.916, -0.503, -0.502, 1.3679999999999999, 1.3860000000000001, 0.945, 0.493, 1.329, 1.156, 0.46399999999999997, 1.335, 1.4489999999999998, 1.4449999999999998, 1.4, 0.497, 1.466, 1.439, 1.311, 1.443, -0.002, 1.426, 0.717, 1.452, 0.494, 0.968, -0.506, 0.957, 0.497, -0.001, 1.366, 0.97, 1.251, 1.432, 0.485, 1.377, -0.016000000000000007, 1.278, 1.409, 1.3900000000000001, 1.387, -0.503, 1.4300000000000002, 0.853, 0.953, 0.5899999999999999, 1.221, 1.428, 1.1560000000000001, 1.455, 0.499, 1.333, 0.474, 0.491, 0.918, 0.983, 0.48, 1.125, 1.244, -0.5, 1.12, 1.3900000000000001, 1.4649999999999999, 0.966, 1.201, 1.397, -1.001, 1.393, 1.4409999999999998, 1.393, 1.3639999999999999, 1.4409999999999998, 0.5, 1.329, 1.319, -1.015, 1.3980000000000001, 0.9339999999999999, 0.954, 1.369, -0.503, 1.124, 0.497, 1.3719999999999999, 0.747, -0.504, 1.443, -0.512, 0.945, 0.8130000000000001, 1.3479999999999999, -1.002, 1.349, 0.873], "policy_blue_0_reward": [1.385, 1.363, 1.411, 0.943, 1.249, -0.504, 1.258, -0.506, 1.427, 1.4409999999999998, -1.005, -1.005, -1.003, 1.361, -1.004, -0.024000000000000014, 0.45999999999999996, -0.508, -0.5009999999999999, -1.0, -0.504, 1.3559999999999999, -0.5, 0.498, -0.509, -0.5009999999999999, 1.4249999999999998, 0.498, -0.534, -1.004, 1.327, -1.003, 0.864, -0.5, 1.403, 1.409, -0.507, -0.5009999999999999, 0.495, -0.503, -0.514, -0.505, 1.283, -0.51, 0.497, 0.497, -0.508, 1.421, -0.503, -0.534, -1.002, -0.549, 0.488, -1.001, -0.519, -1.002, 1.4409999999999998, -1.004, 0.45599999999999996, 1.3860000000000001, -1.004, -0.522, 1.06, -0.519, -0.518, 0.972, -0.5259999999999999, -0.505, -1.003, -0.501, -0.517, -0.503, 1.4649999999999999, -1.005, -0.505, -1.006, -0.5069999999999999, -1.0, 1.432, -0.51, -1.01, 0.8119999999999999, -0.507, -0.5069999999999999, -1.001, 0.496, 1.393, -0.51, 1.4060000000000001, -1.003, -1.011, 1.373, -1.001, 0.622, -1.001, -0.511, 0.497, 0.96, -1.006, -0.504]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3753429226785823, "mean_inference_ms": 7.401596858344753, "mean_action_processing_ms": 0.39043194219620775, "mean_env_wait_ms": 0.5148033567317152, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1481539011001587, "StateBufferConnector_ms": 0.009220480918884277, "ViewRequirementAgentConnector_ms": 0.1987839937210083}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.19498560495921, "num_env_steps_trained_throughput_per_sec": 129.19498560495921, "timesteps_total": 216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 30927.207, "sample_time_ms": 3934.942, "learn_time_ms": 26963.578, "learn_throughput": 148.348, "synch_weights_time_ms": 27.218}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "episodes_total": 2108, "training_iteration": 54, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-25-22", "timestamp": 1694838322, "time_this_iter_s": 30.97784686088562, "time_total_s": 1673.5689315795898, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a21cca0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1673.5689315795898, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 24.513333333333335, "ram_util_percent": 56.95555555555556}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.11, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.66, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.66, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.09, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.66, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6528199111421903, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0652827411996744, "policy_loss": -0.10983078023103493, "vf_loss": 0.025104210541273157, "vf_explained_var": 0.5622885659337044, "kl": 0.014723458227840143, "entropy": 1.5459437765181065, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 52320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6052474800186852, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0698544128157664, "policy_loss": -0.11373142180333767, "vf_loss": 0.030320529987996756, "vf_explained_var": 0.5784441312154134, "kl": 0.013336370849773023, "entropy": 1.6651755473266046, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 52320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000}, "sampler_results": {"episode_reward_max": 1.932, "episode_reward_min": -0.264, "episode_reward_mean": 0.7503099999999998, "episode_len_mean": 53.47, "episode_media": {}, "episodes_this_iter": 69, "policy_reward_min": {"red_0": -1.015, "blue_0": -1.011}, "policy_reward_max": {"red_0": 1.458, "blue_0": 1.4649999999999999}, "policy_reward_mean": {"red_0": 0.8676600000000001, "blue_0": -0.11735}, "custom_metrics": {"red_0/door_open_done_mean": 0.11, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.66, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.66, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.09, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.66, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.46499999999999986, 0.6840000000000002, 0.8940000000000001, 0.46399999999999997, 0.3879999999999999, 0.9359999999999999, 0.387, 0.8570000000000002, 0.44099999999999984, 1.932, 0.819, 0.30899999999999994, -0.20300000000000007, 0.891, 0.42700000000000005, -0.04700000000000004, 1.865, 0.89, 0.6139999999999999, 1.903, 0.369, -0.264, 0.869, 0.44199999999999995, 0.10999999999999999, -0.05600000000000005, 0.30200000000000005, 1.845, -0.041999999999999926, 0.34299999999999997, 0.369, 0.514, 0.33199999999999985, 0.45199999999999996, 1.835, 1.794, 1.814, 1.281, 0.45100000000000007, 0.9020000000000001, 0.43999999999999995, 1.6560000000000001, 0.386, 0.893, 0.9279999999999999, 0.469, 0.6040000000000001, 0.579, 0.46599999999999997, 1.6179999999999999, 0.3740000000000001, 0.366, 1.916, -0.09599999999999986, 1.4979999999999998, 0.9239999999999999, -0.050000000000000044, 0.3900000000000001, 0.6339999999999999, 0.47299999999999986, 0.839, 0.3900000000000001, 0.8780000000000001, 0.8359999999999999, 0.708, 0.32799999999999996, 0.42300000000000004, 0.725, -0.041000000000000036, 1.421, 1.8940000000000001, 0.9060000000000001, 0.28400000000000003, 0.393, 0.9329999999999998, 0.44700000000000006, 0.544, 0.9279999999999999, 0.21499999999999986, 0.9409999999999998, 0.46399999999999997, 0.9199999999999999, -0.04800000000000004, 1.827, 0.732, 1.8800000000000001, 0.33099999999999996, -0.09299999999999986, 1.744, 0.09600000000000009, 1.8410000000000002, -0.03300000000000003, 0.915, 1.646, 1.867, 0.8959999999999999, 0.9569999999999999, 0.853, 0.815, 0.383], "episode_lengths": [11, 95, 33, 11, 35, 18, 34, 44, 19, 22, 55, 56, 61, 33, 20, 15, 43, 34, 117, 30, 40, 80, 41, 19, 123, 18, 62, 49, 13, 48, 41, 151, 203, 15, 53, 64, 56, 69, 15, 31, 20, 108, 36, 33, 22, 10, 124, 122, 11, 116, 39, 41, 27, 30, 155, 25, 16, 33, 110, 8, 50, 34, 36, 49, 89, 53, 25, 83, 13, 25, 34, 29, 68, 34, 21, 17, 143, 22, 86, 19, 12, 300, 171, 53, 81, 37, 53, 28, 77, 124, 49, 11, 26, 108, 39, 33, 14, 45, 57, 36], "policy_red_0_reward": [0.966, 1.201, 1.397, -1.001, 1.393, 1.4409999999999998, 1.393, 1.3639999999999999, 1.4409999999999998, 0.5, 1.329, 1.319, -1.015, 1.3980000000000001, 0.9339999999999999, 0.954, 1.369, -0.503, 1.124, 0.497, 1.3719999999999999, 0.747, -0.504, 1.443, -0.512, 0.945, 0.8130000000000001, 1.3479999999999999, -1.002, 1.349, 0.873, 1.029, 0.859, 0.953, 0.497, 0.499, 1.3239999999999998, 1.287, 0.955, 1.405, 0.94, 1.1669999999999998, -0.503, 1.3980000000000001, 1.432, -0.5, 1.113, 1.097, 0.966, 0.483, 1.376, -1.008, 1.4180000000000001, 0.908, 1.0179999999999998, 1.424, 0.952, 0.896, 1.147, 0.975, 1.346, 0.894, 1.3860000000000001, 1.345, 1.217, -1.001, 0.925, -0.514, 0.961, 1.423, 0.498, 1.409, 1.2890000000000001, 0.896, 1.4329999999999998, 0.948, 1.057, 1.432, 1.225, 1.443, 0.964, 0.45799999999999996, -0.521, 0.496, 1.244, 1.383, 1.337, -1.003, 0.486, 0.613, 1.349, 0.967, 1.42, 1.1629999999999998, 0.491, 1.4, 1.458, 1.357, 1.3239999999999998, 0.888], "policy_blue_0_reward": [-0.501, -0.517, -0.503, 1.4649999999999999, -1.005, -0.505, -1.006, -0.5069999999999999, -1.0, 1.432, -0.51, -1.01, 0.8119999999999999, -0.507, -0.5069999999999999, -1.001, 0.496, 1.393, -0.51, 1.4060000000000001, -1.003, -1.011, 1.373, -1.001, 0.622, -1.001, -0.511, 0.497, 0.96, -1.006, -0.504, -0.515, -0.527, -0.501, 1.338, 1.295, 0.49, -0.006, -0.504, -0.503, -0.5, 0.489, 0.889, -0.505, -0.504, 0.969, -0.509, -0.518, -0.5, 1.135, -1.0019999999999998, 1.374, 0.498, -1.0039999999999998, 0.48, -0.5, -1.002, -0.5059999999999999, -0.513, -0.502, -0.5069999999999999, -0.504, -0.508, -0.509, -0.509, 1.329, -0.502, 1.2389999999999999, -1.002, -0.002, 1.396, -0.503, -1.005, -0.503, -0.5, -0.501, -0.513, -0.504, -1.01, -0.502, -0.5, 0.46199999999999997, 0.473, 1.331, -0.512, 0.497, -1.006, 0.91, 1.258, -0.517, 0.492, -1.0, -0.505, 0.483, 1.376, -0.504, -0.501, -0.504, -0.509, -0.505]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3755716469742214, "mean_inference_ms": 7.406516224178144, "mean_action_processing_ms": 0.39055263935376916, "mean_env_wait_ms": 0.5149339864299229, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1498039960861206, "StateBufferConnector_ms": 0.00914764404296875, "ViewRequirementAgentConnector_ms": 0.1833738088607788}}, "episode_reward_max": 1.932, "episode_reward_min": -0.264, "episode_reward_mean": 0.7503099999999998, "episode_len_mean": 53.47, "episodes_this_iter": 69, "policy_reward_min": {"red_0": -1.015, "blue_0": -1.011}, "policy_reward_max": {"red_0": 1.458, "blue_0": 1.4649999999999999}, "policy_reward_mean": {"red_0": 0.8676600000000001, "blue_0": -0.11735}, "hist_stats": {"episode_reward": [0.46499999999999986, 0.6840000000000002, 0.8940000000000001, 0.46399999999999997, 0.3879999999999999, 0.9359999999999999, 0.387, 0.8570000000000002, 0.44099999999999984, 1.932, 0.819, 0.30899999999999994, -0.20300000000000007, 0.891, 0.42700000000000005, -0.04700000000000004, 1.865, 0.89, 0.6139999999999999, 1.903, 0.369, -0.264, 0.869, 0.44199999999999995, 0.10999999999999999, -0.05600000000000005, 0.30200000000000005, 1.845, -0.041999999999999926, 0.34299999999999997, 0.369, 0.514, 0.33199999999999985, 0.45199999999999996, 1.835, 1.794, 1.814, 1.281, 0.45100000000000007, 0.9020000000000001, 0.43999999999999995, 1.6560000000000001, 0.386, 0.893, 0.9279999999999999, 0.469, 0.6040000000000001, 0.579, 0.46599999999999997, 1.6179999999999999, 0.3740000000000001, 0.366, 1.916, -0.09599999999999986, 1.4979999999999998, 0.9239999999999999, -0.050000000000000044, 0.3900000000000001, 0.6339999999999999, 0.47299999999999986, 0.839, 0.3900000000000001, 0.8780000000000001, 0.8359999999999999, 0.708, 0.32799999999999996, 0.42300000000000004, 0.725, -0.041000000000000036, 1.421, 1.8940000000000001, 0.9060000000000001, 0.28400000000000003, 0.393, 0.9329999999999998, 0.44700000000000006, 0.544, 0.9279999999999999, 0.21499999999999986, 0.9409999999999998, 0.46399999999999997, 0.9199999999999999, -0.04800000000000004, 1.827, 0.732, 1.8800000000000001, 0.33099999999999996, -0.09299999999999986, 1.744, 0.09600000000000009, 1.8410000000000002, -0.03300000000000003, 0.915, 1.646, 1.867, 0.8959999999999999, 0.9569999999999999, 0.853, 0.815, 0.383], "episode_lengths": [11, 95, 33, 11, 35, 18, 34, 44, 19, 22, 55, 56, 61, 33, 20, 15, 43, 34, 117, 30, 40, 80, 41, 19, 123, 18, 62, 49, 13, 48, 41, 151, 203, 15, 53, 64, 56, 69, 15, 31, 20, 108, 36, 33, 22, 10, 124, 122, 11, 116, 39, 41, 27, 30, 155, 25, 16, 33, 110, 8, 50, 34, 36, 49, 89, 53, 25, 83, 13, 25, 34, 29, 68, 34, 21, 17, 143, 22, 86, 19, 12, 300, 171, 53, 81, 37, 53, 28, 77, 124, 49, 11, 26, 108, 39, 33, 14, 45, 57, 36], "policy_red_0_reward": [0.966, 1.201, 1.397, -1.001, 1.393, 1.4409999999999998, 1.393, 1.3639999999999999, 1.4409999999999998, 0.5, 1.329, 1.319, -1.015, 1.3980000000000001, 0.9339999999999999, 0.954, 1.369, -0.503, 1.124, 0.497, 1.3719999999999999, 0.747, -0.504, 1.443, -0.512, 0.945, 0.8130000000000001, 1.3479999999999999, -1.002, 1.349, 0.873, 1.029, 0.859, 0.953, 0.497, 0.499, 1.3239999999999998, 1.287, 0.955, 1.405, 0.94, 1.1669999999999998, -0.503, 1.3980000000000001, 1.432, -0.5, 1.113, 1.097, 0.966, 0.483, 1.376, -1.008, 1.4180000000000001, 0.908, 1.0179999999999998, 1.424, 0.952, 0.896, 1.147, 0.975, 1.346, 0.894, 1.3860000000000001, 1.345, 1.217, -1.001, 0.925, -0.514, 0.961, 1.423, 0.498, 1.409, 1.2890000000000001, 0.896, 1.4329999999999998, 0.948, 1.057, 1.432, 1.225, 1.443, 0.964, 0.45799999999999996, -0.521, 0.496, 1.244, 1.383, 1.337, -1.003, 0.486, 0.613, 1.349, 0.967, 1.42, 1.1629999999999998, 0.491, 1.4, 1.458, 1.357, 1.3239999999999998, 0.888], "policy_blue_0_reward": [-0.501, -0.517, -0.503, 1.4649999999999999, -1.005, -0.505, -1.006, -0.5069999999999999, -1.0, 1.432, -0.51, -1.01, 0.8119999999999999, -0.507, -0.5069999999999999, -1.001, 0.496, 1.393, -0.51, 1.4060000000000001, -1.003, -1.011, 1.373, -1.001, 0.622, -1.001, -0.511, 0.497, 0.96, -1.006, -0.504, -0.515, -0.527, -0.501, 1.338, 1.295, 0.49, -0.006, -0.504, -0.503, -0.5, 0.489, 0.889, -0.505, -0.504, 0.969, -0.509, -0.518, -0.5, 1.135, -1.0019999999999998, 1.374, 0.498, -1.0039999999999998, 0.48, -0.5, -1.002, -0.5059999999999999, -0.513, -0.502, -0.5069999999999999, -0.504, -0.508, -0.509, -0.509, 1.329, -0.502, 1.2389999999999999, -1.002, -0.002, 1.396, -0.503, -1.005, -0.503, -0.5, -0.501, -0.513, -0.504, -1.01, -0.502, -0.5, 0.46199999999999997, 0.473, 1.331, -0.512, 0.497, -1.006, 0.91, 1.258, -0.517, 0.492, -1.0, -0.505, 0.483, 1.376, -0.504, -0.501, -0.504, -0.509, -0.505]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3755716469742214, "mean_inference_ms": 7.406516224178144, "mean_action_processing_ms": 0.39055263935376916, "mean_env_wait_ms": 0.5149339864299229, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1498039960861206, "StateBufferConnector_ms": 0.00914764404296875, "ViewRequirementAgentConnector_ms": 0.1833738088607788}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.40037287948422, "num_env_steps_trained_throughput_per_sec": 130.40037287948422, "timesteps_total": 220000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 440000, "timers": {"training_iteration_time_ms": 30867.958, "sample_time_ms": 3933.195, "learn_time_ms": 26906.088, "learn_throughput": 148.665, "synch_weights_time_ms": 27.214}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000}, "done": false, "episodes_total": 2177, "training_iteration": 55, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-25-53", "timestamp": 1694838353, "time_this_iter_s": 30.689469814300537, "time_total_s": 1704.2584013938904, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a254700>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1704.2584013938904, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 25.226666666666667, "ram_util_percent": 56.99333333333333}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.1, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6066636784623066, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0665166667541295, "policy_loss": -0.10633711277065837, "vf_loss": 0.024325340721892037, "vf_explained_var": 0.5824459729716182, "kl": 0.01281731809123509, "entropy": 1.5416782007863123, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 53280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6105375728880366, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06114906650230599, "policy_loss": -0.1055850092379842, "vf_loss": 0.03314634287477626, "vf_explained_var": 0.5861903186887503, "kl": 0.012953801180716103, "entropy": 1.647606389845411, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 53280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "sampler_results": {"episode_reward_max": 1.951, "episode_reward_min": -0.16600000000000004, "episode_reward_mean": 0.8587000000000002, "episode_len_mean": 54.13, "episode_media": {}, "episodes_this_iter": 65, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.01}, "policy_reward_max": {"red_0": 1.458, "blue_0": 1.452}, "policy_reward_mean": {"red_0": 0.85852, "blue_0": 0.0001799999999999935}, "custom_metrics": {"red_0/door_open_done_mean": 0.1, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.32799999999999996, 0.42300000000000004, 0.725, -0.041000000000000036, 1.421, 1.8940000000000001, 0.9060000000000001, 0.28400000000000003, 0.393, 0.9329999999999998, 0.44700000000000006, 0.544, 0.9279999999999999, 0.21499999999999986, 0.9409999999999998, 0.46399999999999997, 0.9199999999999999, -0.04800000000000004, 1.827, 0.732, 1.8800000000000001, 0.33099999999999996, -0.09299999999999986, 1.744, 0.09600000000000009, 1.8410000000000002, -0.03300000000000003, 0.915, 1.646, 1.867, 0.8959999999999999, 0.9569999999999999, 0.853, 0.815, 0.383, 0.887, 0.5269999999999999, 1.357, 0.952, -0.16600000000000004, 0.398, 0.9409999999999998, 0.927, 0.833, 1.775, 0.8519999999999999, 1.911, 0.794, 1.442, 0.9140000000000001, 0.6100000000000001, -0.125, 0.8049999999999999, 0.7639999999999998, 1.8519999999999999, 1.343, 0.9159999999999999, 1.2229999999999999, 0.917, 1.8399999999999999, -0.030999999999999917, 0.8050000000000002, 0.19799999999999995, 0.9020000000000001, 0.8660000000000001, 0.8759999999999999, 0.31700000000000017, 0.31199999999999994, 0.44899999999999984, 1.841, 1.888, 0.947, -0.11399999999999999, 0.41000000000000014, 1.7109999999999999, 1.887, 1.951, 0.9010000000000002, 0.42300000000000004, 0.617, 0.3660000000000001, 1.682, 1.939, 0.41000000000000003, 0.43299999999999983, 0.40600000000000014, 1.9329999999999998, 0.31799999999999995, 1.913, 0.393, 0.3900000000000001, 0.44499999999999984, 0.43300000000000005, 0.863, 0.406, 0.6440000000000001, 1.834, 0.42900000000000005, 0.29899999999999993, 0.355], "episode_lengths": [53, 25, 83, 13, 25, 34, 29, 68, 34, 21, 17, 143, 22, 86, 19, 12, 300, 171, 53, 81, 37, 53, 28, 77, 124, 49, 11, 26, 108, 39, 33, 14, 45, 57, 36, 35, 147, 42, 16, 51, 31, 19, 24, 52, 72, 46, 28, 63, 172, 27, 121, 38, 60, 73, 47, 48, 27, 237, 26, 50, 10, 62, 96, 31, 42, 39, 58, 57, 16, 51, 34, 16, 34, 29, 87, 35, 16, 30, 24, 116, 41, 96, 20, 27, 172, 29, 21, 56, 27, 31, 35, 16, 21, 42, 28, 110, 51, 23, 61, 45], "policy_red_0_reward": [-1.001, 0.925, -0.514, 0.961, 1.423, 0.498, 1.409, 1.2890000000000001, 0.896, 1.4329999999999998, 0.948, 1.057, 1.432, 1.225, 1.443, 0.964, 0.45799999999999996, -0.521, 0.496, 1.244, 1.383, 1.337, -1.003, 0.486, 0.613, 1.349, 0.967, 1.42, 1.1629999999999998, 0.491, 1.4, 1.458, 1.357, 1.3239999999999998, 0.888, 1.392, 1.044, 1.367, 1.452, 0.838, -0.506, 1.442, 1.427, -0.506, 0.492, 1.358, 1.415, 1.2999999999999998, 0.964, 1.415, 1.125, 0.882, 1.315, 1.273, 0.498, 1.346, 1.4180000000000001, 0.7549999999999999, 1.42, 0.494, -1.0, 1.311, 1.204, 1.405, 1.369, 1.38, 1.322, -0.507, 1.451, 0.497, 0.492, -0.502, 0.89, 1.412, 0.49, 0.493, 0.499, 1.4060000000000001, 1.423, 1.133, 1.371, 0.489, 0.499, -1.003, 0.96, 0.91, 1.436, -0.506, 0.498, 1.4020000000000001, 0.892, 1.448, 0.9369999999999999, -0.503, -0.505, 1.15, 0.497, 0.931, 1.303, 1.3599999999999999], "policy_blue_0_reward": [1.329, -0.502, 1.2389999999999999, -1.002, -0.002, 1.396, -0.503, -1.005, -0.503, -0.5, -0.501, -0.513, -0.504, -1.01, -0.502, -0.5, 0.46199999999999997, 0.473, 1.331, -0.512, 0.497, -1.006, 0.91, 1.258, -0.517, 0.492, -1.0, -0.505, 0.483, 1.376, -0.504, -0.501, -0.504, -0.509, -0.505, -0.505, -0.517, -0.010000000000000002, -0.5, -1.004, 0.904, -0.501, -0.5, 1.339, 1.283, -0.506, 0.496, -0.506, 0.478, -0.501, -0.5149999999999999, -1.007, -0.51, -0.509, 1.354, -0.003, -0.502, 0.46799999999999997, -0.503, 1.346, 0.969, -0.506, -1.006, -0.503, -0.5029999999999999, -0.504, -1.005, 0.819, -1.002, 1.3439999999999999, 1.396, 1.4489999999999998, -1.004, -1.002, 1.221, 1.3940000000000001, 1.452, -0.5049999999999999, -1.0, -0.516, -1.005, 1.193, 1.44, 1.413, -0.527, -0.504, 0.497, 0.824, 1.415, -1.009, -0.502, -1.003, -0.5039999999999999, 1.366, 0.911, -0.506, 1.337, -0.502, -1.004, -1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3750074296230448, "mean_inference_ms": 7.401110895679522, "mean_action_processing_ms": 0.39071684315346433, "mean_env_wait_ms": 0.5145966788235776, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1372971534729004, "StateBufferConnector_ms": 0.009039759635925293, "ViewRequirementAgentConnector_ms": 0.1797337532043457}}, "episode_reward_max": 1.951, "episode_reward_min": -0.16600000000000004, "episode_reward_mean": 0.8587000000000002, "episode_len_mean": 54.13, "episodes_this_iter": 65, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.01}, "policy_reward_max": {"red_0": 1.458, "blue_0": 1.452}, "policy_reward_mean": {"red_0": 0.85852, "blue_0": 0.0001799999999999935}, "hist_stats": {"episode_reward": [0.32799999999999996, 0.42300000000000004, 0.725, -0.041000000000000036, 1.421, 1.8940000000000001, 0.9060000000000001, 0.28400000000000003, 0.393, 0.9329999999999998, 0.44700000000000006, 0.544, 0.9279999999999999, 0.21499999999999986, 0.9409999999999998, 0.46399999999999997, 0.9199999999999999, -0.04800000000000004, 1.827, 0.732, 1.8800000000000001, 0.33099999999999996, -0.09299999999999986, 1.744, 0.09600000000000009, 1.8410000000000002, -0.03300000000000003, 0.915, 1.646, 1.867, 0.8959999999999999, 0.9569999999999999, 0.853, 0.815, 0.383, 0.887, 0.5269999999999999, 1.357, 0.952, -0.16600000000000004, 0.398, 0.9409999999999998, 0.927, 0.833, 1.775, 0.8519999999999999, 1.911, 0.794, 1.442, 0.9140000000000001, 0.6100000000000001, -0.125, 0.8049999999999999, 0.7639999999999998, 1.8519999999999999, 1.343, 0.9159999999999999, 1.2229999999999999, 0.917, 1.8399999999999999, -0.030999999999999917, 0.8050000000000002, 0.19799999999999995, 0.9020000000000001, 0.8660000000000001, 0.8759999999999999, 0.31700000000000017, 0.31199999999999994, 0.44899999999999984, 1.841, 1.888, 0.947, -0.11399999999999999, 0.41000000000000014, 1.7109999999999999, 1.887, 1.951, 0.9010000000000002, 0.42300000000000004, 0.617, 0.3660000000000001, 1.682, 1.939, 0.41000000000000003, 0.43299999999999983, 0.40600000000000014, 1.9329999999999998, 0.31799999999999995, 1.913, 0.393, 0.3900000000000001, 0.44499999999999984, 0.43300000000000005, 0.863, 0.406, 0.6440000000000001, 1.834, 0.42900000000000005, 0.29899999999999993, 0.355], "episode_lengths": [53, 25, 83, 13, 25, 34, 29, 68, 34, 21, 17, 143, 22, 86, 19, 12, 300, 171, 53, 81, 37, 53, 28, 77, 124, 49, 11, 26, 108, 39, 33, 14, 45, 57, 36, 35, 147, 42, 16, 51, 31, 19, 24, 52, 72, 46, 28, 63, 172, 27, 121, 38, 60, 73, 47, 48, 27, 237, 26, 50, 10, 62, 96, 31, 42, 39, 58, 57, 16, 51, 34, 16, 34, 29, 87, 35, 16, 30, 24, 116, 41, 96, 20, 27, 172, 29, 21, 56, 27, 31, 35, 16, 21, 42, 28, 110, 51, 23, 61, 45], "policy_red_0_reward": [-1.001, 0.925, -0.514, 0.961, 1.423, 0.498, 1.409, 1.2890000000000001, 0.896, 1.4329999999999998, 0.948, 1.057, 1.432, 1.225, 1.443, 0.964, 0.45799999999999996, -0.521, 0.496, 1.244, 1.383, 1.337, -1.003, 0.486, 0.613, 1.349, 0.967, 1.42, 1.1629999999999998, 0.491, 1.4, 1.458, 1.357, 1.3239999999999998, 0.888, 1.392, 1.044, 1.367, 1.452, 0.838, -0.506, 1.442, 1.427, -0.506, 0.492, 1.358, 1.415, 1.2999999999999998, 0.964, 1.415, 1.125, 0.882, 1.315, 1.273, 0.498, 1.346, 1.4180000000000001, 0.7549999999999999, 1.42, 0.494, -1.0, 1.311, 1.204, 1.405, 1.369, 1.38, 1.322, -0.507, 1.451, 0.497, 0.492, -0.502, 0.89, 1.412, 0.49, 0.493, 0.499, 1.4060000000000001, 1.423, 1.133, 1.371, 0.489, 0.499, -1.003, 0.96, 0.91, 1.436, -0.506, 0.498, 1.4020000000000001, 0.892, 1.448, 0.9369999999999999, -0.503, -0.505, 1.15, 0.497, 0.931, 1.303, 1.3599999999999999], "policy_blue_0_reward": [1.329, -0.502, 1.2389999999999999, -1.002, -0.002, 1.396, -0.503, -1.005, -0.503, -0.5, -0.501, -0.513, -0.504, -1.01, -0.502, -0.5, 0.46199999999999997, 0.473, 1.331, -0.512, 0.497, -1.006, 0.91, 1.258, -0.517, 0.492, -1.0, -0.505, 0.483, 1.376, -0.504, -0.501, -0.504, -0.509, -0.505, -0.505, -0.517, -0.010000000000000002, -0.5, -1.004, 0.904, -0.501, -0.5, 1.339, 1.283, -0.506, 0.496, -0.506, 0.478, -0.501, -0.5149999999999999, -1.007, -0.51, -0.509, 1.354, -0.003, -0.502, 0.46799999999999997, -0.503, 1.346, 0.969, -0.506, -1.006, -0.503, -0.5029999999999999, -0.504, -1.005, 0.819, -1.002, 1.3439999999999999, 1.396, 1.4489999999999998, -1.004, -1.002, 1.221, 1.3940000000000001, 1.452, -0.5049999999999999, -1.0, -0.516, -1.005, 1.193, 1.44, 1.413, -0.527, -0.504, 0.497, 0.824, 1.415, -1.009, -0.502, -1.003, -0.5039999999999999, 1.366, 0.911, -0.506, 1.337, -0.502, -1.004, -1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3750074296230448, "mean_inference_ms": 7.401110895679522, "mean_action_processing_ms": 0.39071684315346433, "mean_env_wait_ms": 0.5145966788235776, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1372971534729004, "StateBufferConnector_ms": 0.009039759635925293, "ViewRequirementAgentConnector_ms": 0.1797337532043457}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.01588937469037, "num_env_steps_trained_throughput_per_sec": 131.01588937469037, "timesteps_total": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 30888.124, "sample_time_ms": 3915.565, "learn_time_ms": 26943.993, "learn_throughput": 148.456, "synch_weights_time_ms": 27.107}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "episodes_total": 2242, "training_iteration": 56, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-26-25", "timestamp": 1694838385, "time_this_iter_s": 30.546738862991333, "time_total_s": 1734.8051402568817, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a21c0d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1734.8051402568817, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 26.238636363636363, "ram_util_percent": 57.05227272727273}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.05, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.61, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.61, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.61, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6122333048221965, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06294860230700579, "policy_loss": -0.10643165552658805, "vf_loss": 0.027652572015843663, "vf_explained_var": 0.5682526615137855, "kl": 0.013700682521581105, "entropy": 1.555100119486451, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 54240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6164598257901768, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06583645934006199, "policy_loss": -0.10750427421929393, "vf_loss": 0.027643886299726243, "vf_explained_var": 0.6438914274796843, "kl": 0.012954200894068891, "entropy": 1.6654188285271327, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 54240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000}, "sampler_results": {"episode_reward_max": 1.951, "episode_reward_min": -0.15799999999999992, "episode_reward_mean": 0.8202200000000001, "episode_len_mean": 59.81, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"red_0": -1.006, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.46, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 0.82451, "blue_0": -0.004289999999999985}, "custom_metrics": {"red_0/door_open_done_mean": 0.05, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.61, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.61, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.61, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.44899999999999984, 1.841, 1.888, 0.947, -0.11399999999999999, 0.41000000000000014, 1.7109999999999999, 1.887, 1.951, 0.9010000000000002, 0.42300000000000004, 0.617, 0.3660000000000001, 1.682, 1.939, 0.41000000000000003, 0.43299999999999983, 0.40600000000000014, 1.9329999999999998, 0.31799999999999995, 1.913, 0.393, 0.3900000000000001, 0.44499999999999984, 0.43300000000000005, 0.863, 0.406, 0.6440000000000001, 1.834, 0.42900000000000005, 0.29899999999999993, 0.355, 0.9279999999999999, 1.849, 0.8820000000000001, 0.8069999999999999, 0.8319999999999999, 1.706, 0.9060000000000001, 0.7010000000000001, 0.833, 1.208, 0.7, 0.831, 0.873, 0.9179999999999999, 0.6659999999999999, 0.952, 1.21, 0.43699999999999983, -0.07999999999999996, 0.74, 0.958, 0.944, 0.879, 0.631, 1.7970000000000002, 1.866, 1.899, 1.8940000000000001, 0.857, 0.395, 0.19499999999999984, 0.8580000000000001, 0.45599999999999996, 0.8980000000000001, 0.40900000000000003, 0.866, 1.927, 0.27, 0.798, 0.8999999999999999, 0.864, 0.18699999999999994, 0.9449999999999998, 0.3380000000000001, 0.43399999999999994, 0.8599999999999999, 0.833, 1.4329999999999998, 0.859, 0.3400000000000001, 0.43399999999999994, 0.3900000000000001, 0.2749999999999999, 0.3719999999999999, 0.45100000000000007, 0.43599999999999994, 0.8119999999999998, 0.30600000000000005, 0.02200000000000002, 0.948, 0.46799999999999997, 0.9420000000000002, 0.16699999999999982, 1.911, 0.2400000000000002, -0.15799999999999992, 0.139, 0.3759999999999999], "episode_lengths": [16, 51, 34, 16, 34, 29, 87, 35, 16, 30, 24, 116, 41, 96, 20, 27, 172, 29, 21, 56, 27, 31, 35, 16, 21, 42, 28, 110, 51, 23, 61, 45, 300, 46, 37, 60, 52, 91, 29, 89, 50, 90, 92, 52, 39, 300, 100, 15, 237, 19, 25, 81, 13, 18, 38, 113, 62, 41, 32, 32, 46, 32, 91, 44, 14, 31, 29, 41, 21, 69, 63, 300, 41, 96, 17, 51, 21, 43, 52, 21, 44, 49, 20, 35, 68, 300, 15, 20, 55, 58, 149, 16, 10, 18, 102, 28, 81, 49, 110, 38], "policy_red_0_reward": [1.451, 0.497, 0.492, -0.502, 0.89, 1.412, 0.49, 0.493, 0.499, 1.4060000000000001, 1.423, 1.133, 1.371, 0.489, 0.499, -1.003, 0.96, 0.91, 1.436, -0.506, 0.498, 1.4020000000000001, 0.892, 1.448, 0.9369999999999999, -0.503, -0.505, 1.15, 0.497, 0.931, 1.303, 1.3599999999999999, 0.474, 1.355, 1.3860000000000001, 1.313, 1.341, 0.49, 1.409, 1.221, 1.343, 1.213, 1.214, 1.3399999999999999, 1.3780000000000001, 0.45899999999999996, 1.189, -0.502, 0.7539999999999999, 1.4409999999999998, 0.922, 1.249, 1.46, 1.4449999999999998, 1.3860000000000001, -0.517, 0.495, 0.495, 0.498, 0.491, -0.501, 1.4, 1.21, 1.3639999999999999, 0.957, 1.404, 1.411, -0.504, 1.434, 1.2839999999999998, 1.3039999999999998, 0.44299999999999995, -0.506, -0.508, 1.4489999999999998, 0.842, 1.435, 1.366, 1.3359999999999999, -0.003, 1.3639999999999999, -0.5079999999999999, 0.9359999999999999, 1.393, 1.288, 0.44199999999999995, 0.953, 0.9369999999999999, 1.327, 1.32, 0.5379999999999999, 1.451, -1.001, 1.446, 1.182, 0.499, 1.249, -1.006, 1.154, 0.878], "policy_blue_0_reward": [-1.002, 1.3439999999999999, 1.396, 1.4489999999999998, -1.004, -1.002, 1.221, 1.3940000000000001, 1.452, -0.5049999999999999, -1.0, -0.516, -1.005, 1.193, 1.44, 1.413, -0.527, -0.504, 0.497, 0.824, 1.415, -1.009, -0.502, -1.003, -0.5039999999999999, 1.366, 0.911, -0.506, 1.337, -0.502, -1.004, -1.005, 0.45399999999999996, 0.494, -0.5039999999999999, -0.506, -0.509, 1.216, -0.503, -0.52, -0.51, -0.005, -0.514, -0.509, -0.505, 0.45899999999999996, -0.523, 1.454, 0.45599999999999996, -1.004, -1.002, -0.509, -0.502, -0.501, -0.507, 1.1480000000000001, 1.302, 1.371, 1.401, 1.403, 1.358, -1.005, -1.015, -0.506, -0.501, -0.506, -1.002, 1.37, 0.493, -1.014, -0.506, 0.45699999999999996, 1.37, 0.695, -0.504, -0.504, -1.001, -0.506, -0.503, 1.436, -0.505, 0.848, -0.502, -1.003, -1.013, -0.07000000000000005, -0.502, -0.501, -0.515, -1.014, -0.5159999999999999, -0.5029999999999999, 1.4689999999999999, -0.5039999999999999, -1.015, 1.412, -1.009, 0.848, -1.015, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3753705905294316, "mean_inference_ms": 7.3955927616743296, "mean_action_processing_ms": 0.38990653692972854, "mean_env_wait_ms": 0.5142820439158962, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14063620567321777, "StateBufferConnector_ms": 0.009109139442443848, "ViewRequirementAgentConnector_ms": 0.18168377876281738}}, "episode_reward_max": 1.951, "episode_reward_min": -0.15799999999999992, "episode_reward_mean": 0.8202200000000001, "episode_len_mean": 59.81, "episodes_this_iter": 68, "policy_reward_min": {"red_0": -1.006, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.46, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 0.82451, "blue_0": -0.004289999999999985}, "hist_stats": {"episode_reward": [0.44899999999999984, 1.841, 1.888, 0.947, -0.11399999999999999, 0.41000000000000014, 1.7109999999999999, 1.887, 1.951, 0.9010000000000002, 0.42300000000000004, 0.617, 0.3660000000000001, 1.682, 1.939, 0.41000000000000003, 0.43299999999999983, 0.40600000000000014, 1.9329999999999998, 0.31799999999999995, 1.913, 0.393, 0.3900000000000001, 0.44499999999999984, 0.43300000000000005, 0.863, 0.406, 0.6440000000000001, 1.834, 0.42900000000000005, 0.29899999999999993, 0.355, 0.9279999999999999, 1.849, 0.8820000000000001, 0.8069999999999999, 0.8319999999999999, 1.706, 0.9060000000000001, 0.7010000000000001, 0.833, 1.208, 0.7, 0.831, 0.873, 0.9179999999999999, 0.6659999999999999, 0.952, 1.21, 0.43699999999999983, -0.07999999999999996, 0.74, 0.958, 0.944, 0.879, 0.631, 1.7970000000000002, 1.866, 1.899, 1.8940000000000001, 0.857, 0.395, 0.19499999999999984, 0.8580000000000001, 0.45599999999999996, 0.8980000000000001, 0.40900000000000003, 0.866, 1.927, 0.27, 0.798, 0.8999999999999999, 0.864, 0.18699999999999994, 0.9449999999999998, 0.3380000000000001, 0.43399999999999994, 0.8599999999999999, 0.833, 1.4329999999999998, 0.859, 0.3400000000000001, 0.43399999999999994, 0.3900000000000001, 0.2749999999999999, 0.3719999999999999, 0.45100000000000007, 0.43599999999999994, 0.8119999999999998, 0.30600000000000005, 0.02200000000000002, 0.948, 0.46799999999999997, 0.9420000000000002, 0.16699999999999982, 1.911, 0.2400000000000002, -0.15799999999999992, 0.139, 0.3759999999999999], "episode_lengths": [16, 51, 34, 16, 34, 29, 87, 35, 16, 30, 24, 116, 41, 96, 20, 27, 172, 29, 21, 56, 27, 31, 35, 16, 21, 42, 28, 110, 51, 23, 61, 45, 300, 46, 37, 60, 52, 91, 29, 89, 50, 90, 92, 52, 39, 300, 100, 15, 237, 19, 25, 81, 13, 18, 38, 113, 62, 41, 32, 32, 46, 32, 91, 44, 14, 31, 29, 41, 21, 69, 63, 300, 41, 96, 17, 51, 21, 43, 52, 21, 44, 49, 20, 35, 68, 300, 15, 20, 55, 58, 149, 16, 10, 18, 102, 28, 81, 49, 110, 38], "policy_red_0_reward": [1.451, 0.497, 0.492, -0.502, 0.89, 1.412, 0.49, 0.493, 0.499, 1.4060000000000001, 1.423, 1.133, 1.371, 0.489, 0.499, -1.003, 0.96, 0.91, 1.436, -0.506, 0.498, 1.4020000000000001, 0.892, 1.448, 0.9369999999999999, -0.503, -0.505, 1.15, 0.497, 0.931, 1.303, 1.3599999999999999, 0.474, 1.355, 1.3860000000000001, 1.313, 1.341, 0.49, 1.409, 1.221, 1.343, 1.213, 1.214, 1.3399999999999999, 1.3780000000000001, 0.45899999999999996, 1.189, -0.502, 0.7539999999999999, 1.4409999999999998, 0.922, 1.249, 1.46, 1.4449999999999998, 1.3860000000000001, -0.517, 0.495, 0.495, 0.498, 0.491, -0.501, 1.4, 1.21, 1.3639999999999999, 0.957, 1.404, 1.411, -0.504, 1.434, 1.2839999999999998, 1.3039999999999998, 0.44299999999999995, -0.506, -0.508, 1.4489999999999998, 0.842, 1.435, 1.366, 1.3359999999999999, -0.003, 1.3639999999999999, -0.5079999999999999, 0.9359999999999999, 1.393, 1.288, 0.44199999999999995, 0.953, 0.9369999999999999, 1.327, 1.32, 0.5379999999999999, 1.451, -1.001, 1.446, 1.182, 0.499, 1.249, -1.006, 1.154, 0.878], "policy_blue_0_reward": [-1.002, 1.3439999999999999, 1.396, 1.4489999999999998, -1.004, -1.002, 1.221, 1.3940000000000001, 1.452, -0.5049999999999999, -1.0, -0.516, -1.005, 1.193, 1.44, 1.413, -0.527, -0.504, 0.497, 0.824, 1.415, -1.009, -0.502, -1.003, -0.5039999999999999, 1.366, 0.911, -0.506, 1.337, -0.502, -1.004, -1.005, 0.45399999999999996, 0.494, -0.5039999999999999, -0.506, -0.509, 1.216, -0.503, -0.52, -0.51, -0.005, -0.514, -0.509, -0.505, 0.45899999999999996, -0.523, 1.454, 0.45599999999999996, -1.004, -1.002, -0.509, -0.502, -0.501, -0.507, 1.1480000000000001, 1.302, 1.371, 1.401, 1.403, 1.358, -1.005, -1.015, -0.506, -0.501, -0.506, -1.002, 1.37, 0.493, -1.014, -0.506, 0.45699999999999996, 1.37, 0.695, -0.504, -0.504, -1.001, -0.506, -0.503, 1.436, -0.505, 0.848, -0.502, -1.003, -1.013, -0.07000000000000005, -0.502, -0.501, -0.515, -1.014, -0.5159999999999999, -0.5029999999999999, 1.4689999999999999, -0.5039999999999999, -1.015, 1.412, -1.009, 0.848, -1.015, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3753705905294316, "mean_inference_ms": 7.3955927616743296, "mean_action_processing_ms": 0.38990653692972854, "mean_env_wait_ms": 0.5142820439158962, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14063620567321777, "StateBufferConnector_ms": 0.009109139442443848, "ViewRequirementAgentConnector_ms": 0.18168377876281738}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 132.177869240923, "num_env_steps_trained_throughput_per_sec": 132.177869240923, "timesteps_total": 228000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 456000, "timers": {"training_iteration_time_ms": 30864.376, "sample_time_ms": 3944.773, "learn_time_ms": 26891.196, "learn_throughput": 148.748, "synch_weights_time_ms": 26.936}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000}, "done": false, "episodes_total": 2310, "training_iteration": 57, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-26-56", "timestamp": 1694838416, "time_this_iter_s": 30.27824115753174, "time_total_s": 1765.0833814144135, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a21cca0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1765.0833814144135, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 25.36818181818182, "ram_util_percent": 57.065909090909095}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.12, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.56, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.18, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.56, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.18, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.56, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.18, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6181187478515009, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06360581961125718, "policy_loss": -0.10664192261222828, "vf_loss": 0.025275228885584512, "vf_explained_var": 0.5933173644045989, "kl": 0.014012783872180532, "entropy": 1.524385683859388, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 55200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6289696766684453, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.058513819298968886, "policy_loss": -0.10004853800977193, "vf_loss": 0.028295586547756102, "vf_explained_var": 0.6209579152986408, "kl": 0.012741732131981345, "entropy": 1.6403339611987273, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 55200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "sampler_results": {"episode_reward_max": 1.943, "episode_reward_min": -0.21400000000000008, "episode_reward_mean": 0.77811, "episode_len_mean": 60.82, "episode_media": {}, "episodes_this_iter": 67, "policy_reward_min": {"red_0": -1.006, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.451, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 0.75684, "blue_0": 0.02127}, "custom_metrics": {"red_0/door_open_done_mean": 0.12, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.56, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.18, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.56, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.18, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.56, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.18, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.866, 1.927, 0.27, 0.798, 0.8999999999999999, 0.864, 0.18699999999999994, 0.9449999999999998, 0.3380000000000001, 0.43399999999999994, 0.8599999999999999, 0.833, 1.4329999999999998, 0.859, 0.3400000000000001, 0.43399999999999994, 0.3900000000000001, 0.2749999999999999, 0.3719999999999999, 0.45100000000000007, 0.43599999999999994, 0.8119999999999998, 0.30600000000000005, 0.02200000000000002, 0.948, 0.46799999999999997, 0.9420000000000002, 0.16699999999999982, 1.911, 0.2400000000000002, -0.15799999999999992, 0.139, 0.3759999999999999, 1.809, 0.796, 0.44799999999999995, 0.3919999999999999, 0.8759999999999999, 0.44899999999999995, 0.3919999999999999, 1.93, 0.8980000000000001, 0.833, -0.136, 0.94, 0.9100000000000001, 0.796, 0.772, 0.30099999999999993, 1.412, 0.15399999999999991, 1.903, -0.03400000000000003, 1.158, 0.69, 1.349, -0.21400000000000008, 0.2370000000000001, 1.752, 0.6659999999999999, 0.9329999999999999, 0.921, 0.843, 0.9430000000000001, 0.20599999999999996, 0.9029999999999999, 0.32399999999999995, 0.8580000000000001, 1.766, 1.831, 1.722, 0.923, 0.883, 1.342, 0.3740000000000001, 1.658, 0.398, -0.05700000000000005, 0.7669999999999999, 0.237, 0.391, 0.7, -0.12499999999999989, 1.694, 1.4140000000000001, 1.189, -0.05600000000000005, 0.8109999999999999, 0.8940000000000001, 0.391, 1.401, 1.718, 0.42899999999999994, 1.943, 1.811, 0.372, 0.43799999999999994, 1.907, 0.4849999999999999, 0.365], "episode_lengths": [41, 21, 69, 63, 300, 41, 96, 17, 51, 21, 43, 52, 21, 44, 49, 20, 35, 68, 300, 15, 20, 55, 58, 149, 16, 10, 18, 102, 28, 81, 49, 110, 38, 59, 62, 16, 34, 39, 15, 33, 22, 31, 50, 43, 19, 28, 61, 71, 61, 27, 107, 31, 11, 248, 92, 48, 67, 82, 78, 102, 21, 25, 48, 18, 92, 300, 55, 44, 73, 53, 86, 25, 37, 49, 37, 105, 31, 174, 70, 80, 34, 92, 38, 91, 27, 97, 17, 60, 33, 34, 31, 86, 22, 18, 58, 39, 17, 29, 157, 41], "policy_red_0_reward": [-0.504, 1.434, 1.2839999999999998, 1.3039999999999998, 0.44299999999999995, -0.506, -0.508, 1.4489999999999998, 0.842, 1.435, 1.366, 1.3359999999999999, -0.003, 1.3639999999999999, -0.5079999999999999, 0.9359999999999999, 1.393, 1.288, 0.44199999999999995, 0.953, 0.9369999999999999, 1.327, 1.32, 0.5379999999999999, 1.451, -1.001, 1.446, 1.182, 0.499, 1.249, -1.006, 1.154, 0.878, 1.3159999999999998, 1.31, 0.952, 1.396, 1.3820000000000001, -0.504, 0.895, 1.4329999999999998, 1.404, 1.341, 0.869, 1.443, 1.416, 1.3079999999999998, 1.283, 1.307, 1.416, 0.67, 0.498, 0.966, 0.701, 1.208, -0.004, 0.7909999999999999, 0.743, 1.26, 1.182, -0.501, -0.501, 1.3519999999999999, 1.4449999999999998, -0.51, 0.44499999999999995, -1.001, 1.363, 1.27, 0.496, 1.2349999999999999, 1.424, 1.387, 1.349, 1.384, 0.49, -0.504, 0.96, 1.274, -0.512, 1.397, 1.2149999999999999, -1.002, 1.208, -0.002, -0.010000000000000002, 0.945, 1.3159999999999998, 1.3980000000000001, -1.005, 1.4060000000000001, 0.486, -1.002, 1.444, 0.49, -0.503, -0.507, 0.499, 1.0, 1.37], "policy_blue_0_reward": [1.37, 0.493, -1.014, -0.506, 0.45699999999999996, 1.37, 0.695, -0.504, -0.504, -1.001, -0.506, -0.503, 1.436, -0.505, 0.848, -0.502, -1.003, -1.013, -0.07000000000000005, -0.502, -0.501, -0.515, -1.014, -0.5159999999999999, -0.5029999999999999, 1.4689999999999999, -0.5039999999999999, -1.015, 1.412, -1.009, 0.848, -1.015, -0.502, 0.493, -0.514, -0.504, -1.004, -0.506, 0.953, -0.503, 0.497, -0.506, -0.508, -1.005, -0.503, -0.506, -0.5119999999999999, -0.511, -1.006, -0.004, -0.516, 1.405, -1.0, 0.45699999999999996, -0.518, 1.353, -1.005, -0.506, 0.492, -0.516, 1.434, 1.4220000000000002, -0.509, -0.502, 0.716, 0.45799999999999996, 1.325, -0.505, 0.496, 1.335, 0.487, -0.501, -0.504, -0.007, -1.01, 1.1680000000000001, 0.902, -1.017, -0.507, 0.749, -1.006, -0.515, 0.877, 0.486, 1.416, 1.199, -1.001, -0.505, -0.504, 1.396, -0.005, 1.232, 1.431, 0.499, 1.3210000000000002, 0.875, 0.945, 1.408, -0.515, -1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3742314769385764, "mean_inference_ms": 7.387968558659111, "mean_action_processing_ms": 0.3899452547827424, "mean_env_wait_ms": 0.5138085158929078, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1386704444885254, "StateBufferConnector_ms": 0.009273171424865723, "ViewRequirementAgentConnector_ms": 0.1838911771774292}}, "episode_reward_max": 1.943, "episode_reward_min": -0.21400000000000008, "episode_reward_mean": 0.77811, "episode_len_mean": 60.82, "episodes_this_iter": 67, "policy_reward_min": {"red_0": -1.006, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.451, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 0.75684, "blue_0": 0.02127}, "hist_stats": {"episode_reward": [0.866, 1.927, 0.27, 0.798, 0.8999999999999999, 0.864, 0.18699999999999994, 0.9449999999999998, 0.3380000000000001, 0.43399999999999994, 0.8599999999999999, 0.833, 1.4329999999999998, 0.859, 0.3400000000000001, 0.43399999999999994, 0.3900000000000001, 0.2749999999999999, 0.3719999999999999, 0.45100000000000007, 0.43599999999999994, 0.8119999999999998, 0.30600000000000005, 0.02200000000000002, 0.948, 0.46799999999999997, 0.9420000000000002, 0.16699999999999982, 1.911, 0.2400000000000002, -0.15799999999999992, 0.139, 0.3759999999999999, 1.809, 0.796, 0.44799999999999995, 0.3919999999999999, 0.8759999999999999, 0.44899999999999995, 0.3919999999999999, 1.93, 0.8980000000000001, 0.833, -0.136, 0.94, 0.9100000000000001, 0.796, 0.772, 0.30099999999999993, 1.412, 0.15399999999999991, 1.903, -0.03400000000000003, 1.158, 0.69, 1.349, -0.21400000000000008, 0.2370000000000001, 1.752, 0.6659999999999999, 0.9329999999999999, 0.921, 0.843, 0.9430000000000001, 0.20599999999999996, 0.9029999999999999, 0.32399999999999995, 0.8580000000000001, 1.766, 1.831, 1.722, 0.923, 0.883, 1.342, 0.3740000000000001, 1.658, 0.398, -0.05700000000000005, 0.7669999999999999, 0.237, 0.391, 0.7, -0.12499999999999989, 1.694, 1.4140000000000001, 1.189, -0.05600000000000005, 0.8109999999999999, 0.8940000000000001, 0.391, 1.401, 1.718, 0.42899999999999994, 1.943, 1.811, 0.372, 0.43799999999999994, 1.907, 0.4849999999999999, 0.365], "episode_lengths": [41, 21, 69, 63, 300, 41, 96, 17, 51, 21, 43, 52, 21, 44, 49, 20, 35, 68, 300, 15, 20, 55, 58, 149, 16, 10, 18, 102, 28, 81, 49, 110, 38, 59, 62, 16, 34, 39, 15, 33, 22, 31, 50, 43, 19, 28, 61, 71, 61, 27, 107, 31, 11, 248, 92, 48, 67, 82, 78, 102, 21, 25, 48, 18, 92, 300, 55, 44, 73, 53, 86, 25, 37, 49, 37, 105, 31, 174, 70, 80, 34, 92, 38, 91, 27, 97, 17, 60, 33, 34, 31, 86, 22, 18, 58, 39, 17, 29, 157, 41], "policy_red_0_reward": [-0.504, 1.434, 1.2839999999999998, 1.3039999999999998, 0.44299999999999995, -0.506, -0.508, 1.4489999999999998, 0.842, 1.435, 1.366, 1.3359999999999999, -0.003, 1.3639999999999999, -0.5079999999999999, 0.9359999999999999, 1.393, 1.288, 0.44199999999999995, 0.953, 0.9369999999999999, 1.327, 1.32, 0.5379999999999999, 1.451, -1.001, 1.446, 1.182, 0.499, 1.249, -1.006, 1.154, 0.878, 1.3159999999999998, 1.31, 0.952, 1.396, 1.3820000000000001, -0.504, 0.895, 1.4329999999999998, 1.404, 1.341, 0.869, 1.443, 1.416, 1.3079999999999998, 1.283, 1.307, 1.416, 0.67, 0.498, 0.966, 0.701, 1.208, -0.004, 0.7909999999999999, 0.743, 1.26, 1.182, -0.501, -0.501, 1.3519999999999999, 1.4449999999999998, -0.51, 0.44499999999999995, -1.001, 1.363, 1.27, 0.496, 1.2349999999999999, 1.424, 1.387, 1.349, 1.384, 0.49, -0.504, 0.96, 1.274, -0.512, 1.397, 1.2149999999999999, -1.002, 1.208, -0.002, -0.010000000000000002, 0.945, 1.3159999999999998, 1.3980000000000001, -1.005, 1.4060000000000001, 0.486, -1.002, 1.444, 0.49, -0.503, -0.507, 0.499, 1.0, 1.37], "policy_blue_0_reward": [1.37, 0.493, -1.014, -0.506, 0.45699999999999996, 1.37, 0.695, -0.504, -0.504, -1.001, -0.506, -0.503, 1.436, -0.505, 0.848, -0.502, -1.003, -1.013, -0.07000000000000005, -0.502, -0.501, -0.515, -1.014, -0.5159999999999999, -0.5029999999999999, 1.4689999999999999, -0.5039999999999999, -1.015, 1.412, -1.009, 0.848, -1.015, -0.502, 0.493, -0.514, -0.504, -1.004, -0.506, 0.953, -0.503, 0.497, -0.506, -0.508, -1.005, -0.503, -0.506, -0.5119999999999999, -0.511, -1.006, -0.004, -0.516, 1.405, -1.0, 0.45699999999999996, -0.518, 1.353, -1.005, -0.506, 0.492, -0.516, 1.434, 1.4220000000000002, -0.509, -0.502, 0.716, 0.45799999999999996, 1.325, -0.505, 0.496, 1.335, 0.487, -0.501, -0.504, -0.007, -1.01, 1.1680000000000001, 0.902, -1.017, -0.507, 0.749, -1.006, -0.515, 0.877, 0.486, 1.416, 1.199, -1.001, -0.505, -0.504, 1.396, -0.005, 1.232, 1.431, 0.499, 1.3210000000000002, 0.875, 0.945, 1.408, -0.515, -1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3742314769385764, "mean_inference_ms": 7.387968558659111, "mean_action_processing_ms": 0.3899452547827424, "mean_env_wait_ms": 0.5138085158929078, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1386704444885254, "StateBufferConnector_ms": 0.009273171424865723, "ViewRequirementAgentConnector_ms": 0.1838911771774292}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 133.59604042901606, "num_env_steps_trained_throughput_per_sec": 133.59604042901606, "timesteps_total": 232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 30807.933, "sample_time_ms": 3934.439, "learn_time_ms": 26845.353, "learn_throughput": 149.002, "synch_weights_time_ms": 26.726}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "episodes_total": 2377, "training_iteration": 58, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-27-27", "timestamp": 1694838447, "time_this_iter_s": 29.95772910118103, "time_total_s": 1795.0411105155945, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a256dd0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1795.0411105155945, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 23.323255813953487, "ram_util_percent": 57.07441860465116}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.11, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.57, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.57, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.57, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6263568844335775, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0665239098307211, "policy_loss": -0.11076300527444498, "vf_loss": 0.02854812044921952, "vf_explained_var": 0.5452814887588223, "kl": 0.013819230991774204, "entropy": 1.5169012501835824, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 56160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6413665346180399, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06730308661159749, "policy_loss": -0.11300052209553542, "vf_loss": 0.03277201098098885, "vf_explained_var": 0.6127888509382804, "kl": 0.013590231780069127, "entropy": 1.6488173995167017, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 56160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000}, "sampler_results": {"episode_reward_max": 1.943, "episode_reward_min": -0.3789999999999999, "episode_reward_mean": 0.8346600000000001, "episode_len_mean": 55.45, "episode_media": {}, "episodes_this_iter": 72, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.025}, "policy_reward_max": {"red_0": 1.458, "blue_0": 1.456}, "policy_reward_mean": {"red_0": 0.7858400000000002, "blue_0": 0.048820000000000016}, "custom_metrics": {"red_0/door_open_done_mean": 0.11, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.57, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.57, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.57, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.883, 1.342, 0.3740000000000001, 1.658, 0.398, -0.05700000000000005, 0.7669999999999999, 0.237, 0.391, 0.7, -0.12499999999999989, 1.694, 1.4140000000000001, 1.189, -0.05600000000000005, 0.8109999999999999, 0.8940000000000001, 0.391, 1.401, 1.718, 0.42899999999999994, 1.943, 1.811, 0.372, 0.43799999999999994, 1.907, 0.4849999999999999, 0.365, 0.21399999999999997, 0.8330000000000002, 0.45499999999999996, 0.8660000000000001, 0.9000000000000001, 0.839, 0.838, 0.5960000000000001, 0.347, 0.32299999999999995, 0.94, 0.931, 1.7839999999999998, 0.829, -0.08799999999999997, 0.817, 0.42500000000000004, 0.3759999999999999, -0.3789999999999999, 0.3540000000000001, 0.861, 1.666, 0.42500000000000004, 0.04800000000000004, 1.857, 0.7010000000000001, 0.8540000000000001, 0.9239999999999999, 0.43699999999999983, 1.924, 0.7709999999999999, 0.95, 0.798, 0.45599999999999996, 0.8239999999999998, 1.854, 0.4289999999999998, 0.35199999999999987, -0.04700000000000004, 0.9329999999999998, 0.7789999999999999, -0.08499999999999996, 0.43399999999999994, 1.8170000000000002, 0.938, 1.857, 1.751, -0.264, 0.899, 0.6990000000000001, 1.737, 1.855, 0.7909999999999999, 1.722, 0.352, 1.424, 1.675, 0.375, 0.698, 1.725, 0.7189999999999999, 0.41600000000000015, 1.246, 1.9169999999999998, -0.018999999999999906, 0.258, 0.762, -0.028000000000000025, 0.85, 0.9319999999999999, 0.8050000000000002, 1.438], "episode_lengths": [37, 49, 37, 105, 31, 174, 70, 80, 34, 92, 38, 91, 27, 97, 17, 60, 33, 34, 31, 86, 22, 18, 58, 39, 17, 29, 157, 41, 89, 52, 14, 41, 30, 49, 51, 118, 48, 54, 18, 21, 67, 53, 26, 57, 23, 39, 117, 43, 43, 104, 23, 134, 45, 92, 46, 24, 20, 24, 72, 16, 62, 14, 54, 46, 22, 43, 15, 22, 70, 27, 21, 56, 19, 44, 75, 78, 31, 91, 81, 46, 64, 86, 46, 24, 103, 40, 94, 86, 84, 27, 233, 24, 6, 226, 74, 9, 46, 21, 58, 20], "policy_red_0_reward": [1.387, 1.349, 1.384, 0.49, -0.504, 0.96, 1.274, -0.512, 1.397, 1.2149999999999999, -1.002, 1.208, -0.002, -0.010000000000000002, 0.945, 1.3159999999999998, 1.3980000000000001, -1.005, 1.4060000000000001, 0.486, -1.002, 1.444, 0.49, -0.503, -0.507, 0.499, 1.0, 1.37, -0.514, 1.338, -1.001, 1.373, -0.5049999999999999, 1.35, -0.505, 1.129, 0.853, 0.832, 1.444, 1.436, 0.491, 1.335, 0.919, 1.3279999999999998, 0.928, 0.881, 0.638, 0.862, 1.366, 0.487, -1.003, 1.073, 0.496, 1.214, 1.3599999999999999, -0.501, 0.938, 0.499, 1.276, 1.451, 1.3090000000000002, 1.458, 1.334, 0.497, 1.4329999999999998, 1.369, 0.954, 1.4329999999999998, 1.283, 0.916, 1.435, 1.326, 1.4409999999999998, 0.493, 1.262, 0.757, 1.405, 1.213, 1.2469999999999999, 1.3599999999999999, 1.3010000000000002, 0.491, -0.505, 1.427, 0.49, 1.377, 1.206, 0.49, 1.229, 0.918, 0.776, 0.494, -1.0, 0.793, 1.27, 0.973, -0.505, 1.436, 1.319, 1.44], "policy_blue_0_reward": [-0.504, -0.007, -1.01, 1.1680000000000001, 0.902, -1.017, -0.507, 0.749, -1.006, -0.515, 0.877, 0.486, 1.416, 1.199, -1.001, -0.505, -0.504, 1.396, -0.005, 1.232, 1.431, 0.499, 1.3210000000000002, 0.875, 0.945, 1.408, -0.515, -1.005, 0.728, -0.5049999999999999, 1.456, -0.507, 1.405, -0.511, 1.343, -0.533, -0.506, -0.509, -0.504, -0.505, 1.293, -0.506, -1.007, -0.511, -0.503, -0.505, -1.017, -0.508, -0.505, 1.1789999999999998, 1.428, -1.025, 1.361, -0.513, -0.5059999999999999, 1.4249999999999998, -0.501, 1.4249999999999998, -0.505, -0.501, -0.511, -1.002, -0.51, 1.357, -1.004, -1.017, -1.001, -0.5, -0.504, -1.001, -1.001, 0.491, -0.503, 1.3639999999999999, 0.489, -1.021, -0.5059999999999999, -0.5139999999999999, 0.49, 0.495, -0.51, 1.2309999999999999, 0.857, -0.003, 1.185, -1.002, -0.508, 1.2349999999999999, -0.51, -0.5019999999999999, 0.47, 1.423, 0.981, -0.535, -0.508, -1.001, 1.355, -0.504, -0.514, -0.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.375196565647339, "mean_inference_ms": 7.399565811647909, "mean_action_processing_ms": 0.3897239986290122, "mean_env_wait_ms": 0.5144724999548249, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.16989398002624512, "StateBufferConnector_ms": 0.010178208351135254, "ViewRequirementAgentConnector_ms": 0.19867658615112305}}, "episode_reward_max": 1.943, "episode_reward_min": -0.3789999999999999, "episode_reward_mean": 0.8346600000000001, "episode_len_mean": 55.45, "episodes_this_iter": 72, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.025}, "policy_reward_max": {"red_0": 1.458, "blue_0": 1.456}, "policy_reward_mean": {"red_0": 0.7858400000000002, "blue_0": 0.048820000000000016}, "hist_stats": {"episode_reward": [0.883, 1.342, 0.3740000000000001, 1.658, 0.398, -0.05700000000000005, 0.7669999999999999, 0.237, 0.391, 0.7, -0.12499999999999989, 1.694, 1.4140000000000001, 1.189, -0.05600000000000005, 0.8109999999999999, 0.8940000000000001, 0.391, 1.401, 1.718, 0.42899999999999994, 1.943, 1.811, 0.372, 0.43799999999999994, 1.907, 0.4849999999999999, 0.365, 0.21399999999999997, 0.8330000000000002, 0.45499999999999996, 0.8660000000000001, 0.9000000000000001, 0.839, 0.838, 0.5960000000000001, 0.347, 0.32299999999999995, 0.94, 0.931, 1.7839999999999998, 0.829, -0.08799999999999997, 0.817, 0.42500000000000004, 0.3759999999999999, -0.3789999999999999, 0.3540000000000001, 0.861, 1.666, 0.42500000000000004, 0.04800000000000004, 1.857, 0.7010000000000001, 0.8540000000000001, 0.9239999999999999, 0.43699999999999983, 1.924, 0.7709999999999999, 0.95, 0.798, 0.45599999999999996, 0.8239999999999998, 1.854, 0.4289999999999998, 0.35199999999999987, -0.04700000000000004, 0.9329999999999998, 0.7789999999999999, -0.08499999999999996, 0.43399999999999994, 1.8170000000000002, 0.938, 1.857, 1.751, -0.264, 0.899, 0.6990000000000001, 1.737, 1.855, 0.7909999999999999, 1.722, 0.352, 1.424, 1.675, 0.375, 0.698, 1.725, 0.7189999999999999, 0.41600000000000015, 1.246, 1.9169999999999998, -0.018999999999999906, 0.258, 0.762, -0.028000000000000025, 0.85, 0.9319999999999999, 0.8050000000000002, 1.438], "episode_lengths": [37, 49, 37, 105, 31, 174, 70, 80, 34, 92, 38, 91, 27, 97, 17, 60, 33, 34, 31, 86, 22, 18, 58, 39, 17, 29, 157, 41, 89, 52, 14, 41, 30, 49, 51, 118, 48, 54, 18, 21, 67, 53, 26, 57, 23, 39, 117, 43, 43, 104, 23, 134, 45, 92, 46, 24, 20, 24, 72, 16, 62, 14, 54, 46, 22, 43, 15, 22, 70, 27, 21, 56, 19, 44, 75, 78, 31, 91, 81, 46, 64, 86, 46, 24, 103, 40, 94, 86, 84, 27, 233, 24, 6, 226, 74, 9, 46, 21, 58, 20], "policy_red_0_reward": [1.387, 1.349, 1.384, 0.49, -0.504, 0.96, 1.274, -0.512, 1.397, 1.2149999999999999, -1.002, 1.208, -0.002, -0.010000000000000002, 0.945, 1.3159999999999998, 1.3980000000000001, -1.005, 1.4060000000000001, 0.486, -1.002, 1.444, 0.49, -0.503, -0.507, 0.499, 1.0, 1.37, -0.514, 1.338, -1.001, 1.373, -0.5049999999999999, 1.35, -0.505, 1.129, 0.853, 0.832, 1.444, 1.436, 0.491, 1.335, 0.919, 1.3279999999999998, 0.928, 0.881, 0.638, 0.862, 1.366, 0.487, -1.003, 1.073, 0.496, 1.214, 1.3599999999999999, -0.501, 0.938, 0.499, 1.276, 1.451, 1.3090000000000002, 1.458, 1.334, 0.497, 1.4329999999999998, 1.369, 0.954, 1.4329999999999998, 1.283, 0.916, 1.435, 1.326, 1.4409999999999998, 0.493, 1.262, 0.757, 1.405, 1.213, 1.2469999999999999, 1.3599999999999999, 1.3010000000000002, 0.491, -0.505, 1.427, 0.49, 1.377, 1.206, 0.49, 1.229, 0.918, 0.776, 0.494, -1.0, 0.793, 1.27, 0.973, -0.505, 1.436, 1.319, 1.44], "policy_blue_0_reward": [-0.504, -0.007, -1.01, 1.1680000000000001, 0.902, -1.017, -0.507, 0.749, -1.006, -0.515, 0.877, 0.486, 1.416, 1.199, -1.001, -0.505, -0.504, 1.396, -0.005, 1.232, 1.431, 0.499, 1.3210000000000002, 0.875, 0.945, 1.408, -0.515, -1.005, 0.728, -0.5049999999999999, 1.456, -0.507, 1.405, -0.511, 1.343, -0.533, -0.506, -0.509, -0.504, -0.505, 1.293, -0.506, -1.007, -0.511, -0.503, -0.505, -1.017, -0.508, -0.505, 1.1789999999999998, 1.428, -1.025, 1.361, -0.513, -0.5059999999999999, 1.4249999999999998, -0.501, 1.4249999999999998, -0.505, -0.501, -0.511, -1.002, -0.51, 1.357, -1.004, -1.017, -1.001, -0.5, -0.504, -1.001, -1.001, 0.491, -0.503, 1.3639999999999999, 0.489, -1.021, -0.5059999999999999, -0.5139999999999999, 0.49, 0.495, -0.51, 1.2309999999999999, 0.857, -0.003, 1.185, -1.002, -0.508, 1.2349999999999999, -0.51, -0.5019999999999999, 0.47, 1.423, 0.981, -0.535, -0.508, -1.001, 1.355, -0.504, -0.514, -0.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.375196565647339, "mean_inference_ms": 7.399565811647909, "mean_action_processing_ms": 0.3897239986290122, "mean_env_wait_ms": 0.5144724999548249, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.16989398002624512, "StateBufferConnector_ms": 0.010178208351135254, "ViewRequirementAgentConnector_ms": 0.19867658615112305}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.9307364597611, "num_env_steps_trained_throughput_per_sec": 128.9307364597611, "timesteps_total": 236000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 472000, "timers": {"training_iteration_time_ms": 30860.632, "sample_time_ms": 3997.21, "learn_time_ms": 26835.13, "learn_throughput": 149.058, "synch_weights_time_ms": 26.834}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000}, "done": false, "episodes_total": 2449, "training_iteration": 59, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-27-59", "timestamp": 1694838479, "time_this_iter_s": 31.0401508808136, "time_total_s": 1826.081261396408, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80ec8ee0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1826.081261396408, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 26.631111111111114, "ram_util_percent": 57.08666666666666}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.16, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.64, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.64, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.64, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6406202444806695, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06328290696207356, "policy_loss": -0.10557963483831069, "vf_loss": 0.022831939998529074, "vf_explained_var": 0.591192955772082, "kl": 0.014239019179675788, "entropy": 1.5575079393883546, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 57120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6105219105258584, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06307972155627795, "policy_loss": -0.10500667999585858, "vf_loss": 0.030448819990851916, "vf_explained_var": 0.5775642650822799, "kl": 0.012449234656297525, "entropy": 1.6583649126191935, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 57120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "sampler_results": {"episode_reward_max": 1.9369999999999998, "episode_reward_min": -0.271, "episode_reward_mean": 0.8316499999999999, "episode_len_mean": 60.98, "episode_media": {}, "episodes_this_iter": 64, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.427}, "policy_reward_mean": {"red_0": 0.97821, "blue_0": -0.14655999999999997}, "custom_metrics": {"red_0/door_open_done_mean": 0.16, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.64, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.64, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.64, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.4289999999999998, 0.35199999999999987, -0.04700000000000004, 0.9329999999999998, 0.7789999999999999, -0.08499999999999996, 0.43399999999999994, 1.8170000000000002, 0.938, 1.857, 1.751, -0.264, 0.899, 0.6990000000000001, 1.737, 1.855, 0.7909999999999999, 1.722, 0.352, 1.424, 1.675, 0.375, 0.698, 1.725, 0.7189999999999999, 0.41600000000000015, 1.246, 1.9169999999999998, -0.018999999999999906, 0.258, 0.762, -0.028000000000000025, 0.85, 0.9319999999999999, 0.8050000000000002, 1.438, 0.10899999999999999, 0.18500000000000005, 0.40700000000000003, 1.826, 1.8319999999999999, 0.41700000000000026, 1.413, 0.42699999999999994, 0.6520000000000001, 1.903, 0.4039999999999999, -0.18900000000000006, 1.889, 0.4079999999999999, 0.871, 0.43399999999999994, 0.46399999999999997, 0.931, 0.3680000000000001, 0.6950000000000001, 0.373, 0.3860000000000001, 1.422, 0.823, 0.605, 0.4590000000000001, 1.7959999999999998, 0.605, 1.0790000000000002, -0.06900000000000006, 1.9369999999999998, 0.44700000000000006, 0.9510000000000001, 0.391, 0.9550000000000001, 1.9249999999999998, 0.30200000000000005, 0.242, 0.9510000000000001, 0.9079999999999999, 1.87, 0.732, 0.3490000000000001, 1.85, 0.266, 0.43699999999999983, 0.33099999999999996, 0.2829999999999999, 1.362, -0.06700000000000006, 0.891, 0.32200000000000006, 0.8620000000000001, 0.7390000000000001, 0.8860000000000001, 1.9020000000000001, 0.79, 0.909, 0.08099999999999996, -0.271, 1.6520000000000001, 0.722, 0.357, 1.834], "episode_lengths": [22, 43, 15, 22, 70, 27, 21, 56, 19, 44, 75, 78, 31, 91, 81, 46, 64, 86, 46, 24, 103, 40, 94, 86, 84, 27, 233, 24, 6, 226, 74, 9, 46, 21, 58, 20, 272, 99, 29, 54, 51, 26, 27, 22, 106, 30, 181, 61, 35, 28, 39, 20, 12, 22, 41, 95, 39, 35, 24, 53, 121, 12, 60, 123, 278, 22, 20, 17, 16, 182, 14, 24, 211, 79, 16, 29, 41, 84, 44, 46, 71, 20, 53, 66, 44, 21, 35, 52, 43, 81, 37, 30, 68, 27, 127, 82, 107, 85, 45, 52], "policy_red_0_reward": [1.4329999999999998, 1.369, 0.954, 1.4329999999999998, 1.283, 0.916, 1.435, 1.326, 1.4409999999999998, 0.493, 1.262, 0.757, 1.405, 1.213, 1.2469999999999999, 1.3599999999999999, 1.3010000000000002, 0.491, -0.505, 1.427, 0.49, 1.377, 1.206, 0.49, 1.229, 0.918, 0.776, 0.494, -1.0, 0.793, 1.27, 0.973, -0.505, 1.436, 1.319, 1.44, -0.536, 1.197, 1.409, 0.492, 1.339, 1.419, 1.417, -0.502, 1.173, 1.409, 0.9369999999999999, 0.813, 0.498, 1.411, 1.38, 1.4369999999999998, 1.464, 1.432, 0.874, 1.205, 0.876, 1.392, -0.003, -0.507, 1.1280000000000001, 0.96, 1.3079999999999998, 1.116, 0.625, 0.9319999999999999, 1.438, 1.448, 1.451, 0.9269999999999999, 1.4569999999999999, 0.498, 0.831, 0.749, 1.452, 1.4100000000000001, 0.496, 1.2389999999999999, -1.007, 0.496, 1.28, 1.439, 0.835, 1.292, 1.365, -1.002, 1.393, 1.334, 1.369, 1.249, 1.388, 0.496, 1.294, 1.416, 1.101, 0.744, 1.167, 1.233, 1.3599999999999999, 1.341], "policy_blue_0_reward": [-1.004, -1.017, -1.001, -0.5, -0.504, -1.001, -1.001, 0.491, -0.503, 1.3639999999999999, 0.489, -1.021, -0.5059999999999999, -0.5139999999999999, 0.49, 0.495, -0.51, 1.2309999999999999, 0.857, -0.003, 1.185, -1.002, -0.508, 1.2349999999999999, -0.51, -0.5019999999999999, 0.47, 1.423, 0.981, -0.535, -0.508, -1.001, 1.355, -0.504, -0.514, -0.002, 0.645, -1.012, -1.002, 1.334, 0.493, -1.0019999999999998, -0.004, 0.9289999999999999, -0.5209999999999999, 0.494, -0.533, -1.002, 1.391, -1.003, -0.5089999999999999, -1.003, -1.0, -0.501, -0.5059999999999999, -0.51, -0.503, -1.0059999999999998, 1.4249999999999998, 1.33, -0.523, -0.501, 0.488, -0.511, 0.45399999999999996, -1.001, 0.499, -1.001, -0.5, -0.536, -0.5019999999999999, 1.427, -0.529, -0.507, -0.501, -0.502, 1.374, -0.507, 1.3559999999999999, 1.354, -1.0139999999999998, -1.002, -0.504, -1.009, -0.003, 0.9349999999999999, -0.502, -1.012, -0.507, -0.5099999999999999, -0.502, 1.4060000000000001, -0.504, -0.507, -1.02, -1.015, 0.485, -0.511, -1.003, 0.493]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3754297388643024, "mean_inference_ms": 7.405130815604166, "mean_action_processing_ms": 0.3900491711715186, "mean_env_wait_ms": 0.5145249370728328, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15596187114715576, "StateBufferConnector_ms": 0.01022493839263916, "ViewRequirementAgentConnector_ms": 0.19563603401184082}}, "episode_reward_max": 1.9369999999999998, "episode_reward_min": -0.271, "episode_reward_mean": 0.8316499999999999, "episode_len_mean": 60.98, "episodes_this_iter": 64, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.021}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.427}, "policy_reward_mean": {"red_0": 0.97821, "blue_0": -0.14655999999999997}, "hist_stats": {"episode_reward": [0.4289999999999998, 0.35199999999999987, -0.04700000000000004, 0.9329999999999998, 0.7789999999999999, -0.08499999999999996, 0.43399999999999994, 1.8170000000000002, 0.938, 1.857, 1.751, -0.264, 0.899, 0.6990000000000001, 1.737, 1.855, 0.7909999999999999, 1.722, 0.352, 1.424, 1.675, 0.375, 0.698, 1.725, 0.7189999999999999, 0.41600000000000015, 1.246, 1.9169999999999998, -0.018999999999999906, 0.258, 0.762, -0.028000000000000025, 0.85, 0.9319999999999999, 0.8050000000000002, 1.438, 0.10899999999999999, 0.18500000000000005, 0.40700000000000003, 1.826, 1.8319999999999999, 0.41700000000000026, 1.413, 0.42699999999999994, 0.6520000000000001, 1.903, 0.4039999999999999, -0.18900000000000006, 1.889, 0.4079999999999999, 0.871, 0.43399999999999994, 0.46399999999999997, 0.931, 0.3680000000000001, 0.6950000000000001, 0.373, 0.3860000000000001, 1.422, 0.823, 0.605, 0.4590000000000001, 1.7959999999999998, 0.605, 1.0790000000000002, -0.06900000000000006, 1.9369999999999998, 0.44700000000000006, 0.9510000000000001, 0.391, 0.9550000000000001, 1.9249999999999998, 0.30200000000000005, 0.242, 0.9510000000000001, 0.9079999999999999, 1.87, 0.732, 0.3490000000000001, 1.85, 0.266, 0.43699999999999983, 0.33099999999999996, 0.2829999999999999, 1.362, -0.06700000000000006, 0.891, 0.32200000000000006, 0.8620000000000001, 0.7390000000000001, 0.8860000000000001, 1.9020000000000001, 0.79, 0.909, 0.08099999999999996, -0.271, 1.6520000000000001, 0.722, 0.357, 1.834], "episode_lengths": [22, 43, 15, 22, 70, 27, 21, 56, 19, 44, 75, 78, 31, 91, 81, 46, 64, 86, 46, 24, 103, 40, 94, 86, 84, 27, 233, 24, 6, 226, 74, 9, 46, 21, 58, 20, 272, 99, 29, 54, 51, 26, 27, 22, 106, 30, 181, 61, 35, 28, 39, 20, 12, 22, 41, 95, 39, 35, 24, 53, 121, 12, 60, 123, 278, 22, 20, 17, 16, 182, 14, 24, 211, 79, 16, 29, 41, 84, 44, 46, 71, 20, 53, 66, 44, 21, 35, 52, 43, 81, 37, 30, 68, 27, 127, 82, 107, 85, 45, 52], "policy_red_0_reward": [1.4329999999999998, 1.369, 0.954, 1.4329999999999998, 1.283, 0.916, 1.435, 1.326, 1.4409999999999998, 0.493, 1.262, 0.757, 1.405, 1.213, 1.2469999999999999, 1.3599999999999999, 1.3010000000000002, 0.491, -0.505, 1.427, 0.49, 1.377, 1.206, 0.49, 1.229, 0.918, 0.776, 0.494, -1.0, 0.793, 1.27, 0.973, -0.505, 1.436, 1.319, 1.44, -0.536, 1.197, 1.409, 0.492, 1.339, 1.419, 1.417, -0.502, 1.173, 1.409, 0.9369999999999999, 0.813, 0.498, 1.411, 1.38, 1.4369999999999998, 1.464, 1.432, 0.874, 1.205, 0.876, 1.392, -0.003, -0.507, 1.1280000000000001, 0.96, 1.3079999999999998, 1.116, 0.625, 0.9319999999999999, 1.438, 1.448, 1.451, 0.9269999999999999, 1.4569999999999999, 0.498, 0.831, 0.749, 1.452, 1.4100000000000001, 0.496, 1.2389999999999999, -1.007, 0.496, 1.28, 1.439, 0.835, 1.292, 1.365, -1.002, 1.393, 1.334, 1.369, 1.249, 1.388, 0.496, 1.294, 1.416, 1.101, 0.744, 1.167, 1.233, 1.3599999999999999, 1.341], "policy_blue_0_reward": [-1.004, -1.017, -1.001, -0.5, -0.504, -1.001, -1.001, 0.491, -0.503, 1.3639999999999999, 0.489, -1.021, -0.5059999999999999, -0.5139999999999999, 0.49, 0.495, -0.51, 1.2309999999999999, 0.857, -0.003, 1.185, -1.002, -0.508, 1.2349999999999999, -0.51, -0.5019999999999999, 0.47, 1.423, 0.981, -0.535, -0.508, -1.001, 1.355, -0.504, -0.514, -0.002, 0.645, -1.012, -1.002, 1.334, 0.493, -1.0019999999999998, -0.004, 0.9289999999999999, -0.5209999999999999, 0.494, -0.533, -1.002, 1.391, -1.003, -0.5089999999999999, -1.003, -1.0, -0.501, -0.5059999999999999, -0.51, -0.503, -1.0059999999999998, 1.4249999999999998, 1.33, -0.523, -0.501, 0.488, -0.511, 0.45399999999999996, -1.001, 0.499, -1.001, -0.5, -0.536, -0.5019999999999999, 1.427, -0.529, -0.507, -0.501, -0.502, 1.374, -0.507, 1.3559999999999999, 1.354, -1.0139999999999998, -1.002, -0.504, -1.009, -0.003, 0.9349999999999999, -0.502, -1.012, -0.507, -0.5099999999999999, -0.502, 1.4060000000000001, -0.504, -0.507, -1.02, -1.015, 0.485, -0.511, -1.003, 0.493]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3754297388643024, "mean_inference_ms": 7.405130815604166, "mean_action_processing_ms": 0.3900491711715186, "mean_env_wait_ms": 0.5145249370728328, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15596187114715576, "StateBufferConnector_ms": 0.01022493839263916, "ViewRequirementAgentConnector_ms": 0.19563603401184082}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.58515211326045, "num_env_steps_trained_throughput_per_sec": 129.58515211326045, "timesteps_total": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 30962.826, "sample_time_ms": 4025.587, "learn_time_ms": 26908.593, "learn_throughput": 148.651, "synch_weights_time_ms": 27.178}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "episodes_total": 2513, "training_iteration": 60, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-28-30", "timestamp": 1694838510, "time_this_iter_s": 30.883782148361206, "time_total_s": 1856.9650435447693, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a257370>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1856.9650435447693, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 24.54666666666667, "ram_util_percent": 57.035555555555554}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.1, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.61, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.15, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.61, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.15, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.61, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.15, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6314919012598693, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.061949179638031635, "policy_loss": -0.1070749734135461, "vf_loss": 0.0307970315470205, "vf_explained_var": 0.6284717500209809, "kl": 0.013707963172043824, "entropy": 1.501176713903745, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 58080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6296689526488384, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05890621436786508, "policy_loss": -0.10902522440010216, "vf_loss": 0.042171910280982654, "vf_explained_var": 0.6055287536854546, "kl": 0.013452563559955834, "entropy": 1.613566981256008, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 58080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000}, "sampler_results": {"episode_reward_max": 1.949, "episode_reward_min": -0.271, "episode_reward_mean": 0.8322399999999999, "episode_len_mean": 47.15, "episode_media": {}, "episodes_this_iter": 88, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.02}, "policy_reward_max": {"red_0": 1.467, "blue_0": 1.472}, "policy_reward_mean": {"red_0": 0.8399899999999998, "blue_0": -0.007749999999999995}, "custom_metrics": {"red_0/door_open_done_mean": 0.1, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.61, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.15, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.61, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.15, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.61, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.15, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.8620000000000001, 0.7390000000000001, 0.8860000000000001, 1.9020000000000001, 0.79, 0.909, 0.08099999999999996, -0.271, 1.6520000000000001, 0.722, 0.357, 1.834, 0.9339999999999999, 0.45999999999999996, 0.272, 0.5259999999999998, 0.46799999999999997, 0.401, 1.798, -0.05699999999999994, 0.821, 0.4289999999999998, 1.9000000000000001, 0.32899999999999996, 0.3700000000000001, 0.4670000000000001, -0.049000000000000044, 0.897, -0.10599999999999998, 0.18800000000000017, 0.889, 0.733, 1.8860000000000001, 0.704, 0.46099999999999985, 1.3519999999999999, 0.9649999999999999, 0.31599999999999995, 0.29400000000000004, 0.884, 0.972, 0.9140000000000001, 1.8780000000000001, 0.31299999999999994, -0.049000000000000044, 0.8159999999999998, 0.841, 1.8039999999999998, 0.41899999999999993, -0.05800000000000005, 0.831, -0.030000000000000027, 0.3580000000000001, 0.46399999999999997, 1.8860000000000001, 0.856, 1.919, 0.632, 0.8620000000000001, 0.44099999999999995, -0.052000000000000046, 0.44300000000000006, 0.9569999999999999, 1.8079999999999998, 0.3820000000000001, 1.452, 1.733, 1.876, 0.45100000000000007, 0.939, -0.10399999999999998, 0.383, -0.08999999999999986, 0.917, 1.916, 1.849, 0.3860000000000001, 0.45799999999999996, 1.901, 0.42799999999999994, 0.653, 1.949, 0.6480000000000001, 0.8740000000000001, 1.798, 0.45500000000000007, 1.772, 0.8679999999999999, 1.14, 0.46399999999999997, 0.774, 0.855, 0.879, 0.9329999999999998, 0.9159999999999999, 1.5659999999999998, 0.696, 0.1409999999999999, 1.872, 0.8740000000000001], "episode_lengths": [43, 81, 37, 30, 68, 27, 127, 82, 107, 85, 45, 52, 21, 13, 71, 145, 10, 31, 62, 17, 57, 22, 32, 52, 40, 11, 15, 32, 32, 97, 32, 84, 36, 91, 13, 42, 11, 54, 66, 35, 9, 28, 38, 59, 15, 57, 48, 60, 24, 18, 53, 10, 44, 11, 36, 44, 25, 113, 42, 19, 16, 17, 14, 59, 36, 16, 83, 38, 15, 20, 31, 36, 26, 25, 27, 46, 34, 13, 31, 22, 108, 16, 106, 38, 64, 14, 71, 42, 267, 11, 71, 44, 37, 21, 26, 131, 92, 112, 40, 38], "policy_red_0_reward": [1.369, 1.249, 1.388, 0.496, 1.294, 1.416, 1.101, 0.744, 1.167, 1.233, 1.3599999999999999, 1.341, 1.435, 1.46, 1.2810000000000001, 1.0419999999999998, 0.969, 1.407, 0.489, 0.948, 1.326, 0.9299999999999999, 1.4020000000000001, 0.838, 1.375, 1.467, -1.002, 1.4, 0.897, 1.199, 1.4020000000000001, -0.506, 0.497, 1.216, 0.961, -0.010000000000000002, 1.467, -0.513, 0.801, -0.504, -0.5, 1.4140000000000001, 0.495, 1.317, -1.001, 1.325, 1.353, 0.489, -1.004, 0.945, -0.505, 0.97, 1.3639999999999999, -1.001, 0.496, -0.506, 1.424, -0.511, 1.369, 0.942, 0.949, 1.447, 1.4569999999999999, 1.315, 1.3900000000000001, 0.0, 0.489, 1.385, 0.954, -0.501, 0.904, 0.888, 0.92, 1.424, 0.5, 1.355, 0.894, 1.459, 1.4060000000000001, 0.9309999999999999, 1.165, 1.452, 1.166, 1.381, 0.496, 1.456, 0.496, 1.371, 0.46599999999999997, 1.467, -0.508, 1.362, 1.3860000000000001, 1.436, 1.419, 0.483, -0.513, -1.007, 1.375, 1.377], "policy_blue_0_reward": [-0.507, -0.5099999999999999, -0.502, 1.4060000000000001, -0.504, -0.507, -1.02, -1.015, 0.485, -0.511, -1.003, 0.493, -0.501, -1.0, -1.009, -0.516, -0.501, -1.006, 1.3090000000000002, -1.005, -0.505, -0.501, 0.498, -0.509, -1.005, -1.0, 0.953, -0.503, -1.003, -1.011, -0.513, 1.2389999999999999, 1.389, -0.512, -0.5, 1.362, -0.502, 0.829, -0.507, 1.388, 1.472, -0.5, 1.383, -1.004, 0.952, -0.509, -0.512, 1.315, 1.423, -1.003, 1.3359999999999999, -1.0, -1.006, 1.4649999999999999, 1.3900000000000001, 1.362, 0.495, 1.143, -0.507, -0.501, -1.001, -1.0039999999999998, -0.5, 0.493, -1.008, 1.452, 1.244, 0.491, -0.5029999999999999, 1.44, -1.008, -0.505, -1.0099999999999998, -0.507, 1.416, 0.494, -0.508, -1.001, 0.495, -0.5029999999999999, -0.512, 0.497, -0.5179999999999999, -0.507, 1.302, -1.001, 1.276, -0.503, 0.6739999999999999, -1.003, 1.282, -0.507, -0.507, -0.503, -0.503, 1.083, 1.209, 1.148, 0.497, -0.503]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3775753550787244, "mean_inference_ms": 7.4191925946965895, "mean_action_processing_ms": 0.3914301999332895, "mean_env_wait_ms": 0.515051670832395, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15572285652160645, "StateBufferConnector_ms": 0.010084986686706543, "ViewRequirementAgentConnector_ms": 0.22714924812316895}}, "episode_reward_max": 1.949, "episode_reward_min": -0.271, "episode_reward_mean": 0.8322399999999999, "episode_len_mean": 47.15, "episodes_this_iter": 88, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.02}, "policy_reward_max": {"red_0": 1.467, "blue_0": 1.472}, "policy_reward_mean": {"red_0": 0.8399899999999998, "blue_0": -0.007749999999999995}, "hist_stats": {"episode_reward": [0.8620000000000001, 0.7390000000000001, 0.8860000000000001, 1.9020000000000001, 0.79, 0.909, 0.08099999999999996, -0.271, 1.6520000000000001, 0.722, 0.357, 1.834, 0.9339999999999999, 0.45999999999999996, 0.272, 0.5259999999999998, 0.46799999999999997, 0.401, 1.798, -0.05699999999999994, 0.821, 0.4289999999999998, 1.9000000000000001, 0.32899999999999996, 0.3700000000000001, 0.4670000000000001, -0.049000000000000044, 0.897, -0.10599999999999998, 0.18800000000000017, 0.889, 0.733, 1.8860000000000001, 0.704, 0.46099999999999985, 1.3519999999999999, 0.9649999999999999, 0.31599999999999995, 0.29400000000000004, 0.884, 0.972, 0.9140000000000001, 1.8780000000000001, 0.31299999999999994, -0.049000000000000044, 0.8159999999999998, 0.841, 1.8039999999999998, 0.41899999999999993, -0.05800000000000005, 0.831, -0.030000000000000027, 0.3580000000000001, 0.46399999999999997, 1.8860000000000001, 0.856, 1.919, 0.632, 0.8620000000000001, 0.44099999999999995, -0.052000000000000046, 0.44300000000000006, 0.9569999999999999, 1.8079999999999998, 0.3820000000000001, 1.452, 1.733, 1.876, 0.45100000000000007, 0.939, -0.10399999999999998, 0.383, -0.08999999999999986, 0.917, 1.916, 1.849, 0.3860000000000001, 0.45799999999999996, 1.901, 0.42799999999999994, 0.653, 1.949, 0.6480000000000001, 0.8740000000000001, 1.798, 0.45500000000000007, 1.772, 0.8679999999999999, 1.14, 0.46399999999999997, 0.774, 0.855, 0.879, 0.9329999999999998, 0.9159999999999999, 1.5659999999999998, 0.696, 0.1409999999999999, 1.872, 0.8740000000000001], "episode_lengths": [43, 81, 37, 30, 68, 27, 127, 82, 107, 85, 45, 52, 21, 13, 71, 145, 10, 31, 62, 17, 57, 22, 32, 52, 40, 11, 15, 32, 32, 97, 32, 84, 36, 91, 13, 42, 11, 54, 66, 35, 9, 28, 38, 59, 15, 57, 48, 60, 24, 18, 53, 10, 44, 11, 36, 44, 25, 113, 42, 19, 16, 17, 14, 59, 36, 16, 83, 38, 15, 20, 31, 36, 26, 25, 27, 46, 34, 13, 31, 22, 108, 16, 106, 38, 64, 14, 71, 42, 267, 11, 71, 44, 37, 21, 26, 131, 92, 112, 40, 38], "policy_red_0_reward": [1.369, 1.249, 1.388, 0.496, 1.294, 1.416, 1.101, 0.744, 1.167, 1.233, 1.3599999999999999, 1.341, 1.435, 1.46, 1.2810000000000001, 1.0419999999999998, 0.969, 1.407, 0.489, 0.948, 1.326, 0.9299999999999999, 1.4020000000000001, 0.838, 1.375, 1.467, -1.002, 1.4, 0.897, 1.199, 1.4020000000000001, -0.506, 0.497, 1.216, 0.961, -0.010000000000000002, 1.467, -0.513, 0.801, -0.504, -0.5, 1.4140000000000001, 0.495, 1.317, -1.001, 1.325, 1.353, 0.489, -1.004, 0.945, -0.505, 0.97, 1.3639999999999999, -1.001, 0.496, -0.506, 1.424, -0.511, 1.369, 0.942, 0.949, 1.447, 1.4569999999999999, 1.315, 1.3900000000000001, 0.0, 0.489, 1.385, 0.954, -0.501, 0.904, 0.888, 0.92, 1.424, 0.5, 1.355, 0.894, 1.459, 1.4060000000000001, 0.9309999999999999, 1.165, 1.452, 1.166, 1.381, 0.496, 1.456, 0.496, 1.371, 0.46599999999999997, 1.467, -0.508, 1.362, 1.3860000000000001, 1.436, 1.419, 0.483, -0.513, -1.007, 1.375, 1.377], "policy_blue_0_reward": [-0.507, -0.5099999999999999, -0.502, 1.4060000000000001, -0.504, -0.507, -1.02, -1.015, 0.485, -0.511, -1.003, 0.493, -0.501, -1.0, -1.009, -0.516, -0.501, -1.006, 1.3090000000000002, -1.005, -0.505, -0.501, 0.498, -0.509, -1.005, -1.0, 0.953, -0.503, -1.003, -1.011, -0.513, 1.2389999999999999, 1.389, -0.512, -0.5, 1.362, -0.502, 0.829, -0.507, 1.388, 1.472, -0.5, 1.383, -1.004, 0.952, -0.509, -0.512, 1.315, 1.423, -1.003, 1.3359999999999999, -1.0, -1.006, 1.4649999999999999, 1.3900000000000001, 1.362, 0.495, 1.143, -0.507, -0.501, -1.001, -1.0039999999999998, -0.5, 0.493, -1.008, 1.452, 1.244, 0.491, -0.5029999999999999, 1.44, -1.008, -0.505, -1.0099999999999998, -0.507, 1.416, 0.494, -0.508, -1.001, 0.495, -0.5029999999999999, -0.512, 0.497, -0.5179999999999999, -0.507, 1.302, -1.001, 1.276, -0.503, 0.6739999999999999, -1.003, 1.282, -0.507, -0.507, -0.503, -0.503, 1.083, 1.209, 1.148, 0.497, -0.503]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3775753550787244, "mean_inference_ms": 7.4191925946965895, "mean_action_processing_ms": 0.3914301999332895, "mean_env_wait_ms": 0.515051670832395, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15572285652160645, "StateBufferConnector_ms": 0.010084986686706543, "ViewRequirementAgentConnector_ms": 0.22714924812316895}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 115.86336310127776, "num_env_steps_trained_throughput_per_sec": 115.86336310127776, "timesteps_total": 244000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 488000, "timers": {"training_iteration_time_ms": 30916.224, "sample_time_ms": 4030.657, "learn_time_ms": 26857.029, "learn_throughput": 148.937, "synch_weights_time_ms": 27.059}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000}, "done": false, "episodes_total": 2601, "training_iteration": 61, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-29-06", "timestamp": 1694838546, "time_this_iter_s": 34.54082894325256, "time_total_s": 1891.5058724880219, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80edb130>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1891.5058724880219, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 31.031372549019615, "ram_util_percent": 57.07058823529412}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.09, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6267940768040716, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06303095348654703, "policy_loss": -0.10782515440441784, "vf_loss": 0.029687840065162164, "vf_explained_var": 0.6361709150175253, "kl": 0.01380689324658643, "entropy": 1.503547968591253, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 59040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.625848422696193, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06266737561575914, "policy_loss": -0.11332901847345056, "vf_loss": 0.03895569814631017, "vf_explained_var": 0.6605184371893604, "kl": 0.014390947255498847, "entropy": 1.6005825440088908, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 59040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "sampler_results": {"episode_reward_max": 1.9369999999999998, "episode_reward_min": -0.08499999999999996, "episode_reward_mean": 0.8961200000000001, "episode_len_mean": 47.03, "episode_media": {}, "episodes_this_iter": 92, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.011}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 0.85953, "blue_0": 0.03659000000000002}, "custom_metrics": {"red_0/door_open_done_mean": 0.09, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.879, 0.9329999999999998, 0.9159999999999999, 1.5659999999999998, 0.696, 0.1409999999999999, 1.872, 0.8740000000000001, 0.22599999999999998, 0.478, 0.857, 0.9620000000000002, 0.44799999999999995, 0.46899999999999986, 1.823, 0.925, 0.9239999999999999, 0.798, 1.876, 1.3239999999999998, 0.9139999999999999, 1.423, 1.416, 0.954, 0.8860000000000001, 1.874, 0.909, 0.9529999999999998, 0.393, 1.417, 0.905, 0.827, 0.8410000000000002, 0.10899999999999999, 0.6779999999999999, 1.874, 0.3570000000000002, 0.4289999999999998, 0.41000000000000014, 0.8479999999999999, 1.9140000000000001, 0.891, 0.377, 0.44999999999999996, -0.08499999999999996, 0.657, 1.884, 0.798, 1.843, 0.9199999999999999, 1.826, 0.7170000000000001, 0.7770000000000001, 0.5999999999999999, -0.052000000000000046, 0.8919999999999999, 0.42599999999999993, 0.42100000000000004, 1.9369999999999998, 0.3340000000000001, 1.927, 0.6339999999999999, 0.44700000000000006, 1.763, 0.353, 0.474, 0.8780000000000001, 0.924, 0.43499999999999994, 0.9609999999999999, 0.3540000000000001, 0.772, 0.45799999999999996, 1.925, 1.436, 0.45899999999999996, 0.567, 0.783, 0.8089999999999999, 0.357, -0.061000000000000054, 0.30699999999999994, 0.512, 1.8900000000000001, 0.361, 1.706, 0.8679999999999999, 0.897, 1.9140000000000001, 0.9300000000000002, 0.6510000000000002, 0.9550000000000001, 0.41100000000000003, 1.8599999999999999, 0.42800000000000005, -0.06500000000000006, 1.3940000000000001, 1.92, 0.774, 0.31299999999999994], "episode_lengths": [37, 21, 26, 131, 92, 112, 40, 38, 84, 7, 44, 12, 17, 10, 54, 23, 24, 64, 39, 55, 300, 25, 26, 15, 35, 39, 28, 14, 34, 26, 29, 52, 48, 121, 99, 40, 45, 22, 28, 48, 27, 34, 38, 15, 27, 103, 35, 64, 49, 24, 54, 89, 67, 120, 16, 32, 22, 26, 21, 51, 22, 112, 16, 72, 45, 8, 36, 23, 19, 12, 44, 71, 14, 23, 20, 13, 128, 68, 59, 43, 18, 58, 149, 35, 43, 92, 42, 32, 28, 22, 107, 14, 27, 42, 23, 21, 32, 25, 70, 57], "policy_red_0_reward": [1.3860000000000001, 1.436, 1.419, 0.483, -0.513, -1.007, 1.375, 1.377, -0.512, -1.001, -0.503, 1.464, 1.4489999999999998, 0.969, 0.491, 1.427, 1.428, 1.3050000000000002, 1.38, 1.33, 0.44999999999999996, 1.424, -0.003, 1.454, 1.392, 0.494, 1.415, 1.456, 0.894, -0.002, -0.502, -0.509, 1.349, 1.12, 1.19, 1.377, 1.361, 0.9309999999999999, 1.412, 1.353, 1.417, 1.396, 1.381, 1.4529999999999998, 0.918, 1.173, 0.495, 1.302, 0.495, -0.505, 0.495, 1.22, 1.29, 1.129, 0.95, 1.4, 1.431, 1.421, 0.5, 1.338, 0.495, -0.518, 0.949, 1.274, 0.861, 0.976, 1.3860000000000001, -0.503, -1.007, 1.462, 1.357, 1.28, 1.458, 0.498, 1.439, -1.002, 1.097, -0.505, 1.319, 1.3639999999999999, 0.94, 1.318, 1.032, 0.498, 1.366, 0.487, 1.371, 1.4, 0.499, 1.4329999999999998, 1.165, 1.4569999999999999, 0.916, 0.496, -0.502, 0.9349999999999999, -0.005, 1.423, 1.2850000000000001, 0.821], "policy_blue_0_reward": [-0.507, -0.503, -0.503, 1.083, 1.209, 1.148, 0.497, -0.503, 0.738, 1.479, 1.3599999999999999, -0.5019999999999999, -1.001, -0.5, 1.3319999999999999, -0.502, -0.504, -0.507, 0.496, -0.006, 0.46399999999999997, -0.001, 1.419, -0.5, -0.506, 1.38, -0.506, -0.503, -0.501, 1.419, 1.407, 1.3359999999999999, -0.5079999999999999, -1.011, -0.512, 0.497, -1.0039999999999998, -0.502, -1.002, -0.505, 0.497, -0.505, -1.004, -1.003, -1.003, -0.516, 1.389, -0.504, 1.3479999999999999, 1.4249999999999998, 1.331, -0.503, -0.5129999999999999, -0.529, -1.002, -0.508, -1.005, -1.0, 1.4369999999999998, -1.004, 1.432, 1.152, -0.502, 0.489, -0.508, -0.502, -0.5079999999999999, 1.427, 1.442, -0.501, -1.003, -0.508, -1.0, 1.427, -0.003, 1.4609999999999999, -0.53, 1.288, -0.51, -1.007, -1.001, -1.011, -0.52, 1.392, -1.005, 1.2189999999999999, -0.503, -0.503, 1.415, -0.5029999999999999, -0.5139999999999999, -0.502, -0.505, 1.3639999999999999, 0.93, -1.0, 1.399, 0.497, -0.511, -0.508]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3811796116136315, "mean_inference_ms": 7.420026746366674, "mean_action_processing_ms": 0.39083371258846794, "mean_env_wait_ms": 0.5156002758652538, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15234136581420898, "StateBufferConnector_ms": 0.009992837905883789, "ViewRequirementAgentConnector_ms": 0.19675910472869873}}, "episode_reward_max": 1.9369999999999998, "episode_reward_min": -0.08499999999999996, "episode_reward_mean": 0.8961200000000001, "episode_len_mean": 47.03, "episodes_this_iter": 92, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.011}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 0.85953, "blue_0": 0.03659000000000002}, "hist_stats": {"episode_reward": [0.879, 0.9329999999999998, 0.9159999999999999, 1.5659999999999998, 0.696, 0.1409999999999999, 1.872, 0.8740000000000001, 0.22599999999999998, 0.478, 0.857, 0.9620000000000002, 0.44799999999999995, 0.46899999999999986, 1.823, 0.925, 0.9239999999999999, 0.798, 1.876, 1.3239999999999998, 0.9139999999999999, 1.423, 1.416, 0.954, 0.8860000000000001, 1.874, 0.909, 0.9529999999999998, 0.393, 1.417, 0.905, 0.827, 0.8410000000000002, 0.10899999999999999, 0.6779999999999999, 1.874, 0.3570000000000002, 0.4289999999999998, 0.41000000000000014, 0.8479999999999999, 1.9140000000000001, 0.891, 0.377, 0.44999999999999996, -0.08499999999999996, 0.657, 1.884, 0.798, 1.843, 0.9199999999999999, 1.826, 0.7170000000000001, 0.7770000000000001, 0.5999999999999999, -0.052000000000000046, 0.8919999999999999, 0.42599999999999993, 0.42100000000000004, 1.9369999999999998, 0.3340000000000001, 1.927, 0.6339999999999999, 0.44700000000000006, 1.763, 0.353, 0.474, 0.8780000000000001, 0.924, 0.43499999999999994, 0.9609999999999999, 0.3540000000000001, 0.772, 0.45799999999999996, 1.925, 1.436, 0.45899999999999996, 0.567, 0.783, 0.8089999999999999, 0.357, -0.061000000000000054, 0.30699999999999994, 0.512, 1.8900000000000001, 0.361, 1.706, 0.8679999999999999, 0.897, 1.9140000000000001, 0.9300000000000002, 0.6510000000000002, 0.9550000000000001, 0.41100000000000003, 1.8599999999999999, 0.42800000000000005, -0.06500000000000006, 1.3940000000000001, 1.92, 0.774, 0.31299999999999994], "episode_lengths": [37, 21, 26, 131, 92, 112, 40, 38, 84, 7, 44, 12, 17, 10, 54, 23, 24, 64, 39, 55, 300, 25, 26, 15, 35, 39, 28, 14, 34, 26, 29, 52, 48, 121, 99, 40, 45, 22, 28, 48, 27, 34, 38, 15, 27, 103, 35, 64, 49, 24, 54, 89, 67, 120, 16, 32, 22, 26, 21, 51, 22, 112, 16, 72, 45, 8, 36, 23, 19, 12, 44, 71, 14, 23, 20, 13, 128, 68, 59, 43, 18, 58, 149, 35, 43, 92, 42, 32, 28, 22, 107, 14, 27, 42, 23, 21, 32, 25, 70, 57], "policy_red_0_reward": [1.3860000000000001, 1.436, 1.419, 0.483, -0.513, -1.007, 1.375, 1.377, -0.512, -1.001, -0.503, 1.464, 1.4489999999999998, 0.969, 0.491, 1.427, 1.428, 1.3050000000000002, 1.38, 1.33, 0.44999999999999996, 1.424, -0.003, 1.454, 1.392, 0.494, 1.415, 1.456, 0.894, -0.002, -0.502, -0.509, 1.349, 1.12, 1.19, 1.377, 1.361, 0.9309999999999999, 1.412, 1.353, 1.417, 1.396, 1.381, 1.4529999999999998, 0.918, 1.173, 0.495, 1.302, 0.495, -0.505, 0.495, 1.22, 1.29, 1.129, 0.95, 1.4, 1.431, 1.421, 0.5, 1.338, 0.495, -0.518, 0.949, 1.274, 0.861, 0.976, 1.3860000000000001, -0.503, -1.007, 1.462, 1.357, 1.28, 1.458, 0.498, 1.439, -1.002, 1.097, -0.505, 1.319, 1.3639999999999999, 0.94, 1.318, 1.032, 0.498, 1.366, 0.487, 1.371, 1.4, 0.499, 1.4329999999999998, 1.165, 1.4569999999999999, 0.916, 0.496, -0.502, 0.9349999999999999, -0.005, 1.423, 1.2850000000000001, 0.821], "policy_blue_0_reward": [-0.507, -0.503, -0.503, 1.083, 1.209, 1.148, 0.497, -0.503, 0.738, 1.479, 1.3599999999999999, -0.5019999999999999, -1.001, -0.5, 1.3319999999999999, -0.502, -0.504, -0.507, 0.496, -0.006, 0.46399999999999997, -0.001, 1.419, -0.5, -0.506, 1.38, -0.506, -0.503, -0.501, 1.419, 1.407, 1.3359999999999999, -0.5079999999999999, -1.011, -0.512, 0.497, -1.0039999999999998, -0.502, -1.002, -0.505, 0.497, -0.505, -1.004, -1.003, -1.003, -0.516, 1.389, -0.504, 1.3479999999999999, 1.4249999999999998, 1.331, -0.503, -0.5129999999999999, -0.529, -1.002, -0.508, -1.005, -1.0, 1.4369999999999998, -1.004, 1.432, 1.152, -0.502, 0.489, -0.508, -0.502, -0.5079999999999999, 1.427, 1.442, -0.501, -1.003, -0.508, -1.0, 1.427, -0.003, 1.4609999999999999, -0.53, 1.288, -0.51, -1.007, -1.001, -1.011, -0.52, 1.392, -1.005, 1.2189999999999999, -0.503, -0.503, 1.415, -0.5029999999999999, -0.5139999999999999, -0.502, -0.505, 1.3639999999999999, 0.93, -1.0, 1.399, 0.497, -0.511, -0.508]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3811796116136315, "mean_inference_ms": 7.420026746366674, "mean_action_processing_ms": 0.39083371258846794, "mean_env_wait_ms": 0.5156002758652538, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15234136581420898, "StateBufferConnector_ms": 0.009992837905883789, "ViewRequirementAgentConnector_ms": 0.19675910472869873}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 126.69650645508011, "num_env_steps_trained_throughput_per_sec": 126.69650645508011, "timesteps_total": 248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 31030.921, "sample_time_ms": 4028.98, "learn_time_ms": 26973.463, "learn_throughput": 148.294, "synch_weights_time_ms": 26.99}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "episodes_total": 2693, "training_iteration": 62, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-29-39", "timestamp": 1694838579, "time_this_iter_s": 31.588027715682983, "time_total_s": 1923.0939002037048, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a254430>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1923.0939002037048, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 24.335555555555548, "ram_util_percent": 57.0911111111111}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.13, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.53, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.12, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.53, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.22, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.12, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.53, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.12, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6478802792417506, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06348274631503349, "policy_loss": -0.10935043837574389, "vf_loss": 0.02892261000476234, "vf_explained_var": 0.6184232225641608, "kl": 0.014425568865131922, "entropy": 1.456863093127807, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6381783400972684, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0626170043736541, "policy_loss": -0.11318134945904604, "vf_loss": 0.03962566199867676, "vf_explained_var": 0.6600238557284077, "kl": 0.014201844472010332, "entropy": 1.6020641735444465, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000}, "sampler_results": {"episode_reward_max": 1.956, "episode_reward_min": -0.30500000000000005, "episode_reward_mean": 0.9377200000000001, "episode_len_mean": 42.37, "episode_media": {}, "episodes_this_iter": 95, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.459, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 0.8215, "blue_0": 0.11622000000000003}, "custom_metrics": {"red_0/door_open_done_mean": 0.13, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.53, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.12, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.53, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.22, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.12, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.53, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.12, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.06500000000000006, 1.3940000000000001, 1.92, 0.774, 0.31299999999999994, -0.05400000000000005, 0.7789999999999999, -0.062000000000000055, 0.39400000000000013, 1.807, 1.9249999999999998, 0.23099999999999987, 0.6839999999999999, 0.915, 1.792, 1.867, 0.804, -0.08599999999999997, 0.43599999999999994, 1.948, 1.892, 0.3759999999999999, 0.956, 0.41100000000000003, -0.08399999999999996, -0.30100000000000005, 0.8700000000000001, 1.956, 1.934, 0.7950000000000002, 0.9339999999999999, 0.43699999999999983, 1.443, -0.11199999999999999, 0.9159999999999999, 1.95, 0.46199999999999997, 0.2839999999999998, 1.826, 0.944, 1.354, 1.8690000000000002, -0.10499999999999998, 0.696, 0.8639999999999999, 1.842, 0.84, 1.896, 1.311, -0.05600000000000005, 1.8679999999999999, 1.6079999999999999, 0.41300000000000003, 0.43499999999999994, 0.958, -0.30500000000000005, 0.4289999999999998, 1.792, 1.8820000000000001, 0.867, 0.2849999999999999, -0.07999999999999996, 1.944, 0.394, 1.903, 1.9489999999999998, 1.934, -0.121, 1.741, 0.47, 1.931, -0.04300000000000004, 0.31999999999999984, 1.955, 0.40400000000000014, 0.34099999999999997, 0.9299999999999999, 0.921, 0.32799999999999985, 0.42300000000000004, 0.867, 0.742, 0.726, 0.706, 0.44999999999999996, 1.786, 0.873, 1.869, 1.857, 1.381, 0.8220000000000001, 1.791, 0.7869999999999999, -0.039000000000000035, 0.829, 1.5939999999999999, 0.881, 0.4670000000000001, 0.4590000000000001, 0.9319999999999999], "episode_lengths": [21, 32, 25, 70, 57, 18, 70, 19, 33, 58, 24, 84, 96, 25, 64, 41, 62, 28, 21, 17, 34, 39, 14, 28, 26, 93, 40, 14, 22, 64, 20, 20, 18, 36, 27, 16, 12, 219, 53, 17, 45, 40, 33, 89, 43, 50, 50, 33, 58, 18, 41, 120, 25, 20, 13, 92, 22, 62, 35, 41, 63, 24, 18, 33, 30, 17, 21, 37, 76, 10, 22, 13, 56, 15, 29, 50, 21, 25, 55, 25, 41, 80, 83, 88, 16, 65, 40, 40, 44, 37, 54, 65, 65, 12, 54, 126, 37, 10, 13, 20], "policy_red_0_reward": [0.9349999999999999, -0.005, 1.423, 1.2850000000000001, 0.821, 0.946, 1.284, 0.94, 1.3980000000000001, 0.493, 1.427, 1.238, -0.514, -0.504, 1.3, 0.496, 1.31, 0.915, 1.4369999999999998, 0.5, 0.499, 1.381, 1.458, 0.913, 0.92, 0.711, 1.376, 1.458, 0.5, 1.3050000000000002, -0.505, 1.44, 1.4449999999999998, 0.891, 1.4180000000000001, 0.499, 0.963, 0.8119999999999999, 0.494, 1.448, 1.358, 1.374, 0.9, 1.214, 1.366, 1.347, -0.502, 0.497, -0.010000000000000002, 0.945, 1.369, 1.1269999999999998, 0.92, -0.5, 1.459, 0.711, 1.432, 0.492, 0.499, -0.503, -0.523, 0.9259999999999999, 0.499, -0.501, 0.498, 0.5, 0.499, 0.882, 1.256, -1.0, 0.5, -1.002, 0.829, 0.5, 1.411, 1.345, 1.434, 1.423, 1.331, 0.923, 1.374, 1.2530000000000001, -0.512, 1.2229999999999999, 1.452, 0.496, 1.375, 0.495, 0.495, 1.3860000000000001, 1.333, 0.49, 1.299, 0.963, 1.3319999999999999, 1.1099999999999999, 1.385, 0.969, 0.959, -0.503], "policy_blue_0_reward": [-1.0, 1.399, 0.497, -0.511, -0.508, -1.0, -0.505, -1.002, -1.004, 1.314, 0.498, -1.007, 1.198, 1.419, 0.492, 1.371, -0.506, -1.001, -1.001, 1.448, 1.393, -1.005, -0.502, -0.5019999999999999, -1.004, -1.012, -0.506, 0.498, 1.434, -0.5099999999999999, 1.439, -1.003, -0.002, -1.003, -0.502, 1.451, -0.501, -0.528, 1.3319999999999999, -0.504, -0.004, 0.495, -1.005, -0.518, -0.502, 0.495, 1.342, 1.399, 1.3210000000000002, -1.001, 0.499, 0.481, -0.507, 0.9349999999999999, -0.501, -1.016, -1.003, 1.3, 1.383, 1.37, 0.8079999999999999, -1.0059999999999998, 1.4449999999999998, 0.895, 1.405, 1.4489999999999998, 1.435, -1.003, 0.485, 1.47, 1.431, 0.959, -0.509, 1.455, -1.007, -1.004, -0.504, -0.502, -1.003, -0.5, -0.507, -0.511, 1.238, -0.517, -1.002, 1.29, -0.502, 1.374, 1.362, -0.005, -0.511, 1.301, -0.512, -1.002, -0.503, 0.484, -0.504, -0.502, -0.5, 1.435]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3790183234678974, "mean_inference_ms": 7.4226291419384856, "mean_action_processing_ms": 0.3913393336988971, "mean_env_wait_ms": 0.5154640014368617, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1476294994354248, "StateBufferConnector_ms": 0.009302973747253418, "ViewRequirementAgentConnector_ms": 0.18500816822052002}}, "episode_reward_max": 1.956, "episode_reward_min": -0.30500000000000005, "episode_reward_mean": 0.9377200000000001, "episode_len_mean": 42.37, "episodes_this_iter": 95, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.459, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 0.8215, "blue_0": 0.11622000000000003}, "hist_stats": {"episode_reward": [-0.06500000000000006, 1.3940000000000001, 1.92, 0.774, 0.31299999999999994, -0.05400000000000005, 0.7789999999999999, -0.062000000000000055, 0.39400000000000013, 1.807, 1.9249999999999998, 0.23099999999999987, 0.6839999999999999, 0.915, 1.792, 1.867, 0.804, -0.08599999999999997, 0.43599999999999994, 1.948, 1.892, 0.3759999999999999, 0.956, 0.41100000000000003, -0.08399999999999996, -0.30100000000000005, 0.8700000000000001, 1.956, 1.934, 0.7950000000000002, 0.9339999999999999, 0.43699999999999983, 1.443, -0.11199999999999999, 0.9159999999999999, 1.95, 0.46199999999999997, 0.2839999999999998, 1.826, 0.944, 1.354, 1.8690000000000002, -0.10499999999999998, 0.696, 0.8639999999999999, 1.842, 0.84, 1.896, 1.311, -0.05600000000000005, 1.8679999999999999, 1.6079999999999999, 0.41300000000000003, 0.43499999999999994, 0.958, -0.30500000000000005, 0.4289999999999998, 1.792, 1.8820000000000001, 0.867, 0.2849999999999999, -0.07999999999999996, 1.944, 0.394, 1.903, 1.9489999999999998, 1.934, -0.121, 1.741, 0.47, 1.931, -0.04300000000000004, 0.31999999999999984, 1.955, 0.40400000000000014, 0.34099999999999997, 0.9299999999999999, 0.921, 0.32799999999999985, 0.42300000000000004, 0.867, 0.742, 0.726, 0.706, 0.44999999999999996, 1.786, 0.873, 1.869, 1.857, 1.381, 0.8220000000000001, 1.791, 0.7869999999999999, -0.039000000000000035, 0.829, 1.5939999999999999, 0.881, 0.4670000000000001, 0.4590000000000001, 0.9319999999999999], "episode_lengths": [21, 32, 25, 70, 57, 18, 70, 19, 33, 58, 24, 84, 96, 25, 64, 41, 62, 28, 21, 17, 34, 39, 14, 28, 26, 93, 40, 14, 22, 64, 20, 20, 18, 36, 27, 16, 12, 219, 53, 17, 45, 40, 33, 89, 43, 50, 50, 33, 58, 18, 41, 120, 25, 20, 13, 92, 22, 62, 35, 41, 63, 24, 18, 33, 30, 17, 21, 37, 76, 10, 22, 13, 56, 15, 29, 50, 21, 25, 55, 25, 41, 80, 83, 88, 16, 65, 40, 40, 44, 37, 54, 65, 65, 12, 54, 126, 37, 10, 13, 20], "policy_red_0_reward": [0.9349999999999999, -0.005, 1.423, 1.2850000000000001, 0.821, 0.946, 1.284, 0.94, 1.3980000000000001, 0.493, 1.427, 1.238, -0.514, -0.504, 1.3, 0.496, 1.31, 0.915, 1.4369999999999998, 0.5, 0.499, 1.381, 1.458, 0.913, 0.92, 0.711, 1.376, 1.458, 0.5, 1.3050000000000002, -0.505, 1.44, 1.4449999999999998, 0.891, 1.4180000000000001, 0.499, 0.963, 0.8119999999999999, 0.494, 1.448, 1.358, 1.374, 0.9, 1.214, 1.366, 1.347, -0.502, 0.497, -0.010000000000000002, 0.945, 1.369, 1.1269999999999998, 0.92, -0.5, 1.459, 0.711, 1.432, 0.492, 0.499, -0.503, -0.523, 0.9259999999999999, 0.499, -0.501, 0.498, 0.5, 0.499, 0.882, 1.256, -1.0, 0.5, -1.002, 0.829, 0.5, 1.411, 1.345, 1.434, 1.423, 1.331, 0.923, 1.374, 1.2530000000000001, -0.512, 1.2229999999999999, 1.452, 0.496, 1.375, 0.495, 0.495, 1.3860000000000001, 1.333, 0.49, 1.299, 0.963, 1.3319999999999999, 1.1099999999999999, 1.385, 0.969, 0.959, -0.503], "policy_blue_0_reward": [-1.0, 1.399, 0.497, -0.511, -0.508, -1.0, -0.505, -1.002, -1.004, 1.314, 0.498, -1.007, 1.198, 1.419, 0.492, 1.371, -0.506, -1.001, -1.001, 1.448, 1.393, -1.005, -0.502, -0.5019999999999999, -1.004, -1.012, -0.506, 0.498, 1.434, -0.5099999999999999, 1.439, -1.003, -0.002, -1.003, -0.502, 1.451, -0.501, -0.528, 1.3319999999999999, -0.504, -0.004, 0.495, -1.005, -0.518, -0.502, 0.495, 1.342, 1.399, 1.3210000000000002, -1.001, 0.499, 0.481, -0.507, 0.9349999999999999, -0.501, -1.016, -1.003, 1.3, 1.383, 1.37, 0.8079999999999999, -1.0059999999999998, 1.4449999999999998, 0.895, 1.405, 1.4489999999999998, 1.435, -1.003, 0.485, 1.47, 1.431, 0.959, -0.509, 1.455, -1.007, -1.004, -0.504, -0.502, -1.003, -0.5, -0.507, -0.511, 1.238, -0.517, -1.002, 1.29, -0.502, 1.374, 1.362, -0.005, -0.511, 1.301, -0.512, -1.002, -0.503, 0.484, -0.504, -0.502, -0.5, 1.435]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3790183234678974, "mean_inference_ms": 7.4226291419384856, "mean_action_processing_ms": 0.3913393336988971, "mean_env_wait_ms": 0.5154640014368617, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1476294994354248, "StateBufferConnector_ms": 0.009302973747253418, "ViewRequirementAgentConnector_ms": 0.18500816822052002}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.56797003804834, "num_env_steps_trained_throughput_per_sec": 128.56797003804834, "timesteps_total": 252000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 504000, "timers": {"training_iteration_time_ms": 31146.834, "sample_time_ms": 4029.308, "learn_time_ms": 27089.08, "learn_throughput": 147.661, "synch_weights_time_ms": 26.96}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000}, "done": false, "episodes_total": 2788, "training_iteration": 63, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-30-11", "timestamp": 1694838611, "time_this_iter_s": 31.12855076789856, "time_total_s": 1954.2224509716034, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80edaef0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1954.2224509716034, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 25.006521739130434, "ram_util_percent": 57.09782608695651}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.13, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.48, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.25, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.48, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.25, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.48, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.25, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6482666103479763, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06451240671643367, "policy_loss": -0.11165983391959647, "vf_loss": 0.03253331846790388, "vf_explained_var": 0.6142339102302988, "kl": 0.014222352968225426, "entropy": 1.5195308862874906, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6336133523533741, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06348135699639292, "policy_loss": -0.11214921143061171, "vf_loss": 0.03725956585258246, "vf_explained_var": 0.5995706829552849, "kl": 0.013895855979463552, "entropy": 1.6184256441891194, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "sampler_results": {"episode_reward_max": 1.947, "episode_reward_min": -0.11499999999999999, "episode_reward_mean": 0.87381, "episode_len_mean": 48.09, "episode_media": {}, "episodes_this_iter": 79, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.452, "blue_0": 1.462}, "policy_reward_mean": {"red_0": 0.6571300000000001, "blue_0": 0.21667999999999998}, "custom_metrics": {"red_0/door_open_done_mean": 0.13, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.48, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.25, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.48, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.25, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.48, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.25, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.42300000000000004, 0.867, 0.742, 0.726, 0.706, 0.44999999999999996, 1.786, 0.873, 1.869, 1.857, 1.381, 0.8220000000000001, 1.791, 0.7869999999999999, -0.039000000000000035, 0.829, 1.5939999999999999, 0.881, 0.4670000000000001, 0.4590000000000001, 0.9319999999999999, 0.4, 1.3399999999999999, 1.435, 0.962, 0.756, 0.893, 0.9260000000000002, 0.7589999999999999, 0.859, 1.8679999999999999, 1.947, 1.909, 0.681, 0.41500000000000004, 0.404, 1.8479999999999999, 0.6479999999999999, 1.6880000000000002, 0.8199999999999998, 0.379, 0.896, 1.439, -0.09199999999999986, 0.919, 0.42600000000000005, 0.41400000000000003, 0.43500000000000005, 0.29700000000000015, 0.9359999999999999, 0.814, 0.41900000000000004, 0.848, 0.44299999999999995, -0.09199999999999997, 0.41900000000000004, 0.925, 0.7909999999999999, 0.363, 0.393, 0.7739999999999999, 0.351, 0.8839999999999999, 1.9060000000000001, 1.19, 0.7969999999999999, 1.725, 1.3820000000000001, 0.32600000000000007, 0.514, 1.407, 0.4209999999999998, 1.9209999999999998, 0.45899999999999996, 0.45699999999999985, 1.487, 0.43399999999999994, 1.875, 0.9329999999999998, 1.923, 0.368, 0.946, 0.1299999999999999, 0.39, 1.8860000000000001, 0.859, -0.05800000000000005, 0.3759999999999999, 0.41700000000000004, 0.45199999999999996, -0.11499999999999999, 0.31199999999999983, 0.7869999999999999, 0.8810000000000002, 1.528, 0.45499999999999996, 0.851, 0.3380000000000001, 1.8359999999999999, 1.443], "episode_lengths": [25, 41, 80, 83, 88, 16, 65, 40, 40, 44, 37, 54, 65, 65, 12, 54, 126, 37, 10, 13, 20, 32, 47, 20, 12, 74, 34, 23, 71, 42, 43, 17, 29, 100, 26, 31, 47, 108, 97, 57, 189, 33, 19, 29, 25, 23, 27, 21, 62, 20, 55, 26, 45, 17, 29, 24, 23, 63, 44, 33, 69, 46, 36, 29, 246, 63, 84, 38, 53, 149, 29, 24, 24, 13, 14, 156, 20, 39, 20, 24, 41, 17, 113, 34, 35, 45, 18, 39, 26, 16, 36, 59, 63, 37, 142, 14, 46, 50, 52, 18], "policy_red_0_reward": [0.923, 1.374, 1.2530000000000001, -0.512, 1.2229999999999999, 1.452, 0.496, 1.375, 0.495, 0.495, 1.3860000000000001, 1.333, 0.49, 1.299, 0.963, 1.3319999999999999, 1.1099999999999999, 1.385, 0.969, 0.959, -0.503, -0.502, 1.351, -0.001, -0.5, 1.268, 1.3940000000000001, 1.429, 1.274, 1.367, 0.499, 0.499, 1.413, -0.5139999999999999, 1.419, -1.001, 0.495, 1.168, 0.491, 1.325, 0.9059999999999999, -0.501, -0.002, -1.001, 1.4220000000000002, -1.003, -0.502, 1.436, 1.31, -0.502, -0.511, -0.501, -0.509, -1.002, 0.909, 0.9199999999999999, 1.428, 1.3079999999999998, -1.002, 0.897, -0.509, 0.861, 1.389, 1.4100000000000001, 0.45999999999999996, 1.309, 1.234, 1.384, 1.3359999999999999, 1.039, 1.409, 1.427, 1.426, -0.5, 0.957, 0.48, -0.502, 1.3820000000000001, 1.436, 0.498, -1.004, -0.502, 0.646, -0.501, 1.389, -0.503, 0.944, 1.38, 1.421, -0.5, 0.887, 1.3159999999999998, 1.2999999999999998, 1.3860000000000001, 0.471, -1.0, 1.3559999999999999, 0.844, 1.342, 1.444], "policy_blue_0_reward": [-0.5, -0.507, -0.511, 1.238, -0.517, -1.002, 1.29, -0.502, 1.374, 1.362, -0.005, -0.511, 1.301, -0.512, -1.002, -0.503, 0.484, -0.504, -0.502, -0.5, 1.435, 0.902, -0.011000000000000003, 1.436, 1.462, -0.512, -0.501, -0.503, -0.515, -0.508, 1.369, 1.448, 0.496, 1.1949999999999998, -1.004, 1.405, 1.353, -0.52, 1.197, -0.505, -0.527, 1.397, 1.4409999999999998, 0.909, -0.5029999999999999, 1.429, 0.916, -1.001, -1.013, 1.438, 1.325, 0.92, 1.357, 1.4449999999999998, -1.001, -0.501, -0.503, -0.517, 1.365, -0.504, 1.283, -0.5099999999999999, -0.505, 0.496, 0.73, -0.512, 0.491, -0.002, -1.01, -0.5249999999999999, -0.002, -1.006, 0.495, 0.959, -0.5, 1.0070000000000001, 0.9359999999999999, 0.493, -0.503, 1.4249999999999998, 1.3719999999999999, 1.448, -0.516, 0.891, 0.497, 1.362, -1.002, -1.004, -1.004, 0.952, -1.002, -1.004, -0.5129999999999999, -0.5049999999999999, 1.057, 1.455, -0.505, -0.506, 0.494, -0.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3805887693708812, "mean_inference_ms": 7.416885508168689, "mean_action_processing_ms": 0.3910368252996368, "mean_env_wait_ms": 0.5154685553271188, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1475125551223755, "StateBufferConnector_ms": 0.009897112846374512, "ViewRequirementAgentConnector_ms": 0.18944323062896729}}, "episode_reward_max": 1.947, "episode_reward_min": -0.11499999999999999, "episode_reward_mean": 0.87381, "episode_len_mean": 48.09, "episodes_this_iter": 79, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.452, "blue_0": 1.462}, "policy_reward_mean": {"red_0": 0.6571300000000001, "blue_0": 0.21667999999999998}, "hist_stats": {"episode_reward": [0.42300000000000004, 0.867, 0.742, 0.726, 0.706, 0.44999999999999996, 1.786, 0.873, 1.869, 1.857, 1.381, 0.8220000000000001, 1.791, 0.7869999999999999, -0.039000000000000035, 0.829, 1.5939999999999999, 0.881, 0.4670000000000001, 0.4590000000000001, 0.9319999999999999, 0.4, 1.3399999999999999, 1.435, 0.962, 0.756, 0.893, 0.9260000000000002, 0.7589999999999999, 0.859, 1.8679999999999999, 1.947, 1.909, 0.681, 0.41500000000000004, 0.404, 1.8479999999999999, 0.6479999999999999, 1.6880000000000002, 0.8199999999999998, 0.379, 0.896, 1.439, -0.09199999999999986, 0.919, 0.42600000000000005, 0.41400000000000003, 0.43500000000000005, 0.29700000000000015, 0.9359999999999999, 0.814, 0.41900000000000004, 0.848, 0.44299999999999995, -0.09199999999999997, 0.41900000000000004, 0.925, 0.7909999999999999, 0.363, 0.393, 0.7739999999999999, 0.351, 0.8839999999999999, 1.9060000000000001, 1.19, 0.7969999999999999, 1.725, 1.3820000000000001, 0.32600000000000007, 0.514, 1.407, 0.4209999999999998, 1.9209999999999998, 0.45899999999999996, 0.45699999999999985, 1.487, 0.43399999999999994, 1.875, 0.9329999999999998, 1.923, 0.368, 0.946, 0.1299999999999999, 0.39, 1.8860000000000001, 0.859, -0.05800000000000005, 0.3759999999999999, 0.41700000000000004, 0.45199999999999996, -0.11499999999999999, 0.31199999999999983, 0.7869999999999999, 0.8810000000000002, 1.528, 0.45499999999999996, 0.851, 0.3380000000000001, 1.8359999999999999, 1.443], "episode_lengths": [25, 41, 80, 83, 88, 16, 65, 40, 40, 44, 37, 54, 65, 65, 12, 54, 126, 37, 10, 13, 20, 32, 47, 20, 12, 74, 34, 23, 71, 42, 43, 17, 29, 100, 26, 31, 47, 108, 97, 57, 189, 33, 19, 29, 25, 23, 27, 21, 62, 20, 55, 26, 45, 17, 29, 24, 23, 63, 44, 33, 69, 46, 36, 29, 246, 63, 84, 38, 53, 149, 29, 24, 24, 13, 14, 156, 20, 39, 20, 24, 41, 17, 113, 34, 35, 45, 18, 39, 26, 16, 36, 59, 63, 37, 142, 14, 46, 50, 52, 18], "policy_red_0_reward": [0.923, 1.374, 1.2530000000000001, -0.512, 1.2229999999999999, 1.452, 0.496, 1.375, 0.495, 0.495, 1.3860000000000001, 1.333, 0.49, 1.299, 0.963, 1.3319999999999999, 1.1099999999999999, 1.385, 0.969, 0.959, -0.503, -0.502, 1.351, -0.001, -0.5, 1.268, 1.3940000000000001, 1.429, 1.274, 1.367, 0.499, 0.499, 1.413, -0.5139999999999999, 1.419, -1.001, 0.495, 1.168, 0.491, 1.325, 0.9059999999999999, -0.501, -0.002, -1.001, 1.4220000000000002, -1.003, -0.502, 1.436, 1.31, -0.502, -0.511, -0.501, -0.509, -1.002, 0.909, 0.9199999999999999, 1.428, 1.3079999999999998, -1.002, 0.897, -0.509, 0.861, 1.389, 1.4100000000000001, 0.45999999999999996, 1.309, 1.234, 1.384, 1.3359999999999999, 1.039, 1.409, 1.427, 1.426, -0.5, 0.957, 0.48, -0.502, 1.3820000000000001, 1.436, 0.498, -1.004, -0.502, 0.646, -0.501, 1.389, -0.503, 0.944, 1.38, 1.421, -0.5, 0.887, 1.3159999999999998, 1.2999999999999998, 1.3860000000000001, 0.471, -1.0, 1.3559999999999999, 0.844, 1.342, 1.444], "policy_blue_0_reward": [-0.5, -0.507, -0.511, 1.238, -0.517, -1.002, 1.29, -0.502, 1.374, 1.362, -0.005, -0.511, 1.301, -0.512, -1.002, -0.503, 0.484, -0.504, -0.502, -0.5, 1.435, 0.902, -0.011000000000000003, 1.436, 1.462, -0.512, -0.501, -0.503, -0.515, -0.508, 1.369, 1.448, 0.496, 1.1949999999999998, -1.004, 1.405, 1.353, -0.52, 1.197, -0.505, -0.527, 1.397, 1.4409999999999998, 0.909, -0.5029999999999999, 1.429, 0.916, -1.001, -1.013, 1.438, 1.325, 0.92, 1.357, 1.4449999999999998, -1.001, -0.501, -0.503, -0.517, 1.365, -0.504, 1.283, -0.5099999999999999, -0.505, 0.496, 0.73, -0.512, 0.491, -0.002, -1.01, -0.5249999999999999, -0.002, -1.006, 0.495, 0.959, -0.5, 1.0070000000000001, 0.9359999999999999, 0.493, -0.503, 1.4249999999999998, 1.3719999999999999, 1.448, -0.516, 0.891, 0.497, 1.362, -1.002, -1.004, -1.004, 0.952, -1.002, -1.004, -0.5129999999999999, -0.5049999999999999, 1.057, 1.455, -0.505, -0.506, 0.494, -0.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3805887693708812, "mean_inference_ms": 7.416885508168689, "mean_action_processing_ms": 0.3910368252996368, "mean_env_wait_ms": 0.5154685553271188, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1475125551223755, "StateBufferConnector_ms": 0.009897112846374512, "ViewRequirementAgentConnector_ms": 0.18944323062896729}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.9187088862863, "num_env_steps_trained_throughput_per_sec": 127.9187088862863, "timesteps_total": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 31177.725, "sample_time_ms": 4006.291, "learn_time_ms": 27143.156, "learn_throughput": 147.367, "synch_weights_time_ms": 26.776}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "episodes_total": 2867, "training_iteration": 64, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-30-43", "timestamp": 1694838643, "time_this_iter_s": 31.284663200378418, "time_total_s": 1985.5071141719818, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f4820>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1985.5071141719818, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 25.295555555555556, "ram_util_percent": 57.09999999999999}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.11, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.57, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.57, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.19, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.57, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6581163423756758, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06407204019924392, "policy_loss": -0.1094834996870001, "vf_loss": 0.030823881655427005, "vf_explained_var": 0.584013822923104, "kl": 0.01382902617129534, "entropy": 1.5047320975611607, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 61920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6262753865060707, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06619135949392027, "policy_loss": -0.11540909986991513, "vf_loss": 0.0391199258971028, "vf_explained_var": 0.6326120763396224, "kl": 0.013724718798845913, "entropy": 1.6088483300060035, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 61920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000}, "sampler_results": {"episode_reward_max": 1.9489999999999998, "episode_reward_min": -0.16300000000000003, "episode_reward_mean": 0.8637699999999999, "episode_len_mean": 48.09, "episode_media": {}, "episodes_this_iter": 88, "policy_reward_min": {"red_0": -1.008, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.4689999999999999, "blue_0": 1.458}, "policy_reward_mean": {"red_0": 0.8320499999999998, "blue_0": 0.03172000000000002}, "custom_metrics": {"red_0/door_open_done_mean": 0.11, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.57, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.57, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.19, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.57, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.41700000000000004, 0.45199999999999996, -0.11499999999999999, 0.31199999999999983, 0.7869999999999999, 0.8810000000000002, 1.528, 0.45499999999999996, 0.851, 0.3380000000000001, 1.8359999999999999, 1.443, 0.94, 1.9489999999999998, 1.429, 1.411, 1.891, 1.4329999999999998, -0.027999999999999914, 0.6299999999999999, 1.729, 0.3660000000000001, 1.9060000000000001, 1.808, 1.7959999999999998, 1.938, 0.45500000000000007, 0.8089999999999999, 1.846, -0.05900000000000005, 0.9689999999999999, 0.23699999999999988, 0.2610000000000001, 0.948, 0.8940000000000001, 0.9279999999999999, 0.8119999999999998, -0.16300000000000003, 0.8700000000000001, 0.917, 0.389, 0.43799999999999994, 0.42100000000000004, 0.3780000000000001, 1.9409999999999998, 0.41400000000000015, 0.742, 0.40700000000000003, 0.255, 0.8660000000000001, 0.4019999999999999, 0.026999999999999913, 1.456, 0.4039999999999999, 1.389, 0.819, 0.8999999999999999, 0.9239999999999999, 1.907, 0.402, 1.887, 0.29000000000000004, 1.7429999999999999, 0.403, -0.08499999999999996, 0.345, 0.3919999999999999, 0.403, 0.399, 1.901, 1.913, 1.3199999999999998, 0.44599999999999995, 0.917, 0.45899999999999996, -0.04300000000000004, 1.3980000000000001, 0.904, 0.754, 0.759, 0.2929999999999999, 0.22199999999999998, 0.579, 1.4819999999999998, 0.7959999999999998, -0.027000000000000024, -0.05500000000000005, 1.345, 0.921, 1.842, 0.871, 0.45699999999999996, 1.9249999999999998, 0.42699999999999994, 0.43100000000000005, 1.892, 0.41700000000000026, 0.3700000000000001, 0.8719999999999999, 1.8239999999999998], "episode_lengths": [26, 16, 36, 59, 63, 37, 142, 14, 46, 50, 52, 18, 19, 17, 23, 28, 34, 22, 9, 111, 83, 40, 30, 62, 63, 20, 171, 60, 46, 19, 10, 231, 74, 16, 33, 22, 59, 51, 41, 25, 34, 18, 25, 38, 19, 26, 78, 29, 75, 41, 182, 296, 14, 29, 32, 55, 31, 24, 29, 30, 36, 63, 81, 28, 26, 47, 33, 28, 31, 30, 28, 55, 17, 27, 13, 14, 32, 30, 77, 72, 61, 86, 131, 155, 63, 8, 17, 50, 26, 48, 40, 13, 24, 22, 22, 32, 26, 40, 40, 54], "policy_red_0_reward": [1.421, -0.5, 0.887, 1.3159999999999998, 1.2999999999999998, 1.3860000000000001, 0.471, -1.0, 1.3559999999999999, 0.844, 1.342, 1.444, 1.443, 1.4489999999999998, 1.4300000000000002, 1.413, 0.496, 1.4329999999999998, 0.973, 1.151, 1.236, 1.376, 0.5, 0.496, 0.491, 1.439, 0.972, 1.3159999999999998, 0.49, -1.0, 1.4689999999999999, 0.7679999999999999, 1.271, 1.451, 1.3980000000000001, 1.434, 1.318, -1.008, 1.371, 1.4220000000000002, 1.393, 0.941, 0.925, 0.881, 0.499, 1.415, 1.254, 0.91, -0.51, 1.374, 0.9249999999999999, 0.572, -0.002, 1.4060000000000001, -0.011000000000000003, 1.3239999999999998, 1.4060000000000001, 1.426, 0.497, -1.003, 0.497, 0.8029999999999999, 0.49, 0.914, 0.92, 1.353, 0.894, 1.4100000000000001, 1.403, 1.4060000000000001, 0.5, 1.327, -0.501, 1.419, -0.5, 0.958, -0.002, -0.502, -0.505, -0.514, 1.306, 1.23, 1.091, 0.471, 1.306, 0.975, 0.948, 1.347, 1.421, 0.492, 1.379, -0.502, 0.498, -0.502, 1.4329999999999998, 0.495, 0.919, 1.373, 1.375, 0.493], "policy_blue_0_reward": [-1.004, 0.952, -1.002, -1.004, -0.5129999999999999, -0.5049999999999999, 1.057, 1.455, -0.505, -0.506, 0.494, -0.001, -0.503, 0.5, -0.001, -0.002, 1.395, 0.0, -1.001, -0.521, 0.493, -1.0099999999999998, 1.4060000000000001, 1.312, 1.305, 0.499, -0.5169999999999999, -0.507, 1.3559999999999999, 0.941, -0.5, -0.531, -1.01, -0.503, -0.504, -0.506, -0.506, 0.845, -0.501, -0.505, -1.004, -0.503, -0.504, -0.503, 1.442, -1.001, -0.5119999999999999, -0.503, 0.765, -0.508, -0.523, -0.545, 1.458, -1.002, 1.4, -0.505, -0.506, -0.502, 1.4100000000000001, 1.405, 1.3900000000000001, -0.513, 1.2530000000000001, -0.5109999999999999, -1.005, -1.008, -0.502, -1.007, -1.004, 0.495, 1.413, -0.007, 0.947, -0.502, 0.959, -1.001, 1.4, 1.4060000000000001, 1.259, 1.2730000000000001, -1.013, -1.008, -0.512, 1.011, -0.51, -1.002, -1.003, -0.002, -0.5, 1.35, -0.5079999999999999, 0.959, 1.427, 0.9289999999999999, -1.002, 1.397, -0.5019999999999999, -1.003, -0.503, 1.331]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3822801963175966, "mean_inference_ms": 7.412773044154726, "mean_action_processing_ms": 0.39142354597277756, "mean_env_wait_ms": 0.5155766054661064, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1493396759033203, "StateBufferConnector_ms": 0.009581685066223145, "ViewRequirementAgentConnector_ms": 0.20132982730865479}}, "episode_reward_max": 1.9489999999999998, "episode_reward_min": -0.16300000000000003, "episode_reward_mean": 0.8637699999999999, "episode_len_mean": 48.09, "episodes_this_iter": 88, "policy_reward_min": {"red_0": -1.008, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.4689999999999999, "blue_0": 1.458}, "policy_reward_mean": {"red_0": 0.8320499999999998, "blue_0": 0.03172000000000002}, "hist_stats": {"episode_reward": [0.41700000000000004, 0.45199999999999996, -0.11499999999999999, 0.31199999999999983, 0.7869999999999999, 0.8810000000000002, 1.528, 0.45499999999999996, 0.851, 0.3380000000000001, 1.8359999999999999, 1.443, 0.94, 1.9489999999999998, 1.429, 1.411, 1.891, 1.4329999999999998, -0.027999999999999914, 0.6299999999999999, 1.729, 0.3660000000000001, 1.9060000000000001, 1.808, 1.7959999999999998, 1.938, 0.45500000000000007, 0.8089999999999999, 1.846, -0.05900000000000005, 0.9689999999999999, 0.23699999999999988, 0.2610000000000001, 0.948, 0.8940000000000001, 0.9279999999999999, 0.8119999999999998, -0.16300000000000003, 0.8700000000000001, 0.917, 0.389, 0.43799999999999994, 0.42100000000000004, 0.3780000000000001, 1.9409999999999998, 0.41400000000000015, 0.742, 0.40700000000000003, 0.255, 0.8660000000000001, 0.4019999999999999, 0.026999999999999913, 1.456, 0.4039999999999999, 1.389, 0.819, 0.8999999999999999, 0.9239999999999999, 1.907, 0.402, 1.887, 0.29000000000000004, 1.7429999999999999, 0.403, -0.08499999999999996, 0.345, 0.3919999999999999, 0.403, 0.399, 1.901, 1.913, 1.3199999999999998, 0.44599999999999995, 0.917, 0.45899999999999996, -0.04300000000000004, 1.3980000000000001, 0.904, 0.754, 0.759, 0.2929999999999999, 0.22199999999999998, 0.579, 1.4819999999999998, 0.7959999999999998, -0.027000000000000024, -0.05500000000000005, 1.345, 0.921, 1.842, 0.871, 0.45699999999999996, 1.9249999999999998, 0.42699999999999994, 0.43100000000000005, 1.892, 0.41700000000000026, 0.3700000000000001, 0.8719999999999999, 1.8239999999999998], "episode_lengths": [26, 16, 36, 59, 63, 37, 142, 14, 46, 50, 52, 18, 19, 17, 23, 28, 34, 22, 9, 111, 83, 40, 30, 62, 63, 20, 171, 60, 46, 19, 10, 231, 74, 16, 33, 22, 59, 51, 41, 25, 34, 18, 25, 38, 19, 26, 78, 29, 75, 41, 182, 296, 14, 29, 32, 55, 31, 24, 29, 30, 36, 63, 81, 28, 26, 47, 33, 28, 31, 30, 28, 55, 17, 27, 13, 14, 32, 30, 77, 72, 61, 86, 131, 155, 63, 8, 17, 50, 26, 48, 40, 13, 24, 22, 22, 32, 26, 40, 40, 54], "policy_red_0_reward": [1.421, -0.5, 0.887, 1.3159999999999998, 1.2999999999999998, 1.3860000000000001, 0.471, -1.0, 1.3559999999999999, 0.844, 1.342, 1.444, 1.443, 1.4489999999999998, 1.4300000000000002, 1.413, 0.496, 1.4329999999999998, 0.973, 1.151, 1.236, 1.376, 0.5, 0.496, 0.491, 1.439, 0.972, 1.3159999999999998, 0.49, -1.0, 1.4689999999999999, 0.7679999999999999, 1.271, 1.451, 1.3980000000000001, 1.434, 1.318, -1.008, 1.371, 1.4220000000000002, 1.393, 0.941, 0.925, 0.881, 0.499, 1.415, 1.254, 0.91, -0.51, 1.374, 0.9249999999999999, 0.572, -0.002, 1.4060000000000001, -0.011000000000000003, 1.3239999999999998, 1.4060000000000001, 1.426, 0.497, -1.003, 0.497, 0.8029999999999999, 0.49, 0.914, 0.92, 1.353, 0.894, 1.4100000000000001, 1.403, 1.4060000000000001, 0.5, 1.327, -0.501, 1.419, -0.5, 0.958, -0.002, -0.502, -0.505, -0.514, 1.306, 1.23, 1.091, 0.471, 1.306, 0.975, 0.948, 1.347, 1.421, 0.492, 1.379, -0.502, 0.498, -0.502, 1.4329999999999998, 0.495, 0.919, 1.373, 1.375, 0.493], "policy_blue_0_reward": [-1.004, 0.952, -1.002, -1.004, -0.5129999999999999, -0.5049999999999999, 1.057, 1.455, -0.505, -0.506, 0.494, -0.001, -0.503, 0.5, -0.001, -0.002, 1.395, 0.0, -1.001, -0.521, 0.493, -1.0099999999999998, 1.4060000000000001, 1.312, 1.305, 0.499, -0.5169999999999999, -0.507, 1.3559999999999999, 0.941, -0.5, -0.531, -1.01, -0.503, -0.504, -0.506, -0.506, 0.845, -0.501, -0.505, -1.004, -0.503, -0.504, -0.503, 1.442, -1.001, -0.5119999999999999, -0.503, 0.765, -0.508, -0.523, -0.545, 1.458, -1.002, 1.4, -0.505, -0.506, -0.502, 1.4100000000000001, 1.405, 1.3900000000000001, -0.513, 1.2530000000000001, -0.5109999999999999, -1.005, -1.008, -0.502, -1.007, -1.004, 0.495, 1.413, -0.007, 0.947, -0.502, 0.959, -1.001, 1.4, 1.4060000000000001, 1.259, 1.2730000000000001, -1.013, -1.008, -0.512, 1.011, -0.51, -1.002, -1.003, -0.002, -0.5, 1.35, -0.5079999999999999, 0.959, 1.427, 0.9289999999999999, -1.002, 1.397, -0.5019999999999999, -1.003, -0.503, 1.331]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3822801963175966, "mean_inference_ms": 7.412773044154726, "mean_action_processing_ms": 0.39142354597277756, "mean_env_wait_ms": 0.5155766054661064, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1493396759033203, "StateBufferConnector_ms": 0.009581685066223145, "ViewRequirementAgentConnector_ms": 0.20132982730865479}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.21484273305433, "num_env_steps_trained_throughput_per_sec": 131.21484273305433, "timesteps_total": 260000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 520000, "timers": {"training_iteration_time_ms": 31158.685, "sample_time_ms": 4006.589, "learn_time_ms": 27123.958, "learn_throughput": 147.471, "synch_weights_time_ms": 26.626}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000}, "done": false, "episodes_total": 2955, "training_iteration": 65, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-31-14", "timestamp": 1694838674, "time_this_iter_s": 30.49962091445923, "time_total_s": 2016.006735086441, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7239e3b0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2016.006735086441, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 24.654545454545453, "ram_util_percent": 57.09090909090908}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.14, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.58, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.58, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.58, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6356016260571777, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05972583527036477, "policy_loss": -0.10611082394364833, "vf_loss": 0.030832354649707364, "vf_explained_var": 0.6185417170325915, "kl": 0.01425146525500246, "entropy": 1.4978093205640712, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 62880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6479677368886769, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05784157741776046, "policy_loss": -0.1071016553369797, "vf_loss": 0.03721440695856775, "vf_explained_var": 0.5565619993954897, "kl": 0.014166037256048487, "entropy": 1.61913028669854, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 62880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "sampler_results": {"episode_reward_max": 1.9569999999999999, "episode_reward_min": -0.11399999999999999, "episode_reward_mean": 0.9130799999999999, "episode_len_mean": 49.76, "episode_media": {}, "episodes_this_iter": 77, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.4689999999999999, "blue_0": 1.429}, "policy_reward_mean": {"red_0": 0.89792, "blue_0": 0.015160000000000005}, "custom_metrics": {"red_0/door_open_done_mean": 0.14, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.58, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.58, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.58, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.904, 0.754, 0.759, 0.2929999999999999, 0.22199999999999998, 0.579, 1.4819999999999998, 0.7959999999999998, -0.027000000000000024, -0.05500000000000005, 1.345, 0.921, 1.842, 0.871, 0.45699999999999996, 1.9249999999999998, 0.42699999999999994, 0.43100000000000005, 1.892, 0.41700000000000026, 0.3700000000000001, 0.8719999999999999, 1.8239999999999998, 0.3580000000000001, 0.399, 0.44799999999999995, 0.966, 0.968, 0.885, 0.938, -0.11199999999999988, 1.435, 1.924, -0.08499999999999996, 1.746, 1.954, 0.8700000000000001, 1.808, 1.887, 0.761, 1.915, 0.8759999999999999, 0.81, 0.9299999999999999, 0.7770000000000001, 1.928, 0.22199999999999998, 0.8700000000000001, 0.8900000000000001, 0.946, 0.4159999999999999, 0.899, 0.893, 0.41900000000000004, 0.8759999999999999, 1.7999999999999998, 1.4500000000000002, 0.9159999999999999, 0.488, 0.9300000000000002, 0.9430000000000001, 0.41800000000000015, 0.8559999999999999, 1.788, -0.07800000000000007, 1.854, 0.246, 0.5339999999999999, 0.9329999999999998, 0.22199999999999998, 0.935, -0.11399999999999999, 1.815, 0.3080000000000003, 0.7690000000000001, 0.929, 1.888, 0.738, 0.394, 0.9470000000000001, 0.7799999999999998, 1.909, 0.34299999999999997, 0.7290000000000001, 1.8479999999999999, 0.3879999999999999, 1.9020000000000001, 0.589, 0.28200000000000003, 0.9430000000000001, 0.938, 0.32200000000000006, 0.8279999999999998, 0.897, 0.22399999999999998, 1.9569999999999999, 0.704, 1.9060000000000001, 0.883, 0.909], "episode_lengths": [30, 77, 72, 61, 86, 131, 155, 63, 8, 17, 50, 26, 48, 40, 13, 24, 22, 22, 32, 26, 40, 40, 54, 45, 31, 16, 11, 10, 35, 20, 35, 20, 24, 27, 79, 15, 40, 58, 36, 74, 26, 38, 59, 300, 68, 23, 85, 40, 34, 17, 27, 30, 33, 25, 40, 59, 16, 27, 157, 23, 19, 25, 47, 66, 24, 46, 76, 139, 21, 88, 21, 36, 57, 58, 72, 23, 35, 79, 32, 17, 67, 29, 201, 83, 48, 36, 31, 125, 68, 18, 20, 57, 55, 31, 86, 14, 91, 30, 37, 28], "policy_red_0_reward": [-0.502, -0.505, -0.514, 1.306, 1.23, 1.091, 0.471, 1.306, 0.975, 0.948, 1.347, 1.421, 0.492, 1.379, -0.502, 0.498, -0.502, 1.4329999999999998, 0.495, 0.919, 1.373, 1.375, 0.493, 0.861, -1.004, 1.45, 1.467, 1.4689999999999999, 1.391, 1.438, 0.892, 1.439, 1.426, 0.916, 1.25, 1.454, 1.375, 0.488, 1.388, -0.507, 0.496, 1.38, 1.318, 0.46499999999999997, 1.29, 0.499, -0.514, 1.376, 1.396, 1.448, 1.4180000000000001, 1.4060000000000001, 1.3980000000000001, 0.923, 1.3780000000000001, 0.489, 1.451, 1.417, 1.0110000000000001, 1.431, 1.443, 1.42, 1.359, 0.491, -1.003, 1.357, -0.516, -0.519, 1.435, 0.73, 1.4369999999999998, 0.888, 1.323, 1.316, 1.278, 1.4300000000000002, 1.3940000000000001, -0.508, -0.507, 1.448, 1.29, 1.412, 0.8609999999999999, 1.244, 1.351, 1.389, 1.4060000000000001, 1.1019999999999999, -0.509, 1.444, 1.438, 0.825, 1.3319999999999999, -0.503, 1.236, 1.458, 1.218, 0.499, -0.503, 1.4100000000000001], "policy_blue_0_reward": [1.4060000000000001, 1.259, 1.2730000000000001, -1.013, -1.008, -0.512, 1.011, -0.51, -1.002, -1.003, -0.002, -0.5, 1.35, -0.5079999999999999, 0.959, 1.427, 0.9289999999999999, -1.002, 1.397, -0.5019999999999999, -1.003, -0.503, 1.331, -0.503, 1.403, -1.002, -0.501, -0.501, -0.506, -0.5, -1.0039999999999998, -0.004, 0.498, -1.001, 0.496, 0.5, -0.505, 1.32, 0.499, 1.268, 1.419, -0.504, -0.508, 0.46499999999999997, -0.513, 1.429, 0.736, -0.506, -0.506, -0.502, -1.002, -0.5069999999999999, -0.505, -0.504, -0.502, 1.311, -0.001, -0.501, -0.523, -0.501, -0.5, -1.002, -0.503, 1.2970000000000002, 0.9249999999999999, 0.497, 0.762, 1.053, -0.502, -0.508, -0.502, -1.002, 0.492, -1.0079999999999998, -0.509, -0.501, 0.494, 1.246, 0.901, -0.501, -0.51, 0.497, -0.518, -0.515, 0.497, -1.001, 0.496, -0.513, 0.791, -0.501, -0.5, -0.503, -0.504, 1.4, -1.012, 0.499, -0.514, 1.407, 1.3860000000000001, -0.501]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3828819130741778, "mean_inference_ms": 7.414656174638873, "mean_action_processing_ms": 0.3908020998616975, "mean_env_wait_ms": 0.5159836247522415, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15688014030456543, "StateBufferConnector_ms": 0.00939476490020752, "ViewRequirementAgentConnector_ms": 0.20234203338623047}}, "episode_reward_max": 1.9569999999999999, "episode_reward_min": -0.11399999999999999, "episode_reward_mean": 0.9130799999999999, "episode_len_mean": 49.76, "episodes_this_iter": 77, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.4689999999999999, "blue_0": 1.429}, "policy_reward_mean": {"red_0": 0.89792, "blue_0": 0.015160000000000005}, "hist_stats": {"episode_reward": [0.904, 0.754, 0.759, 0.2929999999999999, 0.22199999999999998, 0.579, 1.4819999999999998, 0.7959999999999998, -0.027000000000000024, -0.05500000000000005, 1.345, 0.921, 1.842, 0.871, 0.45699999999999996, 1.9249999999999998, 0.42699999999999994, 0.43100000000000005, 1.892, 0.41700000000000026, 0.3700000000000001, 0.8719999999999999, 1.8239999999999998, 0.3580000000000001, 0.399, 0.44799999999999995, 0.966, 0.968, 0.885, 0.938, -0.11199999999999988, 1.435, 1.924, -0.08499999999999996, 1.746, 1.954, 0.8700000000000001, 1.808, 1.887, 0.761, 1.915, 0.8759999999999999, 0.81, 0.9299999999999999, 0.7770000000000001, 1.928, 0.22199999999999998, 0.8700000000000001, 0.8900000000000001, 0.946, 0.4159999999999999, 0.899, 0.893, 0.41900000000000004, 0.8759999999999999, 1.7999999999999998, 1.4500000000000002, 0.9159999999999999, 0.488, 0.9300000000000002, 0.9430000000000001, 0.41800000000000015, 0.8559999999999999, 1.788, -0.07800000000000007, 1.854, 0.246, 0.5339999999999999, 0.9329999999999998, 0.22199999999999998, 0.935, -0.11399999999999999, 1.815, 0.3080000000000003, 0.7690000000000001, 0.929, 1.888, 0.738, 0.394, 0.9470000000000001, 0.7799999999999998, 1.909, 0.34299999999999997, 0.7290000000000001, 1.8479999999999999, 0.3879999999999999, 1.9020000000000001, 0.589, 0.28200000000000003, 0.9430000000000001, 0.938, 0.32200000000000006, 0.8279999999999998, 0.897, 0.22399999999999998, 1.9569999999999999, 0.704, 1.9060000000000001, 0.883, 0.909], "episode_lengths": [30, 77, 72, 61, 86, 131, 155, 63, 8, 17, 50, 26, 48, 40, 13, 24, 22, 22, 32, 26, 40, 40, 54, 45, 31, 16, 11, 10, 35, 20, 35, 20, 24, 27, 79, 15, 40, 58, 36, 74, 26, 38, 59, 300, 68, 23, 85, 40, 34, 17, 27, 30, 33, 25, 40, 59, 16, 27, 157, 23, 19, 25, 47, 66, 24, 46, 76, 139, 21, 88, 21, 36, 57, 58, 72, 23, 35, 79, 32, 17, 67, 29, 201, 83, 48, 36, 31, 125, 68, 18, 20, 57, 55, 31, 86, 14, 91, 30, 37, 28], "policy_red_0_reward": [-0.502, -0.505, -0.514, 1.306, 1.23, 1.091, 0.471, 1.306, 0.975, 0.948, 1.347, 1.421, 0.492, 1.379, -0.502, 0.498, -0.502, 1.4329999999999998, 0.495, 0.919, 1.373, 1.375, 0.493, 0.861, -1.004, 1.45, 1.467, 1.4689999999999999, 1.391, 1.438, 0.892, 1.439, 1.426, 0.916, 1.25, 1.454, 1.375, 0.488, 1.388, -0.507, 0.496, 1.38, 1.318, 0.46499999999999997, 1.29, 0.499, -0.514, 1.376, 1.396, 1.448, 1.4180000000000001, 1.4060000000000001, 1.3980000000000001, 0.923, 1.3780000000000001, 0.489, 1.451, 1.417, 1.0110000000000001, 1.431, 1.443, 1.42, 1.359, 0.491, -1.003, 1.357, -0.516, -0.519, 1.435, 0.73, 1.4369999999999998, 0.888, 1.323, 1.316, 1.278, 1.4300000000000002, 1.3940000000000001, -0.508, -0.507, 1.448, 1.29, 1.412, 0.8609999999999999, 1.244, 1.351, 1.389, 1.4060000000000001, 1.1019999999999999, -0.509, 1.444, 1.438, 0.825, 1.3319999999999999, -0.503, 1.236, 1.458, 1.218, 0.499, -0.503, 1.4100000000000001], "policy_blue_0_reward": [1.4060000000000001, 1.259, 1.2730000000000001, -1.013, -1.008, -0.512, 1.011, -0.51, -1.002, -1.003, -0.002, -0.5, 1.35, -0.5079999999999999, 0.959, 1.427, 0.9289999999999999, -1.002, 1.397, -0.5019999999999999, -1.003, -0.503, 1.331, -0.503, 1.403, -1.002, -0.501, -0.501, -0.506, -0.5, -1.0039999999999998, -0.004, 0.498, -1.001, 0.496, 0.5, -0.505, 1.32, 0.499, 1.268, 1.419, -0.504, -0.508, 0.46499999999999997, -0.513, 1.429, 0.736, -0.506, -0.506, -0.502, -1.002, -0.5069999999999999, -0.505, -0.504, -0.502, 1.311, -0.001, -0.501, -0.523, -0.501, -0.5, -1.002, -0.503, 1.2970000000000002, 0.9249999999999999, 0.497, 0.762, 1.053, -0.502, -0.508, -0.502, -1.002, 0.492, -1.0079999999999998, -0.509, -0.501, 0.494, 1.246, 0.901, -0.501, -0.51, 0.497, -0.518, -0.515, 0.497, -1.001, 0.496, -0.513, 0.791, -0.501, -0.5, -0.503, -0.504, 1.4, -1.012, 0.499, -0.514, 1.407, 1.3860000000000001, -0.501]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3828819130741778, "mean_inference_ms": 7.414656174638873, "mean_action_processing_ms": 0.3908020998616975, "mean_env_wait_ms": 0.5159836247522415, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15688014030456543, "StateBufferConnector_ms": 0.00939476490020752, "ViewRequirementAgentConnector_ms": 0.20234203338623047}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.35235518309392, "num_env_steps_trained_throughput_per_sec": 131.35235518309392, "timesteps_total": 264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 31150.864, "sample_time_ms": 4024.564, "learn_time_ms": 27098.06, "learn_throughput": 147.612, "synch_weights_time_ms": 26.745}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "episodes_total": 3032, "training_iteration": 66, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-31-46", "timestamp": 1694838706, "time_this_iter_s": 30.469568014144897, "time_total_s": 2046.476303100586, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f4e50>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2046.476303100586, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 23.58636363636363, "ram_util_percent": 57.1090909090909}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.19, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.56, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.56, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.15, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.56, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6593722827111681, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.061178715135126065, "policy_loss": -0.10691526405377469, "vf_loss": 0.026208509129355663, "vf_explained_var": 0.6608613137155771, "kl": 0.014972486645221775, "entropy": 1.4769027862697839, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 63840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6078817240893841, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06731688498693984, "policy_loss": -0.1142501352597416, "vf_loss": 0.035111950270948, "vf_explained_var": 0.6391394605860115, "kl": 0.013601246358422288, "entropy": 1.6080640755593776, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 63840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000}, "sampler_results": {"episode_reward_max": 1.9569999999999999, "episode_reward_min": -0.20000000000000007, "episode_reward_mean": 1.00645, "episode_len_mean": 44.08, "episode_media": {}, "episodes_this_iter": 93, "policy_reward_min": {"red_0": -0.522, "blue_0": -1.012}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.432}, "policy_reward_mean": {"red_0": 1.0017699999999998, "blue_0": 0.004680000000000005}, "custom_metrics": {"red_0/door_open_done_mean": 0.19, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.56, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.56, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.15, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.56, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.897, 0.22399999999999998, 1.9569999999999999, 0.704, 1.9060000000000001, 0.883, 0.909, 0.599, 1.911, 1.9020000000000001, 0.9249999999999998, -0.20000000000000007, 1.885, 0.9229999999999999, 0.823, 0.395, 1.879, 1.7109999999999999, 0.8940000000000001, 0.42100000000000004, 0.3620000000000001, 0.3700000000000001, 1.924, -0.06000000000000005, 0.9239999999999999, 0.784, 0.9289999999999998, 1.913, 1.952, 0.9590000000000001, 1.913, 0.23899999999999988, 1.895, 0.367, 0.857, 0.44799999999999995, 0.8719999999999999, 0.9249999999999999, 0.45099999999999996, 1.951, 0.387, 0.6950000000000001, 1.6749999999999998, 0.3620000000000001, 0.3900000000000001, 0.9369999999999998, 0.954, 0.929, 1.918, 0.3820000000000001, 1.8900000000000001, 0.9209999999999998, 1.415, 0.8999999999999999, 0.45999999999999996, 1.9300000000000002, 1.657, 1.9200000000000002, 1.907, 1.92, 0.954, 0.923, 0.43999999999999995, 1.916, 0.573, 0.81, 0.44200000000000017, 1.821, 0.9689999999999999, 0.40700000000000003, -0.03600000000000003, 0.7629999999999999, 0.41400000000000015, 0.927, 1.405, 0.6789999999999998, 1.319, 0.6479999999999999, 0.43399999999999994, 0.4079999999999999, 1.439, 0.8399999999999999, 1.8239999999999998, 1.751, 0.46399999999999997, 1.9180000000000001, 0.833, 1.363, 0.9289999999999999, 0.365, 0.403, 1.388, 0.2629999999999999, 1.83, -0.09699999999999998, 0.32499999999999996, 0.2789999999999999, 0.42100000000000004, 1.9220000000000002, 0.897], "episode_lengths": [31, 86, 14, 91, 30, 37, 28, 121, 28, 30, 24, 61, 33, 24, 54, 33, 36, 89, 33, 26, 199, 41, 24, 19, 300, 66, 22, 27, 16, 13, 27, 81, 32, 40, 45, 17, 39, 24, 16, 16, 36, 95, 96, 43, 34, 20, 14, 23, 24, 37, 34, 24, 27, 32, 13, 23, 107, 25, 29, 25, 14, 23, 18, 27, 131, 57, 18, 55, 10, 30, 11, 73, 27, 24, 31, 98, 57, 108, 21, 28, 19, 48, 54, 77, 11, 26, 51, 41, 22, 43, 31, 35, 73, 52, 29, 53, 69, 25, 23, 31], "policy_red_0_reward": [-0.503, 1.236, 1.458, 1.218, 0.499, -0.503, 1.4100000000000001, -0.515, 0.496, 1.407, 1.426, 0.8069999999999999, 0.493, -0.501, 1.331, 1.397, 1.3860000000000001, 0.493, 1.397, 1.421, 0.887, 1.374, 1.426, 0.941, 0.45299999999999996, 1.2970000000000002, 1.432, 1.416, 1.452, 1.46, 0.499, 0.748, 1.4020000000000001, 0.874, 1.361, 1.4489999999999998, 1.376, -0.501, -0.5, 1.452, 1.389, 1.2040000000000002, 0.483, 1.367, 1.395, 1.439, 1.4569999999999999, 1.4300000000000002, 0.495, 1.388, 0.495, 1.427, 1.419, 1.403, 1.46, 1.431, 1.165, 1.425, 0.498, 1.423, 1.458, 1.4260000000000002, 1.443, 1.419, -0.522, 1.3199999999999998, 1.446, 0.493, 1.47, 0.908, 0.966, 1.271, 1.4180000000000001, 1.427, 1.4060000000000001, 1.192, -0.004, 1.1629999999999998, 1.436, 0.912, 1.4409999999999998, 1.3479999999999999, 0.494, 0.493, 0.965, 1.421, 1.3439999999999999, 1.371, -0.503, 0.869, -0.501, -0.004, 1.269, 0.492, 0.91, 0.834, 1.283, 1.425, 1.429, 1.405], "policy_blue_0_reward": [1.4, -1.012, 0.499, -0.514, 1.407, 1.3860000000000001, -0.501, 1.1139999999999999, 1.415, 0.495, -0.501, -1.007, 1.392, 1.424, -0.508, -1.002, 0.493, 1.218, -0.503, -1.0, -0.525, -1.004, 0.498, -1.001, 0.471, -0.513, -0.503, 0.497, 0.5, -0.501, 1.4140000000000001, -0.509, 0.493, -0.507, -0.504, -1.001, -0.504, 1.426, 0.951, 0.499, -1.002, -0.509, 1.192, -1.005, -1.005, -0.502, -0.503, -0.501, 1.423, -1.006, 1.395, -0.506, -0.004, -0.503, -1.0, 0.499, 0.492, 0.495, 1.409, 0.497, -0.504, -0.503, -1.003, 0.497, 1.095, -0.51, -1.0039999999999998, 1.3279999999999998, -0.501, -0.501, -1.002, -0.5079999999999999, -1.004, -0.5, -0.001, -0.513, 1.323, -0.515, -1.002, -0.504, -0.002, -0.508, 1.33, 1.258, -0.501, 0.497, -0.511, -0.008, 1.432, -0.504, 0.904, 1.392, -1.006, 1.338, -1.007, -0.509, -1.004, -1.004, 0.493, -0.508]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.381313007232838, "mean_inference_ms": 7.407025489462753, "mean_action_processing_ms": 0.39023962884600494, "mean_env_wait_ms": 0.5155508766267652, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1366056203842163, "StateBufferConnector_ms": 0.00888371467590332, "ViewRequirementAgentConnector_ms": 0.175773024559021}}, "episode_reward_max": 1.9569999999999999, "episode_reward_min": -0.20000000000000007, "episode_reward_mean": 1.00645, "episode_len_mean": 44.08, "episodes_this_iter": 93, "policy_reward_min": {"red_0": -0.522, "blue_0": -1.012}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.432}, "policy_reward_mean": {"red_0": 1.0017699999999998, "blue_0": 0.004680000000000005}, "hist_stats": {"episode_reward": [0.897, 0.22399999999999998, 1.9569999999999999, 0.704, 1.9060000000000001, 0.883, 0.909, 0.599, 1.911, 1.9020000000000001, 0.9249999999999998, -0.20000000000000007, 1.885, 0.9229999999999999, 0.823, 0.395, 1.879, 1.7109999999999999, 0.8940000000000001, 0.42100000000000004, 0.3620000000000001, 0.3700000000000001, 1.924, -0.06000000000000005, 0.9239999999999999, 0.784, 0.9289999999999998, 1.913, 1.952, 0.9590000000000001, 1.913, 0.23899999999999988, 1.895, 0.367, 0.857, 0.44799999999999995, 0.8719999999999999, 0.9249999999999999, 0.45099999999999996, 1.951, 0.387, 0.6950000000000001, 1.6749999999999998, 0.3620000000000001, 0.3900000000000001, 0.9369999999999998, 0.954, 0.929, 1.918, 0.3820000000000001, 1.8900000000000001, 0.9209999999999998, 1.415, 0.8999999999999999, 0.45999999999999996, 1.9300000000000002, 1.657, 1.9200000000000002, 1.907, 1.92, 0.954, 0.923, 0.43999999999999995, 1.916, 0.573, 0.81, 0.44200000000000017, 1.821, 0.9689999999999999, 0.40700000000000003, -0.03600000000000003, 0.7629999999999999, 0.41400000000000015, 0.927, 1.405, 0.6789999999999998, 1.319, 0.6479999999999999, 0.43399999999999994, 0.4079999999999999, 1.439, 0.8399999999999999, 1.8239999999999998, 1.751, 0.46399999999999997, 1.9180000000000001, 0.833, 1.363, 0.9289999999999999, 0.365, 0.403, 1.388, 0.2629999999999999, 1.83, -0.09699999999999998, 0.32499999999999996, 0.2789999999999999, 0.42100000000000004, 1.9220000000000002, 0.897], "episode_lengths": [31, 86, 14, 91, 30, 37, 28, 121, 28, 30, 24, 61, 33, 24, 54, 33, 36, 89, 33, 26, 199, 41, 24, 19, 300, 66, 22, 27, 16, 13, 27, 81, 32, 40, 45, 17, 39, 24, 16, 16, 36, 95, 96, 43, 34, 20, 14, 23, 24, 37, 34, 24, 27, 32, 13, 23, 107, 25, 29, 25, 14, 23, 18, 27, 131, 57, 18, 55, 10, 30, 11, 73, 27, 24, 31, 98, 57, 108, 21, 28, 19, 48, 54, 77, 11, 26, 51, 41, 22, 43, 31, 35, 73, 52, 29, 53, 69, 25, 23, 31], "policy_red_0_reward": [-0.503, 1.236, 1.458, 1.218, 0.499, -0.503, 1.4100000000000001, -0.515, 0.496, 1.407, 1.426, 0.8069999999999999, 0.493, -0.501, 1.331, 1.397, 1.3860000000000001, 0.493, 1.397, 1.421, 0.887, 1.374, 1.426, 0.941, 0.45299999999999996, 1.2970000000000002, 1.432, 1.416, 1.452, 1.46, 0.499, 0.748, 1.4020000000000001, 0.874, 1.361, 1.4489999999999998, 1.376, -0.501, -0.5, 1.452, 1.389, 1.2040000000000002, 0.483, 1.367, 1.395, 1.439, 1.4569999999999999, 1.4300000000000002, 0.495, 1.388, 0.495, 1.427, 1.419, 1.403, 1.46, 1.431, 1.165, 1.425, 0.498, 1.423, 1.458, 1.4260000000000002, 1.443, 1.419, -0.522, 1.3199999999999998, 1.446, 0.493, 1.47, 0.908, 0.966, 1.271, 1.4180000000000001, 1.427, 1.4060000000000001, 1.192, -0.004, 1.1629999999999998, 1.436, 0.912, 1.4409999999999998, 1.3479999999999999, 0.494, 0.493, 0.965, 1.421, 1.3439999999999999, 1.371, -0.503, 0.869, -0.501, -0.004, 1.269, 0.492, 0.91, 0.834, 1.283, 1.425, 1.429, 1.405], "policy_blue_0_reward": [1.4, -1.012, 0.499, -0.514, 1.407, 1.3860000000000001, -0.501, 1.1139999999999999, 1.415, 0.495, -0.501, -1.007, 1.392, 1.424, -0.508, -1.002, 0.493, 1.218, -0.503, -1.0, -0.525, -1.004, 0.498, -1.001, 0.471, -0.513, -0.503, 0.497, 0.5, -0.501, 1.4140000000000001, -0.509, 0.493, -0.507, -0.504, -1.001, -0.504, 1.426, 0.951, 0.499, -1.002, -0.509, 1.192, -1.005, -1.005, -0.502, -0.503, -0.501, 1.423, -1.006, 1.395, -0.506, -0.004, -0.503, -1.0, 0.499, 0.492, 0.495, 1.409, 0.497, -0.504, -0.503, -1.003, 0.497, 1.095, -0.51, -1.0039999999999998, 1.3279999999999998, -0.501, -0.501, -1.002, -0.5079999999999999, -1.004, -0.5, -0.001, -0.513, 1.323, -0.515, -1.002, -0.504, -0.002, -0.508, 1.33, 1.258, -0.501, 0.497, -0.511, -0.008, 1.432, -0.504, 0.904, 1.392, -1.006, 1.338, -1.007, -0.509, -1.004, -1.004, 0.493, -0.508]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.381313007232838, "mean_inference_ms": 7.407025489462753, "mean_action_processing_ms": 0.39023962884600494, "mean_env_wait_ms": 0.5155508766267652, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1366056203842163, "StateBufferConnector_ms": 0.00888371467590332, "ViewRequirementAgentConnector_ms": 0.175773024559021}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.3500965672351, "num_env_steps_trained_throughput_per_sec": 129.3500965672351, "timesteps_total": 268000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 536000, "timers": {"training_iteration_time_ms": 31217.021, "sample_time_ms": 3986.179, "learn_time_ms": 27202.522, "learn_throughput": 147.045, "synch_weights_time_ms": 26.83}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000}, "done": false, "episodes_total": 3125, "training_iteration": 67, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-32-17", "timestamp": 1694838737, "time_this_iter_s": 30.939069032669067, "time_total_s": 2077.415372133255, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7239e4d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2077.415372133255, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 25.657777777777774, "ram_util_percent": 57.09555555555555}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.16, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.54, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.54, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.54, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6348236722871661, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05680095989422019, "policy_loss": -0.10698575946492686, "vf_loss": 0.0400150353651649, "vf_explained_var": 0.5629429347192247, "kl": 0.013885171086326423, "entropy": 1.4548741165548562, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 64800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6224013143839936, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0602403351503502, "policy_loss": -0.11038917014739127, "vf_loss": 0.0445693447458325, "vf_explained_var": 0.5968344689657291, "kl": 0.012927620185534276, "entropy": 1.5865727469325066, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 64800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "sampler_results": {"episode_reward_max": 1.948, "episode_reward_min": -0.43599999999999994, "episode_reward_mean": 0.8924800000000002, "episode_len_mean": 40.87, "episode_media": {}, "episodes_this_iter": 96, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.466, "blue_0": 1.46}, "policy_reward_mean": {"red_0": 0.8294600000000001, "blue_0": 0.06302}, "custom_metrics": {"red_0/door_open_done_mean": 0.16, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.54, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.54, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.54, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.2789999999999999, 0.42100000000000004, 1.9220000000000002, 0.897, -0.15200000000000002, 0.9369999999999998, 1.395, 0.966, 0.7749999999999999, 0.45699999999999985, 0.806, 0.849, 0.43199999999999994, 0.869, 1.9100000000000001, 1.771, 0.959, 0.812, -0.040000000000000036, -0.03700000000000003, 0.40600000000000014, 1.8860000000000001, 0.17899999999999983, 0.4289999999999998, 0.44399999999999995, 0.373, 1.438, 1.889, 0.405, 0.7570000000000001, 0.359, 1.948, 1.8279999999999998, 0.893, 0.885, 0.45699999999999985, 0.34199999999999986, 0.7849999999999999, -0.05700000000000005, -0.43599999999999994, 0.45500000000000007, 1.834, 0.798, 1.8130000000000002, 0.42300000000000004, 0.43299999999999983, 0.9220000000000002, 0.45599999999999996, 0.8599999999999999, 1.822, 0.46199999999999997, 1.9180000000000001, 1.926, -0.050999999999999934, -0.119, 0.8070000000000002, 0.9339999999999999, -0.062000000000000055, 1.9329999999999998, 0.719, 1.931, 0.2789999999999999, -0.041000000000000036, 1.5979999999999999, 1.44, 1.87, -0.049000000000000044, 1.912, 0.865, 0.9550000000000001, 0.8479999999999999, 0.892, 0.21799999999999997, -0.14700000000000002, 1.936, 0.8799999999999999, 1.9449999999999998, 1.6680000000000001, 1.3900000000000001, 0.384, 1.861, 0.853, 0.8239999999999998, -0.05399999999999994, 0.8500000000000001, 0.915, -0.04300000000000004, 1.8980000000000001, 1.912, 0.861, -0.04400000000000004, 0.7589999999999999, 0.9279999999999999, 1.7999999999999998, 0.41200000000000003, 1.9180000000000001, 0.397, 1.9180000000000001, -0.15600000000000003, 0.944], "episode_lengths": [69, 25, 23, 31, 47, 20, 33, 11, 68, 14, 61, 46, 21, 38, 28, 71, 13, 58, 12, 12, 30, 34, 98, 22, 17, 39, 20, 34, 29, 74, 42, 16, 54, 32, 36, 164, 201, 67, 17, 136, 14, 51, 63, 58, 24, 21, 25, 13, 45, 55, 12, 25, 24, 15, 37, 62, 21, 18, 21, 87, 22, 68, 13, 120, 19, 40, 15, 28, 40, 14, 47, 33, 88, 46, 20, 37, 17, 101, 33, 35, 44, 46, 54, 17, 45, 26, 14, 31, 27, 44, 14, 77, 22, 61, 25, 26, 32, 27, 47, 18], "policy_red_0_reward": [1.283, 1.425, 1.429, 1.405, 0.855, 1.438, 1.396, 1.466, 1.2850000000000001, 0.958, 1.313, 1.3559999999999999, -0.501, -0.513, 1.4140000000000001, 0.494, -0.501, -0.505, 0.963, 0.963, 1.4060000000000001, 0.494, 0.696, 1.4329999999999998, 0.945, 1.379, -0.002, 0.496, -1.005, 1.2690000000000001, 1.367, 1.452, 1.331, 1.3980000000000001, 1.3900000000000001, 0.986, 0.8739999999999999, -0.51, -1.003, 0.5790000000000001, 1.458, 1.341, 1.3039999999999998, 0.494, 1.426, 0.9349999999999999, 1.423, 0.96, 1.361, 0.494, 1.463, 0.497, 1.428, 0.954, -1.003, 1.3130000000000002, -0.501, -1.005, 0.499, -0.511, 1.432, 1.288, 0.959, 0.478, 1.443, 1.376, -1.001, 1.415, 1.3719999999999999, 1.4569999999999999, 1.353, -0.502, 0.721, 0.857, 0.499, 1.3860000000000001, 1.4489999999999998, 0.483, 1.397, -1.004, 0.498, 1.3559999999999999, 1.331, -1.001, 1.358, 1.42, 0.958, 1.407, 1.4180000000000001, 1.363, 0.958, 1.2650000000000001, 1.431, 0.49, -0.506, 0.498, 1.4, 1.419, 0.852, 1.4449999999999998], "policy_blue_0_reward": [-1.004, -1.004, 0.493, -0.508, -1.007, -0.501, -0.001, -0.5, -0.51, -0.501, -0.507, -0.507, 0.9329999999999999, 1.3820000000000001, 0.496, 1.2770000000000001, 1.46, 1.3170000000000002, -1.003, -1.0, -1.0, 1.392, -0.517, -1.004, -0.501, -1.006, 1.44, 1.393, 1.4100000000000001, -0.512, -1.008, 0.496, 0.497, -0.505, -0.505, -0.529, -0.532, 1.295, 0.946, -1.015, -1.003, 0.493, -0.5059999999999999, 1.319, -1.003, -0.502, -0.501, -0.504, -0.501, 1.3279999999999998, -1.001, 1.421, 0.498, -1.005, 0.884, -0.5059999999999999, 1.435, 0.943, 1.434, 1.23, 0.499, -1.009, -1.0, 1.1199999999999999, -0.003, 0.494, 0.952, 0.497, -0.507, -0.502, -0.505, 1.3940000000000001, -0.503, -1.004, 1.4369999999999998, -0.506, 0.496, 1.185, -0.007, 1.388, 1.363, -0.503, -0.507, 0.947, -0.5079999999999999, -0.505, -1.001, 0.491, 0.494, -0.502, -1.002, -0.506, -0.503, 1.31, 0.918, 1.42, -1.003, 0.499, -1.008, -0.501]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3820771130036953, "mean_inference_ms": 7.413650894238151, "mean_action_processing_ms": 0.3896458616791142, "mean_env_wait_ms": 0.5159888899025986, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1478729248046875, "StateBufferConnector_ms": 0.009518265724182129, "ViewRequirementAgentConnector_ms": 0.19019317626953125}}, "episode_reward_max": 1.948, "episode_reward_min": -0.43599999999999994, "episode_reward_mean": 0.8924800000000002, "episode_len_mean": 40.87, "episodes_this_iter": 96, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.466, "blue_0": 1.46}, "policy_reward_mean": {"red_0": 0.8294600000000001, "blue_0": 0.06302}, "hist_stats": {"episode_reward": [0.2789999999999999, 0.42100000000000004, 1.9220000000000002, 0.897, -0.15200000000000002, 0.9369999999999998, 1.395, 0.966, 0.7749999999999999, 0.45699999999999985, 0.806, 0.849, 0.43199999999999994, 0.869, 1.9100000000000001, 1.771, 0.959, 0.812, -0.040000000000000036, -0.03700000000000003, 0.40600000000000014, 1.8860000000000001, 0.17899999999999983, 0.4289999999999998, 0.44399999999999995, 0.373, 1.438, 1.889, 0.405, 0.7570000000000001, 0.359, 1.948, 1.8279999999999998, 0.893, 0.885, 0.45699999999999985, 0.34199999999999986, 0.7849999999999999, -0.05700000000000005, -0.43599999999999994, 0.45500000000000007, 1.834, 0.798, 1.8130000000000002, 0.42300000000000004, 0.43299999999999983, 0.9220000000000002, 0.45599999999999996, 0.8599999999999999, 1.822, 0.46199999999999997, 1.9180000000000001, 1.926, -0.050999999999999934, -0.119, 0.8070000000000002, 0.9339999999999999, -0.062000000000000055, 1.9329999999999998, 0.719, 1.931, 0.2789999999999999, -0.041000000000000036, 1.5979999999999999, 1.44, 1.87, -0.049000000000000044, 1.912, 0.865, 0.9550000000000001, 0.8479999999999999, 0.892, 0.21799999999999997, -0.14700000000000002, 1.936, 0.8799999999999999, 1.9449999999999998, 1.6680000000000001, 1.3900000000000001, 0.384, 1.861, 0.853, 0.8239999999999998, -0.05399999999999994, 0.8500000000000001, 0.915, -0.04300000000000004, 1.8980000000000001, 1.912, 0.861, -0.04400000000000004, 0.7589999999999999, 0.9279999999999999, 1.7999999999999998, 0.41200000000000003, 1.9180000000000001, 0.397, 1.9180000000000001, -0.15600000000000003, 0.944], "episode_lengths": [69, 25, 23, 31, 47, 20, 33, 11, 68, 14, 61, 46, 21, 38, 28, 71, 13, 58, 12, 12, 30, 34, 98, 22, 17, 39, 20, 34, 29, 74, 42, 16, 54, 32, 36, 164, 201, 67, 17, 136, 14, 51, 63, 58, 24, 21, 25, 13, 45, 55, 12, 25, 24, 15, 37, 62, 21, 18, 21, 87, 22, 68, 13, 120, 19, 40, 15, 28, 40, 14, 47, 33, 88, 46, 20, 37, 17, 101, 33, 35, 44, 46, 54, 17, 45, 26, 14, 31, 27, 44, 14, 77, 22, 61, 25, 26, 32, 27, 47, 18], "policy_red_0_reward": [1.283, 1.425, 1.429, 1.405, 0.855, 1.438, 1.396, 1.466, 1.2850000000000001, 0.958, 1.313, 1.3559999999999999, -0.501, -0.513, 1.4140000000000001, 0.494, -0.501, -0.505, 0.963, 0.963, 1.4060000000000001, 0.494, 0.696, 1.4329999999999998, 0.945, 1.379, -0.002, 0.496, -1.005, 1.2690000000000001, 1.367, 1.452, 1.331, 1.3980000000000001, 1.3900000000000001, 0.986, 0.8739999999999999, -0.51, -1.003, 0.5790000000000001, 1.458, 1.341, 1.3039999999999998, 0.494, 1.426, 0.9349999999999999, 1.423, 0.96, 1.361, 0.494, 1.463, 0.497, 1.428, 0.954, -1.003, 1.3130000000000002, -0.501, -1.005, 0.499, -0.511, 1.432, 1.288, 0.959, 0.478, 1.443, 1.376, -1.001, 1.415, 1.3719999999999999, 1.4569999999999999, 1.353, -0.502, 0.721, 0.857, 0.499, 1.3860000000000001, 1.4489999999999998, 0.483, 1.397, -1.004, 0.498, 1.3559999999999999, 1.331, -1.001, 1.358, 1.42, 0.958, 1.407, 1.4180000000000001, 1.363, 0.958, 1.2650000000000001, 1.431, 0.49, -0.506, 0.498, 1.4, 1.419, 0.852, 1.4449999999999998], "policy_blue_0_reward": [-1.004, -1.004, 0.493, -0.508, -1.007, -0.501, -0.001, -0.5, -0.51, -0.501, -0.507, -0.507, 0.9329999999999999, 1.3820000000000001, 0.496, 1.2770000000000001, 1.46, 1.3170000000000002, -1.003, -1.0, -1.0, 1.392, -0.517, -1.004, -0.501, -1.006, 1.44, 1.393, 1.4100000000000001, -0.512, -1.008, 0.496, 0.497, -0.505, -0.505, -0.529, -0.532, 1.295, 0.946, -1.015, -1.003, 0.493, -0.5059999999999999, 1.319, -1.003, -0.502, -0.501, -0.504, -0.501, 1.3279999999999998, -1.001, 1.421, 0.498, -1.005, 0.884, -0.5059999999999999, 1.435, 0.943, 1.434, 1.23, 0.499, -1.009, -1.0, 1.1199999999999999, -0.003, 0.494, 0.952, 0.497, -0.507, -0.502, -0.505, 1.3940000000000001, -0.503, -1.004, 1.4369999999999998, -0.506, 0.496, 1.185, -0.007, 1.388, 1.363, -0.503, -0.507, 0.947, -0.5079999999999999, -0.505, -1.001, 0.491, 0.494, -0.502, -1.002, -0.506, -0.503, 1.31, 0.918, 1.42, -1.003, 0.499, -1.008, -0.501]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3820771130036953, "mean_inference_ms": 7.413650894238151, "mean_action_processing_ms": 0.3896458616791142, "mean_env_wait_ms": 0.5159888899025986, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1478729248046875, "StateBufferConnector_ms": 0.009518265724182129, "ViewRequirementAgentConnector_ms": 0.19019317626953125}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 125.3443329308226, "num_env_steps_trained_throughput_per_sec": 125.3443329308226, "timesteps_total": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 31414.13, "sample_time_ms": 4015.639, "learn_time_ms": 27370.093, "learn_throughput": 146.145, "synch_weights_time_ms": 26.892}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "episodes_total": 3221, "training_iteration": 68, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-32-50", "timestamp": 1694838770, "time_this_iter_s": 31.928826093673706, "time_total_s": 2109.3441982269287, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f5990>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2109.3441982269287, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 24.367391304347823, "ram_util_percent": 57.082608695652155}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.15, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.56, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.56, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.56, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6549108830901483, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05024595714833898, "policy_loss": -0.09866526620996106, "vf_loss": 0.036195530336893475, "vf_explained_var": 0.5954182347903649, "kl": 0.013963121741742128, "entropy": 1.488193267583847, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 65760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6362775840796531, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06595826232272278, "policy_loss": -0.11494458789966303, "vf_loss": 0.037009362136207834, "vf_explained_var": 0.6344038268551231, "kl": 0.01408763337432027, "entropy": 1.611745892589291, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 65760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 552000, "num_agent_steps_trained": 552000}, "sampler_results": {"episode_reward_max": 1.955, "episode_reward_min": -0.15600000000000003, "episode_reward_mean": 0.9236599999999998, "episode_len_mean": 41.76, "episode_media": {}, "episodes_this_iter": 89, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.478, "blue_0": 1.464}, "policy_reward_mean": {"red_0": 0.8926199999999999, "blue_0": 0.03104}, "custom_metrics": {"red_0/door_open_done_mean": 0.15, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.56, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.56, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.56, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.861, -0.04400000000000004, 0.7589999999999999, 0.9279999999999999, 1.7999999999999998, 0.41200000000000003, 1.9180000000000001, 0.397, 1.9180000000000001, -0.15600000000000003, 0.944, 1.9289999999999998, 1.8770000000000002, 1.791, 1.911, 1.899, 0.45599999999999996, 0.4630000000000001, 0.655, 0.895, 0.9359999999999999, 0.8610000000000002, 0.125, 0.45999999999999996, 0.3620000000000001, 0.18799999999999994, 0.379, 1.4020000000000001, 0.44499999999999995, 1.955, 0.959, 0.44899999999999984, 0.46099999999999985, 0.46699999999999997, 0.9529999999999998, 0.942, -0.039999999999999925, 0.10599999999999987, 0.9430000000000001, 0.917, 0.8679999999999999, 0.3340000000000001, 0.42700000000000005, 0.7730000000000001, 1.8679999999999999, 0.8130000000000002, 1.8399999999999999, 0.897, 0.869, 0.43999999999999995, 1.825, 0.28200000000000003, 1.408, 1.8639999999999999, 0.5680000000000001, 0.567, 0.8199999999999998, 0.6179999999999999, 0.9219999999999999, 0.43399999999999994, 0.963, 1.944, -0.038000000000000034, 0.44899999999999984, 0.889, 0.7829999999999999, 1.792, 0.30200000000000005, 0.85, -0.03400000000000003, 0.923, 1.895, 0.349, 1.431, 0.30000000000000004, 0.45199999999999996, 1.409, 1.857, 1.951, 0.43100000000000005, 0.7320000000000002, 0.9099999999999999, 0.9359999999999999, -0.15400000000000003, 0.6819999999999999, 1.952, 1.8239999999999998, 0.45799999999999996, 1.854, 1.883, 0.944, 0.895, 1.7650000000000001, 0.96, 0.903, 0.923, 0.41000000000000003, 0.901, 0.478, 0.8919999999999999], "episode_lengths": [44, 14, 77, 22, 61, 25, 26, 32, 27, 47, 18, 22, 37, 64, 27, 32, 14, 12, 105, 33, 19, 41, 115, 13, 42, 94, 39, 31, 16, 15, 13, 15, 13, 11, 15, 18, 13, 124, 19, 26, 41, 52, 23, 70, 41, 58, 50, 32, 40, 18, 54, 67, 29, 42, 131, 134, 55, 120, 24, 20, 12, 18, 12, 16, 35, 66, 64, 59, 46, 11, 24, 34, 44, 22, 62, 15, 28, 44, 15, 22, 82, 300, 19, 48, 96, 15, 53, 13, 44, 35, 18, 33, 74, 13, 30, 24, 27, 30, 7, 34], "policy_red_0_reward": [1.363, 0.958, 1.2650000000000001, 1.431, 0.49, -0.506, 0.498, 1.4, 1.419, 0.852, 1.4449999999999998, 0.497, 1.387, 0.49, 1.417, 0.499, 1.458, 0.963, 1.1760000000000002, -0.503, 1.439, 1.373, -0.516, 1.4609999999999999, 1.37, -0.519, 0.88, 1.404, -0.504, 1.455, -0.5, 0.949, 1.4609999999999999, 0.967, 1.454, 1.4449999999999998, -1.001, 0.617, 1.443, 1.421, 1.373, 1.342, -0.502, 1.279, 0.496, 1.3170000000000002, 1.3479999999999999, -0.502, 1.375, 1.444, 1.33, 1.2919999999999998, 0.0, 1.3719999999999999, 1.0939999999999999, 1.08, 1.3279999999999998, -0.514, -0.502, 1.439, -0.501, 1.4449999999999998, 0.963, 0.951, 1.391, 1.288, 0.488, 1.315, -0.503, 0.967, 1.427, 0.498, 0.861, 1.432, 1.3050000000000002, -0.5, 1.415, 1.3639999999999999, 0.497, 1.4329999999999998, 1.241, 0.45399999999999996, 1.4409999999999998, 0.852, 1.2, 1.4529999999999998, 1.3319999999999999, -0.5, 1.361, 0.497, 1.4449999999999998, 1.399, 0.494, 1.46, 1.4060000000000001, 1.426, -0.501, 1.404, 1.478, 1.397], "policy_blue_0_reward": [-0.502, -1.002, -0.506, -0.503, 1.31, 0.918, 1.42, -1.003, 0.499, -1.008, -0.501, 1.432, 0.49, 1.3010000000000002, 0.494, 1.4, -1.002, -0.5, -0.521, 1.3980000000000001, -0.503, -0.5119999999999999, 0.641, -1.001, -1.008, 0.707, -0.501, -0.002, 0.949, 0.5, 1.459, -0.5, -1.0, -0.5, -0.501, -0.503, 0.961, -0.511, -0.5, -0.504, -0.505, -1.008, 0.929, -0.506, 1.3719999999999999, -0.504, 0.492, 1.399, -0.506, -1.004, 0.495, -1.01, 1.408, 0.492, -0.526, -0.513, -0.508, 1.132, 1.424, -1.005, 1.464, 0.499, -1.001, -0.502, -0.502, -0.505, 1.304, -1.013, 1.353, -1.001, -0.504, 1.397, -0.512, -0.001, -1.005, 0.952, -0.006, 0.493, 1.454, -1.002, -0.5089999999999999, 0.45599999999999996, -0.505, -1.006, -0.518, 0.499, 0.492, 0.958, 0.493, 1.3860000000000001, -0.5009999999999999, -0.504, 1.271, -0.5, -0.503, -0.503, 0.911, -0.503, -1.0, -0.505]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3824596771528115, "mean_inference_ms": 7.411886814711406, "mean_action_processing_ms": 0.39176264356948143, "mean_env_wait_ms": 0.5161174940576898, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1748589277267456, "StateBufferConnector_ms": 0.00946652889251709, "ViewRequirementAgentConnector_ms": 0.18881523609161377}}, "episode_reward_max": 1.955, "episode_reward_min": -0.15600000000000003, "episode_reward_mean": 0.9236599999999998, "episode_len_mean": 41.76, "episodes_this_iter": 89, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.478, "blue_0": 1.464}, "policy_reward_mean": {"red_0": 0.8926199999999999, "blue_0": 0.03104}, "hist_stats": {"episode_reward": [0.861, -0.04400000000000004, 0.7589999999999999, 0.9279999999999999, 1.7999999999999998, 0.41200000000000003, 1.9180000000000001, 0.397, 1.9180000000000001, -0.15600000000000003, 0.944, 1.9289999999999998, 1.8770000000000002, 1.791, 1.911, 1.899, 0.45599999999999996, 0.4630000000000001, 0.655, 0.895, 0.9359999999999999, 0.8610000000000002, 0.125, 0.45999999999999996, 0.3620000000000001, 0.18799999999999994, 0.379, 1.4020000000000001, 0.44499999999999995, 1.955, 0.959, 0.44899999999999984, 0.46099999999999985, 0.46699999999999997, 0.9529999999999998, 0.942, -0.039999999999999925, 0.10599999999999987, 0.9430000000000001, 0.917, 0.8679999999999999, 0.3340000000000001, 0.42700000000000005, 0.7730000000000001, 1.8679999999999999, 0.8130000000000002, 1.8399999999999999, 0.897, 0.869, 0.43999999999999995, 1.825, 0.28200000000000003, 1.408, 1.8639999999999999, 0.5680000000000001, 0.567, 0.8199999999999998, 0.6179999999999999, 0.9219999999999999, 0.43399999999999994, 0.963, 1.944, -0.038000000000000034, 0.44899999999999984, 0.889, 0.7829999999999999, 1.792, 0.30200000000000005, 0.85, -0.03400000000000003, 0.923, 1.895, 0.349, 1.431, 0.30000000000000004, 0.45199999999999996, 1.409, 1.857, 1.951, 0.43100000000000005, 0.7320000000000002, 0.9099999999999999, 0.9359999999999999, -0.15400000000000003, 0.6819999999999999, 1.952, 1.8239999999999998, 0.45799999999999996, 1.854, 1.883, 0.944, 0.895, 1.7650000000000001, 0.96, 0.903, 0.923, 0.41000000000000003, 0.901, 0.478, 0.8919999999999999], "episode_lengths": [44, 14, 77, 22, 61, 25, 26, 32, 27, 47, 18, 22, 37, 64, 27, 32, 14, 12, 105, 33, 19, 41, 115, 13, 42, 94, 39, 31, 16, 15, 13, 15, 13, 11, 15, 18, 13, 124, 19, 26, 41, 52, 23, 70, 41, 58, 50, 32, 40, 18, 54, 67, 29, 42, 131, 134, 55, 120, 24, 20, 12, 18, 12, 16, 35, 66, 64, 59, 46, 11, 24, 34, 44, 22, 62, 15, 28, 44, 15, 22, 82, 300, 19, 48, 96, 15, 53, 13, 44, 35, 18, 33, 74, 13, 30, 24, 27, 30, 7, 34], "policy_red_0_reward": [1.363, 0.958, 1.2650000000000001, 1.431, 0.49, -0.506, 0.498, 1.4, 1.419, 0.852, 1.4449999999999998, 0.497, 1.387, 0.49, 1.417, 0.499, 1.458, 0.963, 1.1760000000000002, -0.503, 1.439, 1.373, -0.516, 1.4609999999999999, 1.37, -0.519, 0.88, 1.404, -0.504, 1.455, -0.5, 0.949, 1.4609999999999999, 0.967, 1.454, 1.4449999999999998, -1.001, 0.617, 1.443, 1.421, 1.373, 1.342, -0.502, 1.279, 0.496, 1.3170000000000002, 1.3479999999999999, -0.502, 1.375, 1.444, 1.33, 1.2919999999999998, 0.0, 1.3719999999999999, 1.0939999999999999, 1.08, 1.3279999999999998, -0.514, -0.502, 1.439, -0.501, 1.4449999999999998, 0.963, 0.951, 1.391, 1.288, 0.488, 1.315, -0.503, 0.967, 1.427, 0.498, 0.861, 1.432, 1.3050000000000002, -0.5, 1.415, 1.3639999999999999, 0.497, 1.4329999999999998, 1.241, 0.45399999999999996, 1.4409999999999998, 0.852, 1.2, 1.4529999999999998, 1.3319999999999999, -0.5, 1.361, 0.497, 1.4449999999999998, 1.399, 0.494, 1.46, 1.4060000000000001, 1.426, -0.501, 1.404, 1.478, 1.397], "policy_blue_0_reward": [-0.502, -1.002, -0.506, -0.503, 1.31, 0.918, 1.42, -1.003, 0.499, -1.008, -0.501, 1.432, 0.49, 1.3010000000000002, 0.494, 1.4, -1.002, -0.5, -0.521, 1.3980000000000001, -0.503, -0.5119999999999999, 0.641, -1.001, -1.008, 0.707, -0.501, -0.002, 0.949, 0.5, 1.459, -0.5, -1.0, -0.5, -0.501, -0.503, 0.961, -0.511, -0.5, -0.504, -0.505, -1.008, 0.929, -0.506, 1.3719999999999999, -0.504, 0.492, 1.399, -0.506, -1.004, 0.495, -1.01, 1.408, 0.492, -0.526, -0.513, -0.508, 1.132, 1.424, -1.005, 1.464, 0.499, -1.001, -0.502, -0.502, -0.505, 1.304, -1.013, 1.353, -1.001, -0.504, 1.397, -0.512, -0.001, -1.005, 0.952, -0.006, 0.493, 1.454, -1.002, -0.5089999999999999, 0.45599999999999996, -0.505, -1.006, -0.518, 0.499, 0.492, 0.958, 0.493, 1.3860000000000001, -0.5009999999999999, -0.504, 1.271, -0.5, -0.503, -0.503, 0.911, -0.503, -1.0, -0.505]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3824596771528115, "mean_inference_ms": 7.411886814711406, "mean_action_processing_ms": 0.39176264356948143, "mean_env_wait_ms": 0.5161174940576898, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1748589277267456, "StateBufferConnector_ms": 0.00946652889251709, "ViewRequirementAgentConnector_ms": 0.18881523609161377}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 552000, "num_agent_steps_trained": 552000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 125.60580512505365, "num_env_steps_trained_throughput_per_sec": 125.60580512505365, "timesteps_total": 276000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 552000, "timers": {"training_iteration_time_ms": 31496.255, "sample_time_ms": 3999.494, "learn_time_ms": 27468.071, "learn_throughput": 145.624, "synch_weights_time_ms": 27.148}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 552000, "num_agent_steps_trained": 552000}, "done": false, "episodes_total": 3310, "training_iteration": 69, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-33-23", "timestamp": 1694838803, "time_this_iter_s": 31.863120317459106, "time_total_s": 2141.207318544388, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80edb250>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2141.207318544388, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 25.84130434782609, "ram_util_percent": 57.00434782608697}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.13, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.66, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.66, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.66, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6132211518473923, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05295441674340206, "policy_loss": -0.10052060473414409, "vf_loss": 0.02698467449420908, "vf_explained_var": 0.6441182404135665, "kl": 0.015604460699492772, "entropy": 1.4750612460076808, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 66720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.617222975101322, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06351180042644652, "policy_loss": -0.10930829152299945, "vf_loss": 0.03567656895611435, "vf_explained_var": 0.625162793447574, "kl": 0.012988347580431537, "entropy": 1.6308725573122502, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 66720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "sampler_results": {"episode_reward_max": 1.948, "episode_reward_min": -0.11599999999999999, "episode_reward_mean": 0.86675, "episode_len_mean": 45.08, "episode_media": {}, "episodes_this_iter": 92, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.478, "blue_0": 1.451}, "policy_reward_mean": {"red_0": 1.0183499999999999, "blue_0": -0.15159999999999996}, "custom_metrics": {"red_0/door_open_done_mean": 0.13, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.66, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.66, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.66, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.7650000000000001, 0.96, 0.903, 0.923, 0.41000000000000003, 0.901, 0.478, 0.8919999999999999, 0.907, 0.7290000000000001, 0.9470000000000001, 0.5979999999999999, 1.939, 0.2909999999999999, 0.956, 0.9019999999999999, 0.42300000000000004, 0.8500000000000001, 0.43799999999999994, 1.7530000000000001, 0.44199999999999995, 0.847, 1.803, 1.93, 1.4180000000000001, 0.26900000000000013, 0.389, 1.87, 0.9180000000000001, 0.4630000000000001, -0.04800000000000004, -0.11599999999999999, 1.9249999999999998, 0.43900000000000006, 1.3399999999999999, 0.81, 0.9119999999999999, 1.903, 0.9390000000000001, 0.9100000000000001, 0.698, 0.43999999999999995, 0.6709999999999998, 0.9239999999999999, 0.8300000000000001, 0.383, 0.5419999999999999, 0.8879999999999999, 1.841, -0.07799999999999985, 0.916, 0.44599999999999995, 1.932, 0.44999999999999996, 0.4630000000000001, -0.03200000000000003, 1.9369999999999998, 0.8780000000000001, 1.869, 1.948, 0.931, 0.43599999999999994, 0.45299999999999985, 0.46099999999999985, 1.076, 0.43399999999999994, 0.32299999999999995, -0.052999999999999936, 0.41000000000000003, 1.83, 0.45799999999999996, 0.9689999999999999, 1.9050000000000002, 0.855, 0.4079999999999999, 1.216, 0.889, 0.4039999999999999, 0.8959999999999999, 0.768, 0.9289999999999998, 1.893, 0.30699999999999994, 1.859, 0.391, 1.8319999999999999, 0.17599999999999993, -0.06000000000000005, 0.9299999999999999, 0.8730000000000002, 1.8679999999999999, 0.44399999999999995, 0.69, 1.88, 0.6719999999999999, 0.923, -0.07300000000000006, 0.43100000000000005, 0.44300000000000006, -0.07599999999999996], "episode_lengths": [74, 13, 30, 24, 27, 30, 7, 34, 29, 83, 17, 123, 18, 66, 14, 300, 25, 47, 20, 75, 17, 48, 61, 21, 25, 71, 33, 39, 26, 12, 16, 36, 24, 20, 49, 59, 26, 30, 20, 28, 93, 19, 102, 300, 53, 35, 141, 34, 49, 25, 27, 18, 21, 15, 12, 10, 20, 39, 39, 16, 21, 20, 14, 12, 285, 21, 56, 16, 27, 52, 13, 10, 29, 45, 28, 88, 35, 29, 34, 70, 22, 33, 58, 43, 31, 53, 100, 19, 21, 39, 41, 17, 95, 38, 100, 24, 22, 22, 17, 23], "policy_red_0_reward": [0.494, 1.46, 1.4060000000000001, 1.426, -0.501, 1.404, 1.478, 1.397, 1.413, 1.24, 1.448, 1.116, 1.444, 1.294, 1.4569999999999999, 0.45099999999999996, -0.501, 1.355, -0.502, 1.263, 0.946, 1.35, 0.495, 0.499, 1.423, 1.279, 1.397, 0.492, 1.421, 0.963, 0.952, 0.888, 0.499, 0.94, 1.346, 1.321, 1.417, 1.4060000000000001, 1.44, 1.413, 1.2069999999999999, 1.443, 1.1829999999999998, 0.45999999999999996, 1.335, 0.89, -0.516, 1.393, 1.346, -1.001, -0.501, 1.446, 0.497, 1.4529999999999998, 0.964, 0.969, 0.5, 1.38, 1.375, 0.497, 1.434, 0.9369999999999999, 0.956, 0.963, 0.609, 1.436, 1.327, -1.004, -0.506, 1.335, 1.46, 1.4689999999999999, 1.411, 1.359, 1.412, 1.224, 1.392, 0.907, 1.397, 1.276, 1.432, 0.497, 1.322, 0.492, 1.401, 1.337, 1.188, 0.943, 1.436, 1.3780000000000001, 1.373, 0.948, 1.199, 0.496, 1.1869999999999998, 1.4249999999999998, 0.9319999999999999, 1.432, 1.446, 0.928], "policy_blue_0_reward": [1.271, -0.5, -0.503, -0.503, 0.911, -0.503, -1.0, -0.505, -0.5059999999999999, -0.511, -0.501, -0.518, 0.495, -1.003, -0.501, 0.45099999999999996, 0.924, -0.5049999999999999, 0.94, 0.49, -0.504, -0.503, 1.3079999999999998, 1.431, -0.005, -1.01, -1.008, 1.3780000000000001, -0.5029999999999999, -0.5, -1.0, -1.004, 1.426, -0.501, -0.006, -0.511, -0.505, 0.497, -0.501, -0.503, -0.509, -1.003, -0.512, 0.46399999999999997, -0.505, -0.507, 1.0579999999999998, -0.505, 0.495, 0.923, 1.417, -1.0, 1.435, -1.003, -0.501, -1.001, 1.4369999999999998, -0.502, 0.494, 1.451, -0.503, -0.501, -0.503, -0.502, 0.46699999999999997, -1.002, -1.004, 0.951, 0.916, 0.495, -1.002, -0.5, 0.494, -0.504, -1.004, -0.008, -0.503, -0.503, -0.501, -0.508, -0.503, 1.396, -1.015, 1.367, -1.01, 0.495, -1.012, -1.003, -0.506, -0.5049999999999999, 0.495, -0.504, -0.509, 1.384, -0.515, -0.502, -1.005, -1.001, -1.003, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.384882529405731, "mean_inference_ms": 7.414244583395291, "mean_action_processing_ms": 0.39013942973494214, "mean_env_wait_ms": 0.5163396217583194, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1553102731704712, "StateBufferConnector_ms": 0.010014653205871582, "ViewRequirementAgentConnector_ms": 0.2011432647705078}}, "episode_reward_max": 1.948, "episode_reward_min": -0.11599999999999999, "episode_reward_mean": 0.86675, "episode_len_mean": 45.08, "episodes_this_iter": 92, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.478, "blue_0": 1.451}, "policy_reward_mean": {"red_0": 1.0183499999999999, "blue_0": -0.15159999999999996}, "hist_stats": {"episode_reward": [1.7650000000000001, 0.96, 0.903, 0.923, 0.41000000000000003, 0.901, 0.478, 0.8919999999999999, 0.907, 0.7290000000000001, 0.9470000000000001, 0.5979999999999999, 1.939, 0.2909999999999999, 0.956, 0.9019999999999999, 0.42300000000000004, 0.8500000000000001, 0.43799999999999994, 1.7530000000000001, 0.44199999999999995, 0.847, 1.803, 1.93, 1.4180000000000001, 0.26900000000000013, 0.389, 1.87, 0.9180000000000001, 0.4630000000000001, -0.04800000000000004, -0.11599999999999999, 1.9249999999999998, 0.43900000000000006, 1.3399999999999999, 0.81, 0.9119999999999999, 1.903, 0.9390000000000001, 0.9100000000000001, 0.698, 0.43999999999999995, 0.6709999999999998, 0.9239999999999999, 0.8300000000000001, 0.383, 0.5419999999999999, 0.8879999999999999, 1.841, -0.07799999999999985, 0.916, 0.44599999999999995, 1.932, 0.44999999999999996, 0.4630000000000001, -0.03200000000000003, 1.9369999999999998, 0.8780000000000001, 1.869, 1.948, 0.931, 0.43599999999999994, 0.45299999999999985, 0.46099999999999985, 1.076, 0.43399999999999994, 0.32299999999999995, -0.052999999999999936, 0.41000000000000003, 1.83, 0.45799999999999996, 0.9689999999999999, 1.9050000000000002, 0.855, 0.4079999999999999, 1.216, 0.889, 0.4039999999999999, 0.8959999999999999, 0.768, 0.9289999999999998, 1.893, 0.30699999999999994, 1.859, 0.391, 1.8319999999999999, 0.17599999999999993, -0.06000000000000005, 0.9299999999999999, 0.8730000000000002, 1.8679999999999999, 0.44399999999999995, 0.69, 1.88, 0.6719999999999999, 0.923, -0.07300000000000006, 0.43100000000000005, 0.44300000000000006, -0.07599999999999996], "episode_lengths": [74, 13, 30, 24, 27, 30, 7, 34, 29, 83, 17, 123, 18, 66, 14, 300, 25, 47, 20, 75, 17, 48, 61, 21, 25, 71, 33, 39, 26, 12, 16, 36, 24, 20, 49, 59, 26, 30, 20, 28, 93, 19, 102, 300, 53, 35, 141, 34, 49, 25, 27, 18, 21, 15, 12, 10, 20, 39, 39, 16, 21, 20, 14, 12, 285, 21, 56, 16, 27, 52, 13, 10, 29, 45, 28, 88, 35, 29, 34, 70, 22, 33, 58, 43, 31, 53, 100, 19, 21, 39, 41, 17, 95, 38, 100, 24, 22, 22, 17, 23], "policy_red_0_reward": [0.494, 1.46, 1.4060000000000001, 1.426, -0.501, 1.404, 1.478, 1.397, 1.413, 1.24, 1.448, 1.116, 1.444, 1.294, 1.4569999999999999, 0.45099999999999996, -0.501, 1.355, -0.502, 1.263, 0.946, 1.35, 0.495, 0.499, 1.423, 1.279, 1.397, 0.492, 1.421, 0.963, 0.952, 0.888, 0.499, 0.94, 1.346, 1.321, 1.417, 1.4060000000000001, 1.44, 1.413, 1.2069999999999999, 1.443, 1.1829999999999998, 0.45999999999999996, 1.335, 0.89, -0.516, 1.393, 1.346, -1.001, -0.501, 1.446, 0.497, 1.4529999999999998, 0.964, 0.969, 0.5, 1.38, 1.375, 0.497, 1.434, 0.9369999999999999, 0.956, 0.963, 0.609, 1.436, 1.327, -1.004, -0.506, 1.335, 1.46, 1.4689999999999999, 1.411, 1.359, 1.412, 1.224, 1.392, 0.907, 1.397, 1.276, 1.432, 0.497, 1.322, 0.492, 1.401, 1.337, 1.188, 0.943, 1.436, 1.3780000000000001, 1.373, 0.948, 1.199, 0.496, 1.1869999999999998, 1.4249999999999998, 0.9319999999999999, 1.432, 1.446, 0.928], "policy_blue_0_reward": [1.271, -0.5, -0.503, -0.503, 0.911, -0.503, -1.0, -0.505, -0.5059999999999999, -0.511, -0.501, -0.518, 0.495, -1.003, -0.501, 0.45099999999999996, 0.924, -0.5049999999999999, 0.94, 0.49, -0.504, -0.503, 1.3079999999999998, 1.431, -0.005, -1.01, -1.008, 1.3780000000000001, -0.5029999999999999, -0.5, -1.0, -1.004, 1.426, -0.501, -0.006, -0.511, -0.505, 0.497, -0.501, -0.503, -0.509, -1.003, -0.512, 0.46399999999999997, -0.505, -0.507, 1.0579999999999998, -0.505, 0.495, 0.923, 1.417, -1.0, 1.435, -1.003, -0.501, -1.001, 1.4369999999999998, -0.502, 0.494, 1.451, -0.503, -0.501, -0.503, -0.502, 0.46699999999999997, -1.002, -1.004, 0.951, 0.916, 0.495, -1.002, -0.5, 0.494, -0.504, -1.004, -0.008, -0.503, -0.503, -0.501, -0.508, -0.503, 1.396, -1.015, 1.367, -1.01, 0.495, -1.012, -1.003, -0.506, -0.5049999999999999, 0.495, -0.504, -0.509, 1.384, -0.515, -0.502, -1.005, -1.001, -1.003, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.384882529405731, "mean_inference_ms": 7.414244583395291, "mean_action_processing_ms": 0.39013942973494214, "mean_env_wait_ms": 0.5163396217583194, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1553102731704712, "StateBufferConnector_ms": 0.010014653205871582, "ViewRequirementAgentConnector_ms": 0.2011432647705078}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 123.19342983099197, "num_env_steps_trained_throughput_per_sec": 123.19342983099197, "timesteps_total": 280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 31656.407, "sample_time_ms": 4009.929, "learn_time_ms": 27617.8, "learn_throughput": 144.834, "synch_weights_time_ms": 27.131}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "episodes_total": 3402, "training_iteration": 70, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-33-56", "timestamp": 1694838836, "time_this_iter_s": 32.4863121509552, "time_total_s": 2173.693630695343, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f75b0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2173.693630695343, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 26.272916666666664, "ram_util_percent": 56.90416666666666}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.18, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.56, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.56, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.56, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6318925803527236, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.060806768088271686, "policy_loss": -0.10512523778937369, "vf_loss": 0.027379299149712703, "vf_explained_var": 0.6047186623016994, "kl": 0.014100420667613257, "entropy": 1.4937008370955784, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 67680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.61147617927442, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06590880649164318, "policy_loss": -0.11035544637221999, "vf_loss": 0.035006860438443255, "vf_explained_var": 0.5769877598931392, "kl": 0.0125481288960776, "entropy": 1.6429972605158885, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 67680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 568000, "num_agent_steps_trained": 568000}, "sampler_results": {"episode_reward_max": 1.942, "episode_reward_min": -0.1329999999999999, "episode_reward_mean": 0.8799400000000002, "episode_len_mean": 48.77, "episode_media": {}, "episodes_this_iter": 76, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.452, "blue_0": 1.467}, "policy_reward_mean": {"red_0": 0.9229299999999999, "blue_0": -0.04298999999999998}, "custom_metrics": {"red_0/door_open_done_mean": 0.18, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.56, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.56, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.56, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.889, 0.4039999999999999, 0.8959999999999999, 0.768, 0.9289999999999998, 1.893, 0.30699999999999994, 1.859, 0.391, 1.8319999999999999, 0.17599999999999993, -0.06000000000000005, 0.9299999999999999, 0.8730000000000002, 1.8679999999999999, 0.44399999999999995, 0.69, 1.88, 0.6719999999999999, 0.923, -0.07300000000000006, 0.43100000000000005, 0.44300000000000006, -0.07599999999999996, 0.6779999999999999, 0.8010000000000002, 1.424, 1.9369999999999998, 1.919, -0.031000000000000028, 0.363, 0.387, 0.3799999999999999, 0.951, 0.369, 1.8559999999999999, 0.8599999999999999, 0.8580000000000001, 0.42499999999999993, 1.932, 0.9299999999999999, 0.46699999999999997, 1.7389999999999999, 0.839, 1.0949999999999998, 0.9489999999999998, 1.276, 0.43799999999999994, -0.08099999999999996, -0.029000000000000026, 1.905, 0.885, 1.766, 0.9260000000000002, -0.05800000000000005, 1.899, 0.33499999999999996, 0.9259999999999999, 1.924, 1.745, 1.4060000000000001, 1.174, -0.11999999999999988, 0.43299999999999983, 0.2360000000000002, 0.389, 1.931, 1.429, 0.3900000000000001, 0.40700000000000003, 1.4489999999999998, 1.927, 0.8009999999999999, 0.44899999999999984, 0.7469999999999999, 1.942, 0.798, 1.401, -0.06900000000000005, 1.342, -0.02400000000000002, 0.95, 1.8980000000000001, 0.44799999999999995, 0.7629999999999999, 0.8049999999999999, 0.33099999999999996, 0.9489999999999998, 0.3599999999999999, 0.45299999999999996, 0.051999999999999935, 1.938, 0.72, 0.4039999999999999, 1.893, 0.892, 0.9300000000000002, 1.733, -0.10399999999999987, -0.1329999999999999], "episode_lengths": [35, 29, 34, 70, 22, 33, 58, 43, 31, 53, 100, 19, 21, 39, 41, 17, 95, 38, 100, 24, 22, 22, 17, 23, 251, 60, 24, 20, 25, 10, 42, 34, 38, 15, 40, 45, 44, 44, 22, 22, 21, 11, 80, 51, 276, 16, 68, 19, 25, 9, 30, 33, 71, 23, 19, 31, 51, 300, 24, 80, 29, 102, 36, 21, 83, 34, 22, 23, 35, 29, 16, 24, 61, 16, 78, 19, 62, 31, 300, 49, 8, 16, 32, 17, 74, 60, 52, 17, 42, 15, 133, 20, 85, 30, 33, 34, 23, 84, 33, 39], "policy_red_0_reward": [1.392, 0.907, 1.397, 1.276, 1.432, 0.497, 1.322, 0.492, 1.401, 1.337, 1.188, 0.943, 1.436, 1.3780000000000001, 1.373, 0.948, 1.199, 0.496, 1.1869999999999998, 1.4249999999999998, 0.9319999999999999, 1.432, 1.446, 0.928, 0.704, 1.3159999999999998, 1.426, 0.499, 0.497, 0.969, 1.37, -0.505, 0.883, -0.503, 1.373, 1.359, 1.363, 1.365, -1.005, 0.499, -0.504, -1.0, 1.249, 1.342, 0.6349999999999999, 1.451, 1.2850000000000001, 1.4409999999999998, 0.924, 0.972, 0.498, 1.395, 0.487, 1.429, 0.942, 1.403, 1.339, 0.46199999999999997, 1.426, 0.493, 1.411, 1.182, 0.883, 1.436, 1.244, 0.893, 0.499, 1.429, 1.391, 1.411, 1.452, 1.428, 1.309, 1.452, 1.259, 1.442, 1.307, -0.003, -0.02100000000000001, -0.006, -1.0, 1.452, 1.4020000000000001, 0.949, 1.274, 1.314, 1.3399999999999999, 1.4489999999999998, 1.371, -1.001, -0.517, 0.5, 1.224, 1.409, 1.396, -0.504, 1.431, 0.49, -1.002, 0.875], "policy_blue_0_reward": [-0.503, -0.503, -0.501, -0.508, -0.503, 1.396, -1.015, 1.367, -1.01, 0.495, -1.012, -1.003, -0.506, -0.5049999999999999, 0.495, -0.504, -0.509, 1.384, -0.515, -0.502, -1.005, -1.001, -1.003, -1.004, -0.026000000000000016, -0.5149999999999999, -0.002, 1.438, 1.4220000000000002, -1.0, -1.007, 0.892, -0.503, 1.454, -1.004, 0.497, -0.503, -0.507, 1.43, 1.4329999999999998, 1.434, 1.467, 0.49, -0.503, 0.45999999999999996, -0.502, -0.009000000000000001, -1.003, -1.005, -1.001, 1.407, -0.51, 1.279, -0.503, -1.0, 0.496, -1.004, 0.46399999999999997, 0.498, 1.252, -0.005, -0.008, -1.003, -1.003, -1.0079999999999998, -0.504, 1.432, 0.0, -1.001, -1.004, -0.003, 0.499, -0.508, -1.003, -0.512, 0.5, -0.509, 1.404, -0.048000000000000036, 1.3479999999999999, 0.976, -0.502, 0.496, -0.501, -0.511, -0.509, -1.009, -0.5, -1.011, 1.454, 0.569, 1.438, -0.504, -1.005, 0.497, 1.396, -0.501, 1.2429999999999999, 0.898, -1.0079999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3865413477596553, "mean_inference_ms": 7.419768401067024, "mean_action_processing_ms": 0.3903981611495632, "mean_env_wait_ms": 0.5165288606393122, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15752816200256348, "StateBufferConnector_ms": 0.010010719299316406, "ViewRequirementAgentConnector_ms": 0.20824599266052246}}, "episode_reward_max": 1.942, "episode_reward_min": -0.1329999999999999, "episode_reward_mean": 0.8799400000000002, "episode_len_mean": 48.77, "episodes_this_iter": 76, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.452, "blue_0": 1.467}, "policy_reward_mean": {"red_0": 0.9229299999999999, "blue_0": -0.04298999999999998}, "hist_stats": {"episode_reward": [0.889, 0.4039999999999999, 0.8959999999999999, 0.768, 0.9289999999999998, 1.893, 0.30699999999999994, 1.859, 0.391, 1.8319999999999999, 0.17599999999999993, -0.06000000000000005, 0.9299999999999999, 0.8730000000000002, 1.8679999999999999, 0.44399999999999995, 0.69, 1.88, 0.6719999999999999, 0.923, -0.07300000000000006, 0.43100000000000005, 0.44300000000000006, -0.07599999999999996, 0.6779999999999999, 0.8010000000000002, 1.424, 1.9369999999999998, 1.919, -0.031000000000000028, 0.363, 0.387, 0.3799999999999999, 0.951, 0.369, 1.8559999999999999, 0.8599999999999999, 0.8580000000000001, 0.42499999999999993, 1.932, 0.9299999999999999, 0.46699999999999997, 1.7389999999999999, 0.839, 1.0949999999999998, 0.9489999999999998, 1.276, 0.43799999999999994, -0.08099999999999996, -0.029000000000000026, 1.905, 0.885, 1.766, 0.9260000000000002, -0.05800000000000005, 1.899, 0.33499999999999996, 0.9259999999999999, 1.924, 1.745, 1.4060000000000001, 1.174, -0.11999999999999988, 0.43299999999999983, 0.2360000000000002, 0.389, 1.931, 1.429, 0.3900000000000001, 0.40700000000000003, 1.4489999999999998, 1.927, 0.8009999999999999, 0.44899999999999984, 0.7469999999999999, 1.942, 0.798, 1.401, -0.06900000000000005, 1.342, -0.02400000000000002, 0.95, 1.8980000000000001, 0.44799999999999995, 0.7629999999999999, 0.8049999999999999, 0.33099999999999996, 0.9489999999999998, 0.3599999999999999, 0.45299999999999996, 0.051999999999999935, 1.938, 0.72, 0.4039999999999999, 1.893, 0.892, 0.9300000000000002, 1.733, -0.10399999999999987, -0.1329999999999999], "episode_lengths": [35, 29, 34, 70, 22, 33, 58, 43, 31, 53, 100, 19, 21, 39, 41, 17, 95, 38, 100, 24, 22, 22, 17, 23, 251, 60, 24, 20, 25, 10, 42, 34, 38, 15, 40, 45, 44, 44, 22, 22, 21, 11, 80, 51, 276, 16, 68, 19, 25, 9, 30, 33, 71, 23, 19, 31, 51, 300, 24, 80, 29, 102, 36, 21, 83, 34, 22, 23, 35, 29, 16, 24, 61, 16, 78, 19, 62, 31, 300, 49, 8, 16, 32, 17, 74, 60, 52, 17, 42, 15, 133, 20, 85, 30, 33, 34, 23, 84, 33, 39], "policy_red_0_reward": [1.392, 0.907, 1.397, 1.276, 1.432, 0.497, 1.322, 0.492, 1.401, 1.337, 1.188, 0.943, 1.436, 1.3780000000000001, 1.373, 0.948, 1.199, 0.496, 1.1869999999999998, 1.4249999999999998, 0.9319999999999999, 1.432, 1.446, 0.928, 0.704, 1.3159999999999998, 1.426, 0.499, 0.497, 0.969, 1.37, -0.505, 0.883, -0.503, 1.373, 1.359, 1.363, 1.365, -1.005, 0.499, -0.504, -1.0, 1.249, 1.342, 0.6349999999999999, 1.451, 1.2850000000000001, 1.4409999999999998, 0.924, 0.972, 0.498, 1.395, 0.487, 1.429, 0.942, 1.403, 1.339, 0.46199999999999997, 1.426, 0.493, 1.411, 1.182, 0.883, 1.436, 1.244, 0.893, 0.499, 1.429, 1.391, 1.411, 1.452, 1.428, 1.309, 1.452, 1.259, 1.442, 1.307, -0.003, -0.02100000000000001, -0.006, -1.0, 1.452, 1.4020000000000001, 0.949, 1.274, 1.314, 1.3399999999999999, 1.4489999999999998, 1.371, -1.001, -0.517, 0.5, 1.224, 1.409, 1.396, -0.504, 1.431, 0.49, -1.002, 0.875], "policy_blue_0_reward": [-0.503, -0.503, -0.501, -0.508, -0.503, 1.396, -1.015, 1.367, -1.01, 0.495, -1.012, -1.003, -0.506, -0.5049999999999999, 0.495, -0.504, -0.509, 1.384, -0.515, -0.502, -1.005, -1.001, -1.003, -1.004, -0.026000000000000016, -0.5149999999999999, -0.002, 1.438, 1.4220000000000002, -1.0, -1.007, 0.892, -0.503, 1.454, -1.004, 0.497, -0.503, -0.507, 1.43, 1.4329999999999998, 1.434, 1.467, 0.49, -0.503, 0.45999999999999996, -0.502, -0.009000000000000001, -1.003, -1.005, -1.001, 1.407, -0.51, 1.279, -0.503, -1.0, 0.496, -1.004, 0.46399999999999997, 0.498, 1.252, -0.005, -0.008, -1.003, -1.003, -1.0079999999999998, -0.504, 1.432, 0.0, -1.001, -1.004, -0.003, 0.499, -0.508, -1.003, -0.512, 0.5, -0.509, 1.404, -0.048000000000000036, 1.3479999999999999, 0.976, -0.502, 0.496, -0.501, -0.511, -0.509, -1.009, -0.5, -1.011, 1.454, 0.569, 1.438, -0.504, -1.005, 0.497, 1.396, -0.501, 1.2429999999999999, 0.898, -1.0079999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3865413477596553, "mean_inference_ms": 7.419768401067024, "mean_action_processing_ms": 0.3903981611495632, "mean_env_wait_ms": 0.5165288606393122, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15752816200256348, "StateBufferConnector_ms": 0.010010719299316406, "ViewRequirementAgentConnector_ms": 0.20824599266052246}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 568000, "num_agent_steps_trained": 568000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 109.47943586730624, "num_env_steps_trained_throughput_per_sec": 109.47943586730624, "timesteps_total": 284000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 568000, "timers": {"training_iteration_time_ms": 31857.72, "sample_time_ms": 4011.648, "learn_time_ms": 27817.373, "learn_throughput": 143.795, "synch_weights_time_ms": 27.147}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 568000, "num_agent_steps_trained": 568000}, "done": false, "episodes_total": 3478, "training_iteration": 71, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-34-34", "timestamp": 1694838874, "time_this_iter_s": 36.55613422393799, "time_total_s": 2210.249764919281, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7234b910>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2210.249764919281, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 34.19245283018868, "ram_util_percent": 57.02452830188679}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.2, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.51, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.51, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.51, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.656510894652456, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06423496625308568, "policy_loss": -0.10853554892006893, "vf_loss": 0.025890953811661652, "vf_explained_var": 0.6099404962733388, "kl": 0.014432458109079562, "entropy": 1.5238386997332176, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 68640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6094997111397485, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06390652489693215, "policy_loss": -0.10766709187155357, "vf_loss": 0.030869404906601023, "vf_explained_var": 0.5996587604905168, "kl": 0.013144351051948888, "entropy": 1.6186112405111392, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 68640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "sampler_results": {"episode_reward_max": 1.956, "episode_reward_min": -0.1329999999999999, "episode_reward_mean": 0.93483, "episode_len_mean": 53.72, "episode_media": {}, "episodes_this_iter": 73, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.011}, "policy_reward_max": {"red_0": 1.4569999999999999, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 0.8512899999999999, "blue_0": 0.08353999999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.2, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.51, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.51, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.51, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.44899999999999984, 0.7469999999999999, 1.942, 0.798, 1.401, -0.06900000000000005, 1.342, -0.02400000000000002, 0.95, 1.8980000000000001, 0.44799999999999995, 0.7629999999999999, 0.8049999999999999, 0.33099999999999996, 0.9489999999999998, 0.3599999999999999, 0.45299999999999996, 0.051999999999999935, 1.938, 0.72, 0.4039999999999999, 1.893, 0.892, 0.9300000000000002, 1.733, -0.10399999999999987, -0.1329999999999999, 1.809, 0.829, 1.8719999999999999, 1.8780000000000001, 0.344, 0.915, 0.44699999999999995, 0.44399999999999995, 0.7970000000000002, 0.473, 0.41900000000000004, 1.956, 0.053999999999999826, 1.924, 0.39400000000000013, 0.9299999999999999, 0.44700000000000006, 1.8319999999999999, 0.44300000000000006, 0.4139999999999999, 1.422, 0.6479999999999999, 0.5059999999999998, 0.32399999999999984, 0.746, 0.43999999999999995, 1.853, 1.354, 0.827, 1.888, 1.548, 1.4220000000000002, 0.476, 1.8900000000000001, 0.45499999999999996, 0.46199999999999997, 0.9550000000000001, 0.877, 0.9219999999999999, 0.365, 0.5899999999999999, 0.8479999999999999, 0.44099999999999984, 0.3580000000000001, 0.9359999999999999, 1.932, 1.838, -0.06600000000000006, 1.697, 0.7370000000000001, 0.41100000000000003, 0.7270000000000001, 0.45599999999999996, 0.32399999999999984, 1.835, 0.8620000000000001, 1.778, 0.44499999999999984, 0.09600000000000009, 1.939, 0.44999999999999996, 1.412, 0.911, 1.443, 1.846, 1.799, 0.383, 1.811, 1.908, 0.29899999999999993, 1.408, -0.09999999999999998, 1.8599999999999999], "episode_lengths": [16, 78, 19, 62, 31, 300, 49, 8, 16, 32, 17, 74, 60, 52, 17, 42, 15, 133, 20, 85, 30, 33, 34, 23, 84, 33, 39, 59, 53, 39, 37, 48, 27, 17, 17, 63, 9, 26, 14, 292, 25, 32, 22, 17, 52, 18, 300, 24, 112, 155, 54, 78, 19, 45, 46, 52, 35, 141, 25, 8, 35, 166, 12, 14, 37, 24, 43, 127, 48, 19, 44, 20, 22, 51, 20, 93, 80, 29, 84, 14, 56, 53, 43, 66, 18, 282, 20, 16, 27, 27, 19, 47, 63, 37, 60, 28, 62, 29, 31, 43], "policy_red_0_reward": [1.452, 1.259, 1.442, 1.307, -0.003, -0.02100000000000001, -0.006, -1.0, 1.452, 1.4020000000000001, 0.949, 1.274, 1.314, 1.3399999999999999, 1.4489999999999998, 1.371, -1.001, -0.517, 0.5, 1.224, 1.409, 1.396, -0.504, 1.431, 0.49, -1.002, 0.875, 1.3159999999999998, 1.3359999999999999, 1.38, 0.492, -1.005, 1.4180000000000001, -0.502, 0.945, 1.305, -1.0, -1.001, 1.4569999999999999, 0.5889999999999999, 1.425, 0.898, -0.502, 0.949, 0.489, 1.4449999999999998, 0.44699999999999995, 1.427, 1.153, 1.019, 1.3319999999999999, -0.514, 1.442, 0.492, -0.004, 1.338, 0.498, 0.48, 1.424, 0.976, 0.498, -0.523, 0.964, 1.4569999999999999, -0.505, 1.427, 0.869, 1.105, 1.3519999999999999, 1.443, 0.861, 1.44, 1.434, 1.342, 0.939, 0.49, 1.248, 0.912, 1.24, 0.956, 1.325, 1.3399999999999999, 1.3679999999999999, 1.2890000000000001, 1.4449999999999998, 0.621, 0.5, 1.452, -0.003, 1.4140000000000001, 1.443, 1.351, 1.3039999999999998, 1.387, 1.314, 1.4140000000000001, 1.3090000000000002, 1.411, 0.904, 1.366], "policy_blue_0_reward": [-1.003, -0.512, 0.5, -0.509, 1.404, -0.048000000000000036, 1.3479999999999999, 0.976, -0.502, 0.496, -0.501, -0.511, -0.509, -1.009, -0.5, -1.011, 1.454, 0.569, 1.438, -0.504, -1.005, 0.497, 1.396, -0.501, 1.2429999999999999, 0.898, -1.0079999999999998, 0.493, -0.507, 0.492, 1.3860000000000001, 1.349, -0.503, 0.949, -0.501, -0.5079999999999999, 1.4729999999999999, 1.42, 0.499, -0.535, 0.499, -0.504, 1.432, -0.502, 1.343, -1.002, -0.03300000000000002, -0.005, -0.505, -0.513, -1.008, 1.26, -1.002, 1.361, 1.358, -0.511, 1.3900000000000001, 1.068, -0.002, -0.5, 1.392, 0.978, -0.502, -0.502, 1.3820000000000001, -0.505, -0.504, -0.515, -0.504, -1.002, -0.503, -0.5039999999999999, 0.498, 0.496, -1.005, 1.2069999999999999, -0.511, -0.501, -0.5129999999999999, -0.5, -1.001, 0.495, -0.506, 0.489, -1.0, -0.525, 1.439, -1.002, 1.415, -0.503, 0.0, 0.495, 0.495, -1.004, 0.497, 0.494, -1.01, -0.003, -1.004, 0.494]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3897437952036973, "mean_inference_ms": 7.43169248109624, "mean_action_processing_ms": 0.38939914334135084, "mean_env_wait_ms": 0.5172756322386405, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15780889987945557, "StateBufferConnector_ms": 0.010367989540100098, "ViewRequirementAgentConnector_ms": 0.20975887775421143}}, "episode_reward_max": 1.956, "episode_reward_min": -0.1329999999999999, "episode_reward_mean": 0.93483, "episode_len_mean": 53.72, "episodes_this_iter": 73, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.011}, "policy_reward_max": {"red_0": 1.4569999999999999, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 0.8512899999999999, "blue_0": 0.08353999999999999}, "hist_stats": {"episode_reward": [0.44899999999999984, 0.7469999999999999, 1.942, 0.798, 1.401, -0.06900000000000005, 1.342, -0.02400000000000002, 0.95, 1.8980000000000001, 0.44799999999999995, 0.7629999999999999, 0.8049999999999999, 0.33099999999999996, 0.9489999999999998, 0.3599999999999999, 0.45299999999999996, 0.051999999999999935, 1.938, 0.72, 0.4039999999999999, 1.893, 0.892, 0.9300000000000002, 1.733, -0.10399999999999987, -0.1329999999999999, 1.809, 0.829, 1.8719999999999999, 1.8780000000000001, 0.344, 0.915, 0.44699999999999995, 0.44399999999999995, 0.7970000000000002, 0.473, 0.41900000000000004, 1.956, 0.053999999999999826, 1.924, 0.39400000000000013, 0.9299999999999999, 0.44700000000000006, 1.8319999999999999, 0.44300000000000006, 0.4139999999999999, 1.422, 0.6479999999999999, 0.5059999999999998, 0.32399999999999984, 0.746, 0.43999999999999995, 1.853, 1.354, 0.827, 1.888, 1.548, 1.4220000000000002, 0.476, 1.8900000000000001, 0.45499999999999996, 0.46199999999999997, 0.9550000000000001, 0.877, 0.9219999999999999, 0.365, 0.5899999999999999, 0.8479999999999999, 0.44099999999999984, 0.3580000000000001, 0.9359999999999999, 1.932, 1.838, -0.06600000000000006, 1.697, 0.7370000000000001, 0.41100000000000003, 0.7270000000000001, 0.45599999999999996, 0.32399999999999984, 1.835, 0.8620000000000001, 1.778, 0.44499999999999984, 0.09600000000000009, 1.939, 0.44999999999999996, 1.412, 0.911, 1.443, 1.846, 1.799, 0.383, 1.811, 1.908, 0.29899999999999993, 1.408, -0.09999999999999998, 1.8599999999999999], "episode_lengths": [16, 78, 19, 62, 31, 300, 49, 8, 16, 32, 17, 74, 60, 52, 17, 42, 15, 133, 20, 85, 30, 33, 34, 23, 84, 33, 39, 59, 53, 39, 37, 48, 27, 17, 17, 63, 9, 26, 14, 292, 25, 32, 22, 17, 52, 18, 300, 24, 112, 155, 54, 78, 19, 45, 46, 52, 35, 141, 25, 8, 35, 166, 12, 14, 37, 24, 43, 127, 48, 19, 44, 20, 22, 51, 20, 93, 80, 29, 84, 14, 56, 53, 43, 66, 18, 282, 20, 16, 27, 27, 19, 47, 63, 37, 60, 28, 62, 29, 31, 43], "policy_red_0_reward": [1.452, 1.259, 1.442, 1.307, -0.003, -0.02100000000000001, -0.006, -1.0, 1.452, 1.4020000000000001, 0.949, 1.274, 1.314, 1.3399999999999999, 1.4489999999999998, 1.371, -1.001, -0.517, 0.5, 1.224, 1.409, 1.396, -0.504, 1.431, 0.49, -1.002, 0.875, 1.3159999999999998, 1.3359999999999999, 1.38, 0.492, -1.005, 1.4180000000000001, -0.502, 0.945, 1.305, -1.0, -1.001, 1.4569999999999999, 0.5889999999999999, 1.425, 0.898, -0.502, 0.949, 0.489, 1.4449999999999998, 0.44699999999999995, 1.427, 1.153, 1.019, 1.3319999999999999, -0.514, 1.442, 0.492, -0.004, 1.338, 0.498, 0.48, 1.424, 0.976, 0.498, -0.523, 0.964, 1.4569999999999999, -0.505, 1.427, 0.869, 1.105, 1.3519999999999999, 1.443, 0.861, 1.44, 1.434, 1.342, 0.939, 0.49, 1.248, 0.912, 1.24, 0.956, 1.325, 1.3399999999999999, 1.3679999999999999, 1.2890000000000001, 1.4449999999999998, 0.621, 0.5, 1.452, -0.003, 1.4140000000000001, 1.443, 1.351, 1.3039999999999998, 1.387, 1.314, 1.4140000000000001, 1.3090000000000002, 1.411, 0.904, 1.366], "policy_blue_0_reward": [-1.003, -0.512, 0.5, -0.509, 1.404, -0.048000000000000036, 1.3479999999999999, 0.976, -0.502, 0.496, -0.501, -0.511, -0.509, -1.009, -0.5, -1.011, 1.454, 0.569, 1.438, -0.504, -1.005, 0.497, 1.396, -0.501, 1.2429999999999999, 0.898, -1.0079999999999998, 0.493, -0.507, 0.492, 1.3860000000000001, 1.349, -0.503, 0.949, -0.501, -0.5079999999999999, 1.4729999999999999, 1.42, 0.499, -0.535, 0.499, -0.504, 1.432, -0.502, 1.343, -1.002, -0.03300000000000002, -0.005, -0.505, -0.513, -1.008, 1.26, -1.002, 1.361, 1.358, -0.511, 1.3900000000000001, 1.068, -0.002, -0.5, 1.392, 0.978, -0.502, -0.502, 1.3820000000000001, -0.505, -0.504, -0.515, -0.504, -1.002, -0.503, -0.5039999999999999, 0.498, 0.496, -1.005, 1.2069999999999999, -0.511, -0.501, -0.5129999999999999, -0.5, -1.001, 0.495, -0.506, 0.489, -1.0, -0.525, 1.439, -1.002, 1.415, -0.503, 0.0, 0.495, 0.495, -1.004, 0.497, 0.494, -1.01, -0.003, -1.004, 0.494]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3897437952036973, "mean_inference_ms": 7.43169248109624, "mean_action_processing_ms": 0.38939914334135084, "mean_env_wait_ms": 0.5172756322386405, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15780889987945557, "StateBufferConnector_ms": 0.010367989540100098, "ViewRequirementAgentConnector_ms": 0.20975887775421143}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 124.82686048387006, "num_env_steps_trained_throughput_per_sec": 124.82686048387006, "timesteps_total": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 31905.007, "sample_time_ms": 4043.975, "learn_time_ms": 27831.999, "learn_throughput": 143.719, "synch_weights_time_ms": 27.45}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "episodes_total": 3551, "training_iteration": 72, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-35-07", "timestamp": 1694838907, "time_this_iter_s": 32.06020402908325, "time_total_s": 2242.3099689483643, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f7130>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2242.3099689483643, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 25.639130434782604, "ram_util_percent": 57.04565217391304}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.1743119266055046, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.4954128440366973, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1834862385321101, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.4954128440366973, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14678899082568808, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1834862385321101, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.4954128440366973, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1834862385321101, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6096291212365031, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05526615881923742, "policy_loss": -0.10525445304107658, "vf_loss": 0.03940067554164368, "vf_explained_var": 0.6256051703045765, "kl": 0.013917847492227036, "entropy": 1.4186409493287404, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 69600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6091520978758732, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05971198972353401, "policy_loss": -0.11160204269011349, "vf_loss": 0.04630209229459676, "vf_explained_var": 0.6247960903992256, "kl": 0.013307640221863681, "entropy": 1.577461995060245, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 69600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 584000, "num_agent_steps_trained": 584000}, "sampler_results": {"episode_reward_max": 1.959, "episode_reward_min": -0.18900000000000006, "episode_reward_mean": 0.9830825688073395, "episode_len_mean": 36.55045871559633, "episode_media": {}, "episodes_this_iter": 109, "policy_reward_min": {"red_0": -1.01, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 0.8095045871559633, "blue_0": 0.17357798165137617}, "custom_metrics": {"red_0/door_open_done_mean": 0.1743119266055046, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.4954128440366973, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1834862385321101, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.4954128440366973, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14678899082568808, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1834862385321101, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.4954128440366973, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1834862385321101, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9670000000000001, -0.1369999999999999, 0.3880000000000001, 1.9409999999999998, 1.851, 0.9609999999999999, 1.923, 1.879, 1.8559999999999999, 0.966, 0.44300000000000006, 0.4159999999999999, 0.806, 0.33599999999999985, 0.43599999999999994, -0.030000000000000027, 0.9329999999999998, 0.44799999999999995, 1.413, 1.851, 0.41100000000000003, 0.406, 0.841, 1.884, -0.07299999999999995, 1.847, 1.4180000000000001, 1.899, 0.8999999999999999, 1.83, 0.21099999999999997, -0.18900000000000006, 0.42799999999999994, 0.9140000000000001, 0.384, 1.843, 0.34799999999999986, 0.8460000000000001, 1.8519999999999999, 1.955, 0.46199999999999997, 0.958, 0.915, 0.43799999999999994, 1.788, 0.7090000000000001, 0.9449999999999998, 0.963, 1.851, 0.479, 0.387, 0.475, 0.8439999999999999, 0.43299999999999994, 0.976, 0.4, 0.9470000000000001, 0.395, 1.934, 0.45300000000000007, 1.944, 1.424, 1.224, 0.8279999999999998, 0.4750000000000001, 0.8599999999999999, -0.020000000000000018, 1.946, 1.893, 0.9319999999999999, -0.16399999999999992, 1.959, 0.95, 0.4630000000000001, 0.815, 0.9590000000000001, 0.9529999999999998, 1.545, 0.931, 0.8029999999999999, 1.8679999999999999, 1.924, 0.8940000000000001, 0.385, 0.4249999999999998, 0.7570000000000001, 0.9170000000000003, 1.912, 0.9180000000000001, -0.04299999999999993, 0.41999999999999993, 1.928, 0.905, 0.406, 1.833, 1.7109999999999999, 0.385, 0.859, 1.952, 0.383, 1.9409999999999998, 1.9449999999999998, 0.45599999999999996, 0.966, 0.4870000000000001, 0.382, 0.3759999999999999, 1.875, 0.915], "episode_lengths": [11, 42, 31, 19, 46, 13, 25, 37, 43, 11, 18, 27, 59, 202, 20, 10, 21, 16, 27, 46, 27, 29, 49, 36, 24, 49, 25, 31, 31, 52, 89, 59, 22, 27, 36, 49, 48, 49, 45, 15, 12, 14, 27, 19, 68, 91, 18, 12, 47, 7, 34, 8, 49, 20, 8, 31, 17, 33, 21, 15, 18, 24, 82, 52, 8, 43, 6, 17, 34, 21, 49, 13, 16, 12, 58, 13, 15, 136, 22, 62, 41, 24, 34, 36, 24, 77, 26, 28, 27, 12, 26, 23, 30, 30, 52, 79, 35, 44, 15, 189, 19, 18, 13, 11, 160, 37, 39, 39, 28], "policy_red_0_reward": [1.467, -1.005, -0.5099999999999999, 1.442, 0.494, 1.4609999999999999, 1.425, 1.3860000000000001, 0.49, 1.467, 0.944, 0.919, 1.315, 0.865, 0.938, 0.97, 1.435, 0.95, 1.416, 1.357, 0.918, -0.503, 1.345, 0.497, -1.0, 0.499, -0.004, 0.496, 1.404, 1.334, -0.505, 0.82, 1.431, 1.416, -1.006, 1.351, 1.351, 1.35, 0.495, 1.455, 1.463, -0.5, 1.417, -1.002, 1.2930000000000001, 1.216, 1.446, -0.5, 0.499, -1.0, 1.393, -0.501, 1.3479999999999999, -1.005, 1.476, -0.504, 1.4489999999999998, 0.898, 1.4369999999999998, 1.455, 0.499, 1.426, 1.234, 1.337, 1.476, 1.365, -1.001, 1.4489999999999998, 1.397, 1.435, -1.01, 1.4609999999999999, 1.451, 1.464, 1.3210000000000002, 1.4609999999999999, 1.454, 0.473, 1.4329999999999998, 1.31, 0.493, 1.427, 1.397, -1.001, 1.427, 1.268, 1.421, 0.497, 1.419, -1.006, 1.421, 0.499, 1.408, -0.502, 1.334, 1.221, -0.502, 1.363, 0.497, 0.9109999999999999, 0.499, 1.446, 0.958, 1.467, 1.002, -1.005, 1.381, 0.497, 1.416], "policy_blue_0_reward": [-0.5, 0.868, 0.898, 0.499, 1.357, -0.5, 0.498, 0.493, 1.366, -0.501, -0.501, -0.503, -0.509, -0.529, -0.502, -1.0, -0.502, -0.502, -0.003, 0.494, -0.5069999999999999, 0.909, -0.504, 1.387, 0.9269999999999999, 1.3479999999999999, 1.4220000000000002, 1.403, -0.504, 0.496, 0.716, -1.009, -1.003, -0.502, 1.3900000000000001, 0.492, -1.003, -0.504, 1.357, 0.5, -1.001, 1.458, -0.502, 1.44, 0.495, -0.507, -0.501, 1.463, 1.3519999999999999, 1.479, -1.0059999999999998, 0.976, -0.504, 1.438, -0.5, 0.904, -0.502, -0.503, 0.497, -1.0019999999999998, 1.4449999999999998, -0.002, -0.010000000000000002, -0.509, -1.001, -0.505, 0.981, 0.497, 0.496, -0.5029999999999999, 0.846, 0.498, -0.501, -1.001, -0.506, -0.5019999999999999, -0.501, 1.072, -0.502, -0.507, 1.375, 0.497, -0.503, 1.3860000000000001, -1.002, -0.511, -0.5039999999999999, 1.415, -0.501, 0.963, -1.001, 1.429, -0.503, 0.908, 0.499, 0.49, 0.887, -0.504, 1.455, -0.528, 1.442, 0.499, -0.502, -0.501, -0.515, 1.387, -1.005, 1.3780000000000001, -0.501]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3891698558834766, "mean_inference_ms": 7.439423394173247, "mean_action_processing_ms": 0.3910205399709459, "mean_env_wait_ms": 0.5168745690417963, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15067890149737717, "StateBufferConnector_ms": 0.009844499990480756, "ViewRequirementAgentConnector_ms": 0.19603005243003915}}, "episode_reward_max": 1.959, "episode_reward_min": -0.18900000000000006, "episode_reward_mean": 0.9830825688073395, "episode_len_mean": 36.55045871559633, "episodes_this_iter": 109, "policy_reward_min": {"red_0": -1.01, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 0.8095045871559633, "blue_0": 0.17357798165137617}, "hist_stats": {"episode_reward": [0.9670000000000001, -0.1369999999999999, 0.3880000000000001, 1.9409999999999998, 1.851, 0.9609999999999999, 1.923, 1.879, 1.8559999999999999, 0.966, 0.44300000000000006, 0.4159999999999999, 0.806, 0.33599999999999985, 0.43599999999999994, -0.030000000000000027, 0.9329999999999998, 0.44799999999999995, 1.413, 1.851, 0.41100000000000003, 0.406, 0.841, 1.884, -0.07299999999999995, 1.847, 1.4180000000000001, 1.899, 0.8999999999999999, 1.83, 0.21099999999999997, -0.18900000000000006, 0.42799999999999994, 0.9140000000000001, 0.384, 1.843, 0.34799999999999986, 0.8460000000000001, 1.8519999999999999, 1.955, 0.46199999999999997, 0.958, 0.915, 0.43799999999999994, 1.788, 0.7090000000000001, 0.9449999999999998, 0.963, 1.851, 0.479, 0.387, 0.475, 0.8439999999999999, 0.43299999999999994, 0.976, 0.4, 0.9470000000000001, 0.395, 1.934, 0.45300000000000007, 1.944, 1.424, 1.224, 0.8279999999999998, 0.4750000000000001, 0.8599999999999999, -0.020000000000000018, 1.946, 1.893, 0.9319999999999999, -0.16399999999999992, 1.959, 0.95, 0.4630000000000001, 0.815, 0.9590000000000001, 0.9529999999999998, 1.545, 0.931, 0.8029999999999999, 1.8679999999999999, 1.924, 0.8940000000000001, 0.385, 0.4249999999999998, 0.7570000000000001, 0.9170000000000003, 1.912, 0.9180000000000001, -0.04299999999999993, 0.41999999999999993, 1.928, 0.905, 0.406, 1.833, 1.7109999999999999, 0.385, 0.859, 1.952, 0.383, 1.9409999999999998, 1.9449999999999998, 0.45599999999999996, 0.966, 0.4870000000000001, 0.382, 0.3759999999999999, 1.875, 0.915], "episode_lengths": [11, 42, 31, 19, 46, 13, 25, 37, 43, 11, 18, 27, 59, 202, 20, 10, 21, 16, 27, 46, 27, 29, 49, 36, 24, 49, 25, 31, 31, 52, 89, 59, 22, 27, 36, 49, 48, 49, 45, 15, 12, 14, 27, 19, 68, 91, 18, 12, 47, 7, 34, 8, 49, 20, 8, 31, 17, 33, 21, 15, 18, 24, 82, 52, 8, 43, 6, 17, 34, 21, 49, 13, 16, 12, 58, 13, 15, 136, 22, 62, 41, 24, 34, 36, 24, 77, 26, 28, 27, 12, 26, 23, 30, 30, 52, 79, 35, 44, 15, 189, 19, 18, 13, 11, 160, 37, 39, 39, 28], "policy_red_0_reward": [1.467, -1.005, -0.5099999999999999, 1.442, 0.494, 1.4609999999999999, 1.425, 1.3860000000000001, 0.49, 1.467, 0.944, 0.919, 1.315, 0.865, 0.938, 0.97, 1.435, 0.95, 1.416, 1.357, 0.918, -0.503, 1.345, 0.497, -1.0, 0.499, -0.004, 0.496, 1.404, 1.334, -0.505, 0.82, 1.431, 1.416, -1.006, 1.351, 1.351, 1.35, 0.495, 1.455, 1.463, -0.5, 1.417, -1.002, 1.2930000000000001, 1.216, 1.446, -0.5, 0.499, -1.0, 1.393, -0.501, 1.3479999999999999, -1.005, 1.476, -0.504, 1.4489999999999998, 0.898, 1.4369999999999998, 1.455, 0.499, 1.426, 1.234, 1.337, 1.476, 1.365, -1.001, 1.4489999999999998, 1.397, 1.435, -1.01, 1.4609999999999999, 1.451, 1.464, 1.3210000000000002, 1.4609999999999999, 1.454, 0.473, 1.4329999999999998, 1.31, 0.493, 1.427, 1.397, -1.001, 1.427, 1.268, 1.421, 0.497, 1.419, -1.006, 1.421, 0.499, 1.408, -0.502, 1.334, 1.221, -0.502, 1.363, 0.497, 0.9109999999999999, 0.499, 1.446, 0.958, 1.467, 1.002, -1.005, 1.381, 0.497, 1.416], "policy_blue_0_reward": [-0.5, 0.868, 0.898, 0.499, 1.357, -0.5, 0.498, 0.493, 1.366, -0.501, -0.501, -0.503, -0.509, -0.529, -0.502, -1.0, -0.502, -0.502, -0.003, 0.494, -0.5069999999999999, 0.909, -0.504, 1.387, 0.9269999999999999, 1.3479999999999999, 1.4220000000000002, 1.403, -0.504, 0.496, 0.716, -1.009, -1.003, -0.502, 1.3900000000000001, 0.492, -1.003, -0.504, 1.357, 0.5, -1.001, 1.458, -0.502, 1.44, 0.495, -0.507, -0.501, 1.463, 1.3519999999999999, 1.479, -1.0059999999999998, 0.976, -0.504, 1.438, -0.5, 0.904, -0.502, -0.503, 0.497, -1.0019999999999998, 1.4449999999999998, -0.002, -0.010000000000000002, -0.509, -1.001, -0.505, 0.981, 0.497, 0.496, -0.5029999999999999, 0.846, 0.498, -0.501, -1.001, -0.506, -0.5019999999999999, -0.501, 1.072, -0.502, -0.507, 1.375, 0.497, -0.503, 1.3860000000000001, -1.002, -0.511, -0.5039999999999999, 1.415, -0.501, 0.963, -1.001, 1.429, -0.503, 0.908, 0.499, 0.49, 0.887, -0.504, 1.455, -0.528, 1.442, 0.499, -0.502, -0.501, -0.515, 1.387, -1.005, 1.3780000000000001, -0.501]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3891698558834766, "mean_inference_ms": 7.439423394173247, "mean_action_processing_ms": 0.3910205399709459, "mean_env_wait_ms": 0.5168745690417963, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15067890149737717, "StateBufferConnector_ms": 0.009844499990480756, "ViewRequirementAgentConnector_ms": 0.19603005243003915}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 584000, "num_agent_steps_trained": 584000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 125.1594845292015, "num_env_steps_trained_throughput_per_sec": 125.1594845292015, "timesteps_total": 292000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 584000, "timers": {"training_iteration_time_ms": 31989.734, "sample_time_ms": 4053.637, "learn_time_ms": 27906.836, "learn_throughput": 143.334, "synch_weights_time_ms": 27.65}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 584000, "num_agent_steps_trained": 584000}, "done": false, "episodes_total": 3660, "training_iteration": 73, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-35-40", "timestamp": 1694838940, "time_this_iter_s": 31.97902774810791, "time_total_s": 2274.288996696472, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7234ab90>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2274.288996696472, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 26.623404255319148, "ram_util_percent": 57.034042553191476}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.22, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.46, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.46, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.18, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.46, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6112526911621292, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.057345853567918915, "policy_loss": -0.103266003766718, "vf_loss": 0.03296271735744085, "vf_explained_var": 0.6029425831511617, "kl": 0.013556056902806783, "entropy": 1.4436011175314585, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 70560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.624312919874986, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05778187683220797, "policy_loss": -0.10808632420666982, "vf_loss": 0.04266040046544125, "vf_explained_var": 0.5663095271214843, "kl": 0.013420869063353972, "entropy": 1.6001707176367441, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 70560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "sampler_results": {"episode_reward_max": 1.951, "episode_reward_min": -0.10299999999999998, "episode_reward_mean": 1.05617, "episode_len_mean": 39.76, "episode_media": {}, "episodes_this_iter": 96, "policy_reward_min": {"red_0": -1.026, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 0.8770099999999998, "blue_0": 0.17915999999999996}, "custom_metrics": {"red_0/door_open_done_mean": 0.22, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.46, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.46, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.18, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.46, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.382, 0.3759999999999999, 1.875, 0.915, 0.9079999999999999, 1.539, 1.896, 0.938, 1.9000000000000001, 0.4079999999999999, 1.746, 1.9100000000000001, 1.8820000000000001, 0.931, 0.41700000000000004, 0.958, 0.398, 0.478, 0.43899999999999995, 0.016999999999999904, -0.027000000000000024, 0.472, 1.768, 0.46299999999999997, 1.932, 1.7349999999999999, 0.43499999999999994, 0.929, 1.924, 1.935, 0.94, 0.9039999999999999, 0.45899999999999996, 1.932, 1.696, 1.905, -0.05399999999999994, 0.879, 0.889, 0.919, 1.887, 1.9180000000000001, -0.027000000000000024, -0.03600000000000003, 1.4260000000000002, 0.42300000000000004, 0.45299999999999985, 1.922, -0.06900000000000006, 1.855, 0.9279999999999999, 0.9309999999999999, 0.2469999999999999, 0.40700000000000003, 0.31400000000000006, 0.10199999999999987, 1.867, 1.814, 1.752, 0.3800000000000001, 0.7469999999999999, 0.8700000000000001, 1.785, 1.923, 0.47, -0.050000000000000044, 0.2959999999999998, 0.942, 0.41000000000000014, 1.877, 1.853, 1.8519999999999999, 0.778, 0.9790000000000001, 0.954, 0.96, 1.9100000000000001, 1.9369999999999998, 1.94, 0.43599999999999994, 1.95, -0.10299999999999998, 0.45399999999999996, 0.887, 1.876, 1.925, 1.392, 0.41800000000000015, 0.45100000000000007, 0.44700000000000006, -0.06600000000000006, 1.936, 1.93, 0.45599999999999996, 0.867, 1.899, 0.9060000000000001, 1.951, 1.904, 0.42599999999999993], "episode_lengths": [37, 39, 39, 28, 29, 141, 31, 20, 29, 28, 79, 28, 36, 21, 26, 14, 32, 7, 19, 150, 9, 9, 72, 12, 22, 84, 20, 23, 23, 21, 19, 30, 13, 21, 93, 30, 17, 38, 35, 26, 36, 25, 9, 12, 23, 25, 14, 24, 182, 45, 22, 300, 77, 28, 56, 124, 41, 58, 76, 37, 79, 41, 67, 24, 10, 16, 63, 18, 28, 39, 45, 45, 67, 7, 15, 13, 27, 20, 19, 19, 16, 184, 15, 33, 39, 23, 33, 27, 15, 17, 21, 19, 22, 14, 42, 32, 30, 16, 30, 22], "policy_red_0_reward": [-1.005, 1.381, 0.497, 1.416, 1.4100000000000001, 0.474, 0.499, 1.44, 1.408, 0.912, 1.259, 1.412, 1.387, 1.435, 1.4220000000000002, 1.458, -0.504, -0.5, -1.003, 1.036, 0.973, -1.001, 0.493, -0.5, 1.432, 1.242, -0.503, 1.4300000000000002, 0.496, 0.499, -0.502, 1.4060000000000001, -0.502, 1.435, 1.212, 1.407, 0.949, -0.503, 1.392, 1.421, 0.498, 1.421, 0.973, -1.0, 1.429, 1.423, 0.954, 0.497, 0.44099999999999995, 0.496, 1.431, 0.471, 1.255, 0.912, 1.322, 1.119, 0.495, 0.492, 0.492, 0.885, 1.255, 1.375, 0.494, 1.428, 1.47, 0.95, 0.8029999999999999, 1.444, 0.914, 1.3820000000000001, 1.361, 1.358, 1.289, 1.479, 1.454, 1.4609999999999999, 0.497, 1.44, 1.443, 1.442, 0.499, -1.026, -0.501, 1.396, 1.3820000000000001, 1.428, 1.401, 1.4180000000000001, 1.455, 0.947, 0.9339999999999999, 0.494, 0.498, 1.458, 1.3719999999999999, 1.404, 1.407, 1.451, 0.498, 0.9309999999999999], "policy_blue_0_reward": [1.387, -1.005, 1.3780000000000001, -0.501, -0.502, 1.065, 1.397, -0.502, 0.492, -0.504, 0.487, 0.498, 0.495, -0.504, -1.005, -0.5, 0.902, 0.978, 1.442, -1.019, -1.0, 1.4729999999999999, 1.275, 0.963, 0.5, 0.493, 0.938, -0.501, 1.428, 1.436, 1.442, -0.502, 0.961, 0.497, 0.484, 0.498, -1.003, 1.3820000000000001, -0.503, -0.502, 1.389, 0.497, -1.0, 0.964, -0.003, -1.0, -0.501, 1.4249999999999998, -0.51, 1.359, -0.503, 0.45999999999999996, -1.008, -0.505, -1.008, -1.017, 1.3719999999999999, 1.322, 1.26, -0.5049999999999999, -0.508, -0.505, 1.291, 0.495, -1.0, -1.0, -0.507, -0.502, -0.504, 0.495, 0.492, 0.494, -0.511, -0.5, -0.5, -0.501, 1.413, 0.497, 0.497, -1.006, 1.451, 0.923, 0.955, -0.509, 0.494, 0.497, -0.009000000000000001, -1.0, -1.004, -0.5, -1.0, 1.442, 1.432, -1.002, -0.505, 0.495, -0.501, 0.5, 1.4060000000000001, -0.505]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3899656612287838, "mean_inference_ms": 7.443760380721101, "mean_action_processing_ms": 0.3907594809825455, "mean_env_wait_ms": 0.5176866828782836, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15490424633026123, "StateBufferConnector_ms": 0.01059412956237793, "ViewRequirementAgentConnector_ms": 0.1958068609237671}}, "episode_reward_max": 1.951, "episode_reward_min": -0.10299999999999998, "episode_reward_mean": 1.05617, "episode_len_mean": 39.76, "episodes_this_iter": 96, "policy_reward_min": {"red_0": -1.026, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 0.8770099999999998, "blue_0": 0.17915999999999996}, "hist_stats": {"episode_reward": [0.382, 0.3759999999999999, 1.875, 0.915, 0.9079999999999999, 1.539, 1.896, 0.938, 1.9000000000000001, 0.4079999999999999, 1.746, 1.9100000000000001, 1.8820000000000001, 0.931, 0.41700000000000004, 0.958, 0.398, 0.478, 0.43899999999999995, 0.016999999999999904, -0.027000000000000024, 0.472, 1.768, 0.46299999999999997, 1.932, 1.7349999999999999, 0.43499999999999994, 0.929, 1.924, 1.935, 0.94, 0.9039999999999999, 0.45899999999999996, 1.932, 1.696, 1.905, -0.05399999999999994, 0.879, 0.889, 0.919, 1.887, 1.9180000000000001, -0.027000000000000024, -0.03600000000000003, 1.4260000000000002, 0.42300000000000004, 0.45299999999999985, 1.922, -0.06900000000000006, 1.855, 0.9279999999999999, 0.9309999999999999, 0.2469999999999999, 0.40700000000000003, 0.31400000000000006, 0.10199999999999987, 1.867, 1.814, 1.752, 0.3800000000000001, 0.7469999999999999, 0.8700000000000001, 1.785, 1.923, 0.47, -0.050000000000000044, 0.2959999999999998, 0.942, 0.41000000000000014, 1.877, 1.853, 1.8519999999999999, 0.778, 0.9790000000000001, 0.954, 0.96, 1.9100000000000001, 1.9369999999999998, 1.94, 0.43599999999999994, 1.95, -0.10299999999999998, 0.45399999999999996, 0.887, 1.876, 1.925, 1.392, 0.41800000000000015, 0.45100000000000007, 0.44700000000000006, -0.06600000000000006, 1.936, 1.93, 0.45599999999999996, 0.867, 1.899, 0.9060000000000001, 1.951, 1.904, 0.42599999999999993], "episode_lengths": [37, 39, 39, 28, 29, 141, 31, 20, 29, 28, 79, 28, 36, 21, 26, 14, 32, 7, 19, 150, 9, 9, 72, 12, 22, 84, 20, 23, 23, 21, 19, 30, 13, 21, 93, 30, 17, 38, 35, 26, 36, 25, 9, 12, 23, 25, 14, 24, 182, 45, 22, 300, 77, 28, 56, 124, 41, 58, 76, 37, 79, 41, 67, 24, 10, 16, 63, 18, 28, 39, 45, 45, 67, 7, 15, 13, 27, 20, 19, 19, 16, 184, 15, 33, 39, 23, 33, 27, 15, 17, 21, 19, 22, 14, 42, 32, 30, 16, 30, 22], "policy_red_0_reward": [-1.005, 1.381, 0.497, 1.416, 1.4100000000000001, 0.474, 0.499, 1.44, 1.408, 0.912, 1.259, 1.412, 1.387, 1.435, 1.4220000000000002, 1.458, -0.504, -0.5, -1.003, 1.036, 0.973, -1.001, 0.493, -0.5, 1.432, 1.242, -0.503, 1.4300000000000002, 0.496, 0.499, -0.502, 1.4060000000000001, -0.502, 1.435, 1.212, 1.407, 0.949, -0.503, 1.392, 1.421, 0.498, 1.421, 0.973, -1.0, 1.429, 1.423, 0.954, 0.497, 0.44099999999999995, 0.496, 1.431, 0.471, 1.255, 0.912, 1.322, 1.119, 0.495, 0.492, 0.492, 0.885, 1.255, 1.375, 0.494, 1.428, 1.47, 0.95, 0.8029999999999999, 1.444, 0.914, 1.3820000000000001, 1.361, 1.358, 1.289, 1.479, 1.454, 1.4609999999999999, 0.497, 1.44, 1.443, 1.442, 0.499, -1.026, -0.501, 1.396, 1.3820000000000001, 1.428, 1.401, 1.4180000000000001, 1.455, 0.947, 0.9339999999999999, 0.494, 0.498, 1.458, 1.3719999999999999, 1.404, 1.407, 1.451, 0.498, 0.9309999999999999], "policy_blue_0_reward": [1.387, -1.005, 1.3780000000000001, -0.501, -0.502, 1.065, 1.397, -0.502, 0.492, -0.504, 0.487, 0.498, 0.495, -0.504, -1.005, -0.5, 0.902, 0.978, 1.442, -1.019, -1.0, 1.4729999999999999, 1.275, 0.963, 0.5, 0.493, 0.938, -0.501, 1.428, 1.436, 1.442, -0.502, 0.961, 0.497, 0.484, 0.498, -1.003, 1.3820000000000001, -0.503, -0.502, 1.389, 0.497, -1.0, 0.964, -0.003, -1.0, -0.501, 1.4249999999999998, -0.51, 1.359, -0.503, 0.45999999999999996, -1.008, -0.505, -1.008, -1.017, 1.3719999999999999, 1.322, 1.26, -0.5049999999999999, -0.508, -0.505, 1.291, 0.495, -1.0, -1.0, -0.507, -0.502, -0.504, 0.495, 0.492, 0.494, -0.511, -0.5, -0.5, -0.501, 1.413, 0.497, 0.497, -1.006, 1.451, 0.923, 0.955, -0.509, 0.494, 0.497, -0.009000000000000001, -1.0, -1.004, -0.5, -1.0, 1.442, 1.432, -1.002, -0.505, 0.495, -0.501, 0.5, 1.4060000000000001, -0.505]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3899656612287838, "mean_inference_ms": 7.443760380721101, "mean_action_processing_ms": 0.3907594809825455, "mean_env_wait_ms": 0.5176866828782836, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15490424633026123, "StateBufferConnector_ms": 0.01059412956237793, "ViewRequirementAgentConnector_ms": 0.1958068609237671}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 126.3995869317393, "num_env_steps_trained_throughput_per_sec": 126.3995869317393, "timesteps_total": 296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 32027.316, "sample_time_ms": 4060.242, "learn_time_ms": 27937.671, "learn_throughput": 143.176, "synch_weights_time_ms": 27.795}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "episodes_total": 3756, "training_iteration": 74, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-36-13", "timestamp": 1694838973, "time_this_iter_s": 31.662235021591187, "time_total_s": 2305.9512317180634, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f4e50>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2305.9512317180634, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 25.541304347826088, "ram_util_percent": 57.03260869565217}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.27, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.49, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.49, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.49, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6284861092455685, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05794286394787681, "policy_loss": -0.10288573647364198, "vf_loss": 0.0312708909768844, "vf_explained_var": 0.5945332581177354, "kl": 0.013509207843580385, "entropy": 1.4682375268389782, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 71520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6001969526521862, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06558946330236116, "policy_loss": -0.11171701224326777, "vf_loss": 0.03523313683302452, "vf_explained_var": 0.5737842136994005, "kl": 0.013234314159065737, "entropy": 1.6384416709343592, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 71520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 600000, "num_agent_steps_trained": 600000}, "sampler_results": {"episode_reward_max": 1.951, "episode_reward_min": -0.3370000000000001, "episode_reward_mean": 0.9859600000000002, "episode_len_mean": 47.53, "episode_media": {}, "episodes_this_iter": 83, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.024}, "policy_reward_max": {"red_0": 1.463, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.9595400000000001, "blue_0": 0.026420000000000003}, "custom_metrics": {"red_0/door_open_done_mean": 0.27, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.49, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.49, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.49, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.887, 1.876, 1.925, 1.392, 0.41800000000000015, 0.45100000000000007, 0.44700000000000006, -0.06600000000000006, 1.936, 1.93, 0.45599999999999996, 0.867, 1.899, 0.9060000000000001, 1.951, 1.904, 0.42599999999999993, 0.9169999999999999, 0.9530000000000001, 0.45099999999999996, 0.4750000000000001, 0.35599999999999987, 0.07799999999999985, 0.42199999999999993, -0.3370000000000001, 0.8420000000000001, 1.9100000000000001, 0.44300000000000006, 0.41000000000000014, 0.935, 0.2469999999999999, 0.3860000000000001, 0.22299999999999986, 0.917, 0.9329999999999998, 0.9569999999999999, 0.8759999999999999, 1.626, 0.41200000000000003, 1.421, 0.8500000000000001, 0.10599999999999987, 0.9219999999999999, 0.948, 1.861, 1.931, -0.03399999999999992, 0.44599999999999995, 0.897, 1.925, 0.44199999999999995, 1.3639999999999999, 1.431, 0.46099999999999985, 1.2389999999999999, 1.698, -0.061000000000000054, 0.7909999999999999, 1.432, 0.42499999999999993, 0.45899999999999996, 1.6139999999999999, 1.4969999999999999, 0.9369999999999998, 1.9140000000000001, 1.95, 1.913, 0.6589999999999998, 1.439, 1.5779999999999998, 0.45699999999999985, 1.913, 0.7999999999999998, 0.392, 0.33899999999999997, 0.42399999999999993, 1.915, 1.847, 0.31300000000000017, 0.4159999999999999, 0.08199999999999985, -0.11199999999999999, 1.282, -0.14600000000000002, 0.30000000000000004, 0.9550000000000001, 1.822, 0.43299999999999994, 1.917, 0.859, 1.412, 1.9060000000000001, 1.9249999999999998, 0.43299999999999994, 1.4, 1.404, 1.7469999999999999, 1.891, 1.379, 0.399], "episode_lengths": [33, 39, 23, 33, 27, 15, 17, 21, 19, 22, 14, 42, 32, 30, 16, 30, 22, 300, 15, 16, 7, 47, 282, 24, 104, 50, 28, 18, 28, 20, 77, 37, 244, 26, 21, 14, 39, 116, 28, 25, 46, 121, 24, 16, 45, 22, 11, 17, 33, 23, 19, 42, 22, 12, 79, 94, 19, 64, 21, 24, 13, 120, 155, 20, 26, 16, 27, 108, 19, 132, 14, 27, 63, 34, 48, 23, 27, 48, 58, 25, 128, 34, 64, 46, 64, 15, 54, 22, 26, 44, 27, 30, 24, 20, 31, 30, 78, 34, 38, 186], "policy_red_0_reward": [1.396, 1.3820000000000001, 1.428, 1.401, 1.4180000000000001, 1.455, 0.947, 0.9339999999999999, 0.494, 0.498, 1.458, 1.3719999999999999, 1.404, 1.407, 1.451, 0.498, 0.9309999999999999, 0.45399999999999996, 1.455, -0.501, 0.979, 1.359, 0.61, 1.426, 0.6739999999999999, 1.345, 0.497, 1.4449999999999998, 0.914, 1.4369999999999998, 1.254, 1.387, 0.748, 1.419, 1.435, 1.4569999999999999, 1.379, 1.1400000000000001, -0.502, 1.424, 1.359, 1.13, 1.4249999999999998, 1.451, 0.499, 1.434, -1.0, -0.501, 1.4, 0.498, 1.443, 0.374, 1.434, 1.463, -0.010000000000000002, 0.488, 0.941, 1.299, -0.001, -0.501, -1.002, 1.1239999999999999, 1.021, 1.4369999999999998, 0.497, 0.499, 1.4180000000000001, 1.1669999999999998, 1.442, 1.089, 1.458, 1.416, 1.3039999999999998, -0.502, 1.3519999999999999, 1.428, 1.417, 1.35, 1.319, 0.92, 1.099, 0.893, 1.29, -1.003, 1.302, 1.455, 0.494, -0.501, 1.4220000000000002, 1.3639999999999999, 1.417, 1.408, 1.427, -1.002, 1.405, 1.408, 0.495, 1.393, 1.3820000000000001, 0.9179999999999999], "policy_blue_0_reward": [-0.509, 0.494, 0.497, -0.009000000000000001, -1.0, -1.004, -0.5, -1.0, 1.442, 1.432, -1.002, -0.505, 0.495, -0.501, 0.5, 1.4060000000000001, -0.505, 0.46299999999999997, -0.5019999999999999, 0.952, -0.5039999999999999, -1.003, -0.532, -1.004, -1.011, -0.503, 1.413, -1.002, -0.504, -0.502, -1.007, -1.001, -0.525, -0.502, -0.502, -0.5, -0.503, 0.486, 0.914, -0.003, -0.509, -1.024, -0.503, -0.503, 1.362, 0.497, 0.966, 0.947, -0.503, 1.427, -1.001, 0.99, -0.003, -1.002, 1.249, 1.21, -1.002, -0.508, 1.4329999999999998, 0.9259999999999999, 1.4609999999999999, 0.49, 0.476, -0.5, 1.417, 1.451, 0.495, -0.508, -0.003, 0.489, -1.001, 0.497, -0.504, 0.894, -1.013, -1.004, 0.498, 0.497, -1.006, -0.504, -1.017, -1.005, -0.008, 0.857, -1.002, -0.5, 1.3279999999999998, 0.9339999999999999, 0.495, -0.505, -0.005, 0.498, 0.498, 1.435, -0.005, -0.004, 1.252, 0.498, -0.003, -0.5189999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3902121515560975, "mean_inference_ms": 7.452642955622389, "mean_action_processing_ms": 0.3907232140644216, "mean_env_wait_ms": 0.5178381532776264, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15950214862823486, "StateBufferConnector_ms": 0.010583281517028809, "ViewRequirementAgentConnector_ms": 0.1887880563735962}}, "episode_reward_max": 1.951, "episode_reward_min": -0.3370000000000001, "episode_reward_mean": 0.9859600000000002, "episode_len_mean": 47.53, "episodes_this_iter": 83, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.024}, "policy_reward_max": {"red_0": 1.463, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.9595400000000001, "blue_0": 0.026420000000000003}, "hist_stats": {"episode_reward": [0.887, 1.876, 1.925, 1.392, 0.41800000000000015, 0.45100000000000007, 0.44700000000000006, -0.06600000000000006, 1.936, 1.93, 0.45599999999999996, 0.867, 1.899, 0.9060000000000001, 1.951, 1.904, 0.42599999999999993, 0.9169999999999999, 0.9530000000000001, 0.45099999999999996, 0.4750000000000001, 0.35599999999999987, 0.07799999999999985, 0.42199999999999993, -0.3370000000000001, 0.8420000000000001, 1.9100000000000001, 0.44300000000000006, 0.41000000000000014, 0.935, 0.2469999999999999, 0.3860000000000001, 0.22299999999999986, 0.917, 0.9329999999999998, 0.9569999999999999, 0.8759999999999999, 1.626, 0.41200000000000003, 1.421, 0.8500000000000001, 0.10599999999999987, 0.9219999999999999, 0.948, 1.861, 1.931, -0.03399999999999992, 0.44599999999999995, 0.897, 1.925, 0.44199999999999995, 1.3639999999999999, 1.431, 0.46099999999999985, 1.2389999999999999, 1.698, -0.061000000000000054, 0.7909999999999999, 1.432, 0.42499999999999993, 0.45899999999999996, 1.6139999999999999, 1.4969999999999999, 0.9369999999999998, 1.9140000000000001, 1.95, 1.913, 0.6589999999999998, 1.439, 1.5779999999999998, 0.45699999999999985, 1.913, 0.7999999999999998, 0.392, 0.33899999999999997, 0.42399999999999993, 1.915, 1.847, 0.31300000000000017, 0.4159999999999999, 0.08199999999999985, -0.11199999999999999, 1.282, -0.14600000000000002, 0.30000000000000004, 0.9550000000000001, 1.822, 0.43299999999999994, 1.917, 0.859, 1.412, 1.9060000000000001, 1.9249999999999998, 0.43299999999999994, 1.4, 1.404, 1.7469999999999999, 1.891, 1.379, 0.399], "episode_lengths": [33, 39, 23, 33, 27, 15, 17, 21, 19, 22, 14, 42, 32, 30, 16, 30, 22, 300, 15, 16, 7, 47, 282, 24, 104, 50, 28, 18, 28, 20, 77, 37, 244, 26, 21, 14, 39, 116, 28, 25, 46, 121, 24, 16, 45, 22, 11, 17, 33, 23, 19, 42, 22, 12, 79, 94, 19, 64, 21, 24, 13, 120, 155, 20, 26, 16, 27, 108, 19, 132, 14, 27, 63, 34, 48, 23, 27, 48, 58, 25, 128, 34, 64, 46, 64, 15, 54, 22, 26, 44, 27, 30, 24, 20, 31, 30, 78, 34, 38, 186], "policy_red_0_reward": [1.396, 1.3820000000000001, 1.428, 1.401, 1.4180000000000001, 1.455, 0.947, 0.9339999999999999, 0.494, 0.498, 1.458, 1.3719999999999999, 1.404, 1.407, 1.451, 0.498, 0.9309999999999999, 0.45399999999999996, 1.455, -0.501, 0.979, 1.359, 0.61, 1.426, 0.6739999999999999, 1.345, 0.497, 1.4449999999999998, 0.914, 1.4369999999999998, 1.254, 1.387, 0.748, 1.419, 1.435, 1.4569999999999999, 1.379, 1.1400000000000001, -0.502, 1.424, 1.359, 1.13, 1.4249999999999998, 1.451, 0.499, 1.434, -1.0, -0.501, 1.4, 0.498, 1.443, 0.374, 1.434, 1.463, -0.010000000000000002, 0.488, 0.941, 1.299, -0.001, -0.501, -1.002, 1.1239999999999999, 1.021, 1.4369999999999998, 0.497, 0.499, 1.4180000000000001, 1.1669999999999998, 1.442, 1.089, 1.458, 1.416, 1.3039999999999998, -0.502, 1.3519999999999999, 1.428, 1.417, 1.35, 1.319, 0.92, 1.099, 0.893, 1.29, -1.003, 1.302, 1.455, 0.494, -0.501, 1.4220000000000002, 1.3639999999999999, 1.417, 1.408, 1.427, -1.002, 1.405, 1.408, 0.495, 1.393, 1.3820000000000001, 0.9179999999999999], "policy_blue_0_reward": [-0.509, 0.494, 0.497, -0.009000000000000001, -1.0, -1.004, -0.5, -1.0, 1.442, 1.432, -1.002, -0.505, 0.495, -0.501, 0.5, 1.4060000000000001, -0.505, 0.46299999999999997, -0.5019999999999999, 0.952, -0.5039999999999999, -1.003, -0.532, -1.004, -1.011, -0.503, 1.413, -1.002, -0.504, -0.502, -1.007, -1.001, -0.525, -0.502, -0.502, -0.5, -0.503, 0.486, 0.914, -0.003, -0.509, -1.024, -0.503, -0.503, 1.362, 0.497, 0.966, 0.947, -0.503, 1.427, -1.001, 0.99, -0.003, -1.002, 1.249, 1.21, -1.002, -0.508, 1.4329999999999998, 0.9259999999999999, 1.4609999999999999, 0.49, 0.476, -0.5, 1.417, 1.451, 0.495, -0.508, -0.003, 0.489, -1.001, 0.497, -0.504, 0.894, -1.013, -1.004, 0.498, 0.497, -1.006, -0.504, -1.017, -1.005, -0.008, 0.857, -1.002, -0.5, 1.3279999999999998, 0.9339999999999999, 0.495, -0.505, -0.005, 0.498, 0.498, 1.435, -0.005, -0.004, 1.252, 0.498, -0.003, -0.5189999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3902121515560975, "mean_inference_ms": 7.452642955622389, "mean_action_processing_ms": 0.3907232140644216, "mean_env_wait_ms": 0.5178381532776264, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15950214862823486, "StateBufferConnector_ms": 0.010583281517028809, "ViewRequirementAgentConnector_ms": 0.1887880563735962}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 600000, "num_agent_steps_trained": 600000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 124.41592215272058, "num_env_steps_trained_throughput_per_sec": 124.41592215272058, "timesteps_total": 300000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 600000, "timers": {"training_iteration_time_ms": 32193.903, "sample_time_ms": 4096.242, "learn_time_ms": 28068.146, "learn_throughput": 142.51, "synch_weights_time_ms": 27.894}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 600000, "num_agent_steps_trained": 600000}, "done": false, "episodes_total": 3839, "training_iteration": 75, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-36-46", "timestamp": 1694839006, "time_this_iter_s": 32.16634178161621, "time_total_s": 2338.1175734996796, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7234be20>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2338.1175734996796, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 26.010869565217398, "ram_util_percent": 57.0391304347826}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.31, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.49, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.49, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.49, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6393819280279179, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05303672873415053, "policy_loss": -0.09775509548926493, "vf_loss": 0.027584322041851312, "vf_explained_var": 0.6463439023743073, "kl": 0.01420425710448651, "entropy": 1.4328678359587987, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 72480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6169743689397971, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.058823893438966476, "policy_loss": -0.10768257747695316, "vf_loss": 0.039594869684272754, "vf_explained_var": 0.5616438870007793, "kl": 0.013463135554245283, "entropy": 1.609456163396438, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 72480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "sampler_results": {"episode_reward_max": 1.948, "episode_reward_min": -0.16999999999999993, "episode_reward_mean": 1.06878, "episode_len_mean": 42.09, "episode_media": {}, "episodes_this_iter": 88, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.464}, "policy_reward_mean": {"red_0": 1.00978, "blue_0": 0.05900000000000001}, "custom_metrics": {"red_0/door_open_done_mean": 0.31, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.49, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.49, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.49, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.917, 0.859, 1.412, 1.9060000000000001, 1.9249999999999998, 0.43299999999999994, 1.4, 1.404, 1.7469999999999999, 1.891, 1.379, 0.399, 0.31099999999999994, 1.9240000000000002, 0.8039999999999998, 0.8799999999999999, -0.03300000000000003, 0.8999999999999999, 0.9359999999999999, 1.909, 1.6789999999999998, 1.9260000000000002, 0.829, 0.46299999999999997, 0.7770000000000001, 1.903, 1.877, -0.136, 0.43299999999999983, 0.42300000000000004, -0.062000000000000055, 0.946, 1.921, 1.905, 0.43899999999999995, -0.05700000000000005, 1.448, -0.03700000000000003, 1.808, 1.834, 0.41300000000000026, -0.04200000000000004, 0.8970000000000002, 1.805, 1.919, 0.42300000000000004, 0.835, 1.33, 1.909, 1.907, 0.383, 1.947, -0.028000000000000025, 1.9180000000000001, 1.928, 1.826, 1.8479999999999999, 0.8439999999999999, 0.9390000000000001, 0.95, 0.9259999999999999, 1.938, 0.41100000000000003, 0.64, 0.43299999999999983, 0.41700000000000026, 0.921, 0.43399999999999994, 0.9099999999999999, -0.06800000000000006, 0.958, 0.9550000000000001, 1.615, 1.29, 1.892, 0.756, 0.944, -0.16999999999999993, 1.895, 1.9249999999999998, 1.853, 0.8719999999999999, 0.45100000000000007, 1.948, 0.3860000000000001, 0.9319999999999999, 1.866, 1.8639999999999999, 0.9220000000000002, 1.921, 0.635, -0.14200000000000002, 0.11299999999999999, 0.389, 0.6219999999999999, 0.9369999999999998, 0.44399999999999995, 0.41600000000000004, 0.9180000000000001, 1.936], "episode_lengths": [26, 44, 27, 30, 24, 20, 31, 30, 78, 34, 38, 186, 56, 25, 60, 37, 11, 30, 20, 29, 98, 23, 54, 12, 68, 31, 39, 43, 21, 25, 20, 17, 25, 30, 18, 18, 17, 12, 58, 51, 26, 14, 31, 63, 26, 23, 52, 53, 30, 28, 36, 17, 9, 26, 23, 54, 48, 46, 20, 16, 24, 20, 28, 110, 22, 25, 25, 20, 300, 22, 13, 14, 117, 66, 34, 75, 18, 52, 33, 24, 45, 40, 16, 17, 35, 20, 43, 42, 25, 25, 118, 43, 125, 190, 116, 20, 18, 26, 26, 20], "policy_red_0_reward": [1.4220000000000002, 1.3639999999999999, 1.417, 1.408, 1.427, -1.002, 1.405, 1.408, 0.495, 1.393, 1.3820000000000001, 0.9179999999999999, 0.823, 1.425, 1.313, 1.3860000000000001, 0.967, 1.405, 1.439, 1.411, 0.49, 1.429, 1.333, -1.001, 1.284, 0.5, 1.383, 0.866, 1.436, 1.424, 0.938, -0.501, 0.498, 1.409, -1.002, 0.945, 1.4489999999999998, 0.964, 1.314, 1.342, 1.417, 0.958, 1.405, 1.306, 0.499, 0.928, 1.3399999999999999, 1.333, 1.4100000000000001, 0.496, 0.89, 1.448, 0.972, 1.421, 1.4300000000000002, 0.496, 1.353, 1.355, 1.439, 1.452, -0.501, 1.439, -1.002, -0.511, 0.9339999999999999, 1.423, 1.424, 0.938, 0.43999999999999995, 0.9339999999999999, 1.4609999999999999, 1.4569999999999999, 1.1320000000000001, 1.296, 1.393, 1.264, 1.4449999999999998, 0.839, 1.3980000000000001, 0.5, 0.492, 1.376, 0.952, 0.5, 1.391, 1.436, 1.371, 1.373, 1.4220000000000002, 0.499, 1.1400000000000001, 0.866, 0.622, 0.912, 1.131, 1.439, 1.446, -1.004, 1.419, 1.438], "policy_blue_0_reward": [0.495, -0.505, -0.005, 0.498, 0.498, 1.435, -0.005, -0.004, 1.252, 0.498, -0.003, -0.5189999999999999, -0.5119999999999999, 0.499, -0.509, -0.506, -1.0, -0.505, -0.503, 0.498, 1.189, 0.497, -0.504, 1.464, -0.507, 1.403, 0.494, -1.002, -1.003, -1.001, -1.0, 1.447, 1.423, 0.496, 1.4409999999999998, -1.002, -0.001, -1.001, 0.494, 0.492, -1.0039999999999998, -1.0, -0.5079999999999999, 0.499, 1.42, -0.5049999999999999, -0.505, -0.003, 0.499, 1.411, -0.507, 0.499, -1.0, 0.497, 0.498, 1.33, 0.495, -0.511, -0.5, -0.502, 1.427, 0.499, 1.413, 1.151, -0.501, -1.0059999999999998, -0.503, -0.504, 0.47, -1.002, -0.503, -0.502, 0.483, -0.006, 0.499, -0.508, -0.501, -1.009, 0.497, 1.4249999999999998, 1.361, -0.504, -0.501, 1.448, -1.005, -0.504, 0.495, 0.491, -0.5, 1.4220000000000002, -0.505, -1.008, -0.509, -0.523, -0.509, -0.502, -1.002, 1.42, -0.501, 0.498]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3888155818303023, "mean_inference_ms": 7.444902266346552, "mean_action_processing_ms": 0.3920879306389087, "mean_env_wait_ms": 0.5167690398798673, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1527538299560547, "StateBufferConnector_ms": 0.009637832641601562, "ViewRequirementAgentConnector_ms": 0.19327521324157715}}, "episode_reward_max": 1.948, "episode_reward_min": -0.16999999999999993, "episode_reward_mean": 1.06878, "episode_len_mean": 42.09, "episodes_this_iter": 88, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.464}, "policy_reward_mean": {"red_0": 1.00978, "blue_0": 0.05900000000000001}, "hist_stats": {"episode_reward": [1.917, 0.859, 1.412, 1.9060000000000001, 1.9249999999999998, 0.43299999999999994, 1.4, 1.404, 1.7469999999999999, 1.891, 1.379, 0.399, 0.31099999999999994, 1.9240000000000002, 0.8039999999999998, 0.8799999999999999, -0.03300000000000003, 0.8999999999999999, 0.9359999999999999, 1.909, 1.6789999999999998, 1.9260000000000002, 0.829, 0.46299999999999997, 0.7770000000000001, 1.903, 1.877, -0.136, 0.43299999999999983, 0.42300000000000004, -0.062000000000000055, 0.946, 1.921, 1.905, 0.43899999999999995, -0.05700000000000005, 1.448, -0.03700000000000003, 1.808, 1.834, 0.41300000000000026, -0.04200000000000004, 0.8970000000000002, 1.805, 1.919, 0.42300000000000004, 0.835, 1.33, 1.909, 1.907, 0.383, 1.947, -0.028000000000000025, 1.9180000000000001, 1.928, 1.826, 1.8479999999999999, 0.8439999999999999, 0.9390000000000001, 0.95, 0.9259999999999999, 1.938, 0.41100000000000003, 0.64, 0.43299999999999983, 0.41700000000000026, 0.921, 0.43399999999999994, 0.9099999999999999, -0.06800000000000006, 0.958, 0.9550000000000001, 1.615, 1.29, 1.892, 0.756, 0.944, -0.16999999999999993, 1.895, 1.9249999999999998, 1.853, 0.8719999999999999, 0.45100000000000007, 1.948, 0.3860000000000001, 0.9319999999999999, 1.866, 1.8639999999999999, 0.9220000000000002, 1.921, 0.635, -0.14200000000000002, 0.11299999999999999, 0.389, 0.6219999999999999, 0.9369999999999998, 0.44399999999999995, 0.41600000000000004, 0.9180000000000001, 1.936], "episode_lengths": [26, 44, 27, 30, 24, 20, 31, 30, 78, 34, 38, 186, 56, 25, 60, 37, 11, 30, 20, 29, 98, 23, 54, 12, 68, 31, 39, 43, 21, 25, 20, 17, 25, 30, 18, 18, 17, 12, 58, 51, 26, 14, 31, 63, 26, 23, 52, 53, 30, 28, 36, 17, 9, 26, 23, 54, 48, 46, 20, 16, 24, 20, 28, 110, 22, 25, 25, 20, 300, 22, 13, 14, 117, 66, 34, 75, 18, 52, 33, 24, 45, 40, 16, 17, 35, 20, 43, 42, 25, 25, 118, 43, 125, 190, 116, 20, 18, 26, 26, 20], "policy_red_0_reward": [1.4220000000000002, 1.3639999999999999, 1.417, 1.408, 1.427, -1.002, 1.405, 1.408, 0.495, 1.393, 1.3820000000000001, 0.9179999999999999, 0.823, 1.425, 1.313, 1.3860000000000001, 0.967, 1.405, 1.439, 1.411, 0.49, 1.429, 1.333, -1.001, 1.284, 0.5, 1.383, 0.866, 1.436, 1.424, 0.938, -0.501, 0.498, 1.409, -1.002, 0.945, 1.4489999999999998, 0.964, 1.314, 1.342, 1.417, 0.958, 1.405, 1.306, 0.499, 0.928, 1.3399999999999999, 1.333, 1.4100000000000001, 0.496, 0.89, 1.448, 0.972, 1.421, 1.4300000000000002, 0.496, 1.353, 1.355, 1.439, 1.452, -0.501, 1.439, -1.002, -0.511, 0.9339999999999999, 1.423, 1.424, 0.938, 0.43999999999999995, 0.9339999999999999, 1.4609999999999999, 1.4569999999999999, 1.1320000000000001, 1.296, 1.393, 1.264, 1.4449999999999998, 0.839, 1.3980000000000001, 0.5, 0.492, 1.376, 0.952, 0.5, 1.391, 1.436, 1.371, 1.373, 1.4220000000000002, 0.499, 1.1400000000000001, 0.866, 0.622, 0.912, 1.131, 1.439, 1.446, -1.004, 1.419, 1.438], "policy_blue_0_reward": [0.495, -0.505, -0.005, 0.498, 0.498, 1.435, -0.005, -0.004, 1.252, 0.498, -0.003, -0.5189999999999999, -0.5119999999999999, 0.499, -0.509, -0.506, -1.0, -0.505, -0.503, 0.498, 1.189, 0.497, -0.504, 1.464, -0.507, 1.403, 0.494, -1.002, -1.003, -1.001, -1.0, 1.447, 1.423, 0.496, 1.4409999999999998, -1.002, -0.001, -1.001, 0.494, 0.492, -1.0039999999999998, -1.0, -0.5079999999999999, 0.499, 1.42, -0.5049999999999999, -0.505, -0.003, 0.499, 1.411, -0.507, 0.499, -1.0, 0.497, 0.498, 1.33, 0.495, -0.511, -0.5, -0.502, 1.427, 0.499, 1.413, 1.151, -0.501, -1.0059999999999998, -0.503, -0.504, 0.47, -1.002, -0.503, -0.502, 0.483, -0.006, 0.499, -0.508, -0.501, -1.009, 0.497, 1.4249999999999998, 1.361, -0.504, -0.501, 1.448, -1.005, -0.504, 0.495, 0.491, -0.5, 1.4220000000000002, -0.505, -1.008, -0.509, -0.523, -0.509, -0.502, -1.002, 1.42, -0.501, 0.498]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3888155818303023, "mean_inference_ms": 7.444902266346552, "mean_action_processing_ms": 0.3920879306389087, "mean_env_wait_ms": 0.5167690398798673, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1527538299560547, "StateBufferConnector_ms": 0.009637832641601562, "ViewRequirementAgentConnector_ms": 0.19327521324157715}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.70042810562893, "num_env_steps_trained_throughput_per_sec": 129.70042810562893, "timesteps_total": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 32232.688, "sample_time_ms": 4106.052, "learn_time_ms": 28097.162, "learn_throughput": 142.363, "synch_weights_time_ms": 27.849}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "episodes_total": 3927, "training_iteration": 76, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-37-17", "timestamp": 1694839037, "time_this_iter_s": 30.856849908828735, "time_total_s": 2368.9744234085083, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a21d630>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2368.9744234085083, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 23.63555555555556, "ram_util_percent": 56.977777777777774}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.2647058823529412, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.45098039215686275, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14705882352941177, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.45098039215686275, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12745098039215685, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14705882352941177, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.45098039215686275, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14705882352941177, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.635268479399383, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05556600996836399, "policy_loss": -0.10776240184544197, "vf_loss": 0.041396148801626016, "vf_explained_var": 0.5767484636977315, "kl": 0.014438162552134296, "entropy": 1.3936221620688836, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 73440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6000230758761366, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0632759752984081, "policy_loss": -0.11222942246046538, "vf_loss": 0.04054054163279943, "vf_explained_var": 0.5945204163591067, "kl": 0.013288684206005048, "entropy": 1.5901078864932061, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 73440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 616000, "num_agent_steps_trained": 616000}, "sampler_results": {"episode_reward_max": 1.954, "episode_reward_min": -0.10999999999999999, "episode_reward_mean": 1.0616960784313725, "episode_len_mean": 43.19607843137255, "episode_media": {}, "episodes_this_iter": 102, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.007}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.462}, "policy_reward_mean": {"red_0": 0.9331470588235292, "blue_0": 0.12854901960784315}, "custom_metrics": {"red_0/door_open_done_mean": 0.2647058823529412, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.45098039215686275, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14705882352941177, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.45098039215686275, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12745098039215685, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14705882352941177, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.45098039215686275, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14705882352941177, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.692, 1.883, 0.946, 1.673, 0.875, 0.9529999999999998, 0.45100000000000007, 0.41000000000000014, 0.43299999999999983, 0.946, 1.897, 1.353, 1.87, 0.33999999999999986, 1.87, 1.843, 1.917, 0.9790000000000001, 0.9569999999999999, 0.4750000000000001, 0.246, 0.371, 1.9449999999999998, 1.794, 0.42400000000000015, 1.7109999999999999, 1.924, 0.41500000000000004, 1.899, 1.275, 1.873, 0.44200000000000017, 1.4020000000000001, 1.431, 0.938, 0.9299999999999999, 0.43799999999999994, 0.923, 1.6, 0.962, 0.43199999999999994, 0.8220000000000001, 0.367, 1.432, 0.947, 1.46, 0.45899999999999996, 0.903, 0.43100000000000005, 0.31700000000000017, 0.959, 1.706, 0.6559999999999999, 0.42900000000000005, 1.938, 0.96, 0.956, 0.471, 0.9239999999999999, 0.835, 1.879, 1.9260000000000002, 0.895, 1.948, 0.472, 0.401, -0.10999999999999999, 1.883, 0.381, 0.891, 0.30200000000000005, 1.954, 0.45799999999999996, 0.42700000000000005, 1.7770000000000001, 0.899, 0.914, 0.903, 0.9039999999999999, 1.8639999999999999, 0.44999999999999996, 0.42300000000000004, 1.377, 1.355, 1.443, 1.887, 1.8860000000000001, 0.45100000000000007, 0.952, 1.4329999999999998, 1.9130000000000003, 1.4249999999999998, 0.8839999999999999, 0.6669999999999999, 0.44499999999999984, 0.958, 0.30299999999999994, 1.766, 1.948, 0.375, 0.45999999999999996, 0.41400000000000015], "episode_lengths": [98, 36, 18, 102, 39, 15, 16, 29, 21, 17, 33, 46, 38, 204, 41, 50, 25, 7, 14, 8, 82, 41, 18, 63, 23, 91, 24, 25, 32, 70, 40, 18, 32, 22, 19, 300, 20, 24, 125, 12, 20, 57, 41, 21, 17, 13, 13, 30, 23, 58, 13, 92, 108, 23, 20, 13, 14, 164, 24, 53, 37, 23, 33, 16, 9, 31, 34, 37, 37, 34, 64, 15, 13, 22, 68, 31, 26, 30, 30, 42, 16, 24, 39, 201, 18, 34, 35, 16, 15, 21, 27, 24, 37, 102, 17, 13, 213, 71, 17, 38, 13, 28], "policy_red_0_reward": [0.493, 0.493, 1.446, 0.488, 1.381, 1.455, 1.451, 0.912, 0.9359999999999999, -0.501, 1.4, -0.004, 1.381, 0.8689999999999999, 1.375, 0.495, 1.425, 1.479, 1.458, 1.475, 1.249, 1.375, 1.446, 1.3039999999999998, 1.4260000000000002, 0.492, 0.498, 1.4180000000000001, 1.4020000000000001, 1.2810000000000001, 1.38, 1.446, -0.001, 1.432, 1.4409999999999998, 0.471, 0.939, 1.426, 1.109, -0.5, 0.9359999999999999, 1.327, 1.371, 1.436, -0.501, 1.4609999999999999, -0.502, 1.404, -0.5, 1.323, -0.501, 1.2149999999999999, 1.168, -1.001, 0.5, -0.5, 1.458, -0.521, 1.426, 1.337, 1.3820000000000001, 1.429, 1.4, 1.452, 1.4729999999999999, 1.403, 0.894, 1.3860000000000001, -0.504, 1.395, 1.3050000000000002, 1.455, 1.4609999999999999, 1.43, 1.287, 1.401, -0.505, 1.408, 1.407, 0.495, 0.952, 1.4249999999999998, 1.38, 0.477, -0.002, 1.392, 1.3900000000000001, 1.452, -0.502, 1.436, 1.415, 1.427, 1.3860000000000001, -0.511, 1.447, 1.46, -0.543, 1.2730000000000001, 0.499, 1.3820000000000001, -1.001, 1.416], "policy_blue_0_reward": [1.1989999999999998, 1.3900000000000001, -0.5, 1.185, -0.5059999999999999, -0.502, -1.0, -0.502, -0.503, 1.447, 0.497, 1.357, 0.489, -0.529, 0.495, 1.3479999999999999, 0.492, -0.5, -0.501, -1.0, -1.003, -1.0039999999999998, 0.499, 0.49, -1.0019999999999998, 1.2189999999999999, 1.426, -1.003, 0.497, -0.006, 0.493, -1.0039999999999998, 1.403, -0.001, -0.503, 0.45899999999999996, -0.501, -0.503, 0.491, 1.462, -0.504, -0.505, -1.0039999999999998, -0.004, 1.448, -0.001, 0.961, -0.501, 0.931, -1.006, 1.46, 0.491, -0.512, 1.4300000000000002, 1.438, 1.46, -0.502, 0.992, -0.502, -0.502, 0.497, 0.497, -0.505, 0.496, -1.001, -1.002, -1.004, 0.497, 0.885, -0.5039999999999999, -1.003, 0.499, -1.003, -1.003, 0.49, -0.5019999999999999, 1.419, -0.505, -0.503, 1.369, -0.502, -1.002, -0.003, 0.8779999999999999, 1.4449999999999998, 0.495, 0.496, -1.001, 1.454, -0.003, 0.498, -0.002, -0.502, 1.178, -1.002, -0.502, 0.846, 0.493, 1.4489999999999998, -1.007, 1.4609999999999999, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3894074386550943, "mean_inference_ms": 7.43988749494256, "mean_action_processing_ms": 0.3894388014436565, "mean_env_wait_ms": 0.5169837166204813, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13639073745877134, "StateBufferConnector_ms": 0.009872048508887198, "ViewRequirementAgentConnector_ms": 0.1781761646270752}}, "episode_reward_max": 1.954, "episode_reward_min": -0.10999999999999999, "episode_reward_mean": 1.0616960784313725, "episode_len_mean": 43.19607843137255, "episodes_this_iter": 102, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.007}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.462}, "policy_reward_mean": {"red_0": 0.9331470588235292, "blue_0": 0.12854901960784315}, "hist_stats": {"episode_reward": [1.692, 1.883, 0.946, 1.673, 0.875, 0.9529999999999998, 0.45100000000000007, 0.41000000000000014, 0.43299999999999983, 0.946, 1.897, 1.353, 1.87, 0.33999999999999986, 1.87, 1.843, 1.917, 0.9790000000000001, 0.9569999999999999, 0.4750000000000001, 0.246, 0.371, 1.9449999999999998, 1.794, 0.42400000000000015, 1.7109999999999999, 1.924, 0.41500000000000004, 1.899, 1.275, 1.873, 0.44200000000000017, 1.4020000000000001, 1.431, 0.938, 0.9299999999999999, 0.43799999999999994, 0.923, 1.6, 0.962, 0.43199999999999994, 0.8220000000000001, 0.367, 1.432, 0.947, 1.46, 0.45899999999999996, 0.903, 0.43100000000000005, 0.31700000000000017, 0.959, 1.706, 0.6559999999999999, 0.42900000000000005, 1.938, 0.96, 0.956, 0.471, 0.9239999999999999, 0.835, 1.879, 1.9260000000000002, 0.895, 1.948, 0.472, 0.401, -0.10999999999999999, 1.883, 0.381, 0.891, 0.30200000000000005, 1.954, 0.45799999999999996, 0.42700000000000005, 1.7770000000000001, 0.899, 0.914, 0.903, 0.9039999999999999, 1.8639999999999999, 0.44999999999999996, 0.42300000000000004, 1.377, 1.355, 1.443, 1.887, 1.8860000000000001, 0.45100000000000007, 0.952, 1.4329999999999998, 1.9130000000000003, 1.4249999999999998, 0.8839999999999999, 0.6669999999999999, 0.44499999999999984, 0.958, 0.30299999999999994, 1.766, 1.948, 0.375, 0.45999999999999996, 0.41400000000000015], "episode_lengths": [98, 36, 18, 102, 39, 15, 16, 29, 21, 17, 33, 46, 38, 204, 41, 50, 25, 7, 14, 8, 82, 41, 18, 63, 23, 91, 24, 25, 32, 70, 40, 18, 32, 22, 19, 300, 20, 24, 125, 12, 20, 57, 41, 21, 17, 13, 13, 30, 23, 58, 13, 92, 108, 23, 20, 13, 14, 164, 24, 53, 37, 23, 33, 16, 9, 31, 34, 37, 37, 34, 64, 15, 13, 22, 68, 31, 26, 30, 30, 42, 16, 24, 39, 201, 18, 34, 35, 16, 15, 21, 27, 24, 37, 102, 17, 13, 213, 71, 17, 38, 13, 28], "policy_red_0_reward": [0.493, 0.493, 1.446, 0.488, 1.381, 1.455, 1.451, 0.912, 0.9359999999999999, -0.501, 1.4, -0.004, 1.381, 0.8689999999999999, 1.375, 0.495, 1.425, 1.479, 1.458, 1.475, 1.249, 1.375, 1.446, 1.3039999999999998, 1.4260000000000002, 0.492, 0.498, 1.4180000000000001, 1.4020000000000001, 1.2810000000000001, 1.38, 1.446, -0.001, 1.432, 1.4409999999999998, 0.471, 0.939, 1.426, 1.109, -0.5, 0.9359999999999999, 1.327, 1.371, 1.436, -0.501, 1.4609999999999999, -0.502, 1.404, -0.5, 1.323, -0.501, 1.2149999999999999, 1.168, -1.001, 0.5, -0.5, 1.458, -0.521, 1.426, 1.337, 1.3820000000000001, 1.429, 1.4, 1.452, 1.4729999999999999, 1.403, 0.894, 1.3860000000000001, -0.504, 1.395, 1.3050000000000002, 1.455, 1.4609999999999999, 1.43, 1.287, 1.401, -0.505, 1.408, 1.407, 0.495, 0.952, 1.4249999999999998, 1.38, 0.477, -0.002, 1.392, 1.3900000000000001, 1.452, -0.502, 1.436, 1.415, 1.427, 1.3860000000000001, -0.511, 1.447, 1.46, -0.543, 1.2730000000000001, 0.499, 1.3820000000000001, -1.001, 1.416], "policy_blue_0_reward": [1.1989999999999998, 1.3900000000000001, -0.5, 1.185, -0.5059999999999999, -0.502, -1.0, -0.502, -0.503, 1.447, 0.497, 1.357, 0.489, -0.529, 0.495, 1.3479999999999999, 0.492, -0.5, -0.501, -1.0, -1.003, -1.0039999999999998, 0.499, 0.49, -1.0019999999999998, 1.2189999999999999, 1.426, -1.003, 0.497, -0.006, 0.493, -1.0039999999999998, 1.403, -0.001, -0.503, 0.45899999999999996, -0.501, -0.503, 0.491, 1.462, -0.504, -0.505, -1.0039999999999998, -0.004, 1.448, -0.001, 0.961, -0.501, 0.931, -1.006, 1.46, 0.491, -0.512, 1.4300000000000002, 1.438, 1.46, -0.502, 0.992, -0.502, -0.502, 0.497, 0.497, -0.505, 0.496, -1.001, -1.002, -1.004, 0.497, 0.885, -0.5039999999999999, -1.003, 0.499, -1.003, -1.003, 0.49, -0.5019999999999999, 1.419, -0.505, -0.503, 1.369, -0.502, -1.002, -0.003, 0.8779999999999999, 1.4449999999999998, 0.495, 0.496, -1.001, 1.454, -0.003, 0.498, -0.002, -0.502, 1.178, -1.002, -0.502, 0.846, 0.493, 1.4489999999999998, -1.007, 1.4609999999999999, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3894074386550943, "mean_inference_ms": 7.43988749494256, "mean_action_processing_ms": 0.3894388014436565, "mean_env_wait_ms": 0.5169837166204813, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13639073745877134, "StateBufferConnector_ms": 0.009872048508887198, "ViewRequirementAgentConnector_ms": 0.1781761646270752}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 616000, "num_agent_steps_trained": 616000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.71427460732846, "num_env_steps_trained_throughput_per_sec": 129.71427460732846, "timesteps_total": 308000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 616000, "timers": {"training_iteration_time_ms": 32224.007, "sample_time_ms": 4101.155, "learn_time_ms": 28092.994, "learn_throughput": 142.384, "synch_weights_time_ms": 28.241}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 616000, "num_agent_steps_trained": 616000}, "done": false, "episodes_total": 4029, "training_iteration": 77, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-37-49", "timestamp": 1694839069, "time_this_iter_s": 30.85656499862671, "time_total_s": 2399.830988407135, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f7ac0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2399.830988407135, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 24.78666666666667, "ram_util_percent": 57.04888888888888}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.336283185840708, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.4247787610619469, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08849557522123894, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.4247787610619469, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13274336283185842, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08849557522123894, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.4247787610619469, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08849557522123894, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6280608298256993, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.053634841854606444, "policy_loss": -0.10243364854250103, "vf_loss": 0.037551689051906575, "vf_explained_var": 0.613916119436423, "kl": 0.01378524318556951, "entropy": 1.381546338647604, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 74400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6112460481002927, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05676727203147796, "policy_loss": -0.1085656049088963, "vf_loss": 0.04517388237873092, "vf_explained_var": 0.5756254098067681, "kl": 0.013512839310813063, "entropy": 1.5725457760194936, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 74400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "sampler_results": {"episode_reward_max": 1.955, "episode_reward_min": -0.10099999999999998, "episode_reward_mean": 1.2055663716814158, "episode_len_mean": 34.716814159292035, "episode_media": {}, "episodes_this_iter": 113, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.007}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.467}, "policy_reward_mean": {"red_0": 1.0484513274336285, "blue_0": 0.15711504424778766}, "custom_metrics": {"red_0/door_open_done_mean": 0.336283185840708, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.4247787610619469, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08849557522123894, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.4247787610619469, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13274336283185842, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08849557522123894, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.4247787610619469, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08849557522123894, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.887, 0.42200000000000015, 1.8940000000000001, 1.9449999999999998, -0.05300000000000005, 0.47, 0.9409999999999998, 1.955, 1.869, 0.919, 1.927, 0.9299999999999999, 1.346, 1.907, 1.9369999999999998, 0.963, 0.45699999999999985, 1.934, 0.9239999999999999, 0.9019999999999999, 1.93, 1.391, 1.908, 1.927, 0.6420000000000001, 0.9169999999999999, 1.9180000000000001, 0.9590000000000001, 0.895, 0.44700000000000006, -0.08000000000000007, 0.9609999999999999, 1.9140000000000001, 1.935, 0.365, 1.7719999999999998, 1.9010000000000002, 0.4790000000000001, 1.931, 1.9369999999999998, 1.845, 1.701, 1.9140000000000001, 0.947, 0.45999999999999996, 0.897, 0.46099999999999985, 1.8439999999999999, 1.923, 0.8300000000000001, 1.405, 0.695, 0.46699999999999997, 0.42799999999999994, 1.8780000000000001, 1.4569999999999999, 1.9220000000000002, 1.913, 0.41000000000000003, 1.424, 1.9200000000000002, 1.8940000000000001, 1.954, 1.8860000000000001, 0.9630000000000001, 1.396, 1.334, 1.405, 0.8730000000000002, 1.4289999999999998, 1.8479999999999999, -0.10099999999999998, 1.899, 0.919, 1.8980000000000001, 0.43699999999999983, 0.9329999999999998, 0.956, 0.843, 0.4209999999999998, 0.42200000000000015, 0.8740000000000001, 1.917, 1.81, 0.883, 0.9569999999999999, 1.905, 0.7429999999999999, 0.8359999999999999, 1.896, 0.948, 0.41100000000000003, 0.44399999999999995, 0.966, 0.42399999999999993, 1.94, 0.4590000000000001, 0.97, 0.379, 1.924, 0.945, 0.9079999999999999, 0.9119999999999999, 0.42399999999999993, 0.476, 1.658, 1.877, 0.909, 1.95, 1.385, 0.42500000000000004, 0.9489999999999998, 0.8500000000000001], "episode_lengths": [36, 25, 33, 18, 17, 10, 18, 15, 41, 25, 23, 22, 49, 30, 20, 12, 14, 21, 24, 300, 22, 33, 30, 24, 109, 300, 26, 13, 32, 17, 24, 12, 27, 21, 43, 69, 29, 7, 22, 19, 48, 91, 27, 17, 13, 33, 12, 48, 25, 53, 30, 94, 11, 22, 37, 14, 25, 28, 29, 24, 25, 34, 15, 35, 12, 33, 53, 29, 39, 22, 48, 31, 32, 25, 32, 20, 22, 14, 49, 24, 25, 39, 27, 58, 36, 14, 29, 80, 52, 32, 17, 29, 18, 11, 24, 19, 13, 10, 37, 24, 18, 30, 28, 25, 8, 106, 40, 29, 16, 36, 23, 16, 47], "policy_red_0_reward": [1.391, 1.424, 1.396, 1.446, 0.948, 1.47, 1.446, 0.5, 0.496, -0.501, 1.4300000000000002, 1.4329999999999998, 1.349, 0.499, 1.439, -0.5, 1.458, 1.436, 1.427, 0.43999999999999995, 1.434, 1.3940000000000001, 1.4100000000000001, 1.427, 1.154, 0.45399999999999996, 0.498, 1.4609999999999999, -0.504, 1.448, 0.9219999999999999, 1.463, 1.416, 1.436, 1.37, 1.283, 1.412, 0.979, 1.432, 0.496, 1.354, 0.487, 1.415, -0.502, 1.4609999999999999, 1.399, 0.964, 1.35, 1.425, 1.335, -0.004, -0.515, -1.0, 0.9309999999999999, 0.494, 1.4569999999999999, 1.424, 0.5, -0.502, -0.003, 1.4220000000000002, 1.396, 1.455, 0.495, 1.464, 1.3980000000000001, 1.337, 1.412, 1.38, 1.4329999999999998, 0.499, 0.906, 0.497, 1.421, 1.403, 1.439, 1.434, 1.458, 1.351, 1.423, 0.923, 1.375, 1.419, 1.3130000000000002, 1.389, 1.4569999999999999, 1.408, 1.254, 1.3399999999999999, 0.497, 1.448, -0.5, 1.4449999999999998, 1.467, 1.428, 1.442, 1.46, 1.47, 0.884, 1.424, -0.501, 1.409, 1.4140000000000001, 1.424, -0.5, 1.1709999999999998, 1.379, 1.413, 0.498, 1.388, 0.927, 1.45, 1.355], "policy_blue_0_reward": [0.496, -1.002, 0.498, 0.499, -1.001, -1.0, -0.505, 1.455, 1.373, 1.42, 0.497, -0.503, -0.003, 1.408, 0.498, 1.463, -1.001, 0.498, -0.503, 0.46199999999999997, 0.496, -0.003, 0.498, 0.5, -0.5119999999999999, 0.46299999999999997, 1.42, -0.5019999999999999, 1.399, -1.001, -1.002, -0.502, 0.498, 0.499, -1.005, 0.489, 0.489, -0.5, 0.499, 1.4409999999999998, 0.491, 1.214, 0.499, 1.4489999999999998, -1.001, -0.502, -0.503, 0.494, 0.498, -0.505, 1.409, 1.21, 1.467, -0.5029999999999999, 1.384, 0.0, 0.498, 1.413, 0.912, 1.427, 0.498, 0.498, 0.499, 1.391, -0.501, -0.002, -0.003, -0.007, -0.5069999999999999, -0.004, 1.349, -1.007, 1.4020000000000001, -0.502, 0.495, -1.002, -0.501, -0.502, -0.508, -1.002, -0.501, -0.501, 0.498, 0.497, -0.506, -0.5, 0.497, -0.511, -0.504, 1.399, -0.5, 0.911, -1.001, -0.501, -1.004, 0.498, -1.001, -0.5, -0.505, 0.5, 1.446, -0.501, -0.502, -1.0, 0.976, 0.487, 0.498, -0.504, 1.452, -0.003, -0.502, -0.501, -0.505]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3913245196448925, "mean_inference_ms": 7.42854357865226, "mean_action_processing_ms": 0.38934158534200614, "mean_env_wait_ms": 0.5168505481562206, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13202291674318567, "StateBufferConnector_ms": 0.008815052235021001, "ViewRequirementAgentConnector_ms": 0.1751523102279258}}, "episode_reward_max": 1.955, "episode_reward_min": -0.10099999999999998, "episode_reward_mean": 1.2055663716814158, "episode_len_mean": 34.716814159292035, "episodes_this_iter": 113, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.007}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.467}, "policy_reward_mean": {"red_0": 1.0484513274336285, "blue_0": 0.15711504424778766}, "hist_stats": {"episode_reward": [1.887, 0.42200000000000015, 1.8940000000000001, 1.9449999999999998, -0.05300000000000005, 0.47, 0.9409999999999998, 1.955, 1.869, 0.919, 1.927, 0.9299999999999999, 1.346, 1.907, 1.9369999999999998, 0.963, 0.45699999999999985, 1.934, 0.9239999999999999, 0.9019999999999999, 1.93, 1.391, 1.908, 1.927, 0.6420000000000001, 0.9169999999999999, 1.9180000000000001, 0.9590000000000001, 0.895, 0.44700000000000006, -0.08000000000000007, 0.9609999999999999, 1.9140000000000001, 1.935, 0.365, 1.7719999999999998, 1.9010000000000002, 0.4790000000000001, 1.931, 1.9369999999999998, 1.845, 1.701, 1.9140000000000001, 0.947, 0.45999999999999996, 0.897, 0.46099999999999985, 1.8439999999999999, 1.923, 0.8300000000000001, 1.405, 0.695, 0.46699999999999997, 0.42799999999999994, 1.8780000000000001, 1.4569999999999999, 1.9220000000000002, 1.913, 0.41000000000000003, 1.424, 1.9200000000000002, 1.8940000000000001, 1.954, 1.8860000000000001, 0.9630000000000001, 1.396, 1.334, 1.405, 0.8730000000000002, 1.4289999999999998, 1.8479999999999999, -0.10099999999999998, 1.899, 0.919, 1.8980000000000001, 0.43699999999999983, 0.9329999999999998, 0.956, 0.843, 0.4209999999999998, 0.42200000000000015, 0.8740000000000001, 1.917, 1.81, 0.883, 0.9569999999999999, 1.905, 0.7429999999999999, 0.8359999999999999, 1.896, 0.948, 0.41100000000000003, 0.44399999999999995, 0.966, 0.42399999999999993, 1.94, 0.4590000000000001, 0.97, 0.379, 1.924, 0.945, 0.9079999999999999, 0.9119999999999999, 0.42399999999999993, 0.476, 1.658, 1.877, 0.909, 1.95, 1.385, 0.42500000000000004, 0.9489999999999998, 0.8500000000000001], "episode_lengths": [36, 25, 33, 18, 17, 10, 18, 15, 41, 25, 23, 22, 49, 30, 20, 12, 14, 21, 24, 300, 22, 33, 30, 24, 109, 300, 26, 13, 32, 17, 24, 12, 27, 21, 43, 69, 29, 7, 22, 19, 48, 91, 27, 17, 13, 33, 12, 48, 25, 53, 30, 94, 11, 22, 37, 14, 25, 28, 29, 24, 25, 34, 15, 35, 12, 33, 53, 29, 39, 22, 48, 31, 32, 25, 32, 20, 22, 14, 49, 24, 25, 39, 27, 58, 36, 14, 29, 80, 52, 32, 17, 29, 18, 11, 24, 19, 13, 10, 37, 24, 18, 30, 28, 25, 8, 106, 40, 29, 16, 36, 23, 16, 47], "policy_red_0_reward": [1.391, 1.424, 1.396, 1.446, 0.948, 1.47, 1.446, 0.5, 0.496, -0.501, 1.4300000000000002, 1.4329999999999998, 1.349, 0.499, 1.439, -0.5, 1.458, 1.436, 1.427, 0.43999999999999995, 1.434, 1.3940000000000001, 1.4100000000000001, 1.427, 1.154, 0.45399999999999996, 0.498, 1.4609999999999999, -0.504, 1.448, 0.9219999999999999, 1.463, 1.416, 1.436, 1.37, 1.283, 1.412, 0.979, 1.432, 0.496, 1.354, 0.487, 1.415, -0.502, 1.4609999999999999, 1.399, 0.964, 1.35, 1.425, 1.335, -0.004, -0.515, -1.0, 0.9309999999999999, 0.494, 1.4569999999999999, 1.424, 0.5, -0.502, -0.003, 1.4220000000000002, 1.396, 1.455, 0.495, 1.464, 1.3980000000000001, 1.337, 1.412, 1.38, 1.4329999999999998, 0.499, 0.906, 0.497, 1.421, 1.403, 1.439, 1.434, 1.458, 1.351, 1.423, 0.923, 1.375, 1.419, 1.3130000000000002, 1.389, 1.4569999999999999, 1.408, 1.254, 1.3399999999999999, 0.497, 1.448, -0.5, 1.4449999999999998, 1.467, 1.428, 1.442, 1.46, 1.47, 0.884, 1.424, -0.501, 1.409, 1.4140000000000001, 1.424, -0.5, 1.1709999999999998, 1.379, 1.413, 0.498, 1.388, 0.927, 1.45, 1.355], "policy_blue_0_reward": [0.496, -1.002, 0.498, 0.499, -1.001, -1.0, -0.505, 1.455, 1.373, 1.42, 0.497, -0.503, -0.003, 1.408, 0.498, 1.463, -1.001, 0.498, -0.503, 0.46199999999999997, 0.496, -0.003, 0.498, 0.5, -0.5119999999999999, 0.46299999999999997, 1.42, -0.5019999999999999, 1.399, -1.001, -1.002, -0.502, 0.498, 0.499, -1.005, 0.489, 0.489, -0.5, 0.499, 1.4409999999999998, 0.491, 1.214, 0.499, 1.4489999999999998, -1.001, -0.502, -0.503, 0.494, 0.498, -0.505, 1.409, 1.21, 1.467, -0.5029999999999999, 1.384, 0.0, 0.498, 1.413, 0.912, 1.427, 0.498, 0.498, 0.499, 1.391, -0.501, -0.002, -0.003, -0.007, -0.5069999999999999, -0.004, 1.349, -1.007, 1.4020000000000001, -0.502, 0.495, -1.002, -0.501, -0.502, -0.508, -1.002, -0.501, -0.501, 0.498, 0.497, -0.506, -0.5, 0.497, -0.511, -0.504, 1.399, -0.5, 0.911, -1.001, -0.501, -1.004, 0.498, -1.001, -0.5, -0.505, 0.5, 1.446, -0.501, -0.502, -1.0, 0.976, 0.487, 0.498, -0.504, 1.452, -0.003, -0.502, -0.501, -0.505]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3913245196448925, "mean_inference_ms": 7.42854357865226, "mean_action_processing_ms": 0.38934158534200614, "mean_env_wait_ms": 0.5168505481562206, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13202291674318567, "StateBufferConnector_ms": 0.008815052235021001, "ViewRequirementAgentConnector_ms": 0.1751523102279258}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.080542764748, "num_env_steps_trained_throughput_per_sec": 131.080542764748, "timesteps_total": 312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 32084.357, "sample_time_ms": 4060.799, "learn_time_ms": 27993.273, "learn_throughput": 142.891, "synch_weights_time_ms": 28.683}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "episodes_total": 4142, "training_iteration": 78, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-38-21", "timestamp": 1694839101, "time_this_iter_s": 30.533213138580322, "time_total_s": 2430.3642015457153, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21985360>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2430.3642015457153, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 24.854545454545452, "ram_util_percent": 57.03409090909091}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.25, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.4, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.15, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.4, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.19, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.15, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.4, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.15, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6391038576140999, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05262386942243514, "policy_loss": -0.101678161573606, "vf_loss": 0.03865809012495447, "vf_explained_var": 0.5912260469049215, "kl": 0.01366852203385613, "entropy": 1.4133543434242408, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 75360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6423764933521549, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05942126756708603, "policy_loss": -0.11147530281596119, "vf_loss": 0.04511999841585445, "vf_explained_var": 0.5599935001383225, "kl": 0.013632165695332788, "entropy": 1.5617424013713996, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 75360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 632000, "num_agent_steps_trained": 632000}, "sampler_results": {"episode_reward_max": 1.95, "episode_reward_min": -0.129, "episode_reward_mean": 1.15056, "episode_len_mean": 40.05, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.466}, "policy_reward_mean": {"red_0": 0.86469, "blue_0": 0.28587}, "custom_metrics": {"red_0/door_open_done_mean": 0.25, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.4, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.15, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.4, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.19, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.15, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.4, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.15, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.7029999999999998, 1.927, 0.41999999999999993, 0.9319999999999999, 1.901, -0.129, 0.43100000000000005, 0.923, 1.928, 1.9140000000000001, 0.9449999999999998, 1.827, 0.45599999999999996, 1.927, 1.9329999999999998, 1.8780000000000001, 1.855, -0.06300000000000006, 1.766, 1.455, 0.31299999999999994, 0.43299999999999983, 0.9329999999999999, 1.783, 1.319, 0.9470000000000001, 0.43199999999999994, 0.9409999999999998, 0.393, 0.8639999999999999, 1.8239999999999998, 1.851, 1.454, 0.4750000000000001, 0.96, 0.965, 0.712, 1.4220000000000002, 0.747, 1.95, 0.377, 0.944, 0.3839999999999999, 0.9100000000000001, 0.42799999999999994, 0.44899999999999995, 1.921, 1.333, 0.9470000000000001, 0.907, 1.9289999999999998, 0.9349999999999999, 1.432, 0.9630000000000001, 0.469, 0.948, 1.8239999999999998, 1.635, 0.395, 0.962, 0.7969999999999999, 1.95, 1.813, 0.382, 1.942, 0.8660000000000001, 0.954, 1.88, 0.8239999999999998, 1.9449999999999998, 0.7010000000000001, 1.802, 1.9140000000000001, 1.929, -0.039000000000000035, 0.817, 0.4910000000000001, 1.883, 0.9039999999999999, 1.944, 0.41300000000000003, 1.863, 1.7029999999999998, 1.9329999999999998, 0.912, 0.46299999999999997, 1.926, 1.395, 0.7690000000000001, 1.9409999999999998, -0.030000000000000027, -0.05300000000000005, 1.8900000000000001, 0.9470000000000001, 0.927, 1.95, 1.429, 0.46499999999999997, 0.9569999999999999, 0.818], "episode_lengths": [90, 23, 24, 20, 30, 40, 22, 24, 23, 27, 18, 54, 13, 23, 22, 39, 47, 20, 74, 14, 60, 21, 300, 66, 57, 17, 21, 19, 34, 43, 55, 48, 14, 8, 13, 11, 90, 25, 76, 16, 39, 18, 36, 29, 23, 171, 25, 51, 17, 30, 22, 21, 21, 12, 10, 15, 55, 109, 33, 12, 63, 16, 57, 37, 19, 41, 14, 38, 53, 18, 93, 63, 27, 23, 12, 56, 157, 36, 31, 18, 180, 43, 91, 21, 28, 12, 24, 32, 72, 19, 10, 17, 35, 17, 23, 16, 23, 11, 14, 55], "policy_red_0_reward": [1.2149999999999999, 1.429, -0.502, 1.439, 1.4060000000000001, 0.876, 0.9319999999999999, 1.426, 1.4300000000000002, 1.415, 1.446, 0.497, 1.46, 0.498, 0.499, 0.498, 1.357, 0.938, 1.27, 1.458, 1.3159999999999998, 1.435, 0.45699999999999996, 1.292, 1.322, 1.4489999999999998, 0.9339999999999999, 1.4409999999999998, 0.898, 1.367, 1.327, 0.497, -0.004, 1.476, 1.46, -0.5, 1.224, 1.423, -0.515, 1.451, 0.881, 1.446, 0.889, 1.412, 1.429, -0.525, 0.498, 1.338, 1.4489999999999998, 1.4100000000000001, 1.434, -0.501, 1.436, 1.464, -0.5, -0.503, 0.494, 0.479, 1.4, 1.464, 1.2999999999999998, 0.5, 0.491, -0.503, 1.443, 1.3719999999999999, -0.501, 0.496, 1.333, 0.5, 1.208, 0.496, 1.4180000000000001, 1.431, 0.964, -0.507, 1.01, 0.495, 1.4060000000000001, 1.446, 0.9359999999999999, 1.3639999999999999, 0.485, 1.435, -0.503, -0.501, 0.498, 1.4, 1.274, 0.499, -1.0, 0.949, 0.498, 1.448, 1.429, 1.452, 1.431, -1.001, 1.458, -0.511], "policy_blue_0_reward": [0.488, 0.498, 0.9219999999999999, -0.5069999999999999, 0.495, -1.005, -0.501, -0.503, 0.498, 0.499, -0.501, 1.33, -1.004, 1.429, 1.434, 1.38, 0.498, -1.001, 0.496, -0.003, -1.003, -1.002, 0.476, 0.491, -0.003, -0.502, -0.502, -0.5, -0.505, -0.503, 0.497, 1.354, 1.458, -1.001, -0.5, 1.4649999999999999, -0.512, -0.001, 1.262, 0.499, -0.504, -0.502, -0.505, -0.502, -1.001, 0.974, 1.423, -0.005, -0.5019999999999999, -0.503, 0.495, 1.436, -0.004, -0.501, 0.969, 1.451, 1.33, 1.1560000000000001, -1.005, -0.502, -0.503, 1.45, 1.322, 0.885, 0.499, -0.506, 1.455, 1.384, -0.509, 1.4449999999999998, -0.5069999999999999, 1.306, 0.496, 0.498, -1.003, 1.3239999999999998, -0.519, 1.388, -0.502, 0.498, -0.5229999999999999, 0.499, 1.218, 0.498, 1.415, 0.964, 1.428, -0.005, -0.505, 1.442, 0.97, -1.002, 1.392, -0.501, -0.502, 0.498, -0.002, 1.466, -0.501, 1.329]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3904080315181861, "mean_inference_ms": 7.434291905087198, "mean_action_processing_ms": 0.3909823466039889, "mean_env_wait_ms": 0.5172258195822451, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1409931182861328, "StateBufferConnector_ms": 0.009250283241271973, "ViewRequirementAgentConnector_ms": 0.18248271942138672}}, "episode_reward_max": 1.95, "episode_reward_min": -0.129, "episode_reward_mean": 1.15056, "episode_len_mean": 40.05, "episodes_this_iter": 100, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.466}, "policy_reward_mean": {"red_0": 0.86469, "blue_0": 0.28587}, "hist_stats": {"episode_reward": [1.7029999999999998, 1.927, 0.41999999999999993, 0.9319999999999999, 1.901, -0.129, 0.43100000000000005, 0.923, 1.928, 1.9140000000000001, 0.9449999999999998, 1.827, 0.45599999999999996, 1.927, 1.9329999999999998, 1.8780000000000001, 1.855, -0.06300000000000006, 1.766, 1.455, 0.31299999999999994, 0.43299999999999983, 0.9329999999999999, 1.783, 1.319, 0.9470000000000001, 0.43199999999999994, 0.9409999999999998, 0.393, 0.8639999999999999, 1.8239999999999998, 1.851, 1.454, 0.4750000000000001, 0.96, 0.965, 0.712, 1.4220000000000002, 0.747, 1.95, 0.377, 0.944, 0.3839999999999999, 0.9100000000000001, 0.42799999999999994, 0.44899999999999995, 1.921, 1.333, 0.9470000000000001, 0.907, 1.9289999999999998, 0.9349999999999999, 1.432, 0.9630000000000001, 0.469, 0.948, 1.8239999999999998, 1.635, 0.395, 0.962, 0.7969999999999999, 1.95, 1.813, 0.382, 1.942, 0.8660000000000001, 0.954, 1.88, 0.8239999999999998, 1.9449999999999998, 0.7010000000000001, 1.802, 1.9140000000000001, 1.929, -0.039000000000000035, 0.817, 0.4910000000000001, 1.883, 0.9039999999999999, 1.944, 0.41300000000000003, 1.863, 1.7029999999999998, 1.9329999999999998, 0.912, 0.46299999999999997, 1.926, 1.395, 0.7690000000000001, 1.9409999999999998, -0.030000000000000027, -0.05300000000000005, 1.8900000000000001, 0.9470000000000001, 0.927, 1.95, 1.429, 0.46499999999999997, 0.9569999999999999, 0.818], "episode_lengths": [90, 23, 24, 20, 30, 40, 22, 24, 23, 27, 18, 54, 13, 23, 22, 39, 47, 20, 74, 14, 60, 21, 300, 66, 57, 17, 21, 19, 34, 43, 55, 48, 14, 8, 13, 11, 90, 25, 76, 16, 39, 18, 36, 29, 23, 171, 25, 51, 17, 30, 22, 21, 21, 12, 10, 15, 55, 109, 33, 12, 63, 16, 57, 37, 19, 41, 14, 38, 53, 18, 93, 63, 27, 23, 12, 56, 157, 36, 31, 18, 180, 43, 91, 21, 28, 12, 24, 32, 72, 19, 10, 17, 35, 17, 23, 16, 23, 11, 14, 55], "policy_red_0_reward": [1.2149999999999999, 1.429, -0.502, 1.439, 1.4060000000000001, 0.876, 0.9319999999999999, 1.426, 1.4300000000000002, 1.415, 1.446, 0.497, 1.46, 0.498, 0.499, 0.498, 1.357, 0.938, 1.27, 1.458, 1.3159999999999998, 1.435, 0.45699999999999996, 1.292, 1.322, 1.4489999999999998, 0.9339999999999999, 1.4409999999999998, 0.898, 1.367, 1.327, 0.497, -0.004, 1.476, 1.46, -0.5, 1.224, 1.423, -0.515, 1.451, 0.881, 1.446, 0.889, 1.412, 1.429, -0.525, 0.498, 1.338, 1.4489999999999998, 1.4100000000000001, 1.434, -0.501, 1.436, 1.464, -0.5, -0.503, 0.494, 0.479, 1.4, 1.464, 1.2999999999999998, 0.5, 0.491, -0.503, 1.443, 1.3719999999999999, -0.501, 0.496, 1.333, 0.5, 1.208, 0.496, 1.4180000000000001, 1.431, 0.964, -0.507, 1.01, 0.495, 1.4060000000000001, 1.446, 0.9359999999999999, 1.3639999999999999, 0.485, 1.435, -0.503, -0.501, 0.498, 1.4, 1.274, 0.499, -1.0, 0.949, 0.498, 1.448, 1.429, 1.452, 1.431, -1.001, 1.458, -0.511], "policy_blue_0_reward": [0.488, 0.498, 0.9219999999999999, -0.5069999999999999, 0.495, -1.005, -0.501, -0.503, 0.498, 0.499, -0.501, 1.33, -1.004, 1.429, 1.434, 1.38, 0.498, -1.001, 0.496, -0.003, -1.003, -1.002, 0.476, 0.491, -0.003, -0.502, -0.502, -0.5, -0.505, -0.503, 0.497, 1.354, 1.458, -1.001, -0.5, 1.4649999999999999, -0.512, -0.001, 1.262, 0.499, -0.504, -0.502, -0.505, -0.502, -1.001, 0.974, 1.423, -0.005, -0.5019999999999999, -0.503, 0.495, 1.436, -0.004, -0.501, 0.969, 1.451, 1.33, 1.1560000000000001, -1.005, -0.502, -0.503, 1.45, 1.322, 0.885, 0.499, -0.506, 1.455, 1.384, -0.509, 1.4449999999999998, -0.5069999999999999, 1.306, 0.496, 0.498, -1.003, 1.3239999999999998, -0.519, 1.388, -0.502, 0.498, -0.5229999999999999, 0.499, 1.218, 0.498, 1.415, 0.964, 1.428, -0.005, -0.505, 1.442, 0.97, -1.002, 1.392, -0.501, -0.502, 0.498, -0.002, 1.466, -0.501, 1.329]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3904080315181861, "mean_inference_ms": 7.434291905087198, "mean_action_processing_ms": 0.3909823466039889, "mean_env_wait_ms": 0.5172258195822451, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1409931182861328, "StateBufferConnector_ms": 0.009250283241271973, "ViewRequirementAgentConnector_ms": 0.18248271942138672}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 632000, "num_agent_steps_trained": 632000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 124.56421184630125, "num_env_steps_trained_throughput_per_sec": 124.56421184630125, "timesteps_total": 316000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 632000, "timers": {"training_iteration_time_ms": 32110.984, "sample_time_ms": 4063.802, "learn_time_ms": 28016.746, "learn_throughput": 142.772, "synch_weights_time_ms": 28.876}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 632000, "num_agent_steps_trained": 632000}, "done": false, "episodes_total": 4242, "training_iteration": 79, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-38-54", "timestamp": 1694839134, "time_this_iter_s": 32.1279239654541, "time_total_s": 2462.4921255111694, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a21d6c0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2462.4921255111694, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 24.815217391304348, "ram_util_percent": 57.067391304347815}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.3, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.41, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.41, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.22, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.06, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.41, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6487514299340547, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.058141161467453156, "policy_loss": -0.10083306138161181, "vf_loss": 0.02480536915002934, "vf_explained_var": 0.6595500767230987, "kl": 0.013916530297613782, "entropy": 1.4143807259698709, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 76320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6077847702428698, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06199441921198741, "policy_loss": -0.10605414136152831, "vf_loss": 0.03318689118217056, "vf_explained_var": 0.6210887905831138, "kl": 0.01275156674608255, "entropy": 1.5833864890038967, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 76320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.14300000000000002, "episode_reward_mean": 1.2031100000000001, "episode_len_mean": 37.65, "episode_media": {}, "episodes_this_iter": 92, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.011}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.466}, "policy_reward_mean": {"red_0": 1.00121, "blue_0": 0.20189999999999997}, "custom_metrics": {"red_0/door_open_done_mean": 0.3, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.41, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.41, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.22, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.06, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.41, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.8900000000000001, 0.9470000000000001, 0.927, 1.95, 1.429, 0.46499999999999997, 0.9569999999999999, 0.818, 0.954, 1.955, 0.41500000000000004, 1.355, 0.9039999999999999, 0.8900000000000001, 1.952, 0.774, 0.895, 0.43999999999999995, 0.8330000000000002, 1.952, 0.9179999999999999, 1.351, 1.923, 0.4119999999999999, 1.391, 1.892, 1.672, 1.4180000000000001, 1.9140000000000001, 0.381, 1.857, 1.94, 1.919, 1.3599999999999999, 0.964, -0.121, 0.9460000000000002, 1.916, 1.95, 1.9100000000000001, -0.05400000000000005, 1.428, 1.451, 0.41200000000000003, 1.8439999999999999, 1.903, 1.44, 0.44799999999999995, 0.476, 0.39800000000000013, 0.3799999999999999, 1.939, 1.936, 0.45500000000000007, 1.857, 1.915, 0.8839999999999999, 1.411, 0.643, 1.351, 1.893, 1.9020000000000001, 0.33499999999999996, 1.93, 1.931, 1.944, 0.46099999999999985, 0.46799999999999997, 1.3900000000000001, 1.826, 1.9180000000000001, 0.905, 1.8639999999999999, 0.44399999999999995, 0.3540000000000001, 1.956, 0.9100000000000001, 1.921, 0.9319999999999999, 0.3660000000000001, 0.42100000000000004, 0.43999999999999995, 1.923, 0.952, 1.416, 0.47, 1.909, 1.9609999999999999, 1.937, -0.06300000000000006, -0.14300000000000002, 1.349, 0.8580000000000001, 1.9369999999999998, 1.904, -0.03500000000000003, 0.45299999999999985, 0.9319999999999999, 1.944, 0.964], "episode_lengths": [35, 17, 23, 16, 23, 11, 14, 55, 15, 15, 25, 47, 29, 34, 16, 69, 33, 19, 51, 15, 300, 45, 25, 182, 34, 33, 102, 26, 28, 37, 45, 19, 26, 44, 12, 36, 17, 26, 16, 29, 17, 23, 16, 28, 49, 31, 20, 17, 8, 32, 38, 19, 20, 14, 46, 27, 36, 28, 110, 200, 33, 30, 52, 22, 23, 17, 13, 10, 34, 53, 26, 29, 43, 18, 46, 14, 29, 25, 22, 39, 23, 170, 23, 15, 27, 161, 29, 13, 20, 20, 44, 47, 45, 20, 29, 11, 15, 22, 18, 12], "policy_red_0_reward": [0.498, 1.448, 1.429, 1.452, 1.431, -1.001, 1.458, -0.511, 1.454, 1.455, -0.508, 1.357, 1.4100000000000001, 1.3940000000000001, 0.5, 1.281, 1.397, 0.942, 1.342, 1.454, 0.45899999999999996, 1.359, 0.498, -0.52, 1.395, 1.396, 1.184, -0.001, 0.498, 1.385, 0.497, 0.499, 0.5, -0.006, 1.464, 0.89, 1.4489999999999998, 0.498, 1.452, 0.497, 0.948, 0.0, 1.451, -0.502, 1.347, 1.4060000000000001, 1.44, 1.4489999999999998, 0.976, 0.9, 1.385, 1.443, 0.499, 1.4569999999999999, 0.496, 1.4180000000000001, 1.3900000000000001, 1.416, 1.153, 0.471, 1.3980000000000001, 1.404, 1.3399999999999999, 1.432, 1.431, 1.446, 0.961, 1.47, 1.3940000000000001, 1.338, 0.497, 1.412, 0.497, 1.4449999999999998, 0.858, 1.458, 1.412, 1.425, 1.4329999999999998, 1.3719999999999999, 1.424, 0.963, 1.4300000000000002, -0.501, 1.417, 0.998, 0.498, 0.5, 1.439, 0.939, 0.865, -0.002, 1.361, 1.438, 0.496, 0.967, 1.4529999999999998, 1.4329999999999998, 0.498, 1.464], "policy_blue_0_reward": [1.392, -0.501, -0.502, 0.498, -0.002, 1.466, -0.501, 1.329, -0.5, 0.5, 0.923, -0.002, -0.506, -0.5039999999999999, 1.452, -0.507, -0.502, -0.502, -0.5089999999999999, 0.498, 0.45899999999999996, -0.008, 1.425, 0.9319999999999999, -0.004, 0.496, 0.488, 1.419, 1.416, -1.004, 1.3599999999999999, 1.4409999999999998, 1.419, 1.366, -0.5, -1.011, -0.5029999999999999, 1.4180000000000001, 0.498, 1.413, -1.002, 1.428, 0.0, 0.914, 0.497, 0.497, 0.0, -1.001, -0.5, -0.502, -1.005, 0.496, 1.4369999999999998, -1.002, 1.361, 0.497, -0.506, -0.005, -0.51, 0.88, 0.495, 0.498, -1.005, 0.498, 0.5, 0.498, -0.5, -1.002, -0.004, 0.488, 1.421, -0.507, 1.367, -1.001, -0.504, 0.498, -0.502, 0.496, -0.501, -1.006, -1.003, -0.523, 0.493, 1.4529999999999998, -0.001, -0.528, 1.411, 1.4609999999999999, 0.498, -1.002, -1.008, 1.351, -0.503, 0.499, 1.408, -1.002, -1.0, -0.501, 1.446, -0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3909142718747387, "mean_inference_ms": 7.440448306865164, "mean_action_processing_ms": 0.3898923538752899, "mean_env_wait_ms": 0.5173984908850352, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15877938270568848, "StateBufferConnector_ms": 0.009818553924560547, "ViewRequirementAgentConnector_ms": 0.19578683376312256}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.14300000000000002, "episode_reward_mean": 1.2031100000000001, "episode_len_mean": 37.65, "episodes_this_iter": 92, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.011}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.466}, "policy_reward_mean": {"red_0": 1.00121, "blue_0": 0.20189999999999997}, "hist_stats": {"episode_reward": [1.8900000000000001, 0.9470000000000001, 0.927, 1.95, 1.429, 0.46499999999999997, 0.9569999999999999, 0.818, 0.954, 1.955, 0.41500000000000004, 1.355, 0.9039999999999999, 0.8900000000000001, 1.952, 0.774, 0.895, 0.43999999999999995, 0.8330000000000002, 1.952, 0.9179999999999999, 1.351, 1.923, 0.4119999999999999, 1.391, 1.892, 1.672, 1.4180000000000001, 1.9140000000000001, 0.381, 1.857, 1.94, 1.919, 1.3599999999999999, 0.964, -0.121, 0.9460000000000002, 1.916, 1.95, 1.9100000000000001, -0.05400000000000005, 1.428, 1.451, 0.41200000000000003, 1.8439999999999999, 1.903, 1.44, 0.44799999999999995, 0.476, 0.39800000000000013, 0.3799999999999999, 1.939, 1.936, 0.45500000000000007, 1.857, 1.915, 0.8839999999999999, 1.411, 0.643, 1.351, 1.893, 1.9020000000000001, 0.33499999999999996, 1.93, 1.931, 1.944, 0.46099999999999985, 0.46799999999999997, 1.3900000000000001, 1.826, 1.9180000000000001, 0.905, 1.8639999999999999, 0.44399999999999995, 0.3540000000000001, 1.956, 0.9100000000000001, 1.921, 0.9319999999999999, 0.3660000000000001, 0.42100000000000004, 0.43999999999999995, 1.923, 0.952, 1.416, 0.47, 1.909, 1.9609999999999999, 1.937, -0.06300000000000006, -0.14300000000000002, 1.349, 0.8580000000000001, 1.9369999999999998, 1.904, -0.03500000000000003, 0.45299999999999985, 0.9319999999999999, 1.944, 0.964], "episode_lengths": [35, 17, 23, 16, 23, 11, 14, 55, 15, 15, 25, 47, 29, 34, 16, 69, 33, 19, 51, 15, 300, 45, 25, 182, 34, 33, 102, 26, 28, 37, 45, 19, 26, 44, 12, 36, 17, 26, 16, 29, 17, 23, 16, 28, 49, 31, 20, 17, 8, 32, 38, 19, 20, 14, 46, 27, 36, 28, 110, 200, 33, 30, 52, 22, 23, 17, 13, 10, 34, 53, 26, 29, 43, 18, 46, 14, 29, 25, 22, 39, 23, 170, 23, 15, 27, 161, 29, 13, 20, 20, 44, 47, 45, 20, 29, 11, 15, 22, 18, 12], "policy_red_0_reward": [0.498, 1.448, 1.429, 1.452, 1.431, -1.001, 1.458, -0.511, 1.454, 1.455, -0.508, 1.357, 1.4100000000000001, 1.3940000000000001, 0.5, 1.281, 1.397, 0.942, 1.342, 1.454, 0.45899999999999996, 1.359, 0.498, -0.52, 1.395, 1.396, 1.184, -0.001, 0.498, 1.385, 0.497, 0.499, 0.5, -0.006, 1.464, 0.89, 1.4489999999999998, 0.498, 1.452, 0.497, 0.948, 0.0, 1.451, -0.502, 1.347, 1.4060000000000001, 1.44, 1.4489999999999998, 0.976, 0.9, 1.385, 1.443, 0.499, 1.4569999999999999, 0.496, 1.4180000000000001, 1.3900000000000001, 1.416, 1.153, 0.471, 1.3980000000000001, 1.404, 1.3399999999999999, 1.432, 1.431, 1.446, 0.961, 1.47, 1.3940000000000001, 1.338, 0.497, 1.412, 0.497, 1.4449999999999998, 0.858, 1.458, 1.412, 1.425, 1.4329999999999998, 1.3719999999999999, 1.424, 0.963, 1.4300000000000002, -0.501, 1.417, 0.998, 0.498, 0.5, 1.439, 0.939, 0.865, -0.002, 1.361, 1.438, 0.496, 0.967, 1.4529999999999998, 1.4329999999999998, 0.498, 1.464], "policy_blue_0_reward": [1.392, -0.501, -0.502, 0.498, -0.002, 1.466, -0.501, 1.329, -0.5, 0.5, 0.923, -0.002, -0.506, -0.5039999999999999, 1.452, -0.507, -0.502, -0.502, -0.5089999999999999, 0.498, 0.45899999999999996, -0.008, 1.425, 0.9319999999999999, -0.004, 0.496, 0.488, 1.419, 1.416, -1.004, 1.3599999999999999, 1.4409999999999998, 1.419, 1.366, -0.5, -1.011, -0.5029999999999999, 1.4180000000000001, 0.498, 1.413, -1.002, 1.428, 0.0, 0.914, 0.497, 0.497, 0.0, -1.001, -0.5, -0.502, -1.005, 0.496, 1.4369999999999998, -1.002, 1.361, 0.497, -0.506, -0.005, -0.51, 0.88, 0.495, 0.498, -1.005, 0.498, 0.5, 0.498, -0.5, -1.002, -0.004, 0.488, 1.421, -0.507, 1.367, -1.001, -0.504, 0.498, -0.502, 0.496, -0.501, -1.006, -1.003, -0.523, 0.493, 1.4529999999999998, -0.001, -0.528, 1.411, 1.4609999999999999, 0.498, -1.002, -1.008, 1.351, -0.503, 0.499, 1.408, -1.002, -1.0, -0.501, 1.446, -0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3909142718747387, "mean_inference_ms": 7.440448306865164, "mean_action_processing_ms": 0.3898923538752899, "mean_env_wait_ms": 0.5173984908850352, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15877938270568848, "StateBufferConnector_ms": 0.009818553924560547, "ViewRequirementAgentConnector_ms": 0.19578683376312256}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.3866399630179, "num_env_steps_trained_throughput_per_sec": 128.3866399630179, "timesteps_total": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 31979.647, "sample_time_ms": 4063.331, "learn_time_ms": 27885.568, "learn_throughput": 143.443, "synch_weights_time_ms": 29.194}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "episodes_total": 4334, "training_iteration": 80, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-39-26", "timestamp": 1694839166, "time_this_iter_s": 31.172024726867676, "time_total_s": 2493.664150238037, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a2545e0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2493.664150238037, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 23.94347826086956, "ram_util_percent": 57.09130434782608}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.336283185840708, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.34513274336283184, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.17699115044247787, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.34513274336283184, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12389380530973451, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.17699115044247787, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.34513274336283184, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.17699115044247787, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6090713403498133, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.050653737357545955, "policy_loss": -0.10222811440811104, "vf_loss": 0.04555673003972818, "vf_explained_var": 0.5728952921926975, "kl": 0.01322625494204696, "entropy": 1.335050895313422, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 77280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6047244668627779, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05970785869188452, "policy_loss": -0.11080335987595996, "vf_loss": 0.04463146894122474, "vf_explained_var": 0.574960011181732, "kl": 0.01332508316916209, "entropy": 1.5764398301641147, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 77280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 648000, "num_agent_steps_trained": 648000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.16700000000000004, "episode_reward_mean": 1.1182477876106194, "episode_len_mean": 38.50442477876106, "episode_media": {}, "episodes_this_iter": 113, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.474}, "policy_reward_mean": {"red_0": 0.8509823008849559, "blue_0": 0.2672654867256637}, "custom_metrics": {"red_0/door_open_done_mean": 0.336283185840708, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.34513274336283184, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.17699115044247787, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.34513274336283184, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12389380530973451, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.17699115044247787, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.34513274336283184, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.17699115044247787, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.853, 0.898, 0.376, 0.09499999999999997, 1.875, -0.10100000000000009, 0.951, 0.44700000000000006, 1.435, -0.07299999999999984, 0.46699999999999997, -0.08599999999999985, 1.944, 1.911, 0.46299999999999997, 0.42399999999999993, 1.911, 1.908, 1.932, 1.874, 1.9609999999999999, 1.911, 1.946, 1.924, 0.3380000000000001, 0.691, 0.45399999999999996, 1.915, 0.28200000000000003, 1.4180000000000001, 0.9229999999999999, 0.44399999999999995, 1.915, 1.9140000000000001, 1.438, 1.8780000000000001, 1.806, 1.9449999999999998, 0.6560000000000001, 1.935, 0.43699999999999983, 1.431, 0.8640000000000001, 1.424, -0.08399999999999985, 1.46, 0.403, -0.03700000000000003, 0.974, 0.831, 1.416, 1.928, 0.95, 0.9260000000000002, 1.834, 0.935, 1.111, 0.474, 1.8860000000000001, 0.9470000000000001, 0.7809999999999999, 0.6259999999999999, 0.964, 1.43, 0.94, 0.958, 0.395, 1.4209999999999998, 0.9309999999999999, 1.945, 0.41700000000000004, 0.919, 1.776, 0.9199999999999999, 1.8119999999999998, -0.041000000000000036, 0.43900000000000006, 0.42700000000000005, 0.901, 1.7639999999999998, 1.948, 1.822, 1.775, 1.955, 1.95, 0.43999999999999995, 0.946, 0.9269999999999999, -0.16700000000000004, 1.8860000000000001, 0.915, 1.948, 1.926, 0.391, 1.425, 1.915, 0.5399999999999999, 0.7989999999999999, -0.04200000000000004, 1.403, 1.928, 1.9569999999999999, 0.42799999999999994, 1.9609999999999999, 0.931, 0.9609999999999999, 0.95, 0.41100000000000003, 0.44200000000000017, 0.44300000000000006, 1.3679999999999999, 1.4329999999999998, 0.41400000000000015], "episode_lengths": [48, 33, 38, 126, 39, 186, 16, 17, 20, 23, 11, 27, 18, 26, 12, 25, 27, 29, 22, 38, 13, 26, 17, 24, 53, 93, 15, 26, 68, 26, 24, 17, 27, 27, 20, 39, 62, 18, 105, 20, 20, 23, 41, 24, 26, 13, 30, 12, 8, 54, 26, 23, 16, 23, 52, 20, 119, 8, 37, 17, 67, 116, 12, 22, 19, 13, 32, 24, 300, 18, 26, 25, 71, 26, 57, 12, 20, 23, 31, 73, 16, 55, 70, 14, 16, 19, 17, 300, 52, 36, 26, 17, 24, 35, 23, 28, 141, 62, 14, 31, 23, 14, 22, 13, 22, 13, 16, 28, 19, 17, 40, 22, 26], "policy_red_0_reward": [0.497, -0.5, -0.503, 1.108, 1.381, 0.9159999999999999, -0.501, 1.448, 1.438, 0.93, -0.5, -1.002, 0.499, 1.417, -0.5, 0.925, 0.497, 1.4100000000000001, 1.4329999999999998, 1.3820000000000001, 1.4609999999999999, 1.4180000000000001, 1.448, 0.499, 0.84, -0.516, 1.455, 1.419, 0.787, -0.001, -0.502, -0.501, 1.4180000000000001, 1.4180000000000001, 1.44, 1.3820000000000001, 1.31, 0.5, 1.174, 1.439, 0.938, 1.431, -0.5059999999999999, 1.426, 0.92, 1.4609999999999999, 0.909, 0.963, -0.5, 1.334, -0.002, 0.499, 1.451, 1.428, 0.496, 1.439, 1.13, 1.476, 1.388, 1.448, 1.2919999999999998, 1.1400000000000001, -0.5, 1.432, 1.442, 1.46, -0.5, 1.4249999999999998, 0.45899999999999996, 1.446, -1.0, 1.421, 1.282, 1.421, 1.322, 0.962, 1.439, 1.429, -0.501, 1.273, 1.452, 0.493, 0.492, 0.497, 1.451, -0.501, -0.501, 0.45399999999999996, 0.838, 0.499, 1.417, 1.448, 1.427, -0.501, 1.4300000000000002, 1.416, -0.518, 1.31, 0.958, 1.4060000000000001, 1.4300000000000002, 1.4569999999999999, -1.005, 0.5, 1.4329999999999998, 1.4609999999999999, 1.451, 1.415, 0.943, 1.448, 1.373, 1.434, 0.918], "policy_blue_0_reward": [1.3559999999999999, 1.3980000000000001, 0.879, -1.013, 0.494, -1.017, 1.452, -1.001, -0.003, -1.003, 0.967, 0.916, 1.4449999999999998, 0.494, 0.963, -0.501, 1.4140000000000001, 0.498, 0.499, 0.492, 0.5, 0.493, 0.498, 1.4249999999999998, -0.502, 1.2069999999999999, -1.001, 0.496, -0.505, 1.419, 1.4249999999999998, 0.945, 0.497, 0.496, -0.002, 0.496, 0.496, 1.4449999999999998, -0.518, 0.496, -0.501, 0.0, 1.37, -0.002, -1.0039999999999998, -0.001, -0.506, -1.0, 1.474, -0.503, 1.4180000000000001, 1.429, -0.501, -0.502, 1.338, -0.504, -0.01900000000000001, -1.002, 0.498, -0.5009999999999999, -0.511, -0.514, 1.464, -0.002, -0.502, -0.502, 0.895, -0.004, 0.472, 0.499, 1.417, -0.502, 0.494, -0.501, 0.49, -1.003, -1.0, -1.002, 1.4020000000000001, 0.491, 0.496, 1.329, 1.283, 1.458, 0.499, 0.941, 1.447, 0.473, -1.005, 1.387, -0.502, 0.5, 0.499, 0.892, -0.005, 0.499, 1.0579999999999998, -0.511, -1.0, -0.003, 0.498, 0.5, 1.4329999999999998, 1.4609999999999999, -0.502, -0.5, -0.501, -1.004, -0.5009999999999999, -1.005, -0.005, -0.001, -0.504]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3913971579974052, "mean_inference_ms": 7.452343318662867, "mean_action_processing_ms": 0.39083745810291726, "mean_env_wait_ms": 0.5180150046121258, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15413265312667443, "StateBufferConnector_ms": 0.009985729656388274, "ViewRequirementAgentConnector_ms": 0.22139644200822947}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.16700000000000004, "episode_reward_mean": 1.1182477876106194, "episode_len_mean": 38.50442477876106, "episodes_this_iter": 113, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.474}, "policy_reward_mean": {"red_0": 0.8509823008849559, "blue_0": 0.2672654867256637}, "hist_stats": {"episode_reward": [1.853, 0.898, 0.376, 0.09499999999999997, 1.875, -0.10100000000000009, 0.951, 0.44700000000000006, 1.435, -0.07299999999999984, 0.46699999999999997, -0.08599999999999985, 1.944, 1.911, 0.46299999999999997, 0.42399999999999993, 1.911, 1.908, 1.932, 1.874, 1.9609999999999999, 1.911, 1.946, 1.924, 0.3380000000000001, 0.691, 0.45399999999999996, 1.915, 0.28200000000000003, 1.4180000000000001, 0.9229999999999999, 0.44399999999999995, 1.915, 1.9140000000000001, 1.438, 1.8780000000000001, 1.806, 1.9449999999999998, 0.6560000000000001, 1.935, 0.43699999999999983, 1.431, 0.8640000000000001, 1.424, -0.08399999999999985, 1.46, 0.403, -0.03700000000000003, 0.974, 0.831, 1.416, 1.928, 0.95, 0.9260000000000002, 1.834, 0.935, 1.111, 0.474, 1.8860000000000001, 0.9470000000000001, 0.7809999999999999, 0.6259999999999999, 0.964, 1.43, 0.94, 0.958, 0.395, 1.4209999999999998, 0.9309999999999999, 1.945, 0.41700000000000004, 0.919, 1.776, 0.9199999999999999, 1.8119999999999998, -0.041000000000000036, 0.43900000000000006, 0.42700000000000005, 0.901, 1.7639999999999998, 1.948, 1.822, 1.775, 1.955, 1.95, 0.43999999999999995, 0.946, 0.9269999999999999, -0.16700000000000004, 1.8860000000000001, 0.915, 1.948, 1.926, 0.391, 1.425, 1.915, 0.5399999999999999, 0.7989999999999999, -0.04200000000000004, 1.403, 1.928, 1.9569999999999999, 0.42799999999999994, 1.9609999999999999, 0.931, 0.9609999999999999, 0.95, 0.41100000000000003, 0.44200000000000017, 0.44300000000000006, 1.3679999999999999, 1.4329999999999998, 0.41400000000000015], "episode_lengths": [48, 33, 38, 126, 39, 186, 16, 17, 20, 23, 11, 27, 18, 26, 12, 25, 27, 29, 22, 38, 13, 26, 17, 24, 53, 93, 15, 26, 68, 26, 24, 17, 27, 27, 20, 39, 62, 18, 105, 20, 20, 23, 41, 24, 26, 13, 30, 12, 8, 54, 26, 23, 16, 23, 52, 20, 119, 8, 37, 17, 67, 116, 12, 22, 19, 13, 32, 24, 300, 18, 26, 25, 71, 26, 57, 12, 20, 23, 31, 73, 16, 55, 70, 14, 16, 19, 17, 300, 52, 36, 26, 17, 24, 35, 23, 28, 141, 62, 14, 31, 23, 14, 22, 13, 22, 13, 16, 28, 19, 17, 40, 22, 26], "policy_red_0_reward": [0.497, -0.5, -0.503, 1.108, 1.381, 0.9159999999999999, -0.501, 1.448, 1.438, 0.93, -0.5, -1.002, 0.499, 1.417, -0.5, 0.925, 0.497, 1.4100000000000001, 1.4329999999999998, 1.3820000000000001, 1.4609999999999999, 1.4180000000000001, 1.448, 0.499, 0.84, -0.516, 1.455, 1.419, 0.787, -0.001, -0.502, -0.501, 1.4180000000000001, 1.4180000000000001, 1.44, 1.3820000000000001, 1.31, 0.5, 1.174, 1.439, 0.938, 1.431, -0.5059999999999999, 1.426, 0.92, 1.4609999999999999, 0.909, 0.963, -0.5, 1.334, -0.002, 0.499, 1.451, 1.428, 0.496, 1.439, 1.13, 1.476, 1.388, 1.448, 1.2919999999999998, 1.1400000000000001, -0.5, 1.432, 1.442, 1.46, -0.5, 1.4249999999999998, 0.45899999999999996, 1.446, -1.0, 1.421, 1.282, 1.421, 1.322, 0.962, 1.439, 1.429, -0.501, 1.273, 1.452, 0.493, 0.492, 0.497, 1.451, -0.501, -0.501, 0.45399999999999996, 0.838, 0.499, 1.417, 1.448, 1.427, -0.501, 1.4300000000000002, 1.416, -0.518, 1.31, 0.958, 1.4060000000000001, 1.4300000000000002, 1.4569999999999999, -1.005, 0.5, 1.4329999999999998, 1.4609999999999999, 1.451, 1.415, 0.943, 1.448, 1.373, 1.434, 0.918], "policy_blue_0_reward": [1.3559999999999999, 1.3980000000000001, 0.879, -1.013, 0.494, -1.017, 1.452, -1.001, -0.003, -1.003, 0.967, 0.916, 1.4449999999999998, 0.494, 0.963, -0.501, 1.4140000000000001, 0.498, 0.499, 0.492, 0.5, 0.493, 0.498, 1.4249999999999998, -0.502, 1.2069999999999999, -1.001, 0.496, -0.505, 1.419, 1.4249999999999998, 0.945, 0.497, 0.496, -0.002, 0.496, 0.496, 1.4449999999999998, -0.518, 0.496, -0.501, 0.0, 1.37, -0.002, -1.0039999999999998, -0.001, -0.506, -1.0, 1.474, -0.503, 1.4180000000000001, 1.429, -0.501, -0.502, 1.338, -0.504, -0.01900000000000001, -1.002, 0.498, -0.5009999999999999, -0.511, -0.514, 1.464, -0.002, -0.502, -0.502, 0.895, -0.004, 0.472, 0.499, 1.417, -0.502, 0.494, -0.501, 0.49, -1.003, -1.0, -1.002, 1.4020000000000001, 0.491, 0.496, 1.329, 1.283, 1.458, 0.499, 0.941, 1.447, 0.473, -1.005, 1.387, -0.502, 0.5, 0.499, 0.892, -0.005, 0.499, 1.0579999999999998, -0.511, -1.0, -0.003, 0.498, 0.5, 1.4329999999999998, 1.4609999999999999, -0.502, -0.5, -0.501, -1.004, -0.5009999999999999, -1.005, -0.005, -0.001, -0.504]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3913971579974052, "mean_inference_ms": 7.452343318662867, "mean_action_processing_ms": 0.39083745810291726, "mean_env_wait_ms": 0.5180150046121258, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15413265312667443, "StateBufferConnector_ms": 0.009985729656388274, "ViewRequirementAgentConnector_ms": 0.22139644200822947}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 648000, "num_agent_steps_trained": 648000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 121.24037722449236, "num_env_steps_trained_throughput_per_sec": 121.24037722449236, "timesteps_total": 324000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 648000, "timers": {"training_iteration_time_ms": 31625.223, "sample_time_ms": 4061.856, "learn_time_ms": 27532.956, "learn_throughput": 145.28, "synch_weights_time_ms": 28.891}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 648000, "num_agent_steps_trained": 648000}, "done": false, "episodes_total": 4447, "training_iteration": 81, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-39-59", "timestamp": 1694839199, "time_this_iter_s": 33.01047396659851, "time_total_s": 2526.6746242046356, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21985f30>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2526.6746242046356, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 28.339583333333337, "ram_util_percent": 57.143750000000004}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.31, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.42, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.12, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.42, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.12, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.42, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.12, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6231012323250373, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05788688363487988, "policy_loss": -0.10321513964008773, "vf_loss": 0.03222343935049139, "vf_explained_var": 0.6145775546009342, "kl": 0.013449160453957077, "entropy": 1.4223331447690726, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 78240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6342680714403589, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06372102120270332, "policy_loss": -0.10755567935896883, "vf_loss": 0.031393926842914276, "vf_explained_var": 0.6139162259797255, "kl": 0.013047619084828273, "entropy": 1.586412916208307, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 78240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.5030000000000001, "episode_reward_mean": 1.02788, "episode_len_mean": 43.96, "episode_media": {}, "episodes_this_iter": 90, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.014}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.9250299999999999, "blue_0": 0.10285}, "custom_metrics": {"red_0/door_open_done_mean": 0.31, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.42, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.12, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.42, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.12, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.42, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.12, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.9609999999999999, 0.931, 0.9609999999999999, 0.95, 0.41100000000000003, 0.44200000000000017, 0.44300000000000006, 1.3679999999999999, 1.4329999999999998, 0.41400000000000015, 1.4729999999999999, 1.435, 0.41100000000000003, 1.833, 1.905, 1.742, 0.6499999999999999, 1.307, 0.3039999999999998, 1.877, 1.4489999999999998, -0.05300000000000005, 1.9260000000000002, 1.8820000000000001, 1.881, 1.94, 1.354, 0.732, 0.73, 0.2589999999999999, 1.893, 0.9369999999999999, 1.897, 1.413, -0.04400000000000004, 1.958, 0.6099999999999999, 1.439, 1.943, 0.15699999999999992, 1.456, 0.44999999999999996, 0.2610000000000001, 0.915, -0.07200000000000006, 1.9130000000000003, 1.338, 0.4159999999999999, 1.9140000000000001, 1.9060000000000001, 0.8839999999999999, -0.125, -0.121, 0.09499999999999997, 0.41900000000000004, 0.851, 0.43699999999999983, 0.45799999999999996, 1.956, 1.893, 1.9289999999999998, -0.06099999999999994, 0.398, 1.8679999999999999, 1.9050000000000002, 0.42700000000000005, 0.873, 0.3900000000000001, 0.43299999999999983, 1.955, 1.9529999999999998, 1.455, 0.47, 0.8010000000000002, -0.07299999999999995, 0.894, 1.9329999999999998, 0.39800000000000013, 1.924, 0.383, 1.958, 1.557, 0.34399999999999986, 1.913, -0.5030000000000001, 1.88, 1.403, 0.42600000000000005, 0.9309999999999999, 0.872, 0.403, 0.40200000000000014, 1.875, -0.039000000000000035, 1.927, 0.405, 0.42800000000000016, 0.4039999999999999, 0.3719999999999999, 1.7770000000000001], "episode_lengths": [13, 22, 13, 16, 28, 19, 17, 40, 22, 26, 161, 21, 28, 50, 30, 79, 112, 60, 218, 39, 17, 16, 23, 36, 37, 19, 45, 81, 84, 73, 34, 20, 32, 27, 14, 14, 120, 20, 18, 259, 14, 15, 75, 27, 21, 27, 51, 27, 26, 30, 38, 40, 36, 124, 26, 46, 20, 14, 14, 34, 22, 18, 32, 41, 30, 23, 41, 34, 21, 15, 15, 15, 10, 62, 23, 34, 21, 31, 24, 36, 14, 135, 50, 26, 155, 37, 31, 23, 300, 40, 29, 31, 39, 13, 23, 31, 23, 29, 41, 70], "policy_red_0_reward": [0.5, 1.4329999999999998, 1.4609999999999999, 1.451, 1.415, 0.943, 1.448, 1.373, 1.434, 0.918, 0.991, 1.4369999999999998, 1.416, 0.492, 0.497, 0.491, -0.505, 1.314, 0.829, 1.379, 1.4489999999999998, 0.951, 1.429, 1.385, 0.496, 0.5, 1.362, 1.245, 1.241, 1.2719999999999998, 1.396, -0.502, 1.403, 1.4180000000000001, -1.002, 0.5, 1.1269999999999998, 1.44, 0.5, -0.54, 1.458, -0.501, 1.268, 1.4180000000000001, 0.9339999999999999, 1.416, 1.341, 1.4180000000000001, 1.417, 1.4060000000000001, 1.3860000000000001, 0.878, 0.89, 1.109, 1.4220000000000002, -0.506, 0.94, 0.958, 1.458, 1.396, 1.432, 0.943, -0.503, 0.497, 1.408, 0.929, -0.5, 1.393, 0.9369999999999999, 0.5, 1.455, 1.455, 0.97, 1.307, 0.931, -0.501, 1.436, 1.405, 1.426, 0.888, 0.5, 0.477, 1.347, 1.42, 0.5109999999999999, 1.3860000000000001, 1.404, -0.501, 0.46399999999999997, -0.504, -0.507, 0.905, 0.495, 0.961, 1.431, 1.405, 1.429, 0.91, 1.375, 0.494], "policy_blue_0_reward": [1.4609999999999999, -0.502, -0.5, -0.501, -1.004, -0.5009999999999999, -1.005, -0.005, -0.001, -0.504, 0.482, -0.002, -1.005, 1.341, 1.408, 1.251, 1.1549999999999998, -0.007, -0.525, 0.498, 0.0, -1.004, 0.497, 0.497, 1.385, 1.44, -0.008, -0.513, -0.511, -1.013, 0.497, 1.439, 0.494, -0.005, 0.958, 1.458, -0.517, -0.001, 1.443, 0.697, -0.002, 0.951, -1.007, -0.503, -1.006, 0.497, -0.003, -1.002, 0.497, 0.5, -0.502, -1.003, -1.011, -1.014, -1.003, 1.357, -0.503, -0.5, 0.498, 0.497, 0.497, -1.0039999999999998, 0.901, 1.371, 0.497, -0.502, 1.373, -1.003, -0.504, 1.455, 0.498, 0.0, -0.5, -0.506, -1.004, 1.395, 0.497, -1.007, 0.498, -0.505, 1.458, 1.08, -1.003, 0.493, -1.014, 0.494, -0.001, 0.927, 0.46699999999999997, 1.376, 0.91, -0.5029999999999999, 1.38, -1.0, 0.496, -1.0, -1.001, -0.506, -1.003, 1.283]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3933736166737691, "mean_inference_ms": 7.447078798482489, "mean_action_processing_ms": 0.3899598349381856, "mean_env_wait_ms": 0.518493718741373, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14368903636932373, "StateBufferConnector_ms": 0.009388089179992676, "ViewRequirementAgentConnector_ms": 0.1887146234512329}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.5030000000000001, "episode_reward_mean": 1.02788, "episode_len_mean": 43.96, "episodes_this_iter": 90, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.014}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.9250299999999999, "blue_0": 0.10285}, "hist_stats": {"episode_reward": [1.9609999999999999, 0.931, 0.9609999999999999, 0.95, 0.41100000000000003, 0.44200000000000017, 0.44300000000000006, 1.3679999999999999, 1.4329999999999998, 0.41400000000000015, 1.4729999999999999, 1.435, 0.41100000000000003, 1.833, 1.905, 1.742, 0.6499999999999999, 1.307, 0.3039999999999998, 1.877, 1.4489999999999998, -0.05300000000000005, 1.9260000000000002, 1.8820000000000001, 1.881, 1.94, 1.354, 0.732, 0.73, 0.2589999999999999, 1.893, 0.9369999999999999, 1.897, 1.413, -0.04400000000000004, 1.958, 0.6099999999999999, 1.439, 1.943, 0.15699999999999992, 1.456, 0.44999999999999996, 0.2610000000000001, 0.915, -0.07200000000000006, 1.9130000000000003, 1.338, 0.4159999999999999, 1.9140000000000001, 1.9060000000000001, 0.8839999999999999, -0.125, -0.121, 0.09499999999999997, 0.41900000000000004, 0.851, 0.43699999999999983, 0.45799999999999996, 1.956, 1.893, 1.9289999999999998, -0.06099999999999994, 0.398, 1.8679999999999999, 1.9050000000000002, 0.42700000000000005, 0.873, 0.3900000000000001, 0.43299999999999983, 1.955, 1.9529999999999998, 1.455, 0.47, 0.8010000000000002, -0.07299999999999995, 0.894, 1.9329999999999998, 0.39800000000000013, 1.924, 0.383, 1.958, 1.557, 0.34399999999999986, 1.913, -0.5030000000000001, 1.88, 1.403, 0.42600000000000005, 0.9309999999999999, 0.872, 0.403, 0.40200000000000014, 1.875, -0.039000000000000035, 1.927, 0.405, 0.42800000000000016, 0.4039999999999999, 0.3719999999999999, 1.7770000000000001], "episode_lengths": [13, 22, 13, 16, 28, 19, 17, 40, 22, 26, 161, 21, 28, 50, 30, 79, 112, 60, 218, 39, 17, 16, 23, 36, 37, 19, 45, 81, 84, 73, 34, 20, 32, 27, 14, 14, 120, 20, 18, 259, 14, 15, 75, 27, 21, 27, 51, 27, 26, 30, 38, 40, 36, 124, 26, 46, 20, 14, 14, 34, 22, 18, 32, 41, 30, 23, 41, 34, 21, 15, 15, 15, 10, 62, 23, 34, 21, 31, 24, 36, 14, 135, 50, 26, 155, 37, 31, 23, 300, 40, 29, 31, 39, 13, 23, 31, 23, 29, 41, 70], "policy_red_0_reward": [0.5, 1.4329999999999998, 1.4609999999999999, 1.451, 1.415, 0.943, 1.448, 1.373, 1.434, 0.918, 0.991, 1.4369999999999998, 1.416, 0.492, 0.497, 0.491, -0.505, 1.314, 0.829, 1.379, 1.4489999999999998, 0.951, 1.429, 1.385, 0.496, 0.5, 1.362, 1.245, 1.241, 1.2719999999999998, 1.396, -0.502, 1.403, 1.4180000000000001, -1.002, 0.5, 1.1269999999999998, 1.44, 0.5, -0.54, 1.458, -0.501, 1.268, 1.4180000000000001, 0.9339999999999999, 1.416, 1.341, 1.4180000000000001, 1.417, 1.4060000000000001, 1.3860000000000001, 0.878, 0.89, 1.109, 1.4220000000000002, -0.506, 0.94, 0.958, 1.458, 1.396, 1.432, 0.943, -0.503, 0.497, 1.408, 0.929, -0.5, 1.393, 0.9369999999999999, 0.5, 1.455, 1.455, 0.97, 1.307, 0.931, -0.501, 1.436, 1.405, 1.426, 0.888, 0.5, 0.477, 1.347, 1.42, 0.5109999999999999, 1.3860000000000001, 1.404, -0.501, 0.46399999999999997, -0.504, -0.507, 0.905, 0.495, 0.961, 1.431, 1.405, 1.429, 0.91, 1.375, 0.494], "policy_blue_0_reward": [1.4609999999999999, -0.502, -0.5, -0.501, -1.004, -0.5009999999999999, -1.005, -0.005, -0.001, -0.504, 0.482, -0.002, -1.005, 1.341, 1.408, 1.251, 1.1549999999999998, -0.007, -0.525, 0.498, 0.0, -1.004, 0.497, 0.497, 1.385, 1.44, -0.008, -0.513, -0.511, -1.013, 0.497, 1.439, 0.494, -0.005, 0.958, 1.458, -0.517, -0.001, 1.443, 0.697, -0.002, 0.951, -1.007, -0.503, -1.006, 0.497, -0.003, -1.002, 0.497, 0.5, -0.502, -1.003, -1.011, -1.014, -1.003, 1.357, -0.503, -0.5, 0.498, 0.497, 0.497, -1.0039999999999998, 0.901, 1.371, 0.497, -0.502, 1.373, -1.003, -0.504, 1.455, 0.498, 0.0, -0.5, -0.506, -1.004, 1.395, 0.497, -1.007, 0.498, -0.505, 1.458, 1.08, -1.003, 0.493, -1.014, 0.494, -0.001, 0.927, 0.46699999999999997, 1.376, 0.91, -0.5029999999999999, 1.38, -1.0, 0.496, -1.0, -1.001, -0.506, -1.003, 1.283]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3933736166737691, "mean_inference_ms": 7.447078798482489, "mean_action_processing_ms": 0.3899598349381856, "mean_env_wait_ms": 0.518493718741373, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14368903636932373, "StateBufferConnector_ms": 0.009388089179992676, "ViewRequirementAgentConnector_ms": 0.1887146234512329}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.59874326781171, "num_env_steps_trained_throughput_per_sec": 127.59874326781171, "timesteps_total": 328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 31555.611, "sample_time_ms": 4009.286, "learn_time_ms": 27515.979, "learn_throughput": 145.37, "synch_weights_time_ms": 28.799}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "episodes_total": 4537, "training_iteration": 82, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-40-32", "timestamp": 1694839232, "time_this_iter_s": 31.365225076675415, "time_total_s": 2558.039849281311, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a2564d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2558.039849281311, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 27.63555555555556, "ram_util_percent": 57.08444444444443}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.3925233644859813, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.35514018691588783, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.102803738317757, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.35514018691588783, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14953271028037382, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.102803738317757, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.35514018691588783, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.102803738317757, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6245365269792577, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05544201627393098, "policy_loss": -0.1018022305254514, "vf_loss": 0.03423129772224153, "vf_explained_var": 0.6257832963640492, "kl": 0.01343930817765795, "entropy": 1.3718594388415417, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 79200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6177137242630124, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.061601733781571966, "policy_loss": -0.10843057226253829, "vf_loss": 0.0377618697695046, "vf_explained_var": 0.5850588413576285, "kl": 0.012956849290723464, "entropy": 1.569419237971306, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 79200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 664000, "num_agent_steps_trained": 664000}, "sampler_results": {"episode_reward_max": 1.9569999999999999, "episode_reward_min": -0.16400000000000003, "episode_reward_mean": 1.2236542056074768, "episode_len_mean": 36.60747663551402, "episode_media": {}, "episodes_this_iter": 107, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.022}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 0.9856448598130841, "blue_0": 0.2380093457943925}, "custom_metrics": {"red_0/door_open_done_mean": 0.3925233644859813, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.35514018691588783, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.102803738317757, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.35514018691588783, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14953271028037382, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.102803738317757, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.35514018691588783, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.102803738317757, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.846, 1.8519999999999999, 1.936, 1.948, 1.867, 0.33699999999999997, 0.9529999999999998, 1.905, 0.357, 1.93, 0.86, 1.379, 1.913, 1.751, 1.94, 0.29700000000000004, 1.422, 1.917, 1.399, 1.939, 1.909, 1.685, 0.24799999999999978, 1.9569999999999999, 1.909, 0.41400000000000003, 0.8980000000000001, 0.42399999999999993, 1.9140000000000001, 1.955, -0.08699999999999997, 0.8799999999999999, 1.946, 1.928, 1.9489999999999998, 1.451, 0.40200000000000014, 0.96, 0.42300000000000004, 0.43599999999999994, 1.9220000000000002, 1.9529999999999998, 0.9409999999999998, 0.976, 1.774, 1.846, 1.905, -0.09899999999999998, 1.935, 1.903, 0.472, 0.915, 0.953, 1.4, 1.952, 0.41300000000000003, 0.9489999999999998, 1.7770000000000001, 1.919, 1.895, 1.9, 1.8359999999999999, 0.42599999999999993, 1.948, 0.94, -0.03600000000000003, -0.16400000000000003, 0.08699999999999997, 1.4569999999999999, 0.375, 1.939, 0.399, 0.4209999999999998, 1.951, 1.926, 1.881, 0.921, 0.41700000000000004, 0.15599999999999992, 0.4079999999999999, 0.973, 1.9449999999999998, 1.9409999999999998, 1.804, 0.3420000000000001, 0.43499999999999994, 0.821, 0.44199999999999995, 0.964, -0.03499999999999992, 0.7589999999999999, 1.4180000000000001, 1.299, 1.931, 0.20699999999999985, 1.439, 1.845, 1.762, 0.44799999999999995, 0.4630000000000001, 1.759, 1.859, 1.867, 1.779, 0.43599999999999994, 0.9100000000000001, 0.8799999999999999], "episode_lengths": [47, 47, 21, 17, 41, 52, 15, 31, 46, 22, 44, 37, 28, 78, 19, 62, 24, 27, 31, 20, 29, 96, 230, 14, 29, 26, 33, 24, 28, 15, 27, 39, 17, 22, 17, 16, 30, 13, 23, 20, 26, 15, 19, 8, 70, 47, 28, 30, 21, 29, 9, 27, 15, 31, 16, 27, 16, 70, 26, 33, 31, 52, 24, 17, 18, 12, 47, 127, 14, 38, 20, 31, 24, 16, 24, 38, 25, 27, 104, 30, 9, 18, 19, 61, 48, 20, 54, 18, 12, 11, 76, 25, 63, 22, 243, 19, 48, 72, 16, 12, 73, 44, 42, 67, 20, 29, 37], "policy_red_0_reward": [1.354, 1.3559999999999999, 1.436, 1.4489999999999998, 1.375, -1.002, 1.455, 0.498, 1.3599999999999999, 1.432, -0.504, 1.385, 1.4140000000000001, 1.256, 0.499, -0.511, 1.4249999999999998, 1.4180000000000001, 1.403, 1.44, 1.411, 0.49, 0.7769999999999999, 0.499, 1.4100000000000001, -0.503, 1.4, 0.9259999999999999, 1.416, 0.5, 0.916, 1.3820000000000001, 0.498, 1.431, 1.4489999999999998, 1.451, 0.906, 1.4609999999999999, 1.428, 1.439, 0.5, 1.454, 1.4409999999999998, 1.476, 0.49, 1.355, 0.495, 0.905, 1.436, 0.497, 0.972, 1.415, -0.501, -0.003, 1.452, 1.416, 1.451, 1.286, 1.42, 1.4, 0.498, 1.341, 0.9279999999999999, 1.4489999999999998, -0.503, 0.964, 0.851, 1.1059999999999999, 1.458, -1.004, 0.499, -0.505, 1.424, 1.451, 0.499, 1.384, 1.424, 1.4180000000000001, 1.178, 0.91, -0.5, 1.446, 1.443, 1.309, 1.349, -0.504, 1.329, 0.944, -0.5, 0.966, 1.268, 1.424, 1.303, 0.498, 0.7319999999999999, 1.44, 1.351, 1.276, 0.95, 1.463, 1.267, 1.362, 1.3719999999999999, 0.488, 1.439, 1.413, 1.384], "policy_blue_0_reward": [0.492, 0.496, 0.5, 0.499, 0.492, 1.339, -0.502, 1.407, -1.003, 0.498, 1.3639999999999999, -0.006, 0.499, 0.495, 1.4409999999999998, 0.808, -0.003, 0.499, -0.004, 0.499, 0.498, 1.1949999999999998, -0.529, 1.458, 0.499, 0.917, -0.502, -0.502, 0.498, 1.455, -1.003, -0.502, 1.448, 0.497, 0.5, 0.0, -0.5039999999999999, -0.501, -1.005, -1.003, 1.4220000000000002, 0.499, -0.5, -0.5, 1.284, 0.491, 1.4100000000000001, -1.004, 0.499, 1.4060000000000001, -0.5, -0.5, 1.454, 1.403, 0.5, -1.003, -0.502, 0.491, 0.499, 0.495, 1.4020000000000001, 0.495, -0.502, 0.499, 1.443, -1.0, -1.015, -1.019, -0.001, 1.379, 1.44, 0.904, -1.003, 0.5, 1.427, 0.497, -0.503, -1.001, -1.022, -0.502, 1.4729999999999999, 0.499, 0.498, 0.495, -1.007, 0.939, -0.508, -0.502, 1.464, -1.001, -0.509, -0.006, -0.004, 1.4329999999999998, -0.525, -0.001, 0.494, 0.486, -0.502, -1.0, 0.492, 0.497, 0.495, 1.291, -1.003, -0.503, -0.504]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3939760430062136, "mean_inference_ms": 7.440231977917578, "mean_action_processing_ms": 0.3915675894481177, "mean_env_wait_ms": 0.5172216150515472, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15760169965084467, "StateBufferConnector_ms": 0.010036419485216943, "ViewRequirementAgentConnector_ms": 0.20089015782436478}}, "episode_reward_max": 1.9569999999999999, "episode_reward_min": -0.16400000000000003, "episode_reward_mean": 1.2236542056074768, "episode_len_mean": 36.60747663551402, "episodes_this_iter": 107, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.022}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 0.9856448598130841, "blue_0": 0.2380093457943925}, "hist_stats": {"episode_reward": [1.846, 1.8519999999999999, 1.936, 1.948, 1.867, 0.33699999999999997, 0.9529999999999998, 1.905, 0.357, 1.93, 0.86, 1.379, 1.913, 1.751, 1.94, 0.29700000000000004, 1.422, 1.917, 1.399, 1.939, 1.909, 1.685, 0.24799999999999978, 1.9569999999999999, 1.909, 0.41400000000000003, 0.8980000000000001, 0.42399999999999993, 1.9140000000000001, 1.955, -0.08699999999999997, 0.8799999999999999, 1.946, 1.928, 1.9489999999999998, 1.451, 0.40200000000000014, 0.96, 0.42300000000000004, 0.43599999999999994, 1.9220000000000002, 1.9529999999999998, 0.9409999999999998, 0.976, 1.774, 1.846, 1.905, -0.09899999999999998, 1.935, 1.903, 0.472, 0.915, 0.953, 1.4, 1.952, 0.41300000000000003, 0.9489999999999998, 1.7770000000000001, 1.919, 1.895, 1.9, 1.8359999999999999, 0.42599999999999993, 1.948, 0.94, -0.03600000000000003, -0.16400000000000003, 0.08699999999999997, 1.4569999999999999, 0.375, 1.939, 0.399, 0.4209999999999998, 1.951, 1.926, 1.881, 0.921, 0.41700000000000004, 0.15599999999999992, 0.4079999999999999, 0.973, 1.9449999999999998, 1.9409999999999998, 1.804, 0.3420000000000001, 0.43499999999999994, 0.821, 0.44199999999999995, 0.964, -0.03499999999999992, 0.7589999999999999, 1.4180000000000001, 1.299, 1.931, 0.20699999999999985, 1.439, 1.845, 1.762, 0.44799999999999995, 0.4630000000000001, 1.759, 1.859, 1.867, 1.779, 0.43599999999999994, 0.9100000000000001, 0.8799999999999999], "episode_lengths": [47, 47, 21, 17, 41, 52, 15, 31, 46, 22, 44, 37, 28, 78, 19, 62, 24, 27, 31, 20, 29, 96, 230, 14, 29, 26, 33, 24, 28, 15, 27, 39, 17, 22, 17, 16, 30, 13, 23, 20, 26, 15, 19, 8, 70, 47, 28, 30, 21, 29, 9, 27, 15, 31, 16, 27, 16, 70, 26, 33, 31, 52, 24, 17, 18, 12, 47, 127, 14, 38, 20, 31, 24, 16, 24, 38, 25, 27, 104, 30, 9, 18, 19, 61, 48, 20, 54, 18, 12, 11, 76, 25, 63, 22, 243, 19, 48, 72, 16, 12, 73, 44, 42, 67, 20, 29, 37], "policy_red_0_reward": [1.354, 1.3559999999999999, 1.436, 1.4489999999999998, 1.375, -1.002, 1.455, 0.498, 1.3599999999999999, 1.432, -0.504, 1.385, 1.4140000000000001, 1.256, 0.499, -0.511, 1.4249999999999998, 1.4180000000000001, 1.403, 1.44, 1.411, 0.49, 0.7769999999999999, 0.499, 1.4100000000000001, -0.503, 1.4, 0.9259999999999999, 1.416, 0.5, 0.916, 1.3820000000000001, 0.498, 1.431, 1.4489999999999998, 1.451, 0.906, 1.4609999999999999, 1.428, 1.439, 0.5, 1.454, 1.4409999999999998, 1.476, 0.49, 1.355, 0.495, 0.905, 1.436, 0.497, 0.972, 1.415, -0.501, -0.003, 1.452, 1.416, 1.451, 1.286, 1.42, 1.4, 0.498, 1.341, 0.9279999999999999, 1.4489999999999998, -0.503, 0.964, 0.851, 1.1059999999999999, 1.458, -1.004, 0.499, -0.505, 1.424, 1.451, 0.499, 1.384, 1.424, 1.4180000000000001, 1.178, 0.91, -0.5, 1.446, 1.443, 1.309, 1.349, -0.504, 1.329, 0.944, -0.5, 0.966, 1.268, 1.424, 1.303, 0.498, 0.7319999999999999, 1.44, 1.351, 1.276, 0.95, 1.463, 1.267, 1.362, 1.3719999999999999, 0.488, 1.439, 1.413, 1.384], "policy_blue_0_reward": [0.492, 0.496, 0.5, 0.499, 0.492, 1.339, -0.502, 1.407, -1.003, 0.498, 1.3639999999999999, -0.006, 0.499, 0.495, 1.4409999999999998, 0.808, -0.003, 0.499, -0.004, 0.499, 0.498, 1.1949999999999998, -0.529, 1.458, 0.499, 0.917, -0.502, -0.502, 0.498, 1.455, -1.003, -0.502, 1.448, 0.497, 0.5, 0.0, -0.5039999999999999, -0.501, -1.005, -1.003, 1.4220000000000002, 0.499, -0.5, -0.5, 1.284, 0.491, 1.4100000000000001, -1.004, 0.499, 1.4060000000000001, -0.5, -0.5, 1.454, 1.403, 0.5, -1.003, -0.502, 0.491, 0.499, 0.495, 1.4020000000000001, 0.495, -0.502, 0.499, 1.443, -1.0, -1.015, -1.019, -0.001, 1.379, 1.44, 0.904, -1.003, 0.5, 1.427, 0.497, -0.503, -1.001, -1.022, -0.502, 1.4729999999999999, 0.499, 0.498, 0.495, -1.007, 0.939, -0.508, -0.502, 1.464, -1.001, -0.509, -0.006, -0.004, 1.4329999999999998, -0.525, -0.001, 0.494, 0.486, -0.502, -1.0, 0.492, 0.497, 0.495, 1.291, -1.003, -0.503, -0.504]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3939760430062136, "mean_inference_ms": 7.440231977917578, "mean_action_processing_ms": 0.3915675894481177, "mean_env_wait_ms": 0.5172216150515472, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15760169965084467, "StateBufferConnector_ms": 0.010036419485216943, "ViewRequirementAgentConnector_ms": 0.20089015782436478}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 664000, "num_agent_steps_trained": 664000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.73467288166174, "num_env_steps_trained_throughput_per_sec": 130.73467288166174, "timesteps_total": 332000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 664000, "timers": {"training_iteration_time_ms": 31419.321, "sample_time_ms": 4020.322, "learn_time_ms": 27368.757, "learn_throughput": 146.152, "synch_weights_time_ms": 28.704}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 664000, "num_agent_steps_trained": 664000}, "done": false, "episodes_total": 4644, "training_iteration": 83, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-41-04", "timestamp": 1694839264, "time_this_iter_s": 30.612154006958008, "time_total_s": 2588.652003288269, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21985480>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2588.652003288269, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 24.22222222222222, "ram_util_percent": 57.06666666666667}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.4036697247706422, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.3669724770642202, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10091743119266056, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.3669724770642202, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11926605504587157, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10091743119266056, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.3669724770642202, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10091743119266056, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6379005716492733, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05541589233131769, "policy_loss": -0.10452104595121152, "vf_loss": 0.037038157521359, "vf_explained_var": 0.5998233366757632, "kl": 0.014012042380765402, "entropy": 1.3351099734505019, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 80160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5889629441003005, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05650040981903051, "policy_loss": -0.10369442649825941, "vf_loss": 0.042154176023905164, "vf_explained_var": 0.545138851304849, "kl": 0.012147918575797327, "entropy": 1.5575492362181345, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 80160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "sampler_results": {"episode_reward_max": 1.9569999999999999, "episode_reward_min": -0.11599999999999988, "episode_reward_mean": 1.1889357798165139, "episode_len_mean": 35.20183486238532, "episode_media": {}, "episodes_this_iter": 109, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.007}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.448}, "policy_reward_mean": {"red_0": 1.0394954128440368, "blue_0": 0.1494403669724771}, "custom_metrics": {"red_0/door_open_done_mean": 0.4036697247706422, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.3669724770642202, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10091743119266056, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.3669724770642202, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11926605504587157, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10091743119266056, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.3669724770642202, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10091743119266056, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.545, 0.43999999999999995, 1.935, 1.94, 0.44299999999999995, 1.94, 1.929, 0.43000000000000016, 0.9289999999999999, 0.9449999999999998, 0.929, 1.759, 1.931, 0.46899999999999986, 1.674, 1.889, 0.8260000000000001, 0.46899999999999986, -0.03700000000000003, 1.908, 1.434, 0.43599999999999994, 0.9199999999999999, 1.9220000000000002, 1.899, 0.938, 1.4, 0.788, 1.3279999999999998, 1.447, 0.387, 1.925, 0.32799999999999985, -0.04700000000000004, 1.95, 1.7469999999999999, 1.3199999999999998, 1.4100000000000001, -0.05999999999999994, 1.904, 0.45099999999999996, 0.44399999999999995, -0.11599999999999988, 1.448, 1.888, 0.945, 0.8359999999999999, 0.41100000000000003, 0.6829999999999998, 1.9249999999999998, 0.39400000000000013, 1.423, 0.43500000000000005, 0.45100000000000007, 1.94, -0.08899999999999997, 0.9620000000000002, 1.938, 0.9140000000000001, 0.45300000000000007, 1.9300000000000002, -0.08899999999999997, 1.869, 1.861, 0.935, 1.677, 0.9119999999999999, 0.44799999999999995, 0.895, 0.405, 0.851, 1.9329999999999998, 0.9279999999999999, 1.421, 1.927, 1.9329999999999998, 1.8359999999999999, 1.8930000000000002, 1.435, 1.935, 1.911, 0.905, 1.9180000000000001, 1.415, 1.939, 0.9159999999999999, 1.837, 1.415, 1.8519999999999999, 1.912, 1.351, 0.43900000000000006, 0.44599999999999995, 1.9209999999999998, 0.8959999999999999, 0.35599999999999987, 1.884, 1.429, 1.9409999999999998, 1.9569999999999999, 1.412, 0.45399999999999996, 0.47299999999999986, 1.895, 0.46799999999999997, 0.8239999999999998, 0.42999999999999994, 0.7809999999999999, 1.877], "episode_lengths": [143, 20, 21, 18, 17, 19, 23, 23, 22, 18, 23, 75, 22, 10, 101, 35, 54, 10, 12, 29, 22, 20, 25, 25, 31, 19, 32, 65, 54, 17, 36, 23, 55, 15, 16, 73, 57, 29, 19, 29, 15, 18, 37, 17, 36, 300, 49, 27, 100, 24, 33, 24, 20, 15, 19, 27, 12, 19, 27, 14, 22, 28, 41, 40, 21, 99, 27, 17, 32, 30, 47, 21, 22, 25, 23, 20, 52, 32, 21, 21, 29, 30, 26, 27, 20, 27, 51, 26, 46, 28, 198, 18, 16, 24, 32, 44, 36, 23, 19, 14, 28, 14, 9, 33, 10, 53, 22, 65, 38], "policy_red_0_reward": [1.059, 1.44, 1.4369999999999998, 1.4449999999999998, -0.502, 1.443, 0.499, 1.431, -0.504, 1.4449999999999998, -0.502, 1.264, 0.499, 1.47, 1.186, 0.496, 1.333, 1.47, 0.964, 0.497, 1.434, -0.503, 1.423, 1.424, 1.4020000000000001, 1.4409999999999998, 1.403, 1.295, 1.333, 1.448, 1.389, 1.429, 1.329, 0.954, 1.452, 0.483, 1.323, 1.411, 0.942, 1.411, -0.501, 1.446, -1.002, 1.4489999999999998, 1.3900000000000001, 0.475, 1.342, 1.416, 1.197, 1.426, 1.4, 1.4249999999999998, 1.44, 0.954, 1.442, 0.918, 1.463, 1.44, 1.416, -0.5019999999999999, 1.4329999999999998, 0.914, 1.373, 1.3719999999999999, 1.436, 0.486, 1.415, -1.0, 1.4, 1.408, 1.355, 1.4369999999999998, 1.43, 1.423, 1.429, 1.438, 0.495, 1.4020000000000001, 1.436, 1.4369999999999998, 1.413, -0.503, 0.499, 1.4180000000000001, 1.44, 1.4180000000000001, 0.496, 1.4220000000000002, 0.496, 1.415, 0.8709999999999999, 1.444, -0.501, 0.497, 1.399, 0.862, 1.391, 1.431, 0.499, 1.458, 1.4140000000000001, 0.955, 0.973, 1.4, -0.501, 1.331, 1.432, 1.293, 0.497], "policy_blue_0_reward": [0.486, -1.0, 0.498, 0.495, 0.945, 0.497, 1.4300000000000002, -1.001, 1.4329999999999998, -0.5, 1.431, 0.495, 1.432, -1.001, 0.488, 1.393, -0.507, -1.001, -1.001, 1.411, 0.0, 0.939, -0.503, 0.498, 0.497, -0.503, -0.003, -0.5069999999999999, -0.005, -0.001, -1.002, 0.496, -1.001, -1.001, 0.498, 1.2639999999999998, -0.003, -0.001, -1.0019999999999998, 0.493, 0.952, -1.002, 0.886, -0.001, 0.498, 0.47, -0.506, -1.005, -0.514, 0.499, -1.006, -0.002, -1.005, -0.503, 0.498, -1.007, -0.5009999999999999, 0.498, -0.502, 0.955, 0.497, -1.003, 0.496, 0.489, -0.501, 1.1909999999999998, -0.503, 1.448, -0.505, -1.003, -0.504, 0.496, -0.502, -0.002, 0.498, 0.495, 1.341, 0.491, -0.001, 0.498, 0.498, 1.408, 1.419, -0.003, 0.499, -0.502, 1.341, -0.007, 1.3559999999999999, 0.497, 0.48, -1.005, 0.947, 1.424, -0.503, -0.506, 0.493, -0.002, 1.442, 0.499, -0.002, -0.501, -0.5, 0.495, 0.969, -0.507, -1.002, -0.512, 1.38]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.394914775544411, "mean_inference_ms": 7.448152087844559, "mean_action_processing_ms": 0.3911530577016114, "mean_env_wait_ms": 0.5180468380499489, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.18700569047840362, "StateBufferConnector_ms": 0.010286996123987601, "ViewRequirementAgentConnector_ms": 0.2038374953313705}}, "episode_reward_max": 1.9569999999999999, "episode_reward_min": -0.11599999999999988, "episode_reward_mean": 1.1889357798165139, "episode_len_mean": 35.20183486238532, "episodes_this_iter": 109, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.007}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.448}, "policy_reward_mean": {"red_0": 1.0394954128440368, "blue_0": 0.1494403669724771}, "hist_stats": {"episode_reward": [1.545, 0.43999999999999995, 1.935, 1.94, 0.44299999999999995, 1.94, 1.929, 0.43000000000000016, 0.9289999999999999, 0.9449999999999998, 0.929, 1.759, 1.931, 0.46899999999999986, 1.674, 1.889, 0.8260000000000001, 0.46899999999999986, -0.03700000000000003, 1.908, 1.434, 0.43599999999999994, 0.9199999999999999, 1.9220000000000002, 1.899, 0.938, 1.4, 0.788, 1.3279999999999998, 1.447, 0.387, 1.925, 0.32799999999999985, -0.04700000000000004, 1.95, 1.7469999999999999, 1.3199999999999998, 1.4100000000000001, -0.05999999999999994, 1.904, 0.45099999999999996, 0.44399999999999995, -0.11599999999999988, 1.448, 1.888, 0.945, 0.8359999999999999, 0.41100000000000003, 0.6829999999999998, 1.9249999999999998, 0.39400000000000013, 1.423, 0.43500000000000005, 0.45100000000000007, 1.94, -0.08899999999999997, 0.9620000000000002, 1.938, 0.9140000000000001, 0.45300000000000007, 1.9300000000000002, -0.08899999999999997, 1.869, 1.861, 0.935, 1.677, 0.9119999999999999, 0.44799999999999995, 0.895, 0.405, 0.851, 1.9329999999999998, 0.9279999999999999, 1.421, 1.927, 1.9329999999999998, 1.8359999999999999, 1.8930000000000002, 1.435, 1.935, 1.911, 0.905, 1.9180000000000001, 1.415, 1.939, 0.9159999999999999, 1.837, 1.415, 1.8519999999999999, 1.912, 1.351, 0.43900000000000006, 0.44599999999999995, 1.9209999999999998, 0.8959999999999999, 0.35599999999999987, 1.884, 1.429, 1.9409999999999998, 1.9569999999999999, 1.412, 0.45399999999999996, 0.47299999999999986, 1.895, 0.46799999999999997, 0.8239999999999998, 0.42999999999999994, 0.7809999999999999, 1.877], "episode_lengths": [143, 20, 21, 18, 17, 19, 23, 23, 22, 18, 23, 75, 22, 10, 101, 35, 54, 10, 12, 29, 22, 20, 25, 25, 31, 19, 32, 65, 54, 17, 36, 23, 55, 15, 16, 73, 57, 29, 19, 29, 15, 18, 37, 17, 36, 300, 49, 27, 100, 24, 33, 24, 20, 15, 19, 27, 12, 19, 27, 14, 22, 28, 41, 40, 21, 99, 27, 17, 32, 30, 47, 21, 22, 25, 23, 20, 52, 32, 21, 21, 29, 30, 26, 27, 20, 27, 51, 26, 46, 28, 198, 18, 16, 24, 32, 44, 36, 23, 19, 14, 28, 14, 9, 33, 10, 53, 22, 65, 38], "policy_red_0_reward": [1.059, 1.44, 1.4369999999999998, 1.4449999999999998, -0.502, 1.443, 0.499, 1.431, -0.504, 1.4449999999999998, -0.502, 1.264, 0.499, 1.47, 1.186, 0.496, 1.333, 1.47, 0.964, 0.497, 1.434, -0.503, 1.423, 1.424, 1.4020000000000001, 1.4409999999999998, 1.403, 1.295, 1.333, 1.448, 1.389, 1.429, 1.329, 0.954, 1.452, 0.483, 1.323, 1.411, 0.942, 1.411, -0.501, 1.446, -1.002, 1.4489999999999998, 1.3900000000000001, 0.475, 1.342, 1.416, 1.197, 1.426, 1.4, 1.4249999999999998, 1.44, 0.954, 1.442, 0.918, 1.463, 1.44, 1.416, -0.5019999999999999, 1.4329999999999998, 0.914, 1.373, 1.3719999999999999, 1.436, 0.486, 1.415, -1.0, 1.4, 1.408, 1.355, 1.4369999999999998, 1.43, 1.423, 1.429, 1.438, 0.495, 1.4020000000000001, 1.436, 1.4369999999999998, 1.413, -0.503, 0.499, 1.4180000000000001, 1.44, 1.4180000000000001, 0.496, 1.4220000000000002, 0.496, 1.415, 0.8709999999999999, 1.444, -0.501, 0.497, 1.399, 0.862, 1.391, 1.431, 0.499, 1.458, 1.4140000000000001, 0.955, 0.973, 1.4, -0.501, 1.331, 1.432, 1.293, 0.497], "policy_blue_0_reward": [0.486, -1.0, 0.498, 0.495, 0.945, 0.497, 1.4300000000000002, -1.001, 1.4329999999999998, -0.5, 1.431, 0.495, 1.432, -1.001, 0.488, 1.393, -0.507, -1.001, -1.001, 1.411, 0.0, 0.939, -0.503, 0.498, 0.497, -0.503, -0.003, -0.5069999999999999, -0.005, -0.001, -1.002, 0.496, -1.001, -1.001, 0.498, 1.2639999999999998, -0.003, -0.001, -1.0019999999999998, 0.493, 0.952, -1.002, 0.886, -0.001, 0.498, 0.47, -0.506, -1.005, -0.514, 0.499, -1.006, -0.002, -1.005, -0.503, 0.498, -1.007, -0.5009999999999999, 0.498, -0.502, 0.955, 0.497, -1.003, 0.496, 0.489, -0.501, 1.1909999999999998, -0.503, 1.448, -0.505, -1.003, -0.504, 0.496, -0.502, -0.002, 0.498, 0.495, 1.341, 0.491, -0.001, 0.498, 0.498, 1.408, 1.419, -0.003, 0.499, -0.502, 1.341, -0.007, 1.3559999999999999, 0.497, 0.48, -1.005, 0.947, 1.424, -0.503, -0.506, 0.493, -0.002, 1.442, 0.499, -0.002, -0.501, -0.5, 0.495, 0.969, -0.507, -1.002, -0.512, 1.38]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.394914775544411, "mean_inference_ms": 7.448152087844559, "mean_action_processing_ms": 0.3911530577016114, "mean_env_wait_ms": 0.5180468380499489, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.18700569047840362, "StateBufferConnector_ms": 0.010286996123987601, "ViewRequirementAgentConnector_ms": 0.2038374953313705}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.16225827894887, "num_env_steps_trained_throughput_per_sec": 127.16225827894887, "timesteps_total": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 31400.341, "sample_time_ms": 4050.815, "learn_time_ms": 27319.352, "learn_throughput": 146.416, "synch_weights_time_ms": 28.656}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "episodes_total": 4753, "training_iteration": 84, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-41-36", "timestamp": 1694839296, "time_this_iter_s": 31.47352409362793, "time_total_s": 2620.125527381897, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f44c0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2620.125527381897, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 26.360869565217385, "ram_util_percent": 57.071739130434764}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.45161290322580644, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.31451612903225806, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10483870967741936, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.31451612903225806, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12903225806451613, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10483870967741936, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.31451612903225806, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10483870967741936, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6203898780979216, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05262774900378039, "policy_loss": -0.1034095604220056, "vf_loss": 0.041176766112524396, "vf_explained_var": 0.6141933248688777, "kl": 0.013822432895898207, "entropy": 1.295802070076267, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 81120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6135839269806941, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05846715682613043, "policy_loss": -0.10677519001231607, "vf_loss": 0.04152055971208028, "vf_explained_var": 0.5731883140280842, "kl": 0.012759890285768188, "entropy": 1.5208732668310403, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 81120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 680000, "num_agent_steps_trained": 680000}, "sampler_results": {"episode_reward_max": 1.959, "episode_reward_min": -0.08399999999999996, "episode_reward_mean": 1.2402096774193547, "episode_len_mean": 34.483870967741936, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.463}, "policy_reward_mean": {"red_0": 1.007806451612903, "blue_0": 0.23240322580645165}, "custom_metrics": {"red_0/door_open_done_mean": 0.45161290322580644, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.31451612903225806, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10483870967741936, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.31451612903225806, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12903225806451613, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10483870967741936, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.31451612903225806, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10483870967741936, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.21299999999999997, 1.951, 1.826, -0.04299999999999993, 1.9409999999999998, 1.912, 1.938, 0.399, 0.4079999999999999, 1.401, 1.415, 0.9060000000000001, 1.959, 1.955, 1.9260000000000002, 0.45399999999999996, 1.928, -0.08399999999999996, 1.879, 1.421, 1.3820000000000001, 1.434, 1.431, 0.8399999999999999, 0.963, 1.396, 1.866, 0.836, 1.936, 1.928, 1.874, 1.876, 1.835, 0.9100000000000001, 0.4790000000000001, 0.884, -0.07400000000000007, 1.9329999999999998, 1.426, 0.9079999999999999, 0.3740000000000001, 1.416, 0.9119999999999999, 1.876, 1.897, 0.47, 0.42799999999999994, 1.923, 0.8029999999999999, -0.05300000000000005, 1.921, -0.06700000000000006, 0.46599999999999997, 0.928, 0.41000000000000014, 0.9359999999999999, 1.85, 1.426, 1.4100000000000001, 1.427, 0.241, 1.46, 0.020999999999999908, 1.892, 0.03399999999999981, 1.4329999999999998, 0.8559999999999999, 1.9249999999999998, 1.502, 0.44300000000000006, 1.419, 0.43999999999999995, 0.8300000000000001, 0.44799999999999995, 1.46, 1.8599999999999999, 1.9329999999999998, 0.9569999999999999, 0.949, 0.845, 1.921, 0.44899999999999984, 1.8770000000000002, 0.907, 1.935, 1.429, 1.859, 1.917, 1.421, 1.796, 0.958, 1.455, 1.874, 1.916, 0.782, 0.43199999999999994, 1.432, 1.916, 1.8780000000000001, 1.797, 0.45599999999999996, 1.924, 1.881, 0.4630000000000001, 1.901, 0.46299999999999997, 1.6269999999999998, 1.927, 1.916, 1.4409999999999998, 0.393, 1.837, 1.3719999999999999, 1.9329999999999998, 1.924, -0.039999999999999925, 0.44399999999999995, 0.956, 1.944, 1.8079999999999998, 0.95, -0.02300000000000002, 0.9710000000000001, 1.8980000000000001], "episode_lengths": [242, 16, 52, 13, 19, 27, 20, 31, 28, 31, 27, 29, 13, 15, 23, 14, 23, 26, 38, 26, 37, 21, 22, 50, 12, 33, 42, 50, 20, 23, 40, 37, 50, 29, 7, 38, 21, 22, 24, 28, 40, 26, 27, 40, 32, 10, 22, 24, 61, 17, 25, 22, 11, 23, 29, 21, 47, 24, 29, 23, 82, 13, 150, 35, 294, 21, 46, 24, 144, 18, 25, 19, 53, 16, 13, 43, 22, 14, 16, 48, 26, 17, 38, 29, 21, 22, 42, 26, 25, 64, 14, 15, 40, 26, 68, 22, 22, 27, 38, 63, 14, 24, 36, 12, 31, 12, 112, 23, 25, 19, 33, 51, 40, 21, 24, 13, 18, 14, 18, 59, 16, 7, 9, 32], "policy_red_0_reward": [-0.529, 1.452, 1.338, 0.961, 1.442, 1.417, 1.439, 0.904, 0.913, 1.404, 1.417, 1.409, 1.4609999999999999, 1.455, 1.429, -1.003, 1.4300000000000002, 0.921, 1.3820000000000001, 1.421, -0.005, 1.436, 1.4329999999999998, 1.345, -0.5, -0.002, 1.37, -0.509, 1.439, 0.499, 1.376, 0.492, 0.49, 1.412, 0.979, -0.501, 0.9299999999999999, 1.4329999999999998, 1.428, 1.4140000000000001, 0.878, -0.004, 1.415, 1.379, 1.4020000000000001, 1.47, 1.432, 1.426, 1.3119999999999998, -1.001, 1.423, 0.9329999999999999, 1.466, -0.502, 1.4100000000000001, 1.436, 0.497, 1.427, 1.411, 1.4300000000000002, -0.508, 1.4609999999999999, 1.034, 0.499, 0.57, 1.435, 1.3599999999999999, 1.428, 0.475, 1.444, -0.003, 1.44, 1.3359999999999999, 0.951, -0.001, 1.367, 1.434, 1.458, -0.502, 1.3519999999999999, 1.4220000000000002, 1.4489999999999998, 1.383, 1.4100000000000001, 1.4369999999999998, 1.431, 1.366, 0.497, 1.4220000000000002, 1.306, 1.458, 1.455, 1.3780000000000001, 0.497, 1.2890000000000001, 1.4329999999999998, 1.434, 0.499, 1.383, 0.49, -0.5, 1.428, 1.3860000000000001, 0.963, 1.405, -0.5, 1.145, 1.4300000000000002, 1.4220000000000002, 1.443, -0.504, 1.341, 1.379, 1.435, 1.426, -1.001, 1.4449999999999998, 1.4569999999999999, 1.4449999999999998, 0.489, 1.452, 0.977, 1.4729999999999999, 1.401], "policy_blue_0_reward": [0.742, 0.499, 0.488, -1.0039999999999998, 0.499, 0.495, 0.499, -0.505, -0.505, -0.003, -0.002, -0.503, 0.498, 0.5, 0.497, 1.4569999999999999, 0.498, -1.005, 0.497, 0.0, 1.387, -0.002, -0.002, -0.505, 1.463, 1.3980000000000001, 0.496, 1.345, 0.497, 1.429, 0.498, 1.384, 1.345, -0.5019999999999999, -0.5, 1.385, -1.004, 0.5, -0.002, -0.506, -0.504, 1.42, -0.503, 0.497, 0.495, -1.0, -1.004, 0.497, -0.509, 0.948, 0.498, -1.0, -1.0, 1.4300000000000002, -1.0, -0.5, 1.353, -0.001, -0.001, -0.003, 0.749, -0.001, -1.013, 1.393, -0.536, -0.002, -0.504, 0.497, 1.0270000000000001, -1.001, 1.4220000000000002, -1.0, -0.506, -0.503, 1.4609999999999999, 0.493, 0.499, -0.501, 1.451, -0.507, 0.499, -1.0, 0.494, -0.503, 0.498, -0.002, 0.493, 1.42, -0.001, 0.49, -0.5, 0.0, 0.496, 1.419, -0.507, -1.001, -0.002, 1.417, 0.495, 1.307, 0.956, 0.496, 0.495, -0.5, 0.496, 0.963, 0.482, 0.497, 0.494, -0.002, 0.897, 0.496, -0.007, 0.498, 0.498, 0.961, -1.001, -0.501, 0.499, 1.319, -0.502, -1.0, -0.502, 0.497]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.396127085255047, "mean_inference_ms": 7.44419127222299, "mean_action_processing_ms": 0.3907394422683644, "mean_env_wait_ms": 0.518113450457781, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15609687374484155, "StateBufferConnector_ms": 0.009337259877112604, "ViewRequirementAgentConnector_ms": 0.18791431380856422}}, "episode_reward_max": 1.959, "episode_reward_min": -0.08399999999999996, "episode_reward_mean": 1.2402096774193547, "episode_len_mean": 34.483870967741936, "episodes_this_iter": 124, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.463}, "policy_reward_mean": {"red_0": 1.007806451612903, "blue_0": 0.23240322580645165}, "hist_stats": {"episode_reward": [0.21299999999999997, 1.951, 1.826, -0.04299999999999993, 1.9409999999999998, 1.912, 1.938, 0.399, 0.4079999999999999, 1.401, 1.415, 0.9060000000000001, 1.959, 1.955, 1.9260000000000002, 0.45399999999999996, 1.928, -0.08399999999999996, 1.879, 1.421, 1.3820000000000001, 1.434, 1.431, 0.8399999999999999, 0.963, 1.396, 1.866, 0.836, 1.936, 1.928, 1.874, 1.876, 1.835, 0.9100000000000001, 0.4790000000000001, 0.884, -0.07400000000000007, 1.9329999999999998, 1.426, 0.9079999999999999, 0.3740000000000001, 1.416, 0.9119999999999999, 1.876, 1.897, 0.47, 0.42799999999999994, 1.923, 0.8029999999999999, -0.05300000000000005, 1.921, -0.06700000000000006, 0.46599999999999997, 0.928, 0.41000000000000014, 0.9359999999999999, 1.85, 1.426, 1.4100000000000001, 1.427, 0.241, 1.46, 0.020999999999999908, 1.892, 0.03399999999999981, 1.4329999999999998, 0.8559999999999999, 1.9249999999999998, 1.502, 0.44300000000000006, 1.419, 0.43999999999999995, 0.8300000000000001, 0.44799999999999995, 1.46, 1.8599999999999999, 1.9329999999999998, 0.9569999999999999, 0.949, 0.845, 1.921, 0.44899999999999984, 1.8770000000000002, 0.907, 1.935, 1.429, 1.859, 1.917, 1.421, 1.796, 0.958, 1.455, 1.874, 1.916, 0.782, 0.43199999999999994, 1.432, 1.916, 1.8780000000000001, 1.797, 0.45599999999999996, 1.924, 1.881, 0.4630000000000001, 1.901, 0.46299999999999997, 1.6269999999999998, 1.927, 1.916, 1.4409999999999998, 0.393, 1.837, 1.3719999999999999, 1.9329999999999998, 1.924, -0.039999999999999925, 0.44399999999999995, 0.956, 1.944, 1.8079999999999998, 0.95, -0.02300000000000002, 0.9710000000000001, 1.8980000000000001], "episode_lengths": [242, 16, 52, 13, 19, 27, 20, 31, 28, 31, 27, 29, 13, 15, 23, 14, 23, 26, 38, 26, 37, 21, 22, 50, 12, 33, 42, 50, 20, 23, 40, 37, 50, 29, 7, 38, 21, 22, 24, 28, 40, 26, 27, 40, 32, 10, 22, 24, 61, 17, 25, 22, 11, 23, 29, 21, 47, 24, 29, 23, 82, 13, 150, 35, 294, 21, 46, 24, 144, 18, 25, 19, 53, 16, 13, 43, 22, 14, 16, 48, 26, 17, 38, 29, 21, 22, 42, 26, 25, 64, 14, 15, 40, 26, 68, 22, 22, 27, 38, 63, 14, 24, 36, 12, 31, 12, 112, 23, 25, 19, 33, 51, 40, 21, 24, 13, 18, 14, 18, 59, 16, 7, 9, 32], "policy_red_0_reward": [-0.529, 1.452, 1.338, 0.961, 1.442, 1.417, 1.439, 0.904, 0.913, 1.404, 1.417, 1.409, 1.4609999999999999, 1.455, 1.429, -1.003, 1.4300000000000002, 0.921, 1.3820000000000001, 1.421, -0.005, 1.436, 1.4329999999999998, 1.345, -0.5, -0.002, 1.37, -0.509, 1.439, 0.499, 1.376, 0.492, 0.49, 1.412, 0.979, -0.501, 0.9299999999999999, 1.4329999999999998, 1.428, 1.4140000000000001, 0.878, -0.004, 1.415, 1.379, 1.4020000000000001, 1.47, 1.432, 1.426, 1.3119999999999998, -1.001, 1.423, 0.9329999999999999, 1.466, -0.502, 1.4100000000000001, 1.436, 0.497, 1.427, 1.411, 1.4300000000000002, -0.508, 1.4609999999999999, 1.034, 0.499, 0.57, 1.435, 1.3599999999999999, 1.428, 0.475, 1.444, -0.003, 1.44, 1.3359999999999999, 0.951, -0.001, 1.367, 1.434, 1.458, -0.502, 1.3519999999999999, 1.4220000000000002, 1.4489999999999998, 1.383, 1.4100000000000001, 1.4369999999999998, 1.431, 1.366, 0.497, 1.4220000000000002, 1.306, 1.458, 1.455, 1.3780000000000001, 0.497, 1.2890000000000001, 1.4329999999999998, 1.434, 0.499, 1.383, 0.49, -0.5, 1.428, 1.3860000000000001, 0.963, 1.405, -0.5, 1.145, 1.4300000000000002, 1.4220000000000002, 1.443, -0.504, 1.341, 1.379, 1.435, 1.426, -1.001, 1.4449999999999998, 1.4569999999999999, 1.4449999999999998, 0.489, 1.452, 0.977, 1.4729999999999999, 1.401], "policy_blue_0_reward": [0.742, 0.499, 0.488, -1.0039999999999998, 0.499, 0.495, 0.499, -0.505, -0.505, -0.003, -0.002, -0.503, 0.498, 0.5, 0.497, 1.4569999999999999, 0.498, -1.005, 0.497, 0.0, 1.387, -0.002, -0.002, -0.505, 1.463, 1.3980000000000001, 0.496, 1.345, 0.497, 1.429, 0.498, 1.384, 1.345, -0.5019999999999999, -0.5, 1.385, -1.004, 0.5, -0.002, -0.506, -0.504, 1.42, -0.503, 0.497, 0.495, -1.0, -1.004, 0.497, -0.509, 0.948, 0.498, -1.0, -1.0, 1.4300000000000002, -1.0, -0.5, 1.353, -0.001, -0.001, -0.003, 0.749, -0.001, -1.013, 1.393, -0.536, -0.002, -0.504, 0.497, 1.0270000000000001, -1.001, 1.4220000000000002, -1.0, -0.506, -0.503, 1.4609999999999999, 0.493, 0.499, -0.501, 1.451, -0.507, 0.499, -1.0, 0.494, -0.503, 0.498, -0.002, 0.493, 1.42, -0.001, 0.49, -0.5, 0.0, 0.496, 1.419, -0.507, -1.001, -0.002, 1.417, 0.495, 1.307, 0.956, 0.496, 0.495, -0.5, 0.496, 0.963, 0.482, 0.497, 0.494, -0.002, 0.897, 0.496, -0.007, 0.498, 0.498, 0.961, -1.001, -0.501, 0.499, 1.319, -0.502, -1.0, -0.502, 0.497]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.396127085255047, "mean_inference_ms": 7.44419127222299, "mean_action_processing_ms": 0.3907394422683644, "mean_env_wait_ms": 0.518113450457781, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15609687374484155, "StateBufferConnector_ms": 0.009337259877112604, "ViewRequirementAgentConnector_ms": 0.18791431380856422}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 680000, "num_agent_steps_trained": 680000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 132.49507996828436, "num_env_steps_trained_throughput_per_sec": 132.49507996828436, "timesteps_total": 340000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 680000, "timers": {"training_iteration_time_ms": 31204.299, "sample_time_ms": 4017.215, "learn_time_ms": 27156.929, "learn_throughput": 147.292, "synch_weights_time_ms": 28.645}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 680000, "num_agent_steps_trained": 680000}, "done": false, "episodes_total": 4877, "training_iteration": 85, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-42-07", "timestamp": 1694839327, "time_this_iter_s": 30.207652807235718, "time_total_s": 2650.3331801891327, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21987760>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2650.3331801891327, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 24.469767441860466, "ram_util_percent": 57.12093023255814}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.4727272727272727, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.3, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.12727272727272726, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.3, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.09090909090909091, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.12727272727272726, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.3, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.12727272727272726, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6174049846207103, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04768003214849159, "policy_loss": -0.09536482463881839, "vf_loss": 0.03748464226955548, "vf_explained_var": 0.6377451591193676, "kl": 0.013282335392438489, "entropy": 1.3163498969127734, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 82080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6054488958170017, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05798295599767395, "policy_loss": -0.10580947607619844, "vf_loss": 0.03921244901624353, "vf_explained_var": 0.538527526644369, "kl": 0.013074572512258935, "entropy": 1.5652152082572381, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 82080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "sampler_results": {"episode_reward_max": 1.9569999999999999, "episode_reward_min": -0.11099999999999988, "episode_reward_mean": 1.237190909090909, "episode_len_mean": 35.054545454545455, "episode_media": {}, "episodes_this_iter": 110, "policy_reward_min": {"red_0": -1.01, "blue_0": -1.01}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.466}, "policy_reward_mean": {"red_0": 1.000981818181818, "blue_0": 0.23620909090909087}, "custom_metrics": {"red_0/door_open_done_mean": 0.4727272727272727, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.3, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.12727272727272726, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.3, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.09090909090909091, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.12727272727272726, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.3, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.12727272727272726, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.938, 0.966, 1.43, 0.31899999999999995, 1.862, 1.9300000000000002, 1.4569999999999999, 1.834, 0.44599999999999995, 0.9119999999999999, 0.44199999999999995, 1.927, 1.403, 1.912, 1.401, 0.44599999999999995, 0.44499999999999984, 0.8220000000000001, -0.11099999999999988, 1.412, 1.879, 1.937, 1.885, 1.451, 1.458, 1.3820000000000001, 0.374, 0.966, 1.934, 0.953, 1.129, 0.42900000000000005, 1.954, 0.8620000000000001, 1.415, 1.932, 0.43900000000000006, 1.956, 1.317, 0.385, 1.924, 1.83, 0.07499999999999996, 0.44999999999999996, 1.8690000000000002, 1.943, 0.838, 1.44, 1.358, 0.959, 1.412, 0.9359999999999999, 1.9140000000000001, 1.8599999999999999, 1.891, 1.931, 1.915, 0.46199999999999997, 1.9060000000000001, 0.6479999999999999, 0.8660000000000001, 0.43599999999999994, 1.892, 1.931, 1.931, 0.44599999999999995, 1.874, 0.9430000000000001, -0.04799999999999993, 0.47299999999999986, 0.45099999999999996, 0.935, 0.44199999999999995, 1.932, 1.936, 1.9060000000000001, 1.436, 1.903, 0.8479999999999999, 1.435, 0.45299999999999985, 0.9259999999999999, 1.417, 0.8559999999999999, 1.9569999999999999, 1.805, 1.448, 1.932, 0.45799999999999996, 0.45899999999999996, -0.041999999999999926, 0.9339999999999999, 1.905, 0.31899999999999995, 1.939, 1.904, 1.399, 1.956, 0.348, 1.942, 1.392, 0.3799999999999999, 1.379, 0.669, 0.903, 1.823, 0.9140000000000001, 1.6989999999999998, 0.9530000000000001, 0.905], "episode_lengths": [20, 11, 22, 55, 45, 23, 14, 53, 17, 27, 18, 24, 31, 27, 31, 16, 17, 55, 32, 26, 39, 20, 36, 15, 14, 36, 39, 11, 20, 15, 271, 22, 15, 42, 26, 21, 20, 14, 56, 37, 25, 54, 134, 16, 39, 18, 51, 20, 44, 13, 28, 21, 27, 43, 34, 22, 27, 12, 30, 108, 42, 20, 34, 22, 22, 17, 40, 18, 14, 9, 15, 20, 19, 21, 20, 30, 21, 31, 47, 21, 15, 22, 27, 45, 14, 59, 17, 22, 14, 13, 13, 300, 31, 57, 19, 31, 31, 14, 47, 18, 34, 38, 39, 104, 30, 56, 28, 92, 15, 29], "policy_red_0_reward": [1.438, -0.5, 1.434, 1.325, 0.498, 1.431, 1.458, 1.338, 1.4489999999999998, 1.416, -0.502, 1.428, 1.4060000000000001, 0.498, 1.4060000000000001, 0.951, 1.447, 1.326, -1.01, 1.4180000000000001, 1.38, 1.44, 0.496, 1.455, 1.458, 1.3860000000000001, -1.003, 1.467, 1.4369999999999998, -0.501, 0.6509999999999999, 1.432, 1.454, 1.369, 1.419, 1.435, 0.94, 1.458, 1.323, 1.388, 1.424, 0.497, 1.085, 1.451, 1.3780000000000001, 0.498, -0.503, 1.44, 1.361, -0.501, 1.416, 1.4369999999999998, 1.4180000000000001, 0.495, 1.395, 1.432, 1.417, 1.464, 1.408, 1.166, 1.3719999999999999, 1.438, 1.397, 1.434, 1.434, -0.502, 1.3780000000000001, 1.4449999999999998, 0.955, 1.4729999999999999, -0.501, 1.439, 0.943, 1.436, 0.499, 1.409, 1.436, 1.407, 1.3559999999999999, 1.4369999999999998, 1.454, 1.431, 0.0, 1.359, 1.4569999999999999, 1.319, 1.448, 1.4329999999999998, 0.958, -1.0, -1.001, 0.45699999999999996, 1.407, -1.009, 1.442, 0.499, 1.403, 1.458, -1.005, 1.446, -0.003, 0.882, 1.381, 1.181, 1.407, 1.3279999999999998, 1.4140000000000001, 1.209, 1.455, -0.504], "policy_blue_0_reward": [0.5, 1.466, -0.004, -1.006, 1.3639999999999999, 0.499, -0.001, 0.496, -1.003, -0.504, 0.944, 0.499, -0.003, 1.4140000000000001, -0.005, -0.505, -1.002, -0.504, 0.899, -0.006, 0.499, 0.497, 1.389, -0.004, 0.0, -0.004, 1.377, -0.501, 0.497, 1.454, 0.478, -1.003, 0.5, -0.507, -0.004, 0.497, -0.501, 0.498, -0.006, -1.003, 0.5, 1.333, -1.01, -1.001, 0.491, 1.4449999999999998, 1.341, 0.0, -0.003, 1.46, -0.004, -0.501, 0.496, 1.365, 0.496, 0.499, 0.498, -1.002, 0.498, -0.518, -0.506, -1.002, 0.495, 0.497, 0.497, 0.948, 0.496, -0.502, -1.003, -1.0, 0.952, -0.504, -0.501, 0.496, 1.4369999999999998, 0.497, 0.0, 0.496, -0.508, -0.002, -1.001, -0.505, 1.417, -0.503, 0.5, 0.486, 0.0, 0.499, -0.5, 1.459, 0.959, 0.477, 0.498, 1.3279999999999998, 0.497, 1.405, -0.004, 0.498, 1.353, 0.496, 1.395, -0.502, -0.002, -0.512, -0.5039999999999999, 0.495, -0.5, 0.49, -0.5019999999999999, 1.409]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3971481601069886, "mean_inference_ms": 7.446844644492905, "mean_action_processing_ms": 0.39138972432722396, "mean_env_wait_ms": 0.5181206384054655, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14223998243158514, "StateBufferConnector_ms": 0.009549964557994495, "ViewRequirementAgentConnector_ms": 0.19562363624572754}}, "episode_reward_max": 1.9569999999999999, "episode_reward_min": -0.11099999999999988, "episode_reward_mean": 1.237190909090909, "episode_len_mean": 35.054545454545455, "episodes_this_iter": 110, "policy_reward_min": {"red_0": -1.01, "blue_0": -1.01}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.466}, "policy_reward_mean": {"red_0": 1.000981818181818, "blue_0": 0.23620909090909087}, "hist_stats": {"episode_reward": [1.938, 0.966, 1.43, 0.31899999999999995, 1.862, 1.9300000000000002, 1.4569999999999999, 1.834, 0.44599999999999995, 0.9119999999999999, 0.44199999999999995, 1.927, 1.403, 1.912, 1.401, 0.44599999999999995, 0.44499999999999984, 0.8220000000000001, -0.11099999999999988, 1.412, 1.879, 1.937, 1.885, 1.451, 1.458, 1.3820000000000001, 0.374, 0.966, 1.934, 0.953, 1.129, 0.42900000000000005, 1.954, 0.8620000000000001, 1.415, 1.932, 0.43900000000000006, 1.956, 1.317, 0.385, 1.924, 1.83, 0.07499999999999996, 0.44999999999999996, 1.8690000000000002, 1.943, 0.838, 1.44, 1.358, 0.959, 1.412, 0.9359999999999999, 1.9140000000000001, 1.8599999999999999, 1.891, 1.931, 1.915, 0.46199999999999997, 1.9060000000000001, 0.6479999999999999, 0.8660000000000001, 0.43599999999999994, 1.892, 1.931, 1.931, 0.44599999999999995, 1.874, 0.9430000000000001, -0.04799999999999993, 0.47299999999999986, 0.45099999999999996, 0.935, 0.44199999999999995, 1.932, 1.936, 1.9060000000000001, 1.436, 1.903, 0.8479999999999999, 1.435, 0.45299999999999985, 0.9259999999999999, 1.417, 0.8559999999999999, 1.9569999999999999, 1.805, 1.448, 1.932, 0.45799999999999996, 0.45899999999999996, -0.041999999999999926, 0.9339999999999999, 1.905, 0.31899999999999995, 1.939, 1.904, 1.399, 1.956, 0.348, 1.942, 1.392, 0.3799999999999999, 1.379, 0.669, 0.903, 1.823, 0.9140000000000001, 1.6989999999999998, 0.9530000000000001, 0.905], "episode_lengths": [20, 11, 22, 55, 45, 23, 14, 53, 17, 27, 18, 24, 31, 27, 31, 16, 17, 55, 32, 26, 39, 20, 36, 15, 14, 36, 39, 11, 20, 15, 271, 22, 15, 42, 26, 21, 20, 14, 56, 37, 25, 54, 134, 16, 39, 18, 51, 20, 44, 13, 28, 21, 27, 43, 34, 22, 27, 12, 30, 108, 42, 20, 34, 22, 22, 17, 40, 18, 14, 9, 15, 20, 19, 21, 20, 30, 21, 31, 47, 21, 15, 22, 27, 45, 14, 59, 17, 22, 14, 13, 13, 300, 31, 57, 19, 31, 31, 14, 47, 18, 34, 38, 39, 104, 30, 56, 28, 92, 15, 29], "policy_red_0_reward": [1.438, -0.5, 1.434, 1.325, 0.498, 1.431, 1.458, 1.338, 1.4489999999999998, 1.416, -0.502, 1.428, 1.4060000000000001, 0.498, 1.4060000000000001, 0.951, 1.447, 1.326, -1.01, 1.4180000000000001, 1.38, 1.44, 0.496, 1.455, 1.458, 1.3860000000000001, -1.003, 1.467, 1.4369999999999998, -0.501, 0.6509999999999999, 1.432, 1.454, 1.369, 1.419, 1.435, 0.94, 1.458, 1.323, 1.388, 1.424, 0.497, 1.085, 1.451, 1.3780000000000001, 0.498, -0.503, 1.44, 1.361, -0.501, 1.416, 1.4369999999999998, 1.4180000000000001, 0.495, 1.395, 1.432, 1.417, 1.464, 1.408, 1.166, 1.3719999999999999, 1.438, 1.397, 1.434, 1.434, -0.502, 1.3780000000000001, 1.4449999999999998, 0.955, 1.4729999999999999, -0.501, 1.439, 0.943, 1.436, 0.499, 1.409, 1.436, 1.407, 1.3559999999999999, 1.4369999999999998, 1.454, 1.431, 0.0, 1.359, 1.4569999999999999, 1.319, 1.448, 1.4329999999999998, 0.958, -1.0, -1.001, 0.45699999999999996, 1.407, -1.009, 1.442, 0.499, 1.403, 1.458, -1.005, 1.446, -0.003, 0.882, 1.381, 1.181, 1.407, 1.3279999999999998, 1.4140000000000001, 1.209, 1.455, -0.504], "policy_blue_0_reward": [0.5, 1.466, -0.004, -1.006, 1.3639999999999999, 0.499, -0.001, 0.496, -1.003, -0.504, 0.944, 0.499, -0.003, 1.4140000000000001, -0.005, -0.505, -1.002, -0.504, 0.899, -0.006, 0.499, 0.497, 1.389, -0.004, 0.0, -0.004, 1.377, -0.501, 0.497, 1.454, 0.478, -1.003, 0.5, -0.507, -0.004, 0.497, -0.501, 0.498, -0.006, -1.003, 0.5, 1.333, -1.01, -1.001, 0.491, 1.4449999999999998, 1.341, 0.0, -0.003, 1.46, -0.004, -0.501, 0.496, 1.365, 0.496, 0.499, 0.498, -1.002, 0.498, -0.518, -0.506, -1.002, 0.495, 0.497, 0.497, 0.948, 0.496, -0.502, -1.003, -1.0, 0.952, -0.504, -0.501, 0.496, 1.4369999999999998, 0.497, 0.0, 0.496, -0.508, -0.002, -1.001, -0.505, 1.417, -0.503, 0.5, 0.486, 0.0, 0.499, -0.5, 1.459, 0.959, 0.477, 0.498, 1.3279999999999998, 0.497, 1.405, -0.004, 0.498, 1.353, 0.496, 1.395, -0.502, -0.002, -0.512, -0.5039999999999999, 0.495, -0.5, 0.49, -0.5019999999999999, 1.409]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3971481601069886, "mean_inference_ms": 7.446844644492905, "mean_action_processing_ms": 0.39138972432722396, "mean_env_wait_ms": 0.5181206384054655, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14223998243158514, "StateBufferConnector_ms": 0.009549964557994495, "ViewRequirementAgentConnector_ms": 0.19562363624572754}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.4708177527688, "num_env_steps_trained_throughput_per_sec": 131.4708177527688, "timesteps_total": 344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 31162.769, "sample_time_ms": 3999.603, "learn_time_ms": 27133.06, "learn_throughput": 147.422, "synch_weights_time_ms": 28.58}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "episodes_total": 4987, "training_iteration": 86, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-42-39", "timestamp": 1694839359, "time_this_iter_s": 30.441318035125732, "time_total_s": 2680.7744982242584, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f6f80>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2680.7744982242584, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 24.90666666666666, "ram_util_percent": 57.11999999999998}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.41025641025641024, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.2905982905982906, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11965811965811966, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.2905982905982906, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.17094017094017094, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.11965811965811966, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.2905982905982906, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11965811965811966, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6001321094421049, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05378281394562994, "policy_loss": -0.10048727834194628, "vf_loss": 0.03676798867624408, "vf_explained_var": 0.6298611388852199, "kl": 0.012993475546579702, "entropy": 1.2802915619065365, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 83040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6072814393478135, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05727945902617648, "policy_loss": -0.10721308404705875, "vf_loss": 0.04184254464829185, "vf_explained_var": 0.5578921576961875, "kl": 0.013399778541717448, "entropy": 1.514018759628137, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 83040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 696000, "num_agent_steps_trained": 696000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.21000000000000008, "episode_reward_mean": 1.2755726495726498, "episode_len_mean": 34.00854700854701, "episode_media": {}, "episodes_this_iter": 117, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.029}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.947923076923077, "blue_0": 0.32764957264957273}, "custom_metrics": {"red_0/door_open_done_mean": 0.41025641025641024, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.2905982905982906, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11965811965811966, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.2905982905982906, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.17094017094017094, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.11965811965811966, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.2905982905982906, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11965811965811966, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.948, 1.444, 1.935, 1.8980000000000001, 1.897, 0.41900000000000004, 1.395, 1.846, 1.8279999999999998, 0.9470000000000001, 1.908, 1.4380000000000002, 1.947, 1.435, 0.829, 0.42599999999999993, 0.32299999999999995, 0.919, 1.734, 1.897, 0.9550000000000001, 1.407, 0.43500000000000005, 1.9569999999999999, -0.03300000000000003, 1.885, 1.944, 0.44899999999999984, 1.403, 1.438, 1.883, 1.851, 0.865, 1.417, 1.93, 1.899, 1.9449999999999998, 0.476, 0.909, 0.94, 0.45999999999999996, 1.385, 1.869, 1.393, 1.934, 1.841, 1.366, 0.45699999999999985, 0.841, 1.9020000000000001, 0.43100000000000005, 1.9329999999999998, 1.9529999999999998, 1.374, 0.9219999999999999, 0.43099999999999994, 0.43999999999999995, 0.2919999999999999, 1.9170000000000003, 0.915, 1.9609999999999999, 1.405, 1.922, 1.435, 1.404, 1.857, 1.955, 0.45699999999999985, 1.865, 1.9260000000000002, 1.443, 0.931, 1.778, 0.891, 1.943, 0.403, 1.935, 1.936, 0.949, 1.946, 0.929, 0.9119999999999999, 0.9339999999999999, 0.9590000000000001, 1.9140000000000001, 1.899, -0.038000000000000034, 1.442, 1.934, 0.45799999999999996, 1.8940000000000001, 1.1179999999999999, 1.888, -0.08299999999999996, 0.476, 1.935, -0.21000000000000008, 1.907, 1.8980000000000001, -0.07199999999999995, 0.958, 0.9510000000000001, 0.9309999999999999, 0.46499999999999997, 0.45199999999999996, 0.40200000000000014, 0.954, 1.935, 1.8359999999999999, 0.9689999999999999, 1.942, -0.049000000000000044, 0.45899999999999996, 0.45199999999999996, 1.923, 1.865, 1.9369999999999998], "episode_lengths": [17, 18, 21, 31, 32, 26, 33, 48, 54, 17, 29, 18, 17, 21, 54, 22, 55, 25, 83, 33, 15, 29, 21, 14, 11, 37, 18, 16, 32, 20, 37, 45, 42, 26, 22, 32, 17, 8, 30, 19, 13, 35, 39, 33, 22, 52, 43, 14, 48, 31, 23, 22, 15, 196, 24, 22, 19, 65, 26, 27, 13, 31, 24, 20, 29, 44, 14, 14, 43, 23, 18, 22, 68, 35, 18, 31, 20, 20, 300, 17, 23, 29, 21, 13, 28, 30, 12, 19, 21, 14, 34, 267, 37, 27, 8, 21, 218, 30, 31, 23, 14, 16, 22, 10, 15, 31, 15, 20, 50, 10, 19, 16, 13, 15, 25, 43, 21], "policy_red_0_reward": [1.4489999999999998, 1.444, 1.4369999999999998, 0.497, 1.3980000000000001, 0.922, 1.3980000000000001, 1.351, 1.33, 1.447, 0.496, 1.4449999999999998, 1.448, 1.436, 1.331, 0.9299999999999999, 0.829, 1.4220000000000002, 0.488, 1.3980000000000001, 1.455, 1.4100000000000001, 1.4369999999999998, 0.499, -1.0, 1.389, 1.446, 1.4489999999999998, 0.0, 1.439, 1.385, 1.357, 1.3719999999999999, 1.4220000000000002, 0.498, 1.401, 1.448, -0.5, 1.4100000000000001, 1.442, -1.0, 1.391, 1.3780000000000001, 1.4, 1.434, 1.3439999999999999, 1.369, 1.458, 1.35, 1.407, 1.431, 0.5, 1.454, 0.496, -0.502, -1.0, 1.442, -1.007, 1.42, -0.504, 0.5, 0.0, 1.4249999999999998, 1.44, 1.411, 1.361, 1.4569999999999999, 0.958, 1.367, 0.498, -0.002, 1.4329999999999998, 1.2890000000000001, -0.501, 1.4449999999999998, 1.403, 1.438, 0.498, 0.472, 0.499, 1.431, 1.413, 1.435, 1.46, 1.416, 0.493, 0.963, 1.443, 1.435, 1.458, 1.3980000000000001, 0.45799999999999996, 0.5, -1.002, 1.476, 0.499, 0.819, 1.409, 1.403, 0.93, 1.458, 1.451, -0.5, -0.5, -1.001, 1.405, 1.454, 0.497, 1.345, 1.4689999999999999, 1.443, 0.952, -0.501, -0.501, 1.424, 1.3679999999999999, 0.5], "policy_blue_0_reward": [0.499, 0.0, 0.498, 1.401, 0.499, -0.503, -0.003, 0.495, 0.498, -0.5, 1.412, -0.007, 0.499, -0.001, -0.502, -0.504, -0.506, -0.503, 1.246, 0.499, -0.5, -0.003, -1.002, 1.458, 0.967, 0.496, 0.498, -1.0, 1.403, -0.001, 0.498, 0.494, -0.507, -0.005, 1.432, 0.498, 0.497, 0.976, -0.501, -0.502, 1.46, -0.006, 0.491, -0.007, 0.5, 0.497, -0.003, -1.001, -0.509, 0.495, -1.0, 1.4329999999999998, 0.499, 0.878, 1.424, 1.431, -1.002, 1.299, 0.497, 1.419, 1.4609999999999999, 1.405, 0.497, -0.005, -0.007, 0.496, 0.498, -0.501, 0.498, 1.428, 1.4449999999999998, -0.502, 0.489, 1.392, 0.498, -1.0, 0.497, 1.438, 0.477, 1.447, -0.502, -0.501, -0.501, -0.501, 0.498, 1.4060000000000001, -1.001, -0.001, 0.499, -1.0, 0.496, 0.6599999999999999, 1.388, 0.919, -1.0, 1.436, -1.029, 0.498, 0.495, -1.002, -0.5, -0.5, 1.431, 0.965, 1.4529999999999998, -1.003, -0.5, 1.438, 0.491, -0.5, 0.499, -1.001, 0.96, 0.953, 0.499, 0.497, 1.4369999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3961723541039464, "mean_inference_ms": 7.441072463459924, "mean_action_processing_ms": 0.3914363395518041, "mean_env_wait_ms": 0.5182079312499522, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14973094320704794, "StateBufferConnector_ms": 0.009162711282061715, "ViewRequirementAgentConnector_ms": 0.1790293261536166}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.21000000000000008, "episode_reward_mean": 1.2755726495726498, "episode_len_mean": 34.00854700854701, "episodes_this_iter": 117, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.029}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.947923076923077, "blue_0": 0.32764957264957273}, "hist_stats": {"episode_reward": [1.948, 1.444, 1.935, 1.8980000000000001, 1.897, 0.41900000000000004, 1.395, 1.846, 1.8279999999999998, 0.9470000000000001, 1.908, 1.4380000000000002, 1.947, 1.435, 0.829, 0.42599999999999993, 0.32299999999999995, 0.919, 1.734, 1.897, 0.9550000000000001, 1.407, 0.43500000000000005, 1.9569999999999999, -0.03300000000000003, 1.885, 1.944, 0.44899999999999984, 1.403, 1.438, 1.883, 1.851, 0.865, 1.417, 1.93, 1.899, 1.9449999999999998, 0.476, 0.909, 0.94, 0.45999999999999996, 1.385, 1.869, 1.393, 1.934, 1.841, 1.366, 0.45699999999999985, 0.841, 1.9020000000000001, 0.43100000000000005, 1.9329999999999998, 1.9529999999999998, 1.374, 0.9219999999999999, 0.43099999999999994, 0.43999999999999995, 0.2919999999999999, 1.9170000000000003, 0.915, 1.9609999999999999, 1.405, 1.922, 1.435, 1.404, 1.857, 1.955, 0.45699999999999985, 1.865, 1.9260000000000002, 1.443, 0.931, 1.778, 0.891, 1.943, 0.403, 1.935, 1.936, 0.949, 1.946, 0.929, 0.9119999999999999, 0.9339999999999999, 0.9590000000000001, 1.9140000000000001, 1.899, -0.038000000000000034, 1.442, 1.934, 0.45799999999999996, 1.8940000000000001, 1.1179999999999999, 1.888, -0.08299999999999996, 0.476, 1.935, -0.21000000000000008, 1.907, 1.8980000000000001, -0.07199999999999995, 0.958, 0.9510000000000001, 0.9309999999999999, 0.46499999999999997, 0.45199999999999996, 0.40200000000000014, 0.954, 1.935, 1.8359999999999999, 0.9689999999999999, 1.942, -0.049000000000000044, 0.45899999999999996, 0.45199999999999996, 1.923, 1.865, 1.9369999999999998], "episode_lengths": [17, 18, 21, 31, 32, 26, 33, 48, 54, 17, 29, 18, 17, 21, 54, 22, 55, 25, 83, 33, 15, 29, 21, 14, 11, 37, 18, 16, 32, 20, 37, 45, 42, 26, 22, 32, 17, 8, 30, 19, 13, 35, 39, 33, 22, 52, 43, 14, 48, 31, 23, 22, 15, 196, 24, 22, 19, 65, 26, 27, 13, 31, 24, 20, 29, 44, 14, 14, 43, 23, 18, 22, 68, 35, 18, 31, 20, 20, 300, 17, 23, 29, 21, 13, 28, 30, 12, 19, 21, 14, 34, 267, 37, 27, 8, 21, 218, 30, 31, 23, 14, 16, 22, 10, 15, 31, 15, 20, 50, 10, 19, 16, 13, 15, 25, 43, 21], "policy_red_0_reward": [1.4489999999999998, 1.444, 1.4369999999999998, 0.497, 1.3980000000000001, 0.922, 1.3980000000000001, 1.351, 1.33, 1.447, 0.496, 1.4449999999999998, 1.448, 1.436, 1.331, 0.9299999999999999, 0.829, 1.4220000000000002, 0.488, 1.3980000000000001, 1.455, 1.4100000000000001, 1.4369999999999998, 0.499, -1.0, 1.389, 1.446, 1.4489999999999998, 0.0, 1.439, 1.385, 1.357, 1.3719999999999999, 1.4220000000000002, 0.498, 1.401, 1.448, -0.5, 1.4100000000000001, 1.442, -1.0, 1.391, 1.3780000000000001, 1.4, 1.434, 1.3439999999999999, 1.369, 1.458, 1.35, 1.407, 1.431, 0.5, 1.454, 0.496, -0.502, -1.0, 1.442, -1.007, 1.42, -0.504, 0.5, 0.0, 1.4249999999999998, 1.44, 1.411, 1.361, 1.4569999999999999, 0.958, 1.367, 0.498, -0.002, 1.4329999999999998, 1.2890000000000001, -0.501, 1.4449999999999998, 1.403, 1.438, 0.498, 0.472, 0.499, 1.431, 1.413, 1.435, 1.46, 1.416, 0.493, 0.963, 1.443, 1.435, 1.458, 1.3980000000000001, 0.45799999999999996, 0.5, -1.002, 1.476, 0.499, 0.819, 1.409, 1.403, 0.93, 1.458, 1.451, -0.5, -0.5, -1.001, 1.405, 1.454, 0.497, 1.345, 1.4689999999999999, 1.443, 0.952, -0.501, -0.501, 1.424, 1.3679999999999999, 0.5], "policy_blue_0_reward": [0.499, 0.0, 0.498, 1.401, 0.499, -0.503, -0.003, 0.495, 0.498, -0.5, 1.412, -0.007, 0.499, -0.001, -0.502, -0.504, -0.506, -0.503, 1.246, 0.499, -0.5, -0.003, -1.002, 1.458, 0.967, 0.496, 0.498, -1.0, 1.403, -0.001, 0.498, 0.494, -0.507, -0.005, 1.432, 0.498, 0.497, 0.976, -0.501, -0.502, 1.46, -0.006, 0.491, -0.007, 0.5, 0.497, -0.003, -1.001, -0.509, 0.495, -1.0, 1.4329999999999998, 0.499, 0.878, 1.424, 1.431, -1.002, 1.299, 0.497, 1.419, 1.4609999999999999, 1.405, 0.497, -0.005, -0.007, 0.496, 0.498, -0.501, 0.498, 1.428, 1.4449999999999998, -0.502, 0.489, 1.392, 0.498, -1.0, 0.497, 1.438, 0.477, 1.447, -0.502, -0.501, -0.501, -0.501, 0.498, 1.4060000000000001, -1.001, -0.001, 0.499, -1.0, 0.496, 0.6599999999999999, 1.388, 0.919, -1.0, 1.436, -1.029, 0.498, 0.495, -1.002, -0.5, -0.5, 1.431, 0.965, 1.4529999999999998, -1.003, -0.5, 1.438, 0.491, -0.5, 0.499, -1.001, 0.96, 0.953, 0.499, 0.497, 1.4369999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3961723541039464, "mean_inference_ms": 7.441072463459924, "mean_action_processing_ms": 0.3914363395518041, "mean_env_wait_ms": 0.5182079312499522, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14973094320704794, "StateBufferConnector_ms": 0.009162711282061715, "ViewRequirementAgentConnector_ms": 0.1790293261536166}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 696000, "num_agent_steps_trained": 696000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 136.84130645330626, "num_env_steps_trained_throughput_per_sec": 136.84130645330626, "timesteps_total": 348000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 696000, "timers": {"training_iteration_time_ms": 31002.161, "sample_time_ms": 4016.826, "learn_time_ms": 26955.381, "learn_throughput": 148.393, "synch_weights_time_ms": 28.405}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 696000, "num_agent_steps_trained": 696000}, "done": false, "episodes_total": 5104, "training_iteration": 87, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-43-09", "timestamp": 1694839389, "time_this_iter_s": 29.246779918670654, "time_total_s": 2710.021278142929, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21984d30>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2710.021278142929, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 21.254761904761907, "ram_util_percent": 57.11904761904763}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.4473684210526316, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.2894736842105263, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09649122807017543, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.2894736842105263, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14912280701754385, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09649122807017543, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.2894736842105263, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09649122807017543, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5901234646327793, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05633839255800315, "policy_loss": -0.10028568968943243, "vf_loss": 0.03246468321206824, "vf_explained_var": 0.7034978426372012, "kl": 0.012733669897052853, "entropy": 1.2939362600445747, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5773506225086749, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.060027099412400274, "policy_loss": -0.10228200328080371, "vf_loss": 0.033382555616359846, "vf_explained_var": 0.6252121900518736, "kl": 0.011899244867538527, "entropy": 1.544341336687406, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "sampler_results": {"episode_reward_max": 1.959, "episode_reward_min": -0.10199999999999987, "episode_reward_mean": 1.2796578947368422, "episode_len_mean": 31.473684210526315, "episode_media": {}, "episodes_this_iter": 114, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 1.0091315789473685, "blue_0": 0.2705263157894737}, "custom_metrics": {"red_0/door_open_done_mean": 0.4473684210526316, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.2894736842105263, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09649122807017543, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.2894736842105263, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14912280701754385, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09649122807017543, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.2894736842105263, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09649122807017543, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.437, -0.027000000000000024, 1.4040000000000001, 0.11499999999999999, 1.935, 1.92, 1.8239999999999998, -0.08499999999999996, 1.4289999999999998, 0.45199999999999996, -0.10199999999999987, 0.9199999999999999, 1.888, 0.9550000000000001, 1.958, 1.904, 1.9569999999999999, 0.907, 0.31200000000000006, 1.4140000000000001, 1.431, 0.9220000000000002, 1.938, 1.939, 1.931, 1.8719999999999999, 1.427, 0.2410000000000001, 1.456, 0.861, 1.9289999999999998, 1.419, 1.45, 1.908, 1.952, 0.45399999999999996, 1.938, 0.9550000000000001, 1.934, 0.46599999999999997, 0.964, 1.952, 1.912, 0.9210000000000003, 0.469, 1.3940000000000001, 1.87, 0.958, 1.432, 1.909, -0.052000000000000046, 0.44899999999999984, 0.44599999999999995, 1.85, 1.4140000000000001, 1.943, 0.567, 1.896, 0.9269999999999999, -0.05600000000000005, 1.863, 1.38, 1.943, 1.959, 1.431, 1.448, 1.896, 0.9120000000000001, 0.44799999999999995, -0.029000000000000026, 1.4529999999999998, 1.439, 1.954, 1.9409999999999998, 0.43399999999999994, 1.959, 1.438, 1.75, 0.845, 0.9219999999999999, 1.9369999999999998, 1.94, 0.9359999999999999, 1.4300000000000002, 1.425, 0.46399999999999997, 1.432, 0.9489999999999998, 0.43199999999999994, 1.807, 0.43799999999999994, 1.943, 0.9100000000000001, 1.9300000000000002, 1.952, 0.8079999999999998, 1.958, 0.847, 0.9630000000000001, 0.44699999999999995, 1.928, 0.97, 0.46899999999999986, 0.9299999999999999, 1.442, 0.854, 0.9100000000000001, 1.9260000000000002, 1.923, 1.931, 1.943, 1.454, 1.346, 1.416], "episode_lengths": [20, 9, 29, 122, 21, 25, 54, 27, 21, 15, 31, 25, 34, 15, 14, 30, 14, 29, 58, 28, 21, 25, 20, 19, 22, 41, 24, 80, 14, 44, 22, 26, 16, 30, 15, 15, 20, 15, 21, 11, 12, 16, 28, 25, 10, 34, 41, 14, 22, 29, 17, 15, 17, 48, 28, 18, 133, 33, 300, 17, 43, 38, 19, 13, 22, 17, 32, 27, 16, 9, 15, 20, 15, 19, 22, 13, 20, 76, 50, 300, 20, 20, 21, 23, 23, 12, 21, 16, 22, 59, 20, 18, 28, 23, 15, 60, 14, 48, 12, 17, 22, 10, 10, 21, 18, 45, 29, 23, 25, 22, 18, 15, 47, 26], "policy_red_0_reward": [1.44, -1.0, 1.409, 0.627, 1.435, 1.4220000000000002, 0.49, -1.004, 1.432, 1.455, -1.006, 1.423, 1.3940000000000001, 1.455, 0.5, 1.407, 0.499, -0.504, -1.007, 1.416, -0.004, 1.425, 1.439, 0.497, 1.4329999999999998, 0.498, 1.428, 1.25, 1.4569999999999999, 1.365, 1.431, 1.421, 1.452, 1.409, 1.454, 0.954, 1.44, 1.455, 1.4369999999999998, -0.5, 1.464, 1.452, 1.416, 1.425, -1.001, 1.396, 1.3719999999999999, 1.458, 1.4329999999999998, 0.498, 0.948, 1.4489999999999998, 1.448, 1.354, 1.415, 1.4449999999999998, 1.081, 1.399, 0.45699999999999996, 0.948, 1.3679999999999999, 1.383, 1.443, 1.4609999999999999, 1.4329999999999998, 1.4489999999999998, 1.4, 1.417, 0.95, 0.972, 1.455, 1.44, 1.455, 1.4409999999999998, -0.5, 1.4609999999999999, 1.438, 0.489, 1.349, 0.46199999999999997, 1.439, 0.5, 1.4369999999999998, 0.0, 1.4300000000000002, 0.964, 1.434, 1.452, 1.4329999999999998, 0.484, 1.438, 1.446, -0.5029999999999999, 1.4300000000000002, 0.497, 1.3159999999999998, 0.5, 1.351, 1.464, -0.5, 0.497, 1.47, 1.47, 1.4329999999999998, -0.002, -0.504, 1.412, 1.429, 1.424, 0.5, 1.4449999999999998, 1.455, 1.355, -0.002], "policy_blue_0_reward": [-0.003, 0.973, -0.005, -0.512, 0.5, 0.498, 1.334, 0.919, -0.003, -1.003, 0.904, -0.503, 0.494, -0.5, 1.458, 0.497, 1.458, 1.411, 1.319, -0.002, 1.435, -0.503, 0.499, 1.442, 0.498, 1.374, -0.001, -1.009, -0.001, -0.504, 0.498, -0.002, -0.002, 0.499, 0.498, -0.5, 0.498, -0.5, 0.497, 0.966, -0.5, 0.5, 0.496, -0.5039999999999999, 1.47, -0.002, 0.498, -0.5, -0.001, 1.411, -1.0, -1.0, -1.002, 0.496, -0.001, 0.498, -0.514, 0.497, 0.47, -1.004, 0.495, -0.003, 0.5, 0.498, -0.002, -0.001, 0.496, -0.5049999999999999, -0.502, -1.001, -0.002, -0.001, 0.499, 0.5, 0.9339999999999999, 0.498, 0.0, 1.2610000000000001, -0.504, 0.45999999999999996, 0.498, 1.44, -0.501, 1.4300000000000002, -0.005, -0.5, -0.002, -0.503, -1.001, 1.323, -1.0, 0.497, 1.413, 0.5, 1.455, -0.508, 1.458, -0.504, -0.5009999999999999, 0.947, 1.431, -0.5, -1.001, -0.503, 1.444, 1.358, -0.502, 0.497, 0.499, 1.431, 0.498, -0.001, -0.009000000000000001, 1.4180000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3936025465140893, "mean_inference_ms": 7.423570209156635, "mean_action_processing_ms": 0.39131484435876995, "mean_env_wait_ms": 0.5170489025795697, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14110218014633447, "StateBufferConnector_ms": 0.00938281678316886, "ViewRequirementAgentConnector_ms": 0.1887015083379913}}, "episode_reward_max": 1.959, "episode_reward_min": -0.10199999999999987, "episode_reward_mean": 1.2796578947368422, "episode_len_mean": 31.473684210526315, "episodes_this_iter": 114, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 1.0091315789473685, "blue_0": 0.2705263157894737}, "hist_stats": {"episode_reward": [1.437, -0.027000000000000024, 1.4040000000000001, 0.11499999999999999, 1.935, 1.92, 1.8239999999999998, -0.08499999999999996, 1.4289999999999998, 0.45199999999999996, -0.10199999999999987, 0.9199999999999999, 1.888, 0.9550000000000001, 1.958, 1.904, 1.9569999999999999, 0.907, 0.31200000000000006, 1.4140000000000001, 1.431, 0.9220000000000002, 1.938, 1.939, 1.931, 1.8719999999999999, 1.427, 0.2410000000000001, 1.456, 0.861, 1.9289999999999998, 1.419, 1.45, 1.908, 1.952, 0.45399999999999996, 1.938, 0.9550000000000001, 1.934, 0.46599999999999997, 0.964, 1.952, 1.912, 0.9210000000000003, 0.469, 1.3940000000000001, 1.87, 0.958, 1.432, 1.909, -0.052000000000000046, 0.44899999999999984, 0.44599999999999995, 1.85, 1.4140000000000001, 1.943, 0.567, 1.896, 0.9269999999999999, -0.05600000000000005, 1.863, 1.38, 1.943, 1.959, 1.431, 1.448, 1.896, 0.9120000000000001, 0.44799999999999995, -0.029000000000000026, 1.4529999999999998, 1.439, 1.954, 1.9409999999999998, 0.43399999999999994, 1.959, 1.438, 1.75, 0.845, 0.9219999999999999, 1.9369999999999998, 1.94, 0.9359999999999999, 1.4300000000000002, 1.425, 0.46399999999999997, 1.432, 0.9489999999999998, 0.43199999999999994, 1.807, 0.43799999999999994, 1.943, 0.9100000000000001, 1.9300000000000002, 1.952, 0.8079999999999998, 1.958, 0.847, 0.9630000000000001, 0.44699999999999995, 1.928, 0.97, 0.46899999999999986, 0.9299999999999999, 1.442, 0.854, 0.9100000000000001, 1.9260000000000002, 1.923, 1.931, 1.943, 1.454, 1.346, 1.416], "episode_lengths": [20, 9, 29, 122, 21, 25, 54, 27, 21, 15, 31, 25, 34, 15, 14, 30, 14, 29, 58, 28, 21, 25, 20, 19, 22, 41, 24, 80, 14, 44, 22, 26, 16, 30, 15, 15, 20, 15, 21, 11, 12, 16, 28, 25, 10, 34, 41, 14, 22, 29, 17, 15, 17, 48, 28, 18, 133, 33, 300, 17, 43, 38, 19, 13, 22, 17, 32, 27, 16, 9, 15, 20, 15, 19, 22, 13, 20, 76, 50, 300, 20, 20, 21, 23, 23, 12, 21, 16, 22, 59, 20, 18, 28, 23, 15, 60, 14, 48, 12, 17, 22, 10, 10, 21, 18, 45, 29, 23, 25, 22, 18, 15, 47, 26], "policy_red_0_reward": [1.44, -1.0, 1.409, 0.627, 1.435, 1.4220000000000002, 0.49, -1.004, 1.432, 1.455, -1.006, 1.423, 1.3940000000000001, 1.455, 0.5, 1.407, 0.499, -0.504, -1.007, 1.416, -0.004, 1.425, 1.439, 0.497, 1.4329999999999998, 0.498, 1.428, 1.25, 1.4569999999999999, 1.365, 1.431, 1.421, 1.452, 1.409, 1.454, 0.954, 1.44, 1.455, 1.4369999999999998, -0.5, 1.464, 1.452, 1.416, 1.425, -1.001, 1.396, 1.3719999999999999, 1.458, 1.4329999999999998, 0.498, 0.948, 1.4489999999999998, 1.448, 1.354, 1.415, 1.4449999999999998, 1.081, 1.399, 0.45699999999999996, 0.948, 1.3679999999999999, 1.383, 1.443, 1.4609999999999999, 1.4329999999999998, 1.4489999999999998, 1.4, 1.417, 0.95, 0.972, 1.455, 1.44, 1.455, 1.4409999999999998, -0.5, 1.4609999999999999, 1.438, 0.489, 1.349, 0.46199999999999997, 1.439, 0.5, 1.4369999999999998, 0.0, 1.4300000000000002, 0.964, 1.434, 1.452, 1.4329999999999998, 0.484, 1.438, 1.446, -0.5029999999999999, 1.4300000000000002, 0.497, 1.3159999999999998, 0.5, 1.351, 1.464, -0.5, 0.497, 1.47, 1.47, 1.4329999999999998, -0.002, -0.504, 1.412, 1.429, 1.424, 0.5, 1.4449999999999998, 1.455, 1.355, -0.002], "policy_blue_0_reward": [-0.003, 0.973, -0.005, -0.512, 0.5, 0.498, 1.334, 0.919, -0.003, -1.003, 0.904, -0.503, 0.494, -0.5, 1.458, 0.497, 1.458, 1.411, 1.319, -0.002, 1.435, -0.503, 0.499, 1.442, 0.498, 1.374, -0.001, -1.009, -0.001, -0.504, 0.498, -0.002, -0.002, 0.499, 0.498, -0.5, 0.498, -0.5, 0.497, 0.966, -0.5, 0.5, 0.496, -0.5039999999999999, 1.47, -0.002, 0.498, -0.5, -0.001, 1.411, -1.0, -1.0, -1.002, 0.496, -0.001, 0.498, -0.514, 0.497, 0.47, -1.004, 0.495, -0.003, 0.5, 0.498, -0.002, -0.001, 0.496, -0.5049999999999999, -0.502, -1.001, -0.002, -0.001, 0.499, 0.5, 0.9339999999999999, 0.498, 0.0, 1.2610000000000001, -0.504, 0.45999999999999996, 0.498, 1.44, -0.501, 1.4300000000000002, -0.005, -0.5, -0.002, -0.503, -1.001, 1.323, -1.0, 0.497, 1.413, 0.5, 1.455, -0.508, 1.458, -0.504, -0.5009999999999999, 0.947, 1.431, -0.5, -1.001, -0.503, 1.444, 1.358, -0.502, 0.497, 0.499, 1.431, 0.498, -0.001, -0.009000000000000001, 1.4180000000000001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3936025465140893, "mean_inference_ms": 7.423570209156635, "mean_action_processing_ms": 0.39131484435876995, "mean_env_wait_ms": 0.5170489025795697, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14110218014633447, "StateBufferConnector_ms": 0.00938281678316886, "ViewRequirementAgentConnector_ms": 0.1887015083379913}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 132.89554490788962, "num_env_steps_trained_throughput_per_sec": 132.89554490788962, "timesteps_total": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 30960.484, "sample_time_ms": 4029.632, "learn_time_ms": 26901.33, "learn_throughput": 148.692, "synch_weights_time_ms": 27.956}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "episodes_total": 5218, "training_iteration": 88, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-43-40", "timestamp": 1694839420, "time_this_iter_s": 30.11586833000183, "time_total_s": 2740.137146472931, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f5bd0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2740.137146472931, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 24.63181818181818, "ram_util_percent": 57.0840909090909}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.46616541353383456, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.3007518796992481, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09022556390977443, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.3007518796992481, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11278195488721804, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09022556390977443, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.3007518796992481, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09022556390977443, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6287751412640016, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04032550306243744, "policy_loss": -0.08878960847505368, "vf_loss": 0.04001396403764375, "vf_explained_var": 0.6618658047790329, "kl": 0.013030479050278893, "entropy": 1.2279372322062652, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6105168768204748, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05479435791470071, "policy_loss": -0.10192841897514882, "vf_loss": 0.0406153106916463, "vf_explained_var": 0.5849560548861822, "kl": 0.012448621814295627, "entropy": 1.5331116086492935, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 712000, "num_agent_steps_trained": 712000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.061000000000000054, "episode_reward_mean": 1.3083533834586463, "episode_len_mean": 33.255639097744364, "episode_media": {}, "episodes_this_iter": 133, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.0199999999999998}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.467}, "policy_reward_mean": {"red_0": 1.0558571428571426, "blue_0": 0.2524962406015038}, "custom_metrics": {"red_0/door_open_done_mean": 0.46616541353383456, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.3007518796992481, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09022556390977443, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.3007518796992481, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11278195488721804, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09022556390977443, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.3007518796992481, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09022556390977443, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.31700000000000017, 1.947, 0.46099999999999985, 1.876, 1.95, 1.9489999999999998, 1.96, 1.877, 0.3839999999999999, 1.9220000000000002, 1.9449999999999998, 1.887, 1.951, 0.964, 1.92, 0.9490000000000001, 1.9489999999999998, 1.9449999999999998, 0.44300000000000006, 1.944, 1.952, 1.7759999999999998, 1.943, 1.958, 1.917, 0.954, 0.931, 1.944, 0.9319999999999999, 1.931, 0.952, 1.87, 1.934, 0.942, 1.42, 0.962, 0.953, 1.9329999999999998, 1.4260000000000002, 1.8930000000000002, 1.905, 0.911, 1.895, 1.9449999999999998, 0.869, 0.42300000000000004, 1.932, 1.935, 1.909, 0.9329999999999998, 0.476, 1.825, 0.94, 1.448, 0.353, 1.932, 1.95, 1.9329999999999998, 1.6790000000000003, 0.899, 1.435, 1.92, 1.938, -0.061000000000000054, 0.9209999999999998, 1.876, 0.44499999999999984, 0.46199999999999997, 0.46599999999999997, 1.424, 1.912, 1.9449999999999998, 0.47, 1.9609999999999999, 0.42300000000000004, 0.941, 1.776, 0.944, 1.931, 0.4670000000000001, 1.935, -0.027000000000000024, 1.934, 0.46599999999999997, 1.4369999999999998, 0.46099999999999985, 0.798, 1.958, 0.946, 1.936, 0.45699999999999985, 1.9500000000000002, 1.921, 1.926, 0.873, 1.9060000000000001, 0.406, 0.46099999999999985, 1.958, 1.951, 1.854, 1.706, 0.948, 0.45999999999999996, 0.47299999999999986, 1.9329999999999998, 1.417, 1.127, 1.367, -0.02299999999999991, 0.44899999999999984, 0.9569999999999999, 1.952, 0.357, 1.404, 1.954, 0.4139999999999999, 1.439, 0.44199999999999995, 0.472, 1.436, 1.439, 1.866, 1.95, 0.4540000000000002, 1.411, -0.04300000000000004, 1.94, 0.45699999999999985, 1.916, 0.46099999999999985, 0.42799999999999994, 0.79], "episode_lengths": [54, 17, 13, 40, 16, 16, 13, 38, 37, 25, 18, 36, 16, 11, 24, 16, 16, 18, 19, 17, 16, 69, 18, 13, 27, 15, 22, 18, 21, 22, 15, 41, 20, 300, 26, 12, 14, 21, 23, 33, 31, 28, 34, 18, 40, 23, 22, 21, 29, 20, 8, 56, 300, 17, 46, 22, 16, 21, 101, 32, 20, 25, 20, 19, 24, 39, 17, 12, 11, 24, 28, 17, 10, 13, 24, 19, 70, 300, 22, 11, 21, 9, 21, 11, 20, 12, 63, 14, 17, 20, 13, 15, 25, 24, 40, 28, 30, 13, 14, 15, 47, 89, 16, 13, 9, 21, 26, 118, 42, 7, 17, 14, 15, 45, 30, 15, 300, 19, 18, 9, 21, 20, 43, 16, 14, 25, 14, 19, 13, 26, 12, 22, 67], "policy_red_0_reward": [1.337, 1.4489999999999998, 0.961, 0.498, 1.451, 1.452, 1.4609999999999999, 0.499, 1.389, 0.498, 1.446, 1.3900000000000001, 1.452, -0.5, 1.426, -0.5019999999999999, 1.451, 0.5, 0.943, 0.498, 1.452, 1.2879999999999998, 1.4449999999999998, 1.4609999999999999, 0.5, 1.455, 1.432, 1.4449999999999998, 1.4369999999999998, 0.498, 1.4529999999999998, 1.3719999999999999, 1.439, 0.46799999999999997, 1.4220000000000002, 1.464, -0.504, 1.436, 1.429, 1.3980000000000001, 1.4060000000000001, 1.412, 1.397, 0.5, 1.373, 1.4300000000000002, 1.434, 0.499, 1.411, 1.436, 1.476, 0.496, 0.46099999999999997, 1.448, -1.004, 1.432, 1.452, 1.4369999999999998, 1.187, 1.4020000000000001, 1.4369999999999998, 1.423, 1.439, -1.001, 1.428, 1.38, 0.947, -0.5, -1.001, 1.428, 1.415, 1.447, -0.5, 0.5, 0.9249999999999999, -0.501, 1.2810000000000001, 0.48, 0.499, 1.467, 1.436, 0.973, 1.4369999999999998, 0.967, 1.438, 0.962, 1.306, 0.5, 1.448, 1.439, 1.46, 1.454, 1.424, 1.428, -0.505, 1.411, -0.502, 1.4609999999999999, 1.458, 1.454, 1.3559999999999999, 1.2189999999999999, 1.451, 1.46, 1.4729999999999999, 1.4369999999999998, 1.4180000000000001, 1.1360000000000001, 1.369, 0.979, 1.4489999999999998, 1.458, 1.454, -0.502, -0.004, 1.455, 0.42899999999999994, 1.442, 1.4449999999999998, 0.972, 1.4369999999999998, 1.439, 1.367, 1.452, 1.458, 1.4180000000000001, 0.958, 1.443, 1.46, 0.496, 0.961, 0.9339999999999999, 1.294], "policy_blue_0_reward": [-1.0199999999999998, 0.498, -0.5, 1.3780000000000001, 0.499, 0.497, 0.499, 1.3780000000000001, -1.005, 1.424, 0.499, 0.497, 0.499, 1.464, 0.494, 1.451, 0.498, 1.4449999999999998, -0.5, 1.446, 0.5, 0.488, 0.498, 0.497, 1.417, -0.501, -0.501, 0.499, -0.505, 1.4329999999999998, -0.501, 0.498, 0.495, 0.474, -0.002, -0.502, 1.4569999999999999, 0.497, -0.003, 0.495, 0.499, -0.501, 0.498, 1.4449999999999998, -0.504, -1.007, 0.498, 1.436, 0.498, -0.503, -1.0, 1.329, 0.479, 0.0, 1.357, 0.5, 0.498, 0.496, 0.492, -0.503, -0.002, 0.497, 0.499, 0.94, -0.507, 0.496, -0.502, 0.962, 1.467, -0.004, 0.497, 0.498, 0.97, 1.4609999999999999, -0.502, 1.442, 0.495, 0.46399999999999997, 1.432, -1.0, 0.499, -1.0, 0.497, -0.501, -0.001, -0.501, -0.508, 1.458, -0.502, 0.497, -1.003, 0.496, 0.497, 0.498, 1.3780000000000001, 0.495, 0.908, -1.0, 0.5, 0.497, 0.498, 0.487, -0.503, -1.0, -1.0, 0.496, -0.001, -0.009000000000000001, -0.002, -1.0019999999999998, -1.0, -0.501, 0.498, 0.859, 1.408, 0.499, -0.015000000000000006, -0.003, -1.003, -0.5, -0.001, 0.0, 0.499, 0.498, -1.0039999999999998, -0.007, -1.001, 0.497, -1.003, 1.42, -0.5, -0.506, -0.504]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3983015381379125, "mean_inference_ms": 7.430496348597423, "mean_action_processing_ms": 0.3904536809013003, "mean_env_wait_ms": 0.5182057477520801, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1412205230024524, "StateBufferConnector_ms": 0.009603787185554217, "ViewRequirementAgentConnector_ms": 0.18611017026399312}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.061000000000000054, "episode_reward_mean": 1.3083533834586463, "episode_len_mean": 33.255639097744364, "episodes_this_iter": 133, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.0199999999999998}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.467}, "policy_reward_mean": {"red_0": 1.0558571428571426, "blue_0": 0.2524962406015038}, "hist_stats": {"episode_reward": [0.31700000000000017, 1.947, 0.46099999999999985, 1.876, 1.95, 1.9489999999999998, 1.96, 1.877, 0.3839999999999999, 1.9220000000000002, 1.9449999999999998, 1.887, 1.951, 0.964, 1.92, 0.9490000000000001, 1.9489999999999998, 1.9449999999999998, 0.44300000000000006, 1.944, 1.952, 1.7759999999999998, 1.943, 1.958, 1.917, 0.954, 0.931, 1.944, 0.9319999999999999, 1.931, 0.952, 1.87, 1.934, 0.942, 1.42, 0.962, 0.953, 1.9329999999999998, 1.4260000000000002, 1.8930000000000002, 1.905, 0.911, 1.895, 1.9449999999999998, 0.869, 0.42300000000000004, 1.932, 1.935, 1.909, 0.9329999999999998, 0.476, 1.825, 0.94, 1.448, 0.353, 1.932, 1.95, 1.9329999999999998, 1.6790000000000003, 0.899, 1.435, 1.92, 1.938, -0.061000000000000054, 0.9209999999999998, 1.876, 0.44499999999999984, 0.46199999999999997, 0.46599999999999997, 1.424, 1.912, 1.9449999999999998, 0.47, 1.9609999999999999, 0.42300000000000004, 0.941, 1.776, 0.944, 1.931, 0.4670000000000001, 1.935, -0.027000000000000024, 1.934, 0.46599999999999997, 1.4369999999999998, 0.46099999999999985, 0.798, 1.958, 0.946, 1.936, 0.45699999999999985, 1.9500000000000002, 1.921, 1.926, 0.873, 1.9060000000000001, 0.406, 0.46099999999999985, 1.958, 1.951, 1.854, 1.706, 0.948, 0.45999999999999996, 0.47299999999999986, 1.9329999999999998, 1.417, 1.127, 1.367, -0.02299999999999991, 0.44899999999999984, 0.9569999999999999, 1.952, 0.357, 1.404, 1.954, 0.4139999999999999, 1.439, 0.44199999999999995, 0.472, 1.436, 1.439, 1.866, 1.95, 0.4540000000000002, 1.411, -0.04300000000000004, 1.94, 0.45699999999999985, 1.916, 0.46099999999999985, 0.42799999999999994, 0.79], "episode_lengths": [54, 17, 13, 40, 16, 16, 13, 38, 37, 25, 18, 36, 16, 11, 24, 16, 16, 18, 19, 17, 16, 69, 18, 13, 27, 15, 22, 18, 21, 22, 15, 41, 20, 300, 26, 12, 14, 21, 23, 33, 31, 28, 34, 18, 40, 23, 22, 21, 29, 20, 8, 56, 300, 17, 46, 22, 16, 21, 101, 32, 20, 25, 20, 19, 24, 39, 17, 12, 11, 24, 28, 17, 10, 13, 24, 19, 70, 300, 22, 11, 21, 9, 21, 11, 20, 12, 63, 14, 17, 20, 13, 15, 25, 24, 40, 28, 30, 13, 14, 15, 47, 89, 16, 13, 9, 21, 26, 118, 42, 7, 17, 14, 15, 45, 30, 15, 300, 19, 18, 9, 21, 20, 43, 16, 14, 25, 14, 19, 13, 26, 12, 22, 67], "policy_red_0_reward": [1.337, 1.4489999999999998, 0.961, 0.498, 1.451, 1.452, 1.4609999999999999, 0.499, 1.389, 0.498, 1.446, 1.3900000000000001, 1.452, -0.5, 1.426, -0.5019999999999999, 1.451, 0.5, 0.943, 0.498, 1.452, 1.2879999999999998, 1.4449999999999998, 1.4609999999999999, 0.5, 1.455, 1.432, 1.4449999999999998, 1.4369999999999998, 0.498, 1.4529999999999998, 1.3719999999999999, 1.439, 0.46799999999999997, 1.4220000000000002, 1.464, -0.504, 1.436, 1.429, 1.3980000000000001, 1.4060000000000001, 1.412, 1.397, 0.5, 1.373, 1.4300000000000002, 1.434, 0.499, 1.411, 1.436, 1.476, 0.496, 0.46099999999999997, 1.448, -1.004, 1.432, 1.452, 1.4369999999999998, 1.187, 1.4020000000000001, 1.4369999999999998, 1.423, 1.439, -1.001, 1.428, 1.38, 0.947, -0.5, -1.001, 1.428, 1.415, 1.447, -0.5, 0.5, 0.9249999999999999, -0.501, 1.2810000000000001, 0.48, 0.499, 1.467, 1.436, 0.973, 1.4369999999999998, 0.967, 1.438, 0.962, 1.306, 0.5, 1.448, 1.439, 1.46, 1.454, 1.424, 1.428, -0.505, 1.411, -0.502, 1.4609999999999999, 1.458, 1.454, 1.3559999999999999, 1.2189999999999999, 1.451, 1.46, 1.4729999999999999, 1.4369999999999998, 1.4180000000000001, 1.1360000000000001, 1.369, 0.979, 1.4489999999999998, 1.458, 1.454, -0.502, -0.004, 1.455, 0.42899999999999994, 1.442, 1.4449999999999998, 0.972, 1.4369999999999998, 1.439, 1.367, 1.452, 1.458, 1.4180000000000001, 0.958, 1.443, 1.46, 0.496, 0.961, 0.9339999999999999, 1.294], "policy_blue_0_reward": [-1.0199999999999998, 0.498, -0.5, 1.3780000000000001, 0.499, 0.497, 0.499, 1.3780000000000001, -1.005, 1.424, 0.499, 0.497, 0.499, 1.464, 0.494, 1.451, 0.498, 1.4449999999999998, -0.5, 1.446, 0.5, 0.488, 0.498, 0.497, 1.417, -0.501, -0.501, 0.499, -0.505, 1.4329999999999998, -0.501, 0.498, 0.495, 0.474, -0.002, -0.502, 1.4569999999999999, 0.497, -0.003, 0.495, 0.499, -0.501, 0.498, 1.4449999999999998, -0.504, -1.007, 0.498, 1.436, 0.498, -0.503, -1.0, 1.329, 0.479, 0.0, 1.357, 0.5, 0.498, 0.496, 0.492, -0.503, -0.002, 0.497, 0.499, 0.94, -0.507, 0.496, -0.502, 0.962, 1.467, -0.004, 0.497, 0.498, 0.97, 1.4609999999999999, -0.502, 1.442, 0.495, 0.46399999999999997, 1.432, -1.0, 0.499, -1.0, 0.497, -0.501, -0.001, -0.501, -0.508, 1.458, -0.502, 0.497, -1.003, 0.496, 0.497, 0.498, 1.3780000000000001, 0.495, 0.908, -1.0, 0.5, 0.497, 0.498, 0.487, -0.503, -1.0, -1.0, 0.496, -0.001, -0.009000000000000001, -0.002, -1.0019999999999998, -1.0, -0.501, 0.498, 0.859, 1.408, 0.499, -0.015000000000000006, -0.003, -1.003, -0.5, -0.001, 0.0, 0.499, 0.498, -1.0039999999999998, -0.007, -1.001, 0.497, -1.003, 1.42, -0.5, -0.506, -0.504]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3983015381379125, "mean_inference_ms": 7.430496348597423, "mean_action_processing_ms": 0.3904536809013003, "mean_env_wait_ms": 0.5182057477520801, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1412205230024524, "StateBufferConnector_ms": 0.009603787185554217, "ViewRequirementAgentConnector_ms": 0.18611017026399312}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 712000, "num_agent_steps_trained": 712000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.9505141528691, "num_env_steps_trained_throughput_per_sec": 131.9505141528691, "timesteps_total": 356000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 712000, "timers": {"training_iteration_time_ms": 30780.73, "sample_time_ms": 4011.286, "learn_time_ms": 26740.26, "learn_throughput": 149.587, "synch_weights_time_ms": 27.636}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 712000, "num_agent_steps_trained": 712000}, "done": false, "episodes_total": 5351, "training_iteration": 89, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-44-11", "timestamp": 1694839451, "time_this_iter_s": 30.333459854125977, "time_total_s": 2770.470606327057, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21980940>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2770.470606327057, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 25.131818181818186, "ram_util_percent": 57.136363636363626}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.41, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.29, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.29, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.29, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.598713429334263, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04874496345194833, "policy_loss": -0.09017104594070892, "vf_loss": 0.031895392676233314, "vf_explained_var": 0.6662820985540747, "kl": 0.011706153673810605, "entropy": 1.1896943358083567, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 85920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5855361383408308, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.056970146500195065, "policy_loss": -0.09950172345803973, "vf_loss": 0.03389029401587322, "vf_explained_var": 0.558040707372129, "kl": 0.011925975058764004, "entropy": 1.5824326569835345, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 85920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "sampler_results": {"episode_reward_max": 1.958, "episode_reward_min": -0.07700000000000007, "episode_reward_mean": 1.13481, "episode_len_mean": 38.46, "episode_media": {}, "episodes_this_iter": 94, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.006}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.464}, "policy_reward_mean": {"red_0": 0.86881, "blue_0": 0.26599999999999996}, "custom_metrics": {"red_0/door_open_done_mean": 0.41, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.29, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.29, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.29, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.94, 0.45699999999999985, 1.916, 0.46099999999999985, 0.42799999999999994, 0.79, 1.884, 0.9449999999999998, 0.371, 1.435, 1.866, 1.899, 0.46299999999999997, 1.934, 1.4409999999999998, 0.476, 1.954, 1.8800000000000001, 0.8900000000000001, 1.891, -0.07700000000000007, 0.45699999999999996, 0.28400000000000003, 1.863, 1.947, 0.4570000000000001, 1.9289999999999998, -0.07299999999999984, 0.964, 0.44499999999999984, 1.8780000000000001, 1.329, 1.876, 0.877, 1.432, 1.854, 1.387, 1.858, 1.899, 1.4369999999999998, 1.917, 0.24799999999999978, 0.3880000000000001, 1.3940000000000001, 0.931, 0.32699999999999996, 0.3860000000000001, 1.46, 0.8780000000000001, 1.434, 1.917, 0.955, 1.942, 0.9390000000000001, 0.3759999999999999, 1.931, 1.46, 1.903, 0.4710000000000001, 0.42799999999999994, 1.892, 1.9569999999999999, 1.4409999999999998, -0.05500000000000005, 0.397, 1.938, 0.911, 1.9449999999999998, 1.424, 0.389, 1.919, 0.8260000000000001, 1.931, 1.303, 1.958, 1.913, -0.026000000000000023, 0.42800000000000005, 0.44599999999999995, 0.42000000000000004, 1.95, 1.412, -0.04500000000000004, 0.15799999999999992, 0.8860000000000001, 0.42300000000000004, 1.4689999999999999, 0.469, 0.2749999999999998, 0.43100000000000005, 1.9140000000000001, 1.434, 1.935, 1.395, 0.3589999999999999, 1.37, 0.9359999999999999, 1.4220000000000002, 0.45599999999999996, 0.44599999999999995], "episode_lengths": [19, 13, 26, 12, 22, 67, 36, 17, 41, 21, 41, 30, 12, 20, 18, 8, 15, 36, 34, 34, 24, 14, 68, 42, 17, 14, 22, 23, 12, 17, 37, 53, 40, 38, 22, 45, 35, 44, 30, 20, 27, 300, 35, 34, 22, 54, 36, 13, 39, 20, 27, 14, 19, 19, 38, 21, 13, 31, 9, 23, 34, 14, 19, 18, 34, 19, 27, 18, 25, 34, 25, 55, 22, 63, 13, 27, 8, 23, 17, 25, 16, 28, 14, 259, 36, 24, 162, 10, 300, 21, 28, 21, 21, 34, 300, 42, 21, 25, 14, 17], "policy_red_0_reward": [1.443, 1.46, 0.496, 0.961, 0.9339999999999999, 1.294, 0.496, 1.447, 1.373, 1.435, 0.496, 0.498, -1.001, 1.438, 1.4449999999999998, -0.5, 1.455, 1.385, 1.396, 1.395, 0.9249999999999999, -0.501, -1.004, 1.366, 1.4489999999999998, -0.5009999999999999, 1.431, 0.93, 1.464, 1.448, 1.384, 1.335, 1.38, 1.383, 1.4329999999999998, 1.357, -0.004, 1.365, 0.493, 1.439, 1.419, 0.2829999999999998, -0.5029999999999999, 1.396, 1.4329999999999998, 1.329, 1.391, 1.4609999999999999, 1.38, 1.439, 1.4180000000000001, -0.5, 1.442, 1.4409999999999998, 1.3820000000000001, 1.436, -0.001, 1.4060000000000001, 1.4729999999999999, 0.929, 1.397, 1.458, -0.001, 0.946, -0.501, 1.442, 1.417, 1.446, 1.425, -0.506, 1.423, 1.33, 1.432, 1.307, 1.4609999999999999, 1.417, -1.001, -1.001, -0.501, -1.003, 1.452, -0.002, 0.957, 0.691, 1.388, 1.427, 0.988, -0.501, 0.2989999999999998, -1.003, 0.5, 1.436, 1.436, 1.396, 0.3949999999999999, 1.3719999999999999, 1.4369999999999998, -0.001, 0.957, -0.502], "policy_blue_0_reward": [0.497, -1.003, 1.42, -0.5, -0.506, -0.504, 1.388, -0.502, -1.002, 0.0, 1.37, 1.401, 1.464, 0.496, -0.004, 0.976, 0.499, 0.495, -0.506, 0.496, -1.002, 0.958, 1.288, 0.497, 0.498, 0.958, 0.498, -1.003, -0.5, -1.003, 0.494, -0.006, 0.496, -0.506, -0.001, 0.497, 1.391, 0.493, 1.4060000000000001, -0.002, 0.498, -0.035000000000000024, 0.891, -0.002, -0.502, -1.002, -1.005, -0.001, -0.502, -0.005, 0.499, 1.455, 0.5, -0.502, -1.006, 0.495, 1.4609999999999999, 0.497, -1.002, -0.501, 0.495, 0.499, 1.442, -1.001, 0.898, 0.496, -0.5059999999999999, 0.499, -0.001, 0.895, 0.496, -0.504, 0.499, -0.004, 0.497, 0.496, 0.975, 1.429, 0.947, 1.423, 0.498, 1.4140000000000001, -1.002, -0.533, -0.502, -1.004, 0.481, 0.97, -0.024000000000000014, 1.434, 1.4140000000000001, -0.002, 0.499, -0.001, -0.036000000000000025, -0.002, -0.501, 1.423, -0.501, 0.948]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3987980157233446, "mean_inference_ms": 7.426251025721415, "mean_action_processing_ms": 0.3903356901414078, "mean_env_wait_ms": 0.5183693947932796, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14683830738067627, "StateBufferConnector_ms": 0.009438157081604004, "ViewRequirementAgentConnector_ms": 0.18471980094909668}}, "episode_reward_max": 1.958, "episode_reward_min": -0.07700000000000007, "episode_reward_mean": 1.13481, "episode_len_mean": 38.46, "episodes_this_iter": 94, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.006}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.464}, "policy_reward_mean": {"red_0": 0.86881, "blue_0": 0.26599999999999996}, "hist_stats": {"episode_reward": [1.94, 0.45699999999999985, 1.916, 0.46099999999999985, 0.42799999999999994, 0.79, 1.884, 0.9449999999999998, 0.371, 1.435, 1.866, 1.899, 0.46299999999999997, 1.934, 1.4409999999999998, 0.476, 1.954, 1.8800000000000001, 0.8900000000000001, 1.891, -0.07700000000000007, 0.45699999999999996, 0.28400000000000003, 1.863, 1.947, 0.4570000000000001, 1.9289999999999998, -0.07299999999999984, 0.964, 0.44499999999999984, 1.8780000000000001, 1.329, 1.876, 0.877, 1.432, 1.854, 1.387, 1.858, 1.899, 1.4369999999999998, 1.917, 0.24799999999999978, 0.3880000000000001, 1.3940000000000001, 0.931, 0.32699999999999996, 0.3860000000000001, 1.46, 0.8780000000000001, 1.434, 1.917, 0.955, 1.942, 0.9390000000000001, 0.3759999999999999, 1.931, 1.46, 1.903, 0.4710000000000001, 0.42799999999999994, 1.892, 1.9569999999999999, 1.4409999999999998, -0.05500000000000005, 0.397, 1.938, 0.911, 1.9449999999999998, 1.424, 0.389, 1.919, 0.8260000000000001, 1.931, 1.303, 1.958, 1.913, -0.026000000000000023, 0.42800000000000005, 0.44599999999999995, 0.42000000000000004, 1.95, 1.412, -0.04500000000000004, 0.15799999999999992, 0.8860000000000001, 0.42300000000000004, 1.4689999999999999, 0.469, 0.2749999999999998, 0.43100000000000005, 1.9140000000000001, 1.434, 1.935, 1.395, 0.3589999999999999, 1.37, 0.9359999999999999, 1.4220000000000002, 0.45599999999999996, 0.44599999999999995], "episode_lengths": [19, 13, 26, 12, 22, 67, 36, 17, 41, 21, 41, 30, 12, 20, 18, 8, 15, 36, 34, 34, 24, 14, 68, 42, 17, 14, 22, 23, 12, 17, 37, 53, 40, 38, 22, 45, 35, 44, 30, 20, 27, 300, 35, 34, 22, 54, 36, 13, 39, 20, 27, 14, 19, 19, 38, 21, 13, 31, 9, 23, 34, 14, 19, 18, 34, 19, 27, 18, 25, 34, 25, 55, 22, 63, 13, 27, 8, 23, 17, 25, 16, 28, 14, 259, 36, 24, 162, 10, 300, 21, 28, 21, 21, 34, 300, 42, 21, 25, 14, 17], "policy_red_0_reward": [1.443, 1.46, 0.496, 0.961, 0.9339999999999999, 1.294, 0.496, 1.447, 1.373, 1.435, 0.496, 0.498, -1.001, 1.438, 1.4449999999999998, -0.5, 1.455, 1.385, 1.396, 1.395, 0.9249999999999999, -0.501, -1.004, 1.366, 1.4489999999999998, -0.5009999999999999, 1.431, 0.93, 1.464, 1.448, 1.384, 1.335, 1.38, 1.383, 1.4329999999999998, 1.357, -0.004, 1.365, 0.493, 1.439, 1.419, 0.2829999999999998, -0.5029999999999999, 1.396, 1.4329999999999998, 1.329, 1.391, 1.4609999999999999, 1.38, 1.439, 1.4180000000000001, -0.5, 1.442, 1.4409999999999998, 1.3820000000000001, 1.436, -0.001, 1.4060000000000001, 1.4729999999999999, 0.929, 1.397, 1.458, -0.001, 0.946, -0.501, 1.442, 1.417, 1.446, 1.425, -0.506, 1.423, 1.33, 1.432, 1.307, 1.4609999999999999, 1.417, -1.001, -1.001, -0.501, -1.003, 1.452, -0.002, 0.957, 0.691, 1.388, 1.427, 0.988, -0.501, 0.2989999999999998, -1.003, 0.5, 1.436, 1.436, 1.396, 0.3949999999999999, 1.3719999999999999, 1.4369999999999998, -0.001, 0.957, -0.502], "policy_blue_0_reward": [0.497, -1.003, 1.42, -0.5, -0.506, -0.504, 1.388, -0.502, -1.002, 0.0, 1.37, 1.401, 1.464, 0.496, -0.004, 0.976, 0.499, 0.495, -0.506, 0.496, -1.002, 0.958, 1.288, 0.497, 0.498, 0.958, 0.498, -1.003, -0.5, -1.003, 0.494, -0.006, 0.496, -0.506, -0.001, 0.497, 1.391, 0.493, 1.4060000000000001, -0.002, 0.498, -0.035000000000000024, 0.891, -0.002, -0.502, -1.002, -1.005, -0.001, -0.502, -0.005, 0.499, 1.455, 0.5, -0.502, -1.006, 0.495, 1.4609999999999999, 0.497, -1.002, -0.501, 0.495, 0.499, 1.442, -1.001, 0.898, 0.496, -0.5059999999999999, 0.499, -0.001, 0.895, 0.496, -0.504, 0.499, -0.004, 0.497, 0.496, 0.975, 1.429, 0.947, 1.423, 0.498, 1.4140000000000001, -1.002, -0.533, -0.502, -1.004, 0.481, 0.97, -0.024000000000000014, 1.434, 1.4140000000000001, -0.002, 0.499, -0.001, -0.036000000000000025, -0.002, -0.501, 1.423, -0.501, 0.948]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3987980157233446, "mean_inference_ms": 7.426251025721415, "mean_action_processing_ms": 0.3903356901414078, "mean_env_wait_ms": 0.5183693947932796, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14683830738067627, "StateBufferConnector_ms": 0.009438157081604004, "ViewRequirementAgentConnector_ms": 0.18471980094909668}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 132.99724842644213, "num_env_steps_trained_throughput_per_sec": 132.99724842644213, "timesteps_total": 360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 30672.722, "sample_time_ms": 3980.505, "learn_time_ms": 26663.698, "learn_throughput": 150.017, "synch_weights_time_ms": 26.929}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "episodes_total": 5445, "training_iteration": 90, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-44-42", "timestamp": 1694839482, "time_this_iter_s": 30.091016054153442, "time_total_s": 2800.5616223812103, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f72e0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2800.5616223812103, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 24.937209302325584, "ram_util_percent": 57.13953488372092}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5217391304347826, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.2463768115942029, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10144927536231885, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.2463768115942029, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.10869565217391304, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10144927536231885, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.2463768115942029, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10144927536231885, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6001609642989933, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04587071396041817, "policy_loss": -0.09200823090335082, "vf_loss": 0.03863747116993181, "vf_explained_var": 0.667096792285641, "kl": 0.012300813706123025, "entropy": 1.2040097830196221, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 86880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5639853524354597, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06240106904782199, "policy_loss": -0.10866289023482144, "vf_loss": 0.039512223526253366, "vf_explained_var": 0.5825259668752552, "kl": 0.012297200790628364, "entropy": 1.5088518114139637, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 86880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 728000, "num_agent_steps_trained": 728000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.041000000000000036, "episode_reward_mean": 1.3899275362318841, "episode_len_mean": 32.44927536231884, "episode_media": {}, "episodes_this_iter": 138, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.004}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.0519710144927537, "blue_0": 0.33795652173913043}, "custom_metrics": {"red_0/door_open_done_mean": 0.5217391304347826, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.2463768115942029, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10144927536231885, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.2463768115942029, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.10869565217391304, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10144927536231885, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.2463768115942029, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10144927536231885, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.799, 1.9609999999999999, 1.944, 0.9750000000000001, 0.935, 1.934, 1.908, 1.934, 1.713, 0.954, 1.928, 1.932, 1.92, 0.8980000000000001, 0.4179999999999999, 1.369, 1.9060000000000001, 1.384, 0.9590000000000001, 0.911, 1.959, 0.1549999999999998, 1.435, 1.9569999999999999, 1.955, 0.43299999999999994, 0.968, 1.951, 1.946, 1.437, 1.9329999999999998, 0.956, 0.956, 1.915, -0.027999999999999914, 0.46899999999999986, 1.947, 1.8980000000000001, 0.45299999999999996, 0.46599999999999997, 0.958, 1.885, 0.45599999999999996, 0.46399999999999997, 1.9180000000000001, 1.919, 1.96, 0.964, 1.921, 1.943, 1.9449999999999998, 1.936, 0.948, 1.95, 0.2749999999999998, 0.979, 0.9299999999999999, 1.938, 0.45299999999999985, 1.924, 1.866, 0.7570000000000001, 1.9260000000000002, 0.756, 1.46, 0.43299999999999983, 0.9409999999999998, 1.96, 1.393, 0.6389999999999999, 1.915, 1.686, 1.9329999999999998, 1.911, 1.948, 1.951, -0.03399999999999992, 0.46399999999999997, 1.938, 1.956, 1.931, 1.8519999999999999, 0.4790000000000001, 0.96, 1.92, 1.4260000000000002, 0.9180000000000001, 0.46199999999999997, 0.46099999999999985, 1.94, 1.888, 0.45399999999999996, 0.352, -0.041000000000000036, 1.069, 1.419, 0.46399999999999997, 1.8980000000000001, 1.415, 1.958, 1.4340000000000002, 1.944, 1.9060000000000001, 0.9319999999999999, 1.9569999999999999, 1.907, 1.454, 0.9409999999999998, 1.932, 1.935, 1.915, 1.94, 1.946, 0.45699999999999996, 1.8940000000000001, 1.92, 1.852, 0.942, 1.943, 1.409, 1.889, 0.45199999999999996, 1.4449999999999998, 0.44399999999999995, 1.942, 1.939, 1.375, 0.9279999999999999, 1.911, 1.944, 1.385, 1.383, 0.955, 0.9470000000000001, 1.945, 1.9609999999999999, 0.9210000000000003, 1.951], "episode_lengths": [65, 13, 18, 8, 21, 21, 29, 20, 89, 14, 23, 22, 25, 32, 300, 39, 31, 36, 13, 28, 13, 106, 20, 14, 15, 300, 10, 16, 17, 20, 21, 14, 14, 27, 9, 10, 17, 33, 15, 11, 14, 37, 14, 12, 26, 25, 13, 12, 26, 18, 17, 21, 17, 16, 300, 7, 21, 20, 15, 24, 43, 75, 23, 76, 13, 21, 19, 13, 34, 112, 27, 99, 22, 27, 17, 16, 11, 12, 19, 14, 22, 46, 7, 13, 26, 23, 26, 12, 13, 20, 35, 14, 46, 12, 288, 25, 11, 33, 28, 13, 21, 18, 29, 22, 14, 30, 15, 19, 22, 21, 27, 19, 18, 14, 32, 24, 47, 18, 19, 30, 35, 16, 17, 18, 18, 20, 40, 22, 29, 18, 37, 37, 14, 17, 18, 13, 25, 15], "policy_red_0_reward": [0.497, 1.4609999999999999, 1.4449999999999998, 1.476, 1.436, 1.435, 1.409, 1.4369999999999998, 1.2229999999999999, 1.456, 1.429, 1.4329999999999998, 0.497, 1.4020000000000001, 0.45799999999999996, 1.379, 0.499, 1.3860000000000001, 1.46, 1.415, 1.4609999999999999, 0.6629999999999999, 1.44, 1.458, 1.455, 0.46599999999999997, -0.501, 1.452, 1.447, 1.44, 1.436, -0.501, 1.458, 1.416, -1.0, 1.47, 1.4489999999999998, 1.401, -0.5, -0.501, -0.5, 1.387, 0.956, 0.964, 1.419, 1.424, 1.4609999999999999, 1.464, 1.4220000000000002, 1.4449999999999998, 1.448, 1.4369999999999998, 1.4489999999999998, 0.499, 0.2949999999999998, -0.5, -0.503, 1.439, 0.953, 1.427, 1.369, 1.2650000000000001, 1.429, 1.2650000000000001, 1.4609999999999999, 1.434, 1.442, 1.4609999999999999, 1.396, -0.512, 0.499, 0.489, 0.499, 0.497, 1.448, 1.452, 0.967, 1.464, 1.4409999999999998, 1.4569999999999999, 1.434, 1.359, 0.979, 1.46, 1.4220000000000002, 1.431, 1.42, 1.464, 0.961, 1.44, 1.3900000000000001, 1.455, -1.004, 0.963, 0.595, 1.423, -0.501, 1.4, 1.416, 1.4609999999999999, 1.436, 1.446, 1.411, 1.434, 1.458, 1.408, -0.001, 1.4409999999999998, 1.4329999999999998, 1.436, 1.417, 0.497, 1.446, -0.501, 0.495, 0.497, 1.3559999999999999, 1.4449999999999998, 0.5, 1.409, 1.391, 0.952, 1.4489999999999998, 1.446, 1.446, 1.439, -0.003, -0.503, 1.412, 1.4449999999999998, 1.387, -0.004, -0.5, 1.448, 1.446, 1.4609999999999999, 1.423, 1.455], "policy_blue_0_reward": [1.302, 0.5, 0.499, -0.501, -0.501, 0.499, 0.499, 0.497, 0.49, -0.502, 0.499, 0.499, 1.423, -0.5039999999999999, -0.04000000000000003, -0.010000000000000002, 1.407, -0.002, -0.501, -0.504, 0.498, -0.508, -0.005, 0.499, 0.5, -0.03300000000000002, 1.4689999999999999, 0.499, 0.499, -0.003, 0.497, 1.4569999999999999, -0.502, 0.499, 0.972, -1.001, 0.498, 0.497, 0.953, 0.967, 1.458, 0.498, -0.5, -0.5, 0.499, 0.495, 0.499, -0.5, 0.499, 0.498, 0.497, 0.499, -0.501, 1.451, -0.02000000000000001, 1.479, 1.4329999999999998, 0.499, -0.5, 0.497, 0.497, -0.5079999999999999, 0.497, -0.509, -0.001, -1.001, -0.501, 0.499, -0.003, 1.1509999999999998, 1.416, 1.197, 1.434, 1.4140000000000001, 0.5, 0.499, -1.001, -1.0, 0.497, 0.499, 0.497, 0.493, -0.5, -0.5, 0.498, -0.005, -0.502, -1.002, -0.5, 0.5, 0.498, -1.001, 1.3559999999999999, -1.004, 0.474, -0.004, 0.965, 0.498, -0.001, 0.497, -0.002, 0.498, 0.495, -0.502, 0.499, 0.499, 1.455, -0.5, 0.499, 0.499, 0.498, 1.443, 0.5, 0.958, 1.399, 1.423, 0.496, -0.503, 1.443, 0.0, 0.498, -0.5, -0.004, -1.002, 0.496, 0.5, 1.3780000000000001, 1.431, 0.499, 0.499, -0.002, 1.387, 1.455, -0.501, 0.499, 0.5, -0.5019999999999999, 0.496]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.398666496456346, "mean_inference_ms": 7.429179865420954, "mean_action_processing_ms": 0.3897516767740054, "mean_env_wait_ms": 0.5179552299505887, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14622867971226788, "StateBufferConnector_ms": 0.009724540986876556, "ViewRequirementAgentConnector_ms": 0.19530999487724857}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.041000000000000036, "episode_reward_mean": 1.3899275362318841, "episode_len_mean": 32.44927536231884, "episodes_this_iter": 138, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.004}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.0519710144927537, "blue_0": 0.33795652173913043}, "hist_stats": {"episode_reward": [1.799, 1.9609999999999999, 1.944, 0.9750000000000001, 0.935, 1.934, 1.908, 1.934, 1.713, 0.954, 1.928, 1.932, 1.92, 0.8980000000000001, 0.4179999999999999, 1.369, 1.9060000000000001, 1.384, 0.9590000000000001, 0.911, 1.959, 0.1549999999999998, 1.435, 1.9569999999999999, 1.955, 0.43299999999999994, 0.968, 1.951, 1.946, 1.437, 1.9329999999999998, 0.956, 0.956, 1.915, -0.027999999999999914, 0.46899999999999986, 1.947, 1.8980000000000001, 0.45299999999999996, 0.46599999999999997, 0.958, 1.885, 0.45599999999999996, 0.46399999999999997, 1.9180000000000001, 1.919, 1.96, 0.964, 1.921, 1.943, 1.9449999999999998, 1.936, 0.948, 1.95, 0.2749999999999998, 0.979, 0.9299999999999999, 1.938, 0.45299999999999985, 1.924, 1.866, 0.7570000000000001, 1.9260000000000002, 0.756, 1.46, 0.43299999999999983, 0.9409999999999998, 1.96, 1.393, 0.6389999999999999, 1.915, 1.686, 1.9329999999999998, 1.911, 1.948, 1.951, -0.03399999999999992, 0.46399999999999997, 1.938, 1.956, 1.931, 1.8519999999999999, 0.4790000000000001, 0.96, 1.92, 1.4260000000000002, 0.9180000000000001, 0.46199999999999997, 0.46099999999999985, 1.94, 1.888, 0.45399999999999996, 0.352, -0.041000000000000036, 1.069, 1.419, 0.46399999999999997, 1.8980000000000001, 1.415, 1.958, 1.4340000000000002, 1.944, 1.9060000000000001, 0.9319999999999999, 1.9569999999999999, 1.907, 1.454, 0.9409999999999998, 1.932, 1.935, 1.915, 1.94, 1.946, 0.45699999999999996, 1.8940000000000001, 1.92, 1.852, 0.942, 1.943, 1.409, 1.889, 0.45199999999999996, 1.4449999999999998, 0.44399999999999995, 1.942, 1.939, 1.375, 0.9279999999999999, 1.911, 1.944, 1.385, 1.383, 0.955, 0.9470000000000001, 1.945, 1.9609999999999999, 0.9210000000000003, 1.951], "episode_lengths": [65, 13, 18, 8, 21, 21, 29, 20, 89, 14, 23, 22, 25, 32, 300, 39, 31, 36, 13, 28, 13, 106, 20, 14, 15, 300, 10, 16, 17, 20, 21, 14, 14, 27, 9, 10, 17, 33, 15, 11, 14, 37, 14, 12, 26, 25, 13, 12, 26, 18, 17, 21, 17, 16, 300, 7, 21, 20, 15, 24, 43, 75, 23, 76, 13, 21, 19, 13, 34, 112, 27, 99, 22, 27, 17, 16, 11, 12, 19, 14, 22, 46, 7, 13, 26, 23, 26, 12, 13, 20, 35, 14, 46, 12, 288, 25, 11, 33, 28, 13, 21, 18, 29, 22, 14, 30, 15, 19, 22, 21, 27, 19, 18, 14, 32, 24, 47, 18, 19, 30, 35, 16, 17, 18, 18, 20, 40, 22, 29, 18, 37, 37, 14, 17, 18, 13, 25, 15], "policy_red_0_reward": [0.497, 1.4609999999999999, 1.4449999999999998, 1.476, 1.436, 1.435, 1.409, 1.4369999999999998, 1.2229999999999999, 1.456, 1.429, 1.4329999999999998, 0.497, 1.4020000000000001, 0.45799999999999996, 1.379, 0.499, 1.3860000000000001, 1.46, 1.415, 1.4609999999999999, 0.6629999999999999, 1.44, 1.458, 1.455, 0.46599999999999997, -0.501, 1.452, 1.447, 1.44, 1.436, -0.501, 1.458, 1.416, -1.0, 1.47, 1.4489999999999998, 1.401, -0.5, -0.501, -0.5, 1.387, 0.956, 0.964, 1.419, 1.424, 1.4609999999999999, 1.464, 1.4220000000000002, 1.4449999999999998, 1.448, 1.4369999999999998, 1.4489999999999998, 0.499, 0.2949999999999998, -0.5, -0.503, 1.439, 0.953, 1.427, 1.369, 1.2650000000000001, 1.429, 1.2650000000000001, 1.4609999999999999, 1.434, 1.442, 1.4609999999999999, 1.396, -0.512, 0.499, 0.489, 0.499, 0.497, 1.448, 1.452, 0.967, 1.464, 1.4409999999999998, 1.4569999999999999, 1.434, 1.359, 0.979, 1.46, 1.4220000000000002, 1.431, 1.42, 1.464, 0.961, 1.44, 1.3900000000000001, 1.455, -1.004, 0.963, 0.595, 1.423, -0.501, 1.4, 1.416, 1.4609999999999999, 1.436, 1.446, 1.411, 1.434, 1.458, 1.408, -0.001, 1.4409999999999998, 1.4329999999999998, 1.436, 1.417, 0.497, 1.446, -0.501, 0.495, 0.497, 1.3559999999999999, 1.4449999999999998, 0.5, 1.409, 1.391, 0.952, 1.4489999999999998, 1.446, 1.446, 1.439, -0.003, -0.503, 1.412, 1.4449999999999998, 1.387, -0.004, -0.5, 1.448, 1.446, 1.4609999999999999, 1.423, 1.455], "policy_blue_0_reward": [1.302, 0.5, 0.499, -0.501, -0.501, 0.499, 0.499, 0.497, 0.49, -0.502, 0.499, 0.499, 1.423, -0.5039999999999999, -0.04000000000000003, -0.010000000000000002, 1.407, -0.002, -0.501, -0.504, 0.498, -0.508, -0.005, 0.499, 0.5, -0.03300000000000002, 1.4689999999999999, 0.499, 0.499, -0.003, 0.497, 1.4569999999999999, -0.502, 0.499, 0.972, -1.001, 0.498, 0.497, 0.953, 0.967, 1.458, 0.498, -0.5, -0.5, 0.499, 0.495, 0.499, -0.5, 0.499, 0.498, 0.497, 0.499, -0.501, 1.451, -0.02000000000000001, 1.479, 1.4329999999999998, 0.499, -0.5, 0.497, 0.497, -0.5079999999999999, 0.497, -0.509, -0.001, -1.001, -0.501, 0.499, -0.003, 1.1509999999999998, 1.416, 1.197, 1.434, 1.4140000000000001, 0.5, 0.499, -1.001, -1.0, 0.497, 0.499, 0.497, 0.493, -0.5, -0.5, 0.498, -0.005, -0.502, -1.002, -0.5, 0.5, 0.498, -1.001, 1.3559999999999999, -1.004, 0.474, -0.004, 0.965, 0.498, -0.001, 0.497, -0.002, 0.498, 0.495, -0.502, 0.499, 0.499, 1.455, -0.5, 0.499, 0.499, 0.498, 1.443, 0.5, 0.958, 1.399, 1.423, 0.496, -0.503, 1.443, 0.0, 0.498, -0.5, -0.004, -1.002, 0.496, 0.5, 1.3780000000000001, 1.431, 0.499, 0.499, -0.002, 1.387, 1.455, -0.501, 0.499, 0.5, -0.5019999999999999, 0.496]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.398666496456346, "mean_inference_ms": 7.429179865420954, "mean_action_processing_ms": 0.3897516767740054, "mean_env_wait_ms": 0.5179552299505887, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14622867971226788, "StateBufferConnector_ms": 0.009724540986876556, "ViewRequirementAgentConnector_ms": 0.19530999487724857}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 728000, "num_agent_steps_trained": 728000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 123.95099500145622, "num_env_steps_trained_throughput_per_sec": 123.95099500145622, "timesteps_total": 364000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 728000, "timers": {"training_iteration_time_ms": 30600.574, "sample_time_ms": 3952.851, "learn_time_ms": 26619.09, "learn_throughput": 150.268, "synch_weights_time_ms": 27.052}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 728000, "num_agent_steps_trained": 728000}, "done": false, "episodes_total": 5583, "training_iteration": 91, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-45-15", "timestamp": 1694839515, "time_this_iter_s": 32.29124927520752, "time_total_s": 2832.852871656418, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219800d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2832.852871656418, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 26.88723404255319, "ram_util_percent": 57.14042553191488}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.22413793103448276, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10344827586206896, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.22413793103448276, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16379310344827586, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10344827586206896, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.22413793103448276, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10344827586206896, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6283003248584768, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0506957029343539, "policy_loss": -0.09700125274151408, "vf_loss": 0.035352739873148194, "vf_explained_var": 0.6294915447632472, "kl": 0.013113525507893065, "entropy": 1.245070834333698, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 87840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5872548919791977, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.056909238972972766, "policy_loss": -0.10276760532481906, "vf_loss": 0.03746624527557287, "vf_explained_var": 0.525328694904844, "kl": 0.01257277406792522, "entropy": 1.5171070648978153, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 87840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.1259999999999999, "episode_reward_mean": 1.3689051724137928, "episode_len_mean": 34.11206896551724, "episode_media": {}, "episodes_this_iter": 116, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.46}, "policy_reward_mean": {"red_0": 0.991560344827586, "blue_0": 0.3773448275862069}, "custom_metrics": {"red_0/door_open_done_mean": 0.5, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.22413793103448276, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10344827586206896, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.22413793103448276, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16379310344827586, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10344827586206896, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.22413793103448276, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10344827586206896, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.904, 1.4020000000000001, 0.9609999999999999, 1.935, 1.9300000000000002, 1.869, 1.936, 1.938, 1.889, 1.4, 1.416, 1.931, 0.31400000000000006, 0.45899999999999996, 1.9609999999999999, 0.41900000000000004, 1.95, 0.387, 1.373, 0.913, 1.92, 0.399, 1.829, 0.46799999999999997, 0.43699999999999983, 1.94, 1.9409999999999998, 0.957, 0.44799999999999995, 1.8900000000000001, -0.1259999999999999, 0.9289999999999999, 1.867, 1.359, 0.379, 0.9409999999999998, 1.9060000000000001, 0.929, 1.445, 0.956, 1.9540000000000002, 0.9409999999999998, 1.9180000000000001, 1.93, 1.822, 0.9689999999999999, 1.4249999999999998, 1.766, 1.9449999999999998, 0.9119999999999999, 1.4329999999999998, 0.44299999999999995, 1.4489999999999998, 1.3279999999999998, 0.35599999999999987, 1.942, 0.30299999999999994, 1.889, 1.9140000000000001, 1.525, 1.952, 1.444, 0.42700000000000005, 0.923, 1.403, 1.9180000000000001, 1.865, 1.942, 0.9689999999999999, 1.432, 0.33199999999999985, 1.806, 0.909, 1.889, 1.561, 1.955, 0.45699999999999985, 1.4249999999999998, 0.4750000000000001, 1.889, 1.9449999999999998, 1.822, 1.446, 1.948, 1.904, 1.952, 1.96, 0.405, 1.8860000000000001, 1.895, 1.4220000000000002, 1.424, 1.9100000000000001, 1.891, 1.373, 1.432, 1.928, 0.922, 0.46299999999999997, 1.9409999999999998, 1.9180000000000001, 1.4369999999999998, 1.446, 1.874, 0.962, 1.921, 1.8599999999999999, 0.20199999999999996, -0.04600000000000004, 1.883, 0.45699999999999996, 0.8519999999999999, 0.8860000000000001, 1.939, 1.8279999999999998, 1.267], "episode_lengths": [30, 32, 12, 21, 23, 42, 20, 19, 35, 31, 26, 22, 57, 13, 13, 23, 16, 36, 38, 28, 26, 31, 54, 10, 19, 19, 19, 13, 17, 35, 39, 300, 42, 46, 36, 19, 29, 23, 18, 14, 15, 19, 26, 22, 56, 10, 24, 73, 18, 27, 22, 18, 17, 54, 44, 19, 60, 34, 27, 145, 16, 18, 23, 25, 30, 25, 40, 19, 10, 21, 52, 60, 28, 36, 133, 15, 14, 24, 8, 35, 18, 55, 17, 16, 31, 16, 13, 29, 35, 33, 25, 24, 28, 35, 41, 22, 23, 25, 12, 19, 25, 20, 17, 40, 12, 25, 43, 94, 15, 35, 14, 47, 37, 19, 54, 235], "policy_red_0_reward": [0.497, 1.403, 1.462, 1.436, 1.431, 0.497, 1.438, 0.497, 1.3940000000000001, 1.405, 1.42, 1.4329999999999998, 1.319, -0.502, 1.4609999999999999, -0.503, 1.452, 0.89, -0.007, 1.4140000000000001, 1.421, 1.404, 1.335, -0.5, 1.443, 0.498, 0.499, -0.503, 0.948, 1.393, -1.005, 0.45099999999999996, 1.369, 1.362, 1.388, 1.443, 1.408, -0.501, 1.446, 1.458, 1.455, 1.4409999999999998, 1.42, 1.431, 0.499, 1.4689999999999999, 1.426, 1.275, 0.5, 1.416, 0.0, 0.943, 1.4489999999999998, 1.333, 0.861, 1.443, 1.309, 0.496, 1.417, 1.039, 1.452, 1.446, -1.002, -0.5, 1.4060000000000001, 1.4220000000000002, 0.494, 0.5, 1.4689999999999999, -0.002, 1.3399999999999999, 1.313, 1.413, 1.3900000000000001, 1.073, 1.455, 1.4569999999999999, 1.426, 1.476, 1.392, 0.5, 1.33, -0.003, 1.45, 1.405, 1.452, 1.4609999999999999, -0.507, 1.392, 0.497, 1.425, 1.428, 1.415, 1.395, 1.374, 1.434, 1.431, -0.5, -0.5, 1.442, 1.424, 1.438, 1.448, 1.377, 1.464, 0.5, 0.495, 0.712, 0.955, 1.387, -0.501, 1.353, 1.389, 0.498, 1.334, 0.791], "policy_blue_0_reward": [1.407, -0.001, -0.501, 0.499, 0.499, 1.3719999999999999, 0.498, 1.4409999999999998, 0.495, -0.005, -0.004, 0.498, -1.005, 0.961, 0.5, 0.922, 0.498, -0.5029999999999999, 1.38, -0.501, 0.499, -1.005, 0.494, 0.968, -1.006, 1.442, 1.442, 1.46, -0.5, 0.497, 0.879, 0.478, 0.498, -0.003, -1.009, -0.502, 0.498, 1.4300000000000002, -0.001, -0.502, 0.499, -0.5, 0.498, 0.499, 1.323, -0.5, -0.001, 0.491, 1.4449999999999998, -0.504, 1.4329999999999998, -0.5, 0.0, -0.005, -0.505, 0.499, -1.006, 1.393, 0.497, 0.486, 0.5, -0.002, 1.429, 1.423, -0.003, 0.496, 1.371, 1.442, -0.5, 1.434, -1.008, 0.493, -0.504, 0.499, 0.488, 0.5, -1.0, -0.001, -1.001, 0.497, 1.4449999999999998, 0.492, 1.4489999999999998, 0.498, 0.499, 0.5, 0.499, 0.912, 0.494, 1.3980000000000001, -0.003, -0.004, 0.495, 0.496, -0.001, -0.002, 0.497, 1.4220000000000002, 0.963, 0.499, 0.494, -0.001, -0.002, 0.497, -0.502, 1.421, 1.365, -0.51, -1.001, 0.496, 0.958, -0.501, -0.503, 1.4409999999999998, 0.494, 0.476]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3980578390983591, "mean_inference_ms": 7.419490762737707, "mean_action_processing_ms": 0.39049710719978115, "mean_env_wait_ms": 0.5174505935107281, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13813653896594869, "StateBufferConnector_ms": 0.009330593306442788, "ViewRequirementAgentConnector_ms": 0.18584358281102673}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.1259999999999999, "episode_reward_mean": 1.3689051724137928, "episode_len_mean": 34.11206896551724, "episodes_this_iter": 116, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.46}, "policy_reward_mean": {"red_0": 0.991560344827586, "blue_0": 0.3773448275862069}, "hist_stats": {"episode_reward": [1.904, 1.4020000000000001, 0.9609999999999999, 1.935, 1.9300000000000002, 1.869, 1.936, 1.938, 1.889, 1.4, 1.416, 1.931, 0.31400000000000006, 0.45899999999999996, 1.9609999999999999, 0.41900000000000004, 1.95, 0.387, 1.373, 0.913, 1.92, 0.399, 1.829, 0.46799999999999997, 0.43699999999999983, 1.94, 1.9409999999999998, 0.957, 0.44799999999999995, 1.8900000000000001, -0.1259999999999999, 0.9289999999999999, 1.867, 1.359, 0.379, 0.9409999999999998, 1.9060000000000001, 0.929, 1.445, 0.956, 1.9540000000000002, 0.9409999999999998, 1.9180000000000001, 1.93, 1.822, 0.9689999999999999, 1.4249999999999998, 1.766, 1.9449999999999998, 0.9119999999999999, 1.4329999999999998, 0.44299999999999995, 1.4489999999999998, 1.3279999999999998, 0.35599999999999987, 1.942, 0.30299999999999994, 1.889, 1.9140000000000001, 1.525, 1.952, 1.444, 0.42700000000000005, 0.923, 1.403, 1.9180000000000001, 1.865, 1.942, 0.9689999999999999, 1.432, 0.33199999999999985, 1.806, 0.909, 1.889, 1.561, 1.955, 0.45699999999999985, 1.4249999999999998, 0.4750000000000001, 1.889, 1.9449999999999998, 1.822, 1.446, 1.948, 1.904, 1.952, 1.96, 0.405, 1.8860000000000001, 1.895, 1.4220000000000002, 1.424, 1.9100000000000001, 1.891, 1.373, 1.432, 1.928, 0.922, 0.46299999999999997, 1.9409999999999998, 1.9180000000000001, 1.4369999999999998, 1.446, 1.874, 0.962, 1.921, 1.8599999999999999, 0.20199999999999996, -0.04600000000000004, 1.883, 0.45699999999999996, 0.8519999999999999, 0.8860000000000001, 1.939, 1.8279999999999998, 1.267], "episode_lengths": [30, 32, 12, 21, 23, 42, 20, 19, 35, 31, 26, 22, 57, 13, 13, 23, 16, 36, 38, 28, 26, 31, 54, 10, 19, 19, 19, 13, 17, 35, 39, 300, 42, 46, 36, 19, 29, 23, 18, 14, 15, 19, 26, 22, 56, 10, 24, 73, 18, 27, 22, 18, 17, 54, 44, 19, 60, 34, 27, 145, 16, 18, 23, 25, 30, 25, 40, 19, 10, 21, 52, 60, 28, 36, 133, 15, 14, 24, 8, 35, 18, 55, 17, 16, 31, 16, 13, 29, 35, 33, 25, 24, 28, 35, 41, 22, 23, 25, 12, 19, 25, 20, 17, 40, 12, 25, 43, 94, 15, 35, 14, 47, 37, 19, 54, 235], "policy_red_0_reward": [0.497, 1.403, 1.462, 1.436, 1.431, 0.497, 1.438, 0.497, 1.3940000000000001, 1.405, 1.42, 1.4329999999999998, 1.319, -0.502, 1.4609999999999999, -0.503, 1.452, 0.89, -0.007, 1.4140000000000001, 1.421, 1.404, 1.335, -0.5, 1.443, 0.498, 0.499, -0.503, 0.948, 1.393, -1.005, 0.45099999999999996, 1.369, 1.362, 1.388, 1.443, 1.408, -0.501, 1.446, 1.458, 1.455, 1.4409999999999998, 1.42, 1.431, 0.499, 1.4689999999999999, 1.426, 1.275, 0.5, 1.416, 0.0, 0.943, 1.4489999999999998, 1.333, 0.861, 1.443, 1.309, 0.496, 1.417, 1.039, 1.452, 1.446, -1.002, -0.5, 1.4060000000000001, 1.4220000000000002, 0.494, 0.5, 1.4689999999999999, -0.002, 1.3399999999999999, 1.313, 1.413, 1.3900000000000001, 1.073, 1.455, 1.4569999999999999, 1.426, 1.476, 1.392, 0.5, 1.33, -0.003, 1.45, 1.405, 1.452, 1.4609999999999999, -0.507, 1.392, 0.497, 1.425, 1.428, 1.415, 1.395, 1.374, 1.434, 1.431, -0.5, -0.5, 1.442, 1.424, 1.438, 1.448, 1.377, 1.464, 0.5, 0.495, 0.712, 0.955, 1.387, -0.501, 1.353, 1.389, 0.498, 1.334, 0.791], "policy_blue_0_reward": [1.407, -0.001, -0.501, 0.499, 0.499, 1.3719999999999999, 0.498, 1.4409999999999998, 0.495, -0.005, -0.004, 0.498, -1.005, 0.961, 0.5, 0.922, 0.498, -0.5029999999999999, 1.38, -0.501, 0.499, -1.005, 0.494, 0.968, -1.006, 1.442, 1.442, 1.46, -0.5, 0.497, 0.879, 0.478, 0.498, -0.003, -1.009, -0.502, 0.498, 1.4300000000000002, -0.001, -0.502, 0.499, -0.5, 0.498, 0.499, 1.323, -0.5, -0.001, 0.491, 1.4449999999999998, -0.504, 1.4329999999999998, -0.5, 0.0, -0.005, -0.505, 0.499, -1.006, 1.393, 0.497, 0.486, 0.5, -0.002, 1.429, 1.423, -0.003, 0.496, 1.371, 1.442, -0.5, 1.434, -1.008, 0.493, -0.504, 0.499, 0.488, 0.5, -1.0, -0.001, -1.001, 0.497, 1.4449999999999998, 0.492, 1.4489999999999998, 0.498, 0.499, 0.5, 0.499, 0.912, 0.494, 1.3980000000000001, -0.003, -0.004, 0.495, 0.496, -0.001, -0.002, 0.497, 1.4220000000000002, 0.963, 0.499, 0.494, -0.001, -0.002, 0.497, -0.502, 1.421, 1.365, -0.51, -1.001, 0.496, 0.958, -0.501, -0.503, 1.4409999999999998, 0.494, 0.476]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3980578390983591, "mean_inference_ms": 7.419490762737707, "mean_action_processing_ms": 0.39049710719978115, "mean_env_wait_ms": 0.5174505935107281, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13813653896594869, "StateBufferConnector_ms": 0.009330593306442788, "ViewRequirementAgentConnector_ms": 0.18584358281102673}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.1723019315468, "num_env_steps_trained_throughput_per_sec": 130.1723019315468, "timesteps_total": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 30538.598, "sample_time_ms": 3948.881, "learn_time_ms": 26561.395, "learn_throughput": 150.595, "synch_weights_time_ms": 26.801}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "episodes_total": 5699, "training_iteration": 92, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-45-47", "timestamp": 1694839547, "time_this_iter_s": 30.74694013595581, "time_total_s": 2863.5998117923737, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f7250>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2863.5998117923737, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 26.060000000000002, "ram_util_percent": 57.15777777777777}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.46218487394957986, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.2689075630252101, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07563025210084033, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.2689075630252101, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.18487394957983194, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.07563025210084033, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.2689075630252101, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07563025210084033, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5906263727384309, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05026434432414438, "policy_loss": -0.09337146787826593, "vf_loss": 0.03365805479794896, "vf_explained_var": 0.646984709178408, "kl": 0.012085902484192591, "entropy": 1.2551011934876442, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 88800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5833986750803888, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.055798974181137356, "policy_loss": -0.10056381920658168, "vf_loss": 0.036500042230666926, "vf_explained_var": 0.6151612862323721, "kl": 0.012301654841668145, "entropy": 1.509884402776758, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 88800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 744000, "num_agent_steps_trained": 744000}, "sampler_results": {"episode_reward_max": 1.959, "episode_reward_min": -0.09399999999999997, "episode_reward_mean": 1.3708571428571426, "episode_len_mean": 33.63865546218487, "episode_media": {}, "episodes_this_iter": 119, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.472}, "policy_reward_mean": {"red_0": 1.0075378151260503, "blue_0": 0.3633193277310925}, "custom_metrics": {"red_0/door_open_done_mean": 0.46218487394957986, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.2689075630252101, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07563025210084033, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.2689075630252101, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.18487394957983194, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.07563025210084033, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.2689075630252101, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07563025210084033, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9369999999999998, 1.439, 0.46399999999999997, 1.8519999999999999, 0.955, -0.03299999999999992, 0.9590000000000001, 1.901, 1.931, 0.39800000000000013, 1.443, 1.9529999999999998, 1.447, 1.951, 1.946, 1.923, 1.419, 1.943, 1.421, 1.93, 1.8850000000000002, 1.897, 1.9180000000000001, 0.867, -0.04400000000000004, 1.883, 1.92, 1.942, 0.44099999999999984, 1.9220000000000002, 0.8780000000000001, 1.921, 1.879, 0.43000000000000016, 0.964, 0.39600000000000013, 1.434, 1.8610000000000002, 1.911, 0.4710000000000001, 1.912, 1.959, 0.972, 1.9409999999999998, 1.9260000000000002, 0.9299999999999999, 0.9319999999999999, 0.3900000000000001, 1.943, 0.954, 1.946, 1.448, 1.494, 1.934, 1.951, 0.46799999999999997, 1.919, 1.939, 0.45899999999999996, 1.427, 1.452, 1.92, 0.39800000000000013, 1.923, 1.917, 0.5379999999999998, 1.754, 1.383, 1.942, 1.944, 0.9409999999999998, 1.841, 1.407, 0.926, 1.9260000000000002, 1.934, 1.938, 0.43900000000000006, 0.94, 0.44900000000000007, 1.942, 1.927, 0.9470000000000001, 0.8860000000000001, 1.955, 0.052000000000000046, 1.447, 1.9449999999999998, 1.81, 1.401, -0.06000000000000005, 0.915, 1.668, 1.954, 1.244, 1.403, 0.3780000000000001, 1.9100000000000001, 0.33000000000000007, 1.931, 0.41800000000000015, 0.45699999999999985, 1.881, 1.841, 0.9609999999999999, 1.94, 1.877, 1.9, 1.946, 1.4529999999999998, 1.4249999999999998, 1.9100000000000001, 0.45699999999999985, -0.09399999999999997, 0.41900000000000004, 1.885, 0.935, 1.929, 1.896], "episode_lengths": [20, 171, 12, 47, 14, 10, 13, 32, 22, 32, 19, 15, 17, 16, 17, 24, 24, 18, 25, 22, 37, 33, 26, 41, 14, 37, 25, 18, 18, 23, 38, 26, 38, 23, 12, 32, 21, 42, 27, 9, 28, 13, 9, 19, 23, 300, 21, 34, 18, 14, 17, 17, 157, 21, 16, 10, 26, 19, 13, 24, 16, 26, 32, 24, 27, 143, 75, 36, 19, 18, 19, 51, 27, 23, 23, 21, 20, 20, 18, 16, 19, 24, 17, 35, 15, 140, 17, 18, 61, 31, 19, 27, 102, 15, 236, 29, 37, 27, 54, 22, 25, 14, 37, 50, 12, 19, 39, 33, 17, 15, 24, 28, 14, 30, 26, 37, 20, 22, 33], "policy_red_0_reward": [1.44, 0.958, 0.964, 0.495, -0.501, 0.969, 1.4609999999999999, 1.4020000000000001, 0.499, 0.902, 1.443, 1.455, 1.4489999999999998, 1.452, 0.498, 1.426, 1.424, 0.498, 1.424, 0.498, 1.387, 0.498, 1.4220000000000002, 1.375, -1.001, 1.389, 0.498, 1.444, 0.944, 1.429, 1.3820000000000001, 1.421, 1.3820000000000001, 0.93, -0.5, 1.3980000000000001, 1.435, 1.369, 1.4180000000000001, 1.4729999999999999, 0.497, 1.4609999999999999, -0.5, 0.498, 0.497, 0.45799999999999996, -0.503, 0.895, 1.4449999999999998, 1.4569999999999999, 0.498, 1.4489999999999998, 1.013, 1.436, 1.451, 0.969, 0.499, 0.496, -0.5, 1.427, 1.452, 1.421, 1.401, 1.4249999999999998, 0.498, 1.053, 0.487, 1.387, 0.499, 1.446, 1.442, 0.499, 1.413, -0.503, 1.429, 1.436, 1.44, 0.94, -0.505, -1.003, 1.442, 1.428, 1.4489999999999998, 1.389, 1.455, 1.068, 1.4489999999999998, 1.446, 1.311, -0.004, 0.941, 1.4180000000000001, 1.184, 1.455, 0.777, -0.007, 1.3860000000000001, 1.4140000000000001, 0.836, 1.4329999999999998, 0.92, 0.957, 1.384, 0.496, 1.463, 0.498, 1.38, 0.499, 1.4489999999999998, 1.454, 1.428, 1.411, 1.458, 0.91, 1.42, 1.387, 1.436, 1.431, 1.397], "policy_blue_0_reward": [-0.503, 0.481, -0.5, 1.357, 1.456, -1.0019999999999998, -0.502, 0.499, 1.432, -0.504, 0.0, 0.498, -0.002, 0.499, 1.448, 0.497, -0.005, 1.4449999999999998, -0.003, 1.432, 0.498, 1.399, 0.496, -0.5079999999999999, 0.957, 0.494, 1.4220000000000002, 0.498, -0.503, 0.493, -0.504, 0.5, 0.497, -0.5, 1.464, -1.0019999999999998, -0.001, 0.492, 0.493, -1.0019999999999998, 1.415, 0.498, 1.472, 1.443, 1.429, 0.472, 1.435, -0.5049999999999999, 0.498, -0.503, 1.448, -0.001, 0.481, 0.498, 0.5, -0.5009999999999999, 1.42, 1.443, 0.959, 0.0, 0.0, 0.499, -1.003, 0.498, 1.419, -0.515, 1.267, -0.004, 1.443, 0.498, -0.501, 1.342, -0.006, 1.429, 0.497, 0.498, 0.498, -0.501, 1.4449999999999998, 1.452, 0.5, 0.499, -0.502, -0.503, 0.5, -1.016, -0.002, 0.499, 0.499, 1.405, -1.001, -0.503, 0.484, 0.499, 0.46699999999999997, 1.4100000000000001, -1.0079999999999998, 0.496, -0.506, 0.498, -0.5019999999999999, -0.5, 0.497, 1.345, -0.502, 1.442, 0.497, 1.401, 0.497, -0.001, -0.003, 0.499, -1.001, -1.004, -1.001, 0.498, -0.501, 0.498, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.397442185105124, "mean_inference_ms": 7.42357968868016, "mean_action_processing_ms": 0.3896400270795217, "mean_env_wait_ms": 0.5179624841239419, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15201518515578838, "StateBufferConnector_ms": 0.009523219421130269, "ViewRequirementAgentConnector_ms": 0.1926314930955903}}, "episode_reward_max": 1.959, "episode_reward_min": -0.09399999999999997, "episode_reward_mean": 1.3708571428571426, "episode_len_mean": 33.63865546218487, "episodes_this_iter": 119, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.472}, "policy_reward_mean": {"red_0": 1.0075378151260503, "blue_0": 0.3633193277310925}, "hist_stats": {"episode_reward": [0.9369999999999998, 1.439, 0.46399999999999997, 1.8519999999999999, 0.955, -0.03299999999999992, 0.9590000000000001, 1.901, 1.931, 0.39800000000000013, 1.443, 1.9529999999999998, 1.447, 1.951, 1.946, 1.923, 1.419, 1.943, 1.421, 1.93, 1.8850000000000002, 1.897, 1.9180000000000001, 0.867, -0.04400000000000004, 1.883, 1.92, 1.942, 0.44099999999999984, 1.9220000000000002, 0.8780000000000001, 1.921, 1.879, 0.43000000000000016, 0.964, 0.39600000000000013, 1.434, 1.8610000000000002, 1.911, 0.4710000000000001, 1.912, 1.959, 0.972, 1.9409999999999998, 1.9260000000000002, 0.9299999999999999, 0.9319999999999999, 0.3900000000000001, 1.943, 0.954, 1.946, 1.448, 1.494, 1.934, 1.951, 0.46799999999999997, 1.919, 1.939, 0.45899999999999996, 1.427, 1.452, 1.92, 0.39800000000000013, 1.923, 1.917, 0.5379999999999998, 1.754, 1.383, 1.942, 1.944, 0.9409999999999998, 1.841, 1.407, 0.926, 1.9260000000000002, 1.934, 1.938, 0.43900000000000006, 0.94, 0.44900000000000007, 1.942, 1.927, 0.9470000000000001, 0.8860000000000001, 1.955, 0.052000000000000046, 1.447, 1.9449999999999998, 1.81, 1.401, -0.06000000000000005, 0.915, 1.668, 1.954, 1.244, 1.403, 0.3780000000000001, 1.9100000000000001, 0.33000000000000007, 1.931, 0.41800000000000015, 0.45699999999999985, 1.881, 1.841, 0.9609999999999999, 1.94, 1.877, 1.9, 1.946, 1.4529999999999998, 1.4249999999999998, 1.9100000000000001, 0.45699999999999985, -0.09399999999999997, 0.41900000000000004, 1.885, 0.935, 1.929, 1.896], "episode_lengths": [20, 171, 12, 47, 14, 10, 13, 32, 22, 32, 19, 15, 17, 16, 17, 24, 24, 18, 25, 22, 37, 33, 26, 41, 14, 37, 25, 18, 18, 23, 38, 26, 38, 23, 12, 32, 21, 42, 27, 9, 28, 13, 9, 19, 23, 300, 21, 34, 18, 14, 17, 17, 157, 21, 16, 10, 26, 19, 13, 24, 16, 26, 32, 24, 27, 143, 75, 36, 19, 18, 19, 51, 27, 23, 23, 21, 20, 20, 18, 16, 19, 24, 17, 35, 15, 140, 17, 18, 61, 31, 19, 27, 102, 15, 236, 29, 37, 27, 54, 22, 25, 14, 37, 50, 12, 19, 39, 33, 17, 15, 24, 28, 14, 30, 26, 37, 20, 22, 33], "policy_red_0_reward": [1.44, 0.958, 0.964, 0.495, -0.501, 0.969, 1.4609999999999999, 1.4020000000000001, 0.499, 0.902, 1.443, 1.455, 1.4489999999999998, 1.452, 0.498, 1.426, 1.424, 0.498, 1.424, 0.498, 1.387, 0.498, 1.4220000000000002, 1.375, -1.001, 1.389, 0.498, 1.444, 0.944, 1.429, 1.3820000000000001, 1.421, 1.3820000000000001, 0.93, -0.5, 1.3980000000000001, 1.435, 1.369, 1.4180000000000001, 1.4729999999999999, 0.497, 1.4609999999999999, -0.5, 0.498, 0.497, 0.45799999999999996, -0.503, 0.895, 1.4449999999999998, 1.4569999999999999, 0.498, 1.4489999999999998, 1.013, 1.436, 1.451, 0.969, 0.499, 0.496, -0.5, 1.427, 1.452, 1.421, 1.401, 1.4249999999999998, 0.498, 1.053, 0.487, 1.387, 0.499, 1.446, 1.442, 0.499, 1.413, -0.503, 1.429, 1.436, 1.44, 0.94, -0.505, -1.003, 1.442, 1.428, 1.4489999999999998, 1.389, 1.455, 1.068, 1.4489999999999998, 1.446, 1.311, -0.004, 0.941, 1.4180000000000001, 1.184, 1.455, 0.777, -0.007, 1.3860000000000001, 1.4140000000000001, 0.836, 1.4329999999999998, 0.92, 0.957, 1.384, 0.496, 1.463, 0.498, 1.38, 0.499, 1.4489999999999998, 1.454, 1.428, 1.411, 1.458, 0.91, 1.42, 1.387, 1.436, 1.431, 1.397], "policy_blue_0_reward": [-0.503, 0.481, -0.5, 1.357, 1.456, -1.0019999999999998, -0.502, 0.499, 1.432, -0.504, 0.0, 0.498, -0.002, 0.499, 1.448, 0.497, -0.005, 1.4449999999999998, -0.003, 1.432, 0.498, 1.399, 0.496, -0.5079999999999999, 0.957, 0.494, 1.4220000000000002, 0.498, -0.503, 0.493, -0.504, 0.5, 0.497, -0.5, 1.464, -1.0019999999999998, -0.001, 0.492, 0.493, -1.0019999999999998, 1.415, 0.498, 1.472, 1.443, 1.429, 0.472, 1.435, -0.5049999999999999, 0.498, -0.503, 1.448, -0.001, 0.481, 0.498, 0.5, -0.5009999999999999, 1.42, 1.443, 0.959, 0.0, 0.0, 0.499, -1.003, 0.498, 1.419, -0.515, 1.267, -0.004, 1.443, 0.498, -0.501, 1.342, -0.006, 1.429, 0.497, 0.498, 0.498, -0.501, 1.4449999999999998, 1.452, 0.5, 0.499, -0.502, -0.503, 0.5, -1.016, -0.002, 0.499, 0.499, 1.405, -1.001, -0.503, 0.484, 0.499, 0.46699999999999997, 1.4100000000000001, -1.0079999999999998, 0.496, -0.506, 0.498, -0.5019999999999999, -0.5, 0.497, 1.345, -0.502, 1.442, 0.497, 1.401, 0.497, -0.001, -0.003, 0.499, -1.001, -1.004, -1.001, 0.498, -0.501, 0.498, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.397442185105124, "mean_inference_ms": 7.42357968868016, "mean_action_processing_ms": 0.3896400270795217, "mean_env_wait_ms": 0.5179624841239419, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15201518515578838, "StateBufferConnector_ms": 0.009523219421130269, "ViewRequirementAgentConnector_ms": 0.1926314930955903}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 744000, "num_agent_steps_trained": 744000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.82497077101172, "num_env_steps_trained_throughput_per_sec": 130.82497077101172, "timesteps_total": 372000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 744000, "timers": {"training_iteration_time_ms": 30536.486, "sample_time_ms": 3928.302, "learn_time_ms": 26579.796, "learn_throughput": 150.49, "synch_weights_time_ms": 26.856}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 744000, "num_agent_steps_trained": 744000}, "done": false, "episodes_total": 5818, "training_iteration": 93, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-46-18", "timestamp": 1694839578, "time_this_iter_s": 30.593384981155396, "time_total_s": 2894.193196773529, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219812d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2894.193196773529, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 25.595454545454547, "ram_util_percent": 57.11818181818182}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.4782608695652174, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.2318840579710145, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10869565217391304, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.2318840579710145, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.17391304347826086, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10869565217391304, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.2318840579710145, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10869565217391304, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5923347677725057, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04004886457454025, "policy_loss": -0.08882908162486274, "vf_loss": 0.04558701299053306, "vf_explained_var": 0.6083770921453834, "kl": 0.011917215880624422, "entropy": 1.1621977701162298, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 89760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5834949769700567, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0578700818567692, "policy_loss": -0.10708316135569476, "vf_loss": 0.04513275916979183, "vf_explained_var": 0.5779717518016696, "kl": 0.012345428391907505, "entropy": 1.4777292338510355, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 89760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.11499999999999988, "episode_reward_mean": 1.3638550724637681, "episode_len_mean": 25.528985507246375, "episode_media": {}, "episodes_this_iter": 138, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.0119999999999998}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.463}, "policy_reward_mean": {"red_0": 0.990804347826087, "blue_0": 0.3730507246376812}, "custom_metrics": {"red_0/door_open_done_mean": 0.4782608695652174, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.2318840579710145, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10869565217391304, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.2318840579710145, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.17391304347826086, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10869565217391304, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.2318840579710145, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10869565217391304, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.901, 1.442, 1.452, 1.409, 1.936, 1.9449999999999998, 0.908, 1.9449999999999998, 0.9289999999999998, 0.43699999999999983, 1.4489999999999998, 1.837, 0.43199999999999994, -0.049000000000000044, 1.9260000000000002, 1.954, 0.7830000000000001, 1.452, -0.04400000000000004, 1.959, 1.875, 1.437, 1.901, 1.4060000000000001, 0.43799999999999994, 1.928, -0.039000000000000035, 0.9529999999999998, 1.8940000000000001, 1.9489999999999998, 0.929, 0.43599999999999994, 1.913, 0.9550000000000001, -0.029000000000000026, 0.963, 1.423, 1.342, 1.45, 1.903, 0.957, 0.929, 1.928, 0.4630000000000001, 1.428, 1.928, 1.9369999999999998, 1.947, 1.897, 1.912, 1.9409999999999998, 0.43599999999999994, 0.44799999999999995, -0.029000000000000026, 0.46099999999999997, 1.946, 0.39800000000000013, 0.9079999999999999, 1.9420000000000002, 1.899, 1.923, 0.43599999999999994, 0.44499999999999995, 1.929, 0.841, 0.9430000000000001, 0.9630000000000001, 0.935, 1.9489999999999998, 0.3540000000000001, 0.954, 0.35199999999999987, 1.9609999999999999, 1.4409999999999998, 1.922, 1.951, 1.4260000000000002, 1.9060000000000001, 1.938, 0.948, 1.939, -0.05300000000000005, 1.4529999999999998, 1.4180000000000001, 0.46599999999999997, 1.9409999999999998, 0.9159999999999999, 1.946, 0.95, 1.9569999999999999, 1.4329999999999998, 1.917, 1.954, 1.946, 1.9529999999999998, 1.889, 1.926, 0.44499999999999984, 1.899, -0.11499999999999988, 1.8290000000000002, 1.9140000000000001, 0.4580000000000002, 1.9449999999999998, 1.8940000000000001, 1.944, 1.9220000000000002, 1.935, 1.8719999999999999, 1.44, 1.9489999999999998, 1.9409999999999998, 1.9569999999999999, -0.04500000000000004, 1.891, 1.439, -0.09499999999999997, 1.413, 0.946, 1.926, 1.934, 1.438, 1.954, 1.456, 1.907, 1.942, 1.452, 1.938, 1.939, 0.391, 0.476, 1.9100000000000001, 1.415, 1.928, 1.4260000000000002, 1.944, 0.94, 0.944], "episode_lengths": [31, 18, 15, 29, 20, 18, 27, 18, 22, 20, 17, 51, 21, 15, 23, 15, 68, 15, 14, 13, 39, 19, 32, 29, 19, 22, 13, 15, 33, 17, 22, 18, 28, 14, 9, 12, 24, 50, 16, 31, 14, 23, 23, 11, 22, 24, 20, 17, 32, 28, 19, 21, 17, 9, 12, 17, 31, 300, 18, 32, 25, 20, 17, 23, 50, 18, 12, 20, 16, 46, 15, 204, 13, 19, 24, 16, 23, 30, 20, 17, 19, 17, 15, 25, 11, 19, 26, 17, 16, 14, 21, 27, 15, 17, 15, 35, 24, 18, 32, 32, 54, 28, 13, 18, 33, 17, 25, 21, 40, 20, 17, 19, 14, 14, 35, 19, 30, 28, 17, 24, 21, 20, 15, 14, 28, 19, 16, 19, 19, 35, 8, 30, 27, 22, 23, 18, 20, 18], "policy_red_0_reward": [0.497, 1.4449999999999998, 1.455, 1.411, 1.439, 0.499, -0.508, 1.446, 1.432, 1.439, 1.4489999999999998, 1.345, 1.434, 0.953, 1.428, 1.455, 1.291, 1.455, 0.957, 1.4609999999999999, 1.3820000000000001, 1.442, 0.499, 1.411, -1.002, 0.496, 0.961, 1.454, 0.497, 1.4489999999999998, 1.432, 1.442, 1.4140000000000001, 1.458, 0.973, -0.5, 1.427, -0.002, 1.452, 1.405, -0.5, 1.429, 1.4300000000000002, 1.466, 1.432, 1.428, 1.44, 1.448, 0.495, 1.4140000000000001, 1.443, -0.5, -0.5, -1.0, -0.501, 1.4489999999999998, 0.903, 0.43799999999999994, 1.444, 0.495, 1.424, -0.501, -0.502, 1.429, 1.346, 1.4449999999999998, 1.464, -0.5019999999999999, 1.451, 0.859, 1.455, 0.8719999999999999, 1.4609999999999999, 1.442, 0.497, 1.452, 1.429, 1.4100000000000001, 0.499, 1.4489999999999998, 0.497, -1.0, 1.455, 1.424, 1.467, 1.443, 1.4180000000000001, 0.499, -0.501, 1.458, 1.435, 0.5, 0.499, 0.498, 1.455, 1.3940000000000001, 1.428, 1.4449999999999998, 0.497, 0.897, 1.334, 0.499, 0.959, 1.446, 0.497, 1.448, 1.425, 1.436, 1.3780000000000001, 0.0, 1.4489999999999998, 1.442, 1.458, 0.956, 0.499, 1.442, 0.91, 1.4140000000000001, -0.501, 0.5, 1.435, 1.439, 1.455, 1.4569999999999999, 1.411, 1.443, 1.452, 0.498, 1.442, 0.894, 1.476, 0.5, 1.4180000000000001, 0.495, 1.428, 1.4449999999999998, 1.44, -0.501], "policy_blue_0_reward": [1.404, -0.003, -0.003, -0.002, 0.497, 1.446, 1.416, 0.499, -0.503, -1.002, 0.0, 0.492, -1.002, -1.002, 0.498, 0.499, -0.5079999999999999, -0.003, -1.001, 0.498, 0.493, -0.005, 1.4020000000000001, -0.005, 1.44, 1.432, -1.0, -0.501, 1.397, 0.5, -0.5029999999999999, -1.006, 0.499, -0.503, -1.002, 1.463, -0.004, 1.3439999999999999, -0.002, 0.498, 1.4569999999999999, -0.5, 0.498, -1.003, -0.004, 0.5, 0.497, 0.499, 1.4020000000000001, 0.498, 0.498, 0.9359999999999999, 0.948, 0.971, 0.962, 0.497, -0.5049999999999999, 0.47, 0.498, 1.404, 0.499, 0.9369999999999999, 0.947, 0.5, -0.505, -0.502, -0.501, 1.4369999999999998, 0.498, -0.505, -0.501, -0.52, 0.5, -0.001, 1.4249999999999998, 0.499, -0.003, 0.496, 1.439, -0.501, 1.442, 0.947, -0.002, -0.006, -1.001, 0.498, -0.502, 1.447, 1.451, 0.499, -0.002, 1.417, 1.455, 1.448, 0.498, 0.495, 0.498, -1.0, 1.4020000000000001, -1.0119999999999998, 0.495, 1.415, -0.5009999999999999, 0.499, 1.397, 0.496, 0.497, 0.499, 0.494, 1.44, 0.5, 0.499, 0.499, -1.001, 1.392, -0.003, -1.005, -0.001, 1.447, 1.426, 0.499, -0.001, 0.499, -0.001, 0.496, 0.499, 0.0, 1.44, 0.497, -0.503, -1.0, 1.4100000000000001, -0.003, 1.4329999999999998, -0.002, 0.499, -0.5, 1.4449999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3977478961047087, "mean_inference_ms": 7.4289792557923935, "mean_action_processing_ms": 0.38889791247684957, "mean_env_wait_ms": 0.5178824613632236, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14546496280725452, "StateBufferConnector_ms": 0.010868604632391445, "ViewRequirementAgentConnector_ms": 0.18667388653409653}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.11499999999999988, "episode_reward_mean": 1.3638550724637681, "episode_len_mean": 25.528985507246375, "episodes_this_iter": 138, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.0119999999999998}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.463}, "policy_reward_mean": {"red_0": 0.990804347826087, "blue_0": 0.3730507246376812}, "hist_stats": {"episode_reward": [1.901, 1.442, 1.452, 1.409, 1.936, 1.9449999999999998, 0.908, 1.9449999999999998, 0.9289999999999998, 0.43699999999999983, 1.4489999999999998, 1.837, 0.43199999999999994, -0.049000000000000044, 1.9260000000000002, 1.954, 0.7830000000000001, 1.452, -0.04400000000000004, 1.959, 1.875, 1.437, 1.901, 1.4060000000000001, 0.43799999999999994, 1.928, -0.039000000000000035, 0.9529999999999998, 1.8940000000000001, 1.9489999999999998, 0.929, 0.43599999999999994, 1.913, 0.9550000000000001, -0.029000000000000026, 0.963, 1.423, 1.342, 1.45, 1.903, 0.957, 0.929, 1.928, 0.4630000000000001, 1.428, 1.928, 1.9369999999999998, 1.947, 1.897, 1.912, 1.9409999999999998, 0.43599999999999994, 0.44799999999999995, -0.029000000000000026, 0.46099999999999997, 1.946, 0.39800000000000013, 0.9079999999999999, 1.9420000000000002, 1.899, 1.923, 0.43599999999999994, 0.44499999999999995, 1.929, 0.841, 0.9430000000000001, 0.9630000000000001, 0.935, 1.9489999999999998, 0.3540000000000001, 0.954, 0.35199999999999987, 1.9609999999999999, 1.4409999999999998, 1.922, 1.951, 1.4260000000000002, 1.9060000000000001, 1.938, 0.948, 1.939, -0.05300000000000005, 1.4529999999999998, 1.4180000000000001, 0.46599999999999997, 1.9409999999999998, 0.9159999999999999, 1.946, 0.95, 1.9569999999999999, 1.4329999999999998, 1.917, 1.954, 1.946, 1.9529999999999998, 1.889, 1.926, 0.44499999999999984, 1.899, -0.11499999999999988, 1.8290000000000002, 1.9140000000000001, 0.4580000000000002, 1.9449999999999998, 1.8940000000000001, 1.944, 1.9220000000000002, 1.935, 1.8719999999999999, 1.44, 1.9489999999999998, 1.9409999999999998, 1.9569999999999999, -0.04500000000000004, 1.891, 1.439, -0.09499999999999997, 1.413, 0.946, 1.926, 1.934, 1.438, 1.954, 1.456, 1.907, 1.942, 1.452, 1.938, 1.939, 0.391, 0.476, 1.9100000000000001, 1.415, 1.928, 1.4260000000000002, 1.944, 0.94, 0.944], "episode_lengths": [31, 18, 15, 29, 20, 18, 27, 18, 22, 20, 17, 51, 21, 15, 23, 15, 68, 15, 14, 13, 39, 19, 32, 29, 19, 22, 13, 15, 33, 17, 22, 18, 28, 14, 9, 12, 24, 50, 16, 31, 14, 23, 23, 11, 22, 24, 20, 17, 32, 28, 19, 21, 17, 9, 12, 17, 31, 300, 18, 32, 25, 20, 17, 23, 50, 18, 12, 20, 16, 46, 15, 204, 13, 19, 24, 16, 23, 30, 20, 17, 19, 17, 15, 25, 11, 19, 26, 17, 16, 14, 21, 27, 15, 17, 15, 35, 24, 18, 32, 32, 54, 28, 13, 18, 33, 17, 25, 21, 40, 20, 17, 19, 14, 14, 35, 19, 30, 28, 17, 24, 21, 20, 15, 14, 28, 19, 16, 19, 19, 35, 8, 30, 27, 22, 23, 18, 20, 18], "policy_red_0_reward": [0.497, 1.4449999999999998, 1.455, 1.411, 1.439, 0.499, -0.508, 1.446, 1.432, 1.439, 1.4489999999999998, 1.345, 1.434, 0.953, 1.428, 1.455, 1.291, 1.455, 0.957, 1.4609999999999999, 1.3820000000000001, 1.442, 0.499, 1.411, -1.002, 0.496, 0.961, 1.454, 0.497, 1.4489999999999998, 1.432, 1.442, 1.4140000000000001, 1.458, 0.973, -0.5, 1.427, -0.002, 1.452, 1.405, -0.5, 1.429, 1.4300000000000002, 1.466, 1.432, 1.428, 1.44, 1.448, 0.495, 1.4140000000000001, 1.443, -0.5, -0.5, -1.0, -0.501, 1.4489999999999998, 0.903, 0.43799999999999994, 1.444, 0.495, 1.424, -0.501, -0.502, 1.429, 1.346, 1.4449999999999998, 1.464, -0.5019999999999999, 1.451, 0.859, 1.455, 0.8719999999999999, 1.4609999999999999, 1.442, 0.497, 1.452, 1.429, 1.4100000000000001, 0.499, 1.4489999999999998, 0.497, -1.0, 1.455, 1.424, 1.467, 1.443, 1.4180000000000001, 0.499, -0.501, 1.458, 1.435, 0.5, 0.499, 0.498, 1.455, 1.3940000000000001, 1.428, 1.4449999999999998, 0.497, 0.897, 1.334, 0.499, 0.959, 1.446, 0.497, 1.448, 1.425, 1.436, 1.3780000000000001, 0.0, 1.4489999999999998, 1.442, 1.458, 0.956, 0.499, 1.442, 0.91, 1.4140000000000001, -0.501, 0.5, 1.435, 1.439, 1.455, 1.4569999999999999, 1.411, 1.443, 1.452, 0.498, 1.442, 0.894, 1.476, 0.5, 1.4180000000000001, 0.495, 1.428, 1.4449999999999998, 1.44, -0.501], "policy_blue_0_reward": [1.404, -0.003, -0.003, -0.002, 0.497, 1.446, 1.416, 0.499, -0.503, -1.002, 0.0, 0.492, -1.002, -1.002, 0.498, 0.499, -0.5079999999999999, -0.003, -1.001, 0.498, 0.493, -0.005, 1.4020000000000001, -0.005, 1.44, 1.432, -1.0, -0.501, 1.397, 0.5, -0.5029999999999999, -1.006, 0.499, -0.503, -1.002, 1.463, -0.004, 1.3439999999999999, -0.002, 0.498, 1.4569999999999999, -0.5, 0.498, -1.003, -0.004, 0.5, 0.497, 0.499, 1.4020000000000001, 0.498, 0.498, 0.9359999999999999, 0.948, 0.971, 0.962, 0.497, -0.5049999999999999, 0.47, 0.498, 1.404, 0.499, 0.9369999999999999, 0.947, 0.5, -0.505, -0.502, -0.501, 1.4369999999999998, 0.498, -0.505, -0.501, -0.52, 0.5, -0.001, 1.4249999999999998, 0.499, -0.003, 0.496, 1.439, -0.501, 1.442, 0.947, -0.002, -0.006, -1.001, 0.498, -0.502, 1.447, 1.451, 0.499, -0.002, 1.417, 1.455, 1.448, 0.498, 0.495, 0.498, -1.0, 1.4020000000000001, -1.0119999999999998, 0.495, 1.415, -0.5009999999999999, 0.499, 1.397, 0.496, 0.497, 0.499, 0.494, 1.44, 0.5, 0.499, 0.499, -1.001, 1.392, -0.003, -1.005, -0.001, 1.447, 1.426, 0.499, -0.001, 0.499, -0.001, 0.496, 0.499, 0.0, 1.44, 0.497, -0.503, -1.0, 1.4100000000000001, -0.003, 1.4329999999999998, -0.002, 0.499, -0.5, 1.4449999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3977478961047087, "mean_inference_ms": 7.4289792557923935, "mean_action_processing_ms": 0.38889791247684957, "mean_env_wait_ms": 0.5178824613632236, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14546496280725452, "StateBufferConnector_ms": 0.010868604632391445, "ViewRequirementAgentConnector_ms": 0.18667388653409653}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.57736590859575, "num_env_steps_trained_throughput_per_sec": 127.57736590859575, "timesteps_total": 376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 30526.252, "sample_time_ms": 3891.958, "learn_time_ms": 26605.816, "learn_throughput": 150.343, "synch_weights_time_ms": 26.957}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "episodes_total": 5956, "training_iteration": 94, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-46-50", "timestamp": 1694839610, "time_this_iter_s": 31.373122930526733, "time_total_s": 2925.566319704056, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219857e0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2925.566319704056, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 26.66739130434783, "ram_util_percent": 57.1391304347826}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.4411764705882353, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.23529411764705882, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14705882352941177, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.23529411764705882, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14705882352941177, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14705882352941177, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.23529411764705882, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14705882352941177, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5757009828463197, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04458778414846165, "policy_loss": -0.09167989002792941, "vf_loss": 0.04125377501089436, "vf_explained_var": 0.671672736108303, "kl": 0.012152402675637101, "entropy": 1.2194741908460855, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 90720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5954088269422452, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05210187563401026, "policy_loss": -0.10006856867209232, "vf_loss": 0.042360263369240175, "vf_explained_var": 0.5966407874599099, "kl": 0.012406061215436205, "entropy": 1.4759973160922528, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 90720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 760000, "num_agent_steps_trained": 760000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.061000000000000054, "episode_reward_mean": 1.3113014705882353, "episode_len_mean": 32.875, "episode_media": {}, "episodes_this_iter": 136, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.475, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 0.9139558823529411, "blue_0": 0.39734558823529414}, "custom_metrics": {"red_0/door_open_done_mean": 0.4411764705882353, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.23529411764705882, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.14705882352941177, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.23529411764705882, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14705882352941177, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.14705882352941177, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.23529411764705882, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.14705882352941177, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9279999999999999, 1.917, 0.9630000000000001, 1.3880000000000001, 0.817, 0.9540000000000002, 1.927, 1.9569999999999999, 1.42, 1.448, 0.953, 1.9329999999999998, 1.126, 0.927, 1.8980000000000001, 0.7629999999999999, 1.9329999999999998, 1.857, 1.438, 1.96, 1.915, 1.954, 1.9409999999999998, 0.45199999999999996, 0.472, 0.45100000000000007, 1.9409999999999998, 1.9220000000000002, 1.935, 1.955, 0.4750000000000001, 0.44799999999999995, 0.946, 1.923, 1.958, 1.932, 1.447, 1.943, 1.424, 1.397, 1.94, 0.9279999999999999, 1.435, 1.421, 1.919, 1.9489999999999998, 0.46499999999999997, 1.943, 1.9449999999999998, 0.4570000000000001, 1.893, 1.9609999999999999, 0.43199999999999994, 1.4489999999999998, 1.911, 1.9609999999999999, 1.9529999999999998, 1.926, 0.891, 0.958, 1.955, 1.858, 1.393, 0.45499999999999996, 1.9489999999999998, 0.962, 1.4569999999999999, 1.3860000000000001, 0.908, 1.4140000000000001, -0.061000000000000054, 0.935, -0.02400000000000002, 0.4710000000000001, 0.891, 1.4369999999999998, 0.43899999999999995, 0.46199999999999997, 0.9529999999999998, 1.917, 1.9569999999999999, 0.968, 1.9489999999999998, 0.45599999999999996, 1.9260000000000002, 0.4590000000000001, 0.908, 1.925, 1.936, 0.951, 0.41500000000000004, 0.914, 0.44999999999999996, 1.442, 1.9489999999999998, 1.8940000000000001, 0.9449999999999998, 1.929, 0.976, 0.943, 1.935, 0.9489999999999998, 0.3969999999999999, 1.798, 1.439, 0.43199999999999994, 1.946, -0.03200000000000003, 0.44599999999999995, 1.9529999999999998, 1.442, 0.43299999999999983, 0.879, 1.936, 0.956, 1.8519999999999999, 1.44, 1.951, 1.478, 1.901, 1.8639999999999999, 1.96, 0.43699999999999983, 0.41000000000000014, 1.9200000000000002, -0.041000000000000036, 1.943, 1.4, 0.43699999999999994, 0.931, 0.952, 0.959, 1.373, 1.379, 1.9369999999999998, 1.421], "episode_lengths": [300, 26, 12, 35, 57, 15, 24, 14, 25, 17, 15, 21, 272, 23, 33, 75, 21, 46, 20, 13, 27, 15, 19, 15, 9, 15, 19, 26, 21, 14, 8, 15, 17, 24, 14, 21, 17, 19, 24, 31, 18, 300, 21, 25, 25, 16, 11, 17, 18, 14, 34, 13, 22, 16, 28, 13, 15, 24, 32, 14, 15, 45, 35, 15, 17, 12, 14, 36, 29, 26, 20, 21, 8, 9, 34, 20, 18, 11, 15, 27, 14, 10, 17, 14, 23, 13, 29, 23, 21, 300, 25, 26, 16, 19, 16, 33, 17, 23, 8, 18, 21, 16, 300, 62, 20, 22, 17, 10, 17, 15, 19, 21, 39, 20, 14, 47, 19, 16, 162, 32, 42, 13, 20, 28, 25, 13, 18, 29, 20, 22, 15, 13, 40, 37, 20, 25], "policy_red_0_reward": [0.46299999999999997, 1.421, 1.464, 1.3940000000000001, 1.323, 1.455, 1.428, 1.458, 1.4220000000000002, 1.4489999999999998, -0.5, 1.436, 0.647, -0.501, 1.401, 1.267, 1.435, 1.3599999999999999, 1.44, 1.4609999999999999, 1.4180000000000001, 1.455, 1.442, 1.454, -1.001, 0.951, 1.443, 1.4220000000000002, 1.4369999999999998, 1.458, 1.475, -0.501, 1.447, 1.426, 1.458, 0.498, -0.001, 1.443, 1.4249999999999998, 1.403, 1.443, 0.45699999999999996, 1.436, 1.425, 1.423, 0.497, -0.501, 1.447, 0.499, 1.458, 0.498, 0.5, 1.4329999999999998, 1.451, 1.413, 1.4609999999999999, 1.455, 0.5, -0.509, 1.458, 0.5, 0.497, 0.0, -0.5, 1.4489999999999998, -0.501, 1.4569999999999999, 1.391, -0.503, -0.005, 0.939, 1.436, 0.976, 1.4729999999999999, 1.396, 1.438, -0.502, -0.501, 1.454, 1.4180000000000001, 0.499, -0.502, 1.4489999999999998, 0.957, 1.431, 0.959, -0.502, 1.4300000000000002, 1.4369999999999998, 0.478, 0.915, -0.503, 1.451, 1.443, 1.451, 1.396, 1.447, 1.431, -0.5, -0.503, 1.4369999999999998, 1.451, 0.43399999999999994, 1.306, 1.44, -1.001, 0.498, 0.97, 1.447, 0.5, 1.443, 0.9369999999999999, 1.3820000000000001, 1.439, 1.458, 0.498, -0.002, 1.452, 0.485, 1.403, 0.494, 1.4609999999999999, 1.44, 1.412, 1.424, 0.96, 1.4449999999999998, 1.4060000000000001, -0.501, 1.4329999999999998, -0.5, -0.501, -0.003, -0.008, 1.44, 1.424], "policy_blue_0_reward": [0.46499999999999997, 0.496, -0.5009999999999999, -0.006, -0.506, -0.5009999999999999, 0.499, 0.499, -0.002, -0.001, 1.4529999999999998, 0.497, 0.479, 1.428, 0.497, -0.504, 0.498, 0.497, -0.002, 0.499, 0.497, 0.499, 0.499, -1.002, 1.4729999999999999, -0.5, 0.498, 0.5, 0.498, 0.497, -1.0, 0.949, -0.501, 0.497, 0.5, 1.434, 1.448, 0.5, -0.001, -0.006, 0.497, 0.471, -0.001, -0.004, 0.496, 1.452, 0.966, 0.496, 1.446, -1.001, 1.395, 1.4609999999999999, -1.001, -0.002, 0.498, 0.5, 0.498, 1.426, 1.4, -0.5, 1.455, 1.361, 1.393, 0.955, 0.5, 1.463, 0.0, -0.005, 1.411, 1.419, -1.0, -0.501, -1.0, -1.002, -0.505, -0.001, 0.941, 0.963, -0.501, 0.499, 1.458, 1.47, 0.5, -0.501, 0.495, -0.5, 1.4100000000000001, 0.495, 0.499, 0.473, -0.5, 1.417, -1.001, -0.001, 0.498, 0.498, -0.502, 0.498, 1.476, 1.446, 0.498, -0.502, -0.037000000000000026, 0.492, -0.001, 1.4329999999999998, 1.448, -1.002, -1.001, 1.4529999999999998, -0.001, -0.504, -0.503, 0.497, -0.502, 1.354, 1.442, 0.499, 0.993, 0.498, 1.37, 0.499, -1.003, -1.002, 0.496, -1.001, 0.498, -0.006, 0.938, -0.502, 1.452, 1.46, 1.376, 1.387, 0.497, -0.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3998565227882707, "mean_inference_ms": 7.431714290012314, "mean_action_processing_ms": 0.38941260218170226, "mean_env_wait_ms": 0.5184269523070411, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14450681560179768, "StateBufferConnector_ms": 0.01007686643039479, "ViewRequirementAgentConnector_ms": 0.19645454252467437}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.061000000000000054, "episode_reward_mean": 1.3113014705882353, "episode_len_mean": 32.875, "episodes_this_iter": 136, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.475, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 0.9139558823529411, "blue_0": 0.39734558823529414}, "hist_stats": {"episode_reward": [0.9279999999999999, 1.917, 0.9630000000000001, 1.3880000000000001, 0.817, 0.9540000000000002, 1.927, 1.9569999999999999, 1.42, 1.448, 0.953, 1.9329999999999998, 1.126, 0.927, 1.8980000000000001, 0.7629999999999999, 1.9329999999999998, 1.857, 1.438, 1.96, 1.915, 1.954, 1.9409999999999998, 0.45199999999999996, 0.472, 0.45100000000000007, 1.9409999999999998, 1.9220000000000002, 1.935, 1.955, 0.4750000000000001, 0.44799999999999995, 0.946, 1.923, 1.958, 1.932, 1.447, 1.943, 1.424, 1.397, 1.94, 0.9279999999999999, 1.435, 1.421, 1.919, 1.9489999999999998, 0.46499999999999997, 1.943, 1.9449999999999998, 0.4570000000000001, 1.893, 1.9609999999999999, 0.43199999999999994, 1.4489999999999998, 1.911, 1.9609999999999999, 1.9529999999999998, 1.926, 0.891, 0.958, 1.955, 1.858, 1.393, 0.45499999999999996, 1.9489999999999998, 0.962, 1.4569999999999999, 1.3860000000000001, 0.908, 1.4140000000000001, -0.061000000000000054, 0.935, -0.02400000000000002, 0.4710000000000001, 0.891, 1.4369999999999998, 0.43899999999999995, 0.46199999999999997, 0.9529999999999998, 1.917, 1.9569999999999999, 0.968, 1.9489999999999998, 0.45599999999999996, 1.9260000000000002, 0.4590000000000001, 0.908, 1.925, 1.936, 0.951, 0.41500000000000004, 0.914, 0.44999999999999996, 1.442, 1.9489999999999998, 1.8940000000000001, 0.9449999999999998, 1.929, 0.976, 0.943, 1.935, 0.9489999999999998, 0.3969999999999999, 1.798, 1.439, 0.43199999999999994, 1.946, -0.03200000000000003, 0.44599999999999995, 1.9529999999999998, 1.442, 0.43299999999999983, 0.879, 1.936, 0.956, 1.8519999999999999, 1.44, 1.951, 1.478, 1.901, 1.8639999999999999, 1.96, 0.43699999999999983, 0.41000000000000014, 1.9200000000000002, -0.041000000000000036, 1.943, 1.4, 0.43699999999999994, 0.931, 0.952, 0.959, 1.373, 1.379, 1.9369999999999998, 1.421], "episode_lengths": [300, 26, 12, 35, 57, 15, 24, 14, 25, 17, 15, 21, 272, 23, 33, 75, 21, 46, 20, 13, 27, 15, 19, 15, 9, 15, 19, 26, 21, 14, 8, 15, 17, 24, 14, 21, 17, 19, 24, 31, 18, 300, 21, 25, 25, 16, 11, 17, 18, 14, 34, 13, 22, 16, 28, 13, 15, 24, 32, 14, 15, 45, 35, 15, 17, 12, 14, 36, 29, 26, 20, 21, 8, 9, 34, 20, 18, 11, 15, 27, 14, 10, 17, 14, 23, 13, 29, 23, 21, 300, 25, 26, 16, 19, 16, 33, 17, 23, 8, 18, 21, 16, 300, 62, 20, 22, 17, 10, 17, 15, 19, 21, 39, 20, 14, 47, 19, 16, 162, 32, 42, 13, 20, 28, 25, 13, 18, 29, 20, 22, 15, 13, 40, 37, 20, 25], "policy_red_0_reward": [0.46299999999999997, 1.421, 1.464, 1.3940000000000001, 1.323, 1.455, 1.428, 1.458, 1.4220000000000002, 1.4489999999999998, -0.5, 1.436, 0.647, -0.501, 1.401, 1.267, 1.435, 1.3599999999999999, 1.44, 1.4609999999999999, 1.4180000000000001, 1.455, 1.442, 1.454, -1.001, 0.951, 1.443, 1.4220000000000002, 1.4369999999999998, 1.458, 1.475, -0.501, 1.447, 1.426, 1.458, 0.498, -0.001, 1.443, 1.4249999999999998, 1.403, 1.443, 0.45699999999999996, 1.436, 1.425, 1.423, 0.497, -0.501, 1.447, 0.499, 1.458, 0.498, 0.5, 1.4329999999999998, 1.451, 1.413, 1.4609999999999999, 1.455, 0.5, -0.509, 1.458, 0.5, 0.497, 0.0, -0.5, 1.4489999999999998, -0.501, 1.4569999999999999, 1.391, -0.503, -0.005, 0.939, 1.436, 0.976, 1.4729999999999999, 1.396, 1.438, -0.502, -0.501, 1.454, 1.4180000000000001, 0.499, -0.502, 1.4489999999999998, 0.957, 1.431, 0.959, -0.502, 1.4300000000000002, 1.4369999999999998, 0.478, 0.915, -0.503, 1.451, 1.443, 1.451, 1.396, 1.447, 1.431, -0.5, -0.503, 1.4369999999999998, 1.451, 0.43399999999999994, 1.306, 1.44, -1.001, 0.498, 0.97, 1.447, 0.5, 1.443, 0.9369999999999999, 1.3820000000000001, 1.439, 1.458, 0.498, -0.002, 1.452, 0.485, 1.403, 0.494, 1.4609999999999999, 1.44, 1.412, 1.424, 0.96, 1.4449999999999998, 1.4060000000000001, -0.501, 1.4329999999999998, -0.5, -0.501, -0.003, -0.008, 1.44, 1.424], "policy_blue_0_reward": [0.46499999999999997, 0.496, -0.5009999999999999, -0.006, -0.506, -0.5009999999999999, 0.499, 0.499, -0.002, -0.001, 1.4529999999999998, 0.497, 0.479, 1.428, 0.497, -0.504, 0.498, 0.497, -0.002, 0.499, 0.497, 0.499, 0.499, -1.002, 1.4729999999999999, -0.5, 0.498, 0.5, 0.498, 0.497, -1.0, 0.949, -0.501, 0.497, 0.5, 1.434, 1.448, 0.5, -0.001, -0.006, 0.497, 0.471, -0.001, -0.004, 0.496, 1.452, 0.966, 0.496, 1.446, -1.001, 1.395, 1.4609999999999999, -1.001, -0.002, 0.498, 0.5, 0.498, 1.426, 1.4, -0.5, 1.455, 1.361, 1.393, 0.955, 0.5, 1.463, 0.0, -0.005, 1.411, 1.419, -1.0, -0.501, -1.0, -1.002, -0.505, -0.001, 0.941, 0.963, -0.501, 0.499, 1.458, 1.47, 0.5, -0.501, 0.495, -0.5, 1.4100000000000001, 0.495, 0.499, 0.473, -0.5, 1.417, -1.001, -0.001, 0.498, 0.498, -0.502, 0.498, 1.476, 1.446, 0.498, -0.502, -0.037000000000000026, 0.492, -0.001, 1.4329999999999998, 1.448, -1.002, -1.001, 1.4529999999999998, -0.001, -0.504, -0.503, 0.497, -0.502, 1.354, 1.442, 0.499, 0.993, 0.498, 1.37, 0.499, -1.003, -1.002, 0.496, -1.001, 0.498, -0.006, 0.938, -0.502, 1.452, 1.46, 1.376, 1.387, 0.497, -0.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3998565227882707, "mean_inference_ms": 7.431714290012314, "mean_action_processing_ms": 0.38941260218170226, "mean_env_wait_ms": 0.5184269523070411, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14450681560179768, "StateBufferConnector_ms": 0.01007686643039479, "ViewRequirementAgentConnector_ms": 0.19645454252467437}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 760000, "num_agent_steps_trained": 760000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 132.38890136191918, "num_env_steps_trained_throughput_per_sec": 132.38890136191918, "timesteps_total": 380000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 760000, "timers": {"training_iteration_time_ms": 30528.673, "sample_time_ms": 3918.75, "learn_time_ms": 26581.534, "learn_throughput": 150.48, "synch_weights_time_ms": 26.848}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 760000, "num_agent_steps_trained": 760000}, "done": false, "episodes_total": 6092, "training_iteration": 95, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-47-22", "timestamp": 1694839642, "time_this_iter_s": 30.230797052383423, "time_total_s": 2955.797116756439, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21981510>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2955.797116756439, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 24.136363636363637, "ram_util_percent": 57.0}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5066666666666667, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.26, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07333333333333333, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.26, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.15333333333333332, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.07333333333333333, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.26, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07333333333333333, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5786115388385952, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04498838751848477, "policy_loss": -0.09094148198200855, "vf_loss": 0.03946821789916915, "vf_explained_var": 0.648686333745718, "kl": 0.012016808087315577, "entropy": 1.1568057802816232, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 91680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5953062134174009, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05406785595502394, "policy_loss": -0.1059188503830228, "vf_loss": 0.04798842717815811, "vf_explained_var": 0.5637742903083562, "kl": 0.01286322847166979, "entropy": 1.4472621752570072, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 91680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "sampler_results": {"episode_reward_max": 1.96, "episode_reward_min": -0.11599999999999999, "episode_reward_mean": 1.3810200000000001, "episode_len_mean": 24.653333333333332, "episode_media": {}, "episodes_this_iter": 150, "policy_reward_min": {"red_0": -0.502, "blue_0": -1.007}, "policy_reward_max": {"red_0": 1.467, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 1.0718333333333332, "blue_0": 0.30918666666666667}, "custom_metrics": {"red_0/door_open_done_mean": 0.5066666666666667, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.26, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07333333333333333, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.26, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.15333333333333332, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.07333333333333333, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.26, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07333333333333333, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.948, 1.947, 1.907, 1.438, 0.472, 1.839, 1.96, 1.9529999999999998, 1.888, 1.3850000000000002, 1.959, 1.393, 1.9409999999999998, 0.45199999999999996, 1.948, 0.935, 1.908, 0.45099999999999996, 1.833, 1.439, 1.4489999999999998, 1.892, -0.05900000000000005, 0.46599999999999997, 1.9100000000000001, 1.942, 1.951, 0.44300000000000006, 1.442, 1.956, 1.317, 1.9529999999999998, 1.954, 0.43999999999999995, 0.42200000000000015, 0.46299999999999997, 0.44399999999999995, 0.44700000000000006, 1.952, 0.41700000000000004, 0.946, 1.869, 1.4409999999999998, 0.976, 1.941, 1.944, 0.45399999999999996, 1.423, 1.434, 0.403, 1.881, 0.41000000000000014, 0.9329999999999998, 0.44300000000000006, 1.919, 1.3559999999999999, -0.11599999999999999, 0.41000000000000014, 1.9489999999999998, 1.834, 0.865, 1.4449999999999998, 1.885, -0.05900000000000005, 1.9300000000000002, 1.907, 1.8970000000000002, 0.44300000000000006, 1.959, 1.912, 1.447, 1.95, 1.873, 1.943, 1.447, 1.929, 0.9489999999999998, 1.9449999999999998, 1.425, 1.851, 1.438, 1.9489999999999998, 1.951, 1.446, 1.938, 0.96, 1.939, 1.45, 0.43900000000000006, 0.9660000000000002, 0.915, 0.966, 1.9409999999999998, 1.95, 0.46399999999999997, 1.893, 0.9079999999999999, 1.9369999999999998, 0.45999999999999996, 1.4369999999999998, 0.39400000000000013, 1.9569999999999999, 1.9369999999999998, 0.46499999999999997, 1.924, 0.792, 1.935, 0.9199999999999999, 1.95, 1.439, 1.431, 0.42700000000000005, 1.9569999999999999, 1.956, 1.955, 1.926, 1.927, 1.954, 0.45799999999999996, 1.862, 0.44899999999999984, 1.95, 1.955, 0.472, 0.922, 1.954, 1.927, 0.45299999999999985, 1.455, 1.907, 1.954, 0.9450000000000001, 0.4670000000000001, 1.9449999999999998, 1.439, 1.9409999999999998, 1.9329999999999998, 1.942, 1.425, 1.8940000000000001, 1.939, 0.43899999999999995, 1.919, 0.44399999999999995, 1.9409999999999998, -0.04400000000000004, 1.9289999999999998, 0.9670000000000001, 0.43999999999999995, 1.947], "episode_lengths": [17, 17, 29, 19, 9, 51, 13, 15, 35, 33, 13, 34, 19, 15, 17, 21, 28, 16, 50, 19, 17, 34, 19, 11, 29, 19, 16, 19, 18, 14, 57, 15, 15, 19, 25, 12, 18, 17, 16, 26, 18, 40, 18, 8, 19, 18, 15, 25, 21, 31, 37, 27, 21, 19, 25, 194, 36, 28, 16, 53, 41, 17, 36, 18, 22, 30, 33, 19, 13, 27, 17, 16, 40, 18, 17, 23, 16, 18, 23, 46, 20, 17, 16, 17, 20, 13, 19, 16, 18, 11, 26, 11, 19, 16, 12, 34, 300, 20, 13, 20, 33, 14, 21, 11, 24, 66, 21, 25, 16, 20, 22, 23, 14, 14, 15, 24, 23, 15, 14, 42, 17, 16, 15, 9, 25, 15, 23, 15, 15, 29, 15, 17, 11, 18, 19, 19, 21, 18, 23, 34, 19, 19, 26, 18, 19, 14, 22, 11, 19, 17], "policy_red_0_reward": [1.4489999999999998, 1.4489999999999998, 1.4100000000000001, -0.003, -0.5, 1.3439999999999999, 1.4609999999999999, 1.455, 1.393, 1.3980000000000001, 1.4609999999999999, 0.0, 0.5, 0.953, 1.4489999999999998, 1.4369999999999998, 1.411, -0.501, 0.494, 1.442, 1.4489999999999998, 1.396, 0.941, 1.467, 1.412, 1.443, 1.452, 1.443, -0.001, 1.458, -0.005, 1.455, 1.455, 1.442, 1.423, 0.964, 1.4449999999999998, 1.4489999999999998, 1.452, 1.4180000000000001, -0.5, 1.379, 1.444, -0.5, 1.443, 1.4449999999999998, 0.954, 1.425, -0.003, 0.903, 1.385, 1.4140000000000001, 1.435, 0.943, 1.42, 0.887, 0.89, 1.415, 1.451, 1.337, 1.37, 1.448, 1.392, 0.943, 1.4329999999999998, 1.4100000000000001, 1.399, 1.443, 1.4609999999999999, 1.415, -0.001, 1.452, 1.376, 1.446, 1.448, 1.431, 1.45, 1.446, 1.429, 0.491, 1.44, 0.5, 1.452, 1.448, 1.44, -0.501, 1.442, 1.452, 1.446, 1.467, 1.4180000000000001, 1.467, 1.443, 0.5, 1.464, 0.5, 0.44699999999999995, 1.439, -0.501, -0.002, 1.399, 1.4569999999999999, 1.4369999999999998, -0.501, 1.427, 1.299, 1.4369999999999998, 1.4220000000000002, 0.499, 1.44, -0.001, 0.929, 1.458, 1.458, 1.455, 0.499, 1.4300000000000002, 1.455, 1.458, 1.369, 1.4489999999999998, 1.452, 1.455, -0.5, -0.502, 0.5, 0.496, 0.954, 1.455, 1.412, 1.455, 1.447, 1.467, 1.446, -0.003, 1.4409999999999998, 1.436, 1.4449999999999998, 1.427, 0.497, 1.443, -0.502, 0.499, -0.5, 0.5, 0.956, 0.496, 1.467, 1.442, 1.4489999999999998], "policy_blue_0_reward": [0.499, 0.498, 0.497, 1.4409999999999998, 0.972, 0.495, 0.499, 0.498, 0.495, -0.013000000000000005, 0.498, 1.393, 1.4409999999999998, -0.501, 0.499, -0.502, 0.497, 0.952, 1.339, -0.003, 0.0, 0.496, -1.0, -1.001, 0.498, 0.499, 0.499, -1.0, 1.443, 0.498, 1.322, 0.498, 0.499, -1.002, -1.001, -0.501, -1.001, -1.002, 0.5, -1.001, 1.446, 0.49, -0.003, 1.476, 0.498, 0.499, -0.5, -0.002, 1.4369999999999998, -0.5, 0.496, -1.0039999999999998, -0.502, -0.5, 0.499, 0.469, -1.006, -1.005, 0.498, 0.497, -0.505, -0.003, 0.493, -1.002, 0.497, 0.497, 0.498, -1.0, 0.498, 0.497, 1.448, 0.498, 0.497, 0.497, -0.001, 0.498, -0.501, 0.499, -0.004, 1.3599999999999999, -0.002, 1.4489999999999998, 0.499, -0.002, 0.498, 1.4609999999999999, 0.497, -0.002, -1.007, -0.5009999999999999, -0.503, -0.501, 0.498, 1.45, -1.0, 1.393, 0.46099999999999997, 0.498, 0.961, 1.439, -1.005, 0.5, 0.5, 0.966, 0.497, -0.507, 0.498, -0.502, 1.451, -0.001, 1.432, -0.502, 0.499, 0.498, 0.5, 1.427, 0.497, 0.499, -1.0, 0.493, -1.0, 0.498, 0.5, 0.972, 1.424, 1.454, 1.431, -0.501, 0.0, 0.495, 0.499, -0.5019999999999999, -1.0, 0.499, 1.442, 0.5, 0.497, 0.497, -0.002, 1.397, 0.496, 0.941, 1.42, 0.944, 1.4409999999999998, -1.0, 1.4329999999999998, -0.5, -1.0019999999999998, 0.498]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4006210336850498, "mean_inference_ms": 7.428731135837415, "mean_action_processing_ms": 0.38914682509117826, "mean_env_wait_ms": 0.5187479985248388, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13997729619344076, "StateBufferConnector_ms": 0.009266535441080729, "ViewRequirementAgentConnector_ms": 0.19787200291951498}}, "episode_reward_max": 1.96, "episode_reward_min": -0.11599999999999999, "episode_reward_mean": 1.3810200000000001, "episode_len_mean": 24.653333333333332, "episodes_this_iter": 150, "policy_reward_min": {"red_0": -0.502, "blue_0": -1.007}, "policy_reward_max": {"red_0": 1.467, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 1.0718333333333332, "blue_0": 0.30918666666666667}, "hist_stats": {"episode_reward": [1.948, 1.947, 1.907, 1.438, 0.472, 1.839, 1.96, 1.9529999999999998, 1.888, 1.3850000000000002, 1.959, 1.393, 1.9409999999999998, 0.45199999999999996, 1.948, 0.935, 1.908, 0.45099999999999996, 1.833, 1.439, 1.4489999999999998, 1.892, -0.05900000000000005, 0.46599999999999997, 1.9100000000000001, 1.942, 1.951, 0.44300000000000006, 1.442, 1.956, 1.317, 1.9529999999999998, 1.954, 0.43999999999999995, 0.42200000000000015, 0.46299999999999997, 0.44399999999999995, 0.44700000000000006, 1.952, 0.41700000000000004, 0.946, 1.869, 1.4409999999999998, 0.976, 1.941, 1.944, 0.45399999999999996, 1.423, 1.434, 0.403, 1.881, 0.41000000000000014, 0.9329999999999998, 0.44300000000000006, 1.919, 1.3559999999999999, -0.11599999999999999, 0.41000000000000014, 1.9489999999999998, 1.834, 0.865, 1.4449999999999998, 1.885, -0.05900000000000005, 1.9300000000000002, 1.907, 1.8970000000000002, 0.44300000000000006, 1.959, 1.912, 1.447, 1.95, 1.873, 1.943, 1.447, 1.929, 0.9489999999999998, 1.9449999999999998, 1.425, 1.851, 1.438, 1.9489999999999998, 1.951, 1.446, 1.938, 0.96, 1.939, 1.45, 0.43900000000000006, 0.9660000000000002, 0.915, 0.966, 1.9409999999999998, 1.95, 0.46399999999999997, 1.893, 0.9079999999999999, 1.9369999999999998, 0.45999999999999996, 1.4369999999999998, 0.39400000000000013, 1.9569999999999999, 1.9369999999999998, 0.46499999999999997, 1.924, 0.792, 1.935, 0.9199999999999999, 1.95, 1.439, 1.431, 0.42700000000000005, 1.9569999999999999, 1.956, 1.955, 1.926, 1.927, 1.954, 0.45799999999999996, 1.862, 0.44899999999999984, 1.95, 1.955, 0.472, 0.922, 1.954, 1.927, 0.45299999999999985, 1.455, 1.907, 1.954, 0.9450000000000001, 0.4670000000000001, 1.9449999999999998, 1.439, 1.9409999999999998, 1.9329999999999998, 1.942, 1.425, 1.8940000000000001, 1.939, 0.43899999999999995, 1.919, 0.44399999999999995, 1.9409999999999998, -0.04400000000000004, 1.9289999999999998, 0.9670000000000001, 0.43999999999999995, 1.947], "episode_lengths": [17, 17, 29, 19, 9, 51, 13, 15, 35, 33, 13, 34, 19, 15, 17, 21, 28, 16, 50, 19, 17, 34, 19, 11, 29, 19, 16, 19, 18, 14, 57, 15, 15, 19, 25, 12, 18, 17, 16, 26, 18, 40, 18, 8, 19, 18, 15, 25, 21, 31, 37, 27, 21, 19, 25, 194, 36, 28, 16, 53, 41, 17, 36, 18, 22, 30, 33, 19, 13, 27, 17, 16, 40, 18, 17, 23, 16, 18, 23, 46, 20, 17, 16, 17, 20, 13, 19, 16, 18, 11, 26, 11, 19, 16, 12, 34, 300, 20, 13, 20, 33, 14, 21, 11, 24, 66, 21, 25, 16, 20, 22, 23, 14, 14, 15, 24, 23, 15, 14, 42, 17, 16, 15, 9, 25, 15, 23, 15, 15, 29, 15, 17, 11, 18, 19, 19, 21, 18, 23, 34, 19, 19, 26, 18, 19, 14, 22, 11, 19, 17], "policy_red_0_reward": [1.4489999999999998, 1.4489999999999998, 1.4100000000000001, -0.003, -0.5, 1.3439999999999999, 1.4609999999999999, 1.455, 1.393, 1.3980000000000001, 1.4609999999999999, 0.0, 0.5, 0.953, 1.4489999999999998, 1.4369999999999998, 1.411, -0.501, 0.494, 1.442, 1.4489999999999998, 1.396, 0.941, 1.467, 1.412, 1.443, 1.452, 1.443, -0.001, 1.458, -0.005, 1.455, 1.455, 1.442, 1.423, 0.964, 1.4449999999999998, 1.4489999999999998, 1.452, 1.4180000000000001, -0.5, 1.379, 1.444, -0.5, 1.443, 1.4449999999999998, 0.954, 1.425, -0.003, 0.903, 1.385, 1.4140000000000001, 1.435, 0.943, 1.42, 0.887, 0.89, 1.415, 1.451, 1.337, 1.37, 1.448, 1.392, 0.943, 1.4329999999999998, 1.4100000000000001, 1.399, 1.443, 1.4609999999999999, 1.415, -0.001, 1.452, 1.376, 1.446, 1.448, 1.431, 1.45, 1.446, 1.429, 0.491, 1.44, 0.5, 1.452, 1.448, 1.44, -0.501, 1.442, 1.452, 1.446, 1.467, 1.4180000000000001, 1.467, 1.443, 0.5, 1.464, 0.5, 0.44699999999999995, 1.439, -0.501, -0.002, 1.399, 1.4569999999999999, 1.4369999999999998, -0.501, 1.427, 1.299, 1.4369999999999998, 1.4220000000000002, 0.499, 1.44, -0.001, 0.929, 1.458, 1.458, 1.455, 0.499, 1.4300000000000002, 1.455, 1.458, 1.369, 1.4489999999999998, 1.452, 1.455, -0.5, -0.502, 0.5, 0.496, 0.954, 1.455, 1.412, 1.455, 1.447, 1.467, 1.446, -0.003, 1.4409999999999998, 1.436, 1.4449999999999998, 1.427, 0.497, 1.443, -0.502, 0.499, -0.5, 0.5, 0.956, 0.496, 1.467, 1.442, 1.4489999999999998], "policy_blue_0_reward": [0.499, 0.498, 0.497, 1.4409999999999998, 0.972, 0.495, 0.499, 0.498, 0.495, -0.013000000000000005, 0.498, 1.393, 1.4409999999999998, -0.501, 0.499, -0.502, 0.497, 0.952, 1.339, -0.003, 0.0, 0.496, -1.0, -1.001, 0.498, 0.499, 0.499, -1.0, 1.443, 0.498, 1.322, 0.498, 0.499, -1.002, -1.001, -0.501, -1.001, -1.002, 0.5, -1.001, 1.446, 0.49, -0.003, 1.476, 0.498, 0.499, -0.5, -0.002, 1.4369999999999998, -0.5, 0.496, -1.0039999999999998, -0.502, -0.5, 0.499, 0.469, -1.006, -1.005, 0.498, 0.497, -0.505, -0.003, 0.493, -1.002, 0.497, 0.497, 0.498, -1.0, 0.498, 0.497, 1.448, 0.498, 0.497, 0.497, -0.001, 0.498, -0.501, 0.499, -0.004, 1.3599999999999999, -0.002, 1.4489999999999998, 0.499, -0.002, 0.498, 1.4609999999999999, 0.497, -0.002, -1.007, -0.5009999999999999, -0.503, -0.501, 0.498, 1.45, -1.0, 1.393, 0.46099999999999997, 0.498, 0.961, 1.439, -1.005, 0.5, 0.5, 0.966, 0.497, -0.507, 0.498, -0.502, 1.451, -0.001, 1.432, -0.502, 0.499, 0.498, 0.5, 1.427, 0.497, 0.499, -1.0, 0.493, -1.0, 0.498, 0.5, 0.972, 1.424, 1.454, 1.431, -0.501, 0.0, 0.495, 0.499, -0.5019999999999999, -1.0, 0.499, 1.442, 0.5, 0.497, 0.497, -0.002, 1.397, 0.496, 0.941, 1.42, 0.944, 1.4409999999999998, -1.0, 1.4329999999999998, -0.5, -1.0019999999999998, 0.498]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4006210336850498, "mean_inference_ms": 7.428731135837415, "mean_action_processing_ms": 0.38914682509117826, "mean_env_wait_ms": 0.5187479985248388, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13997729619344076, "StateBufferConnector_ms": 0.009266535441080729, "ViewRequirementAgentConnector_ms": 0.19787200291951498}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.18751113479982, "num_env_steps_trained_throughput_per_sec": 130.18751113479982, "timesteps_total": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 30558.664, "sample_time_ms": 3936.472, "learn_time_ms": 26593.759, "learn_throughput": 150.411, "synch_weights_time_ms": 26.91}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "episodes_total": 6242, "training_iteration": 96, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-47-53", "timestamp": 1694839673, "time_this_iter_s": 30.743810892105103, "time_total_s": 2986.5409276485443, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21985900>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2986.5409276485443, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 25.061363636363637, "ram_util_percent": 56.99318181818182}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5116279069767442, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.24806201550387597, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11627906976744186, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.24806201550387597, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.10852713178294573, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.11627906976744186, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.24806201550387597, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11627906976744186, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5829832823015749, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.035744409305334554, "policy_loss": -0.07940164478253185, "vf_loss": 0.03756856902133829, "vf_explained_var": 0.6850111237416665, "kl": 0.011427204375903936, "entropy": 1.159650138641397, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 92640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6376729321666061, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05052671726831856, "policy_loss": -0.09653191476487942, "vf_loss": 0.03916333455417771, "vf_explained_var": 0.5499372822542985, "kl": 0.012253741281846774, "entropy": 1.4920245921860138, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 92640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 776000, "num_agent_steps_trained": 776000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.371, "episode_reward_mean": 1.29884496124031, "episode_len_mean": 31.131782945736433, "episode_media": {}, "episodes_this_iter": 129, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.011}, "policy_reward_max": {"red_0": 1.4689999999999999, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 1.014782945736434, "blue_0": 0.284062015503876}, "custom_metrics": {"red_0/door_open_done_mean": 0.5116279069767442, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.24806201550387597, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11627906976744186, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.24806201550387597, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.10852713178294573, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.11627906976744186, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.24806201550387597, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11627906976744186, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.040999999999999814, 1.907, 1.409, -0.02400000000000002, 0.45499999999999996, 1.8679999999999999, 0.41000000000000014, 0.44099999999999984, 0.21699999999999997, 1.939, 1.942, 1.9609999999999999, 1.904, 1.424, 1.44, 1.447, 0.831, 1.9569999999999999, 0.9750000000000001, 1.9020000000000001, 1.954, 0.9319999999999999, 1.947, 0.96, 1.939, 0.42300000000000004, 1.952, 1.4409999999999998, 0.94, 0.9609999999999999, 1.44, -0.371, -0.07899999999999996, 1.45, 1.9409999999999998, -0.08699999999999986, 1.411, 1.381, 0.43299999999999983, 1.9409999999999998, -0.252, 1.9529999999999998, 1.9449999999999998, 1.9300000000000002, -0.07099999999999995, 1.94, 0.482, 1.948, 1.9609999999999999, 1.741, 1.9569999999999999, 1.924, -0.07600000000000007, 0.44599999999999995, 1.442, 0.4289999999999998, 0.9630000000000001, 1.9260000000000002, 0.46099999999999997, -0.14400000000000002, -0.08899999999999997, 0.45699999999999985, 1.939, 1.959, 1.9580000000000002, 1.9609999999999999, 1.44, 0.43500000000000005, 0.567, 1.799, 1.922, 0.45999999999999996, 0.946, 1.435, 0.887, 1.9569999999999999, 1.94, 1.9180000000000001, 1.899, 1.9609999999999999, 0.45899999999999996, 1.96, 0.8860000000000001, 1.917, 1.927, 1.82, 1.883, 0.94, 1.458, -0.040000000000000036, 1.875, 0.919, 0.41300000000000003, 1.9420000000000002, 1.936, 0.9590000000000001, 1.955, 1.932, 1.4529999999999998, 1.857, 0.9630000000000001, 0.948, 1.9369999999999998, 1.899, -0.07399999999999995, 1.421, 1.936, 1.88, 1.426, 1.8980000000000001, 1.432, 0.45999999999999996, 1.917, 1.958, 1.4409999999999998, 0.9689999999999999, 1.94, 1.3940000000000001, 1.662, 0.37, 1.435, 1.9489999999999998, 1.954, 1.926, 1.923, 0.9369999999999998, 0.4590000000000001, 0.8500000000000001, 1.9609999999999999], "episode_lengths": [13, 29, 28, 8, 14, 41, 28, 19, 83, 20, 19, 13, 30, 24, 19, 17, 54, 14, 8, 31, 15, 21, 16, 13, 19, 24, 15, 19, 300, 13, 20, 116, 24, 16, 17, 27, 28, 37, 21, 19, 78, 15, 18, 23, 23, 19, 6, 17, 13, 82, 14, 23, 24, 16, 19, 21, 12, 23, 12, 45, 27, 14, 19, 13, 13, 13, 19, 20, 135, 62, 24, 13, 300, 21, 35, 14, 19, 27, 32, 13, 13, 13, 35, 27, 22, 56, 37, 18, 170, 13, 40, 25, 27, 19, 21, 12, 15, 22, 15, 45, 12, 17, 21, 32, 23, 23, 20, 38, 24, 32, 22, 13, 27, 14, 19, 10, 19, 34, 105, 42, 21, 17, 15, 24, 25, 21, 13, 47, 13], "policy_red_0_reward": [-1.0019999999999998, 0.497, 1.412, 0.976, -0.5, 1.371, 1.413, 1.442, -0.514, 1.44, 1.443, 1.4609999999999999, 0.498, 0.0, 1.4409999999999998, 1.4489999999999998, 1.335, 1.458, -0.5009999999999999, 0.499, 1.455, -0.501, 1.451, 1.4609999999999999, 1.443, 0.9259999999999999, 0.499, 1.443, 0.471, 1.4609999999999999, 1.44, 0.64, -1.0, 1.451, 1.446, 0.916, 1.415, 1.384, 1.436, 1.442, 0.755, 0.499, 1.4449999999999998, 1.431, -1.0, 1.442, 0.982, 1.4489999999999998, 1.4609999999999999, 1.25, 1.458, 1.429, 0.9259999999999999, -0.503, 1.442, 1.435, 1.464, 1.428, -0.501, 0.862, -1.004, 1.4569999999999999, 1.442, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.442, 1.44, -0.518, 1.306, 1.426, 1.4609999999999999, 0.478, 1.4369999999999998, -0.506, 1.458, 1.442, 1.419, 0.499, 1.4609999999999999, -0.5, 0.499, 1.3900000000000001, 0.5, 1.43, 1.325, 1.3860000000000001, 1.444, 0.484, 0.961, 1.38, 1.42, 0.917, 1.443, 0.499, 1.46, 1.455, 1.434, 1.454, 0.5, 1.464, -0.5, 1.4369999999999998, 1.401, 0.931, -0.005, 1.439, 1.381, 1.428, 1.401, 1.4329999999999998, 0.961, 1.419, 1.458, 1.443, 1.4689999999999999, 1.443, 1.397, 1.173, -0.501, 1.4369999999999998, 1.4489999999999998, 1.455, 0.5, 1.425, 1.4369999999999998, 1.46, 1.3559999999999999, 1.4609999999999999], "policy_blue_0_reward": [0.961, 1.4100000000000001, -0.003, -1.0, 0.955, 0.497, -1.003, -1.001, 0.731, 0.499, 0.499, 0.5, 1.4060000000000001, 1.424, -0.001, -0.002, -0.504, 0.499, 1.476, 1.403, 0.499, 1.4329999999999998, 0.496, -0.501, 0.496, -0.503, 1.4529999999999998, -0.002, 0.469, -0.5, 0.0, -1.011, 0.9209999999999999, -0.001, 0.495, -1.003, -0.004, -0.003, -1.003, 0.499, -1.007, 1.454, 0.5, 0.499, 0.929, 0.498, -0.5, 0.499, 0.5, 0.491, 0.499, 0.495, -1.002, 0.949, 0.0, -1.006, -0.5009999999999999, 0.498, 0.962, -1.006, 0.915, -1.0, 0.497, 0.498, 0.497, 0.5, -0.002, -1.005, 1.085, 0.493, 0.496, -1.001, 0.46799999999999997, -0.002, 1.393, 0.499, 0.498, 0.499, 1.4, 0.5, 0.959, 1.4609999999999999, -0.504, 1.417, 0.497, 0.495, 0.497, -0.504, 0.974, -1.001, 0.495, -0.501, -0.504, 0.499, 1.4369999999999998, -0.501, 0.5, 0.498, -0.001, 1.357, -0.501, 1.448, 0.5, 0.498, -1.005, 1.4260000000000002, 0.497, 0.499, -0.002, 0.497, -0.001, -0.501, 0.498, 0.5, -0.002, -0.5, 0.497, -0.003, 0.489, 0.871, -0.002, 0.5, 0.499, 1.426, 0.498, -0.5, -1.001, -0.506, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4018994026271019, "mean_inference_ms": 7.431535247950052, "mean_action_processing_ms": 0.38845678392241517, "mean_env_wait_ms": 0.5189855191319483, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14585552289504414, "StateBufferConnector_ms": 0.009359407794567965, "ViewRequirementAgentConnector_ms": 0.1914226731588674}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.371, "episode_reward_mean": 1.29884496124031, "episode_len_mean": 31.131782945736433, "episodes_this_iter": 129, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.011}, "policy_reward_max": {"red_0": 1.4689999999999999, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 1.014782945736434, "blue_0": 0.284062015503876}, "hist_stats": {"episode_reward": [-0.040999999999999814, 1.907, 1.409, -0.02400000000000002, 0.45499999999999996, 1.8679999999999999, 0.41000000000000014, 0.44099999999999984, 0.21699999999999997, 1.939, 1.942, 1.9609999999999999, 1.904, 1.424, 1.44, 1.447, 0.831, 1.9569999999999999, 0.9750000000000001, 1.9020000000000001, 1.954, 0.9319999999999999, 1.947, 0.96, 1.939, 0.42300000000000004, 1.952, 1.4409999999999998, 0.94, 0.9609999999999999, 1.44, -0.371, -0.07899999999999996, 1.45, 1.9409999999999998, -0.08699999999999986, 1.411, 1.381, 0.43299999999999983, 1.9409999999999998, -0.252, 1.9529999999999998, 1.9449999999999998, 1.9300000000000002, -0.07099999999999995, 1.94, 0.482, 1.948, 1.9609999999999999, 1.741, 1.9569999999999999, 1.924, -0.07600000000000007, 0.44599999999999995, 1.442, 0.4289999999999998, 0.9630000000000001, 1.9260000000000002, 0.46099999999999997, -0.14400000000000002, -0.08899999999999997, 0.45699999999999985, 1.939, 1.959, 1.9580000000000002, 1.9609999999999999, 1.44, 0.43500000000000005, 0.567, 1.799, 1.922, 0.45999999999999996, 0.946, 1.435, 0.887, 1.9569999999999999, 1.94, 1.9180000000000001, 1.899, 1.9609999999999999, 0.45899999999999996, 1.96, 0.8860000000000001, 1.917, 1.927, 1.82, 1.883, 0.94, 1.458, -0.040000000000000036, 1.875, 0.919, 0.41300000000000003, 1.9420000000000002, 1.936, 0.9590000000000001, 1.955, 1.932, 1.4529999999999998, 1.857, 0.9630000000000001, 0.948, 1.9369999999999998, 1.899, -0.07399999999999995, 1.421, 1.936, 1.88, 1.426, 1.8980000000000001, 1.432, 0.45999999999999996, 1.917, 1.958, 1.4409999999999998, 0.9689999999999999, 1.94, 1.3940000000000001, 1.662, 0.37, 1.435, 1.9489999999999998, 1.954, 1.926, 1.923, 0.9369999999999998, 0.4590000000000001, 0.8500000000000001, 1.9609999999999999], "episode_lengths": [13, 29, 28, 8, 14, 41, 28, 19, 83, 20, 19, 13, 30, 24, 19, 17, 54, 14, 8, 31, 15, 21, 16, 13, 19, 24, 15, 19, 300, 13, 20, 116, 24, 16, 17, 27, 28, 37, 21, 19, 78, 15, 18, 23, 23, 19, 6, 17, 13, 82, 14, 23, 24, 16, 19, 21, 12, 23, 12, 45, 27, 14, 19, 13, 13, 13, 19, 20, 135, 62, 24, 13, 300, 21, 35, 14, 19, 27, 32, 13, 13, 13, 35, 27, 22, 56, 37, 18, 170, 13, 40, 25, 27, 19, 21, 12, 15, 22, 15, 45, 12, 17, 21, 32, 23, 23, 20, 38, 24, 32, 22, 13, 27, 14, 19, 10, 19, 34, 105, 42, 21, 17, 15, 24, 25, 21, 13, 47, 13], "policy_red_0_reward": [-1.0019999999999998, 0.497, 1.412, 0.976, -0.5, 1.371, 1.413, 1.442, -0.514, 1.44, 1.443, 1.4609999999999999, 0.498, 0.0, 1.4409999999999998, 1.4489999999999998, 1.335, 1.458, -0.5009999999999999, 0.499, 1.455, -0.501, 1.451, 1.4609999999999999, 1.443, 0.9259999999999999, 0.499, 1.443, 0.471, 1.4609999999999999, 1.44, 0.64, -1.0, 1.451, 1.446, 0.916, 1.415, 1.384, 1.436, 1.442, 0.755, 0.499, 1.4449999999999998, 1.431, -1.0, 1.442, 0.982, 1.4489999999999998, 1.4609999999999999, 1.25, 1.458, 1.429, 0.9259999999999999, -0.503, 1.442, 1.435, 1.464, 1.428, -0.501, 0.862, -1.004, 1.4569999999999999, 1.442, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.442, 1.44, -0.518, 1.306, 1.426, 1.4609999999999999, 0.478, 1.4369999999999998, -0.506, 1.458, 1.442, 1.419, 0.499, 1.4609999999999999, -0.5, 0.499, 1.3900000000000001, 0.5, 1.43, 1.325, 1.3860000000000001, 1.444, 0.484, 0.961, 1.38, 1.42, 0.917, 1.443, 0.499, 1.46, 1.455, 1.434, 1.454, 0.5, 1.464, -0.5, 1.4369999999999998, 1.401, 0.931, -0.005, 1.439, 1.381, 1.428, 1.401, 1.4329999999999998, 0.961, 1.419, 1.458, 1.443, 1.4689999999999999, 1.443, 1.397, 1.173, -0.501, 1.4369999999999998, 1.4489999999999998, 1.455, 0.5, 1.425, 1.4369999999999998, 1.46, 1.3559999999999999, 1.4609999999999999], "policy_blue_0_reward": [0.961, 1.4100000000000001, -0.003, -1.0, 0.955, 0.497, -1.003, -1.001, 0.731, 0.499, 0.499, 0.5, 1.4060000000000001, 1.424, -0.001, -0.002, -0.504, 0.499, 1.476, 1.403, 0.499, 1.4329999999999998, 0.496, -0.501, 0.496, -0.503, 1.4529999999999998, -0.002, 0.469, -0.5, 0.0, -1.011, 0.9209999999999999, -0.001, 0.495, -1.003, -0.004, -0.003, -1.003, 0.499, -1.007, 1.454, 0.5, 0.499, 0.929, 0.498, -0.5, 0.499, 0.5, 0.491, 0.499, 0.495, -1.002, 0.949, 0.0, -1.006, -0.5009999999999999, 0.498, 0.962, -1.006, 0.915, -1.0, 0.497, 0.498, 0.497, 0.5, -0.002, -1.005, 1.085, 0.493, 0.496, -1.001, 0.46799999999999997, -0.002, 1.393, 0.499, 0.498, 0.499, 1.4, 0.5, 0.959, 1.4609999999999999, -0.504, 1.417, 0.497, 0.495, 0.497, -0.504, 0.974, -1.001, 0.495, -0.501, -0.504, 0.499, 1.4369999999999998, -0.501, 0.5, 0.498, -0.001, 1.357, -0.501, 1.448, 0.5, 0.498, -1.005, 1.4260000000000002, 0.497, 0.499, -0.002, 0.497, -0.001, -0.501, 0.498, 0.5, -0.002, -0.5, 0.497, -0.003, 0.489, 0.871, -0.002, 0.5, 0.499, 1.426, 0.498, -0.5, -1.001, -0.506, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4018994026271019, "mean_inference_ms": 7.431535247950052, "mean_action_processing_ms": 0.38845678392241517, "mean_env_wait_ms": 0.5189855191319483, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14585552289504414, "StateBufferConnector_ms": 0.009359407794567965, "ViewRequirementAgentConnector_ms": 0.1914226731588674}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 776000, "num_agent_steps_trained": 776000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.43775402528578, "num_env_steps_trained_throughput_per_sec": 127.43775402528578, "timesteps_total": 388000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 776000, "timers": {"training_iteration_time_ms": 30774.358, "sample_time_ms": 3957.993, "learn_time_ms": 26788.198, "learn_throughput": 149.319, "synch_weights_time_ms": 26.658}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 776000, "num_agent_steps_trained": 776000}, "done": false, "episodes_total": 6371, "training_iteration": 97, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-48-26", "timestamp": 1694839706, "time_this_iter_s": 31.405848026275635, "time_total_s": 3017.94677567482, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f7640>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3017.94677567482, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 25.167391304347824, "ram_util_percent": 56.9304347826087}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.4715447154471545, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.15447154471544716, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0975609756097561, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.15447154471544716, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.25203252032520324, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.0975609756097561, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.15447154471544716, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0975609756097561, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6083736677964529, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04501110888935121, "policy_loss": -0.08697235674529415, "vf_loss": 0.032805459116449734, "vf_explained_var": 0.6844213175276915, "kl": 0.011731769593382069, "entropy": 1.1679202828556299, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 93600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5889486293308437, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.06185567293335528, "policy_loss": -0.10534317031075867, "vf_loss": 0.03280654523502259, "vf_explained_var": 0.6143473364412785, "kl": 0.012535922271100794, "entropy": 1.4741736707588038, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 93600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06899999999999995, "episode_reward_mean": 1.4558373983739836, "episode_len_mean": 34.41463414634146, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.463, "blue_0": 1.466}, "policy_reward_mean": {"red_0": 0.902178861788618, "blue_0": 0.5536585365853659}, "custom_metrics": {"red_0/door_open_done_mean": 0.4715447154471545, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.15447154471544716, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0975609756097561, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.15447154471544716, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.25203252032520324, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.0975609756097561, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.15447154471544716, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0975609756097561, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.30999999999999983, 1.9329999999999998, 1.9569999999999999, 1.443, 1.9569999999999999, -0.04300000000000004, 0.9319999999999999, 0.9390000000000001, 1.724, 1.3940000000000001, 1.883, 1.455, 0.9160000000000001, 1.9380000000000002, 1.431, 1.95, 1.4449999999999998, 1.929, 1.944, 1.4489999999999998, 0.8860000000000001, 1.924, 1.925, -0.04700000000000004, 0.921, 1.947, 1.263, 1.9060000000000001, -0.039999999999999925, -0.06899999999999995, 1.929, 0.9119999999999999, 1.9329999999999998, 1.947, 1.451, 1.9489999999999998, 1.9529999999999998, 0.46299999999999997, 1.416, 0.945, 1.95, 1.9020000000000001, 1.718, 1.927, 1.395, 1.6949999999999998, 0.896, 0.43899999999999995, 1.901, 0.43799999999999994, 1.451, 1.956, 1.933, 0.946, 0.952, 1.9489999999999998, 1.029, 1.948, 0.383, 1.815, 0.42299999999999993, 0.5389999999999999, 1.916, 1.899, 0.46699999999999997, 1.951, 0.958, 0.9430000000000001, 0.962, 1.921, 1.9409999999999998, 0.952, 1.951, 1.8559999999999999, 1.884, 1.8559999999999999, -0.026000000000000023, 1.956, 0.962, 0.966, 1.934, 1.4449999999999998, 1.3780000000000001, 1.795, 0.44099999999999984, 0.9159999999999999, 1.96, 1.443, 1.952, 1.9300000000000002, 1.926, 1.93, 1.9329999999999998, 1.438, 1.862, 1.9040000000000001, 1.401, 1.9529999999999998, 1.4409999999999998, 1.92, 1.905, 1.936, 1.436, 1.448, 1.958, 0.44500000000000006, 1.8780000000000001, 1.921, 1.4489999999999998, 1.952, 1.426, 1.943, 1.9100000000000001, 1.935, 1.9609999999999999, 1.899, 1.4260000000000002, 1.9209999999999998, 1.957, 1.3599999999999999, 0.43500000000000005, 1.917, 0.44799999999999995], "episode_lengths": [300, 21, 14, 19, 14, 14, 300, 18, 87, 35, 36, 15, 26, 20, 23, 16, 17, 23, 18, 16, 36, 24, 23, 14, 25, 17, 75, 30, 13, 22, 22, 28, 21, 17, 16, 16, 15, 12, 27, 18, 16, 31, 86, 23, 34, 93, 33, 19, 32, 19, 16, 14, 21, 300, 15, 17, 298, 17, 37, 58, 24, 137, 27, 31, 11, 16, 13, 18, 12, 26, 19, 14, 16, 47, 37, 44, 8, 14, 12, 11, 21, 18, 38, 64, 18, 27, 13, 18, 15, 23, 22, 22, 20, 20, 43, 29, 31, 15, 18, 25, 28, 20, 21, 17, 14, 17, 38, 25, 17, 15, 22, 18, 28, 20, 13, 32, 23, 24, 14, 45, 21, 26, 16], "policy_red_0_reward": [0.33799999999999986, 1.436, 1.458, 0.0, 0.5, 0.957, 0.46399999999999997, 1.444, 1.23, 0.0, 0.496, 1.455, 1.42, 1.44, 1.431, 0.498, -0.003, 1.431, 1.446, 1.452, 1.389, 1.427, 1.428, 0.958, -0.503, 1.447, -0.008, 0.499, -1.001, -1.002, 1.432, 1.415, 0.498, 0.5, 1.452, 1.452, 1.455, -0.501, -0.001, -0.5, 1.451, 1.4060000000000001, 1.23, 1.431, 1.396, 1.206, -0.501, -0.503, 0.499, 0.942, 1.452, 1.4569999999999999, 1.436, 0.476, 1.454, 1.4489999999999998, 0.5559999999999999, 1.4489999999999998, 0.886, 0.494, -0.503, -0.532, 1.4180000000000001, 0.497, -0.5, 1.452, 1.459, 1.446, 1.462, 0.499, 1.442, 1.4569999999999999, 1.452, 0.498, 0.498, 0.491, 0.975, 1.4569999999999999, 1.463, -0.5, 1.435, 1.446, -0.002, 0.493, 0.944, 1.419, 1.4609999999999999, 1.446, 1.454, 1.431, 1.432, 0.498, 1.439, 1.439, 0.495, 1.4100000000000001, -0.004, 1.454, 1.443, 1.424, 0.494, 1.44, 1.436, 1.4489999999999998, 1.458, 1.448, 0.497, 0.498, 1.4489999999999998, 1.4529999999999998, -0.006, 0.497, 0.498, 1.439, 1.4609999999999999, 1.403, -0.003, 0.498, 1.458, 1.363, 1.4369999999999998, 1.42, -1.002], "policy_blue_0_reward": [-0.028000000000000018, 0.497, 0.499, 1.443, 1.4569999999999999, -1.0, 0.46799999999999997, -0.505, 0.494, 1.3940000000000001, 1.387, 0.0, -0.5039999999999999, 0.498, 0.0, 1.452, 1.448, 0.498, 0.498, -0.003, -0.503, 0.497, 0.497, -1.005, 1.424, 0.5, 1.271, 1.407, 0.961, 0.9329999999999999, 0.497, -0.503, 1.435, 1.447, -0.001, 0.497, 0.498, 0.964, 1.417, 1.4449999999999998, 0.499, 0.496, 0.488, 0.496, -0.001, 0.489, 1.397, 0.942, 1.4020000000000001, -0.504, -0.001, 0.499, 0.497, 0.47, -0.502, 0.5, 0.473, 0.499, -0.503, 1.3210000000000002, 0.9259999999999999, 1.071, 0.498, 1.4020000000000001, 0.967, 0.499, -0.501, -0.5029999999999999, -0.5, 1.4220000000000002, 0.499, -0.505, 0.499, 1.358, 1.3860000000000001, 1.365, -1.001, 0.499, -0.501, 1.466, 0.499, -0.001, 1.38, 1.302, -0.503, -0.503, 0.499, -0.003, 0.498, 0.499, 0.494, 1.432, 0.494, -0.001, 1.367, 0.494, 1.405, 0.499, -0.002, 0.496, 1.411, 0.496, 0.0, -0.001, 0.5, -1.003, 1.381, 1.423, 0.0, 0.499, 1.432, 1.446, 1.412, 0.496, 0.5, 0.496, 1.429, 1.423, 0.499, -0.003, -1.002, 0.497, 1.45]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4024359116455098, "mean_inference_ms": 7.432598018163699, "mean_action_processing_ms": 0.3887475805909757, "mean_env_wait_ms": 0.5188800702392137, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15381642473422416, "StateBufferConnector_ms": 0.009852405486068106, "ViewRequirementAgentConnector_ms": 0.196097439866725}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06899999999999995, "episode_reward_mean": 1.4558373983739836, "episode_len_mean": 34.41463414634146, "episodes_this_iter": 123, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.463, "blue_0": 1.466}, "policy_reward_mean": {"red_0": 0.902178861788618, "blue_0": 0.5536585365853659}, "hist_stats": {"episode_reward": [0.30999999999999983, 1.9329999999999998, 1.9569999999999999, 1.443, 1.9569999999999999, -0.04300000000000004, 0.9319999999999999, 0.9390000000000001, 1.724, 1.3940000000000001, 1.883, 1.455, 0.9160000000000001, 1.9380000000000002, 1.431, 1.95, 1.4449999999999998, 1.929, 1.944, 1.4489999999999998, 0.8860000000000001, 1.924, 1.925, -0.04700000000000004, 0.921, 1.947, 1.263, 1.9060000000000001, -0.039999999999999925, -0.06899999999999995, 1.929, 0.9119999999999999, 1.9329999999999998, 1.947, 1.451, 1.9489999999999998, 1.9529999999999998, 0.46299999999999997, 1.416, 0.945, 1.95, 1.9020000000000001, 1.718, 1.927, 1.395, 1.6949999999999998, 0.896, 0.43899999999999995, 1.901, 0.43799999999999994, 1.451, 1.956, 1.933, 0.946, 0.952, 1.9489999999999998, 1.029, 1.948, 0.383, 1.815, 0.42299999999999993, 0.5389999999999999, 1.916, 1.899, 0.46699999999999997, 1.951, 0.958, 0.9430000000000001, 0.962, 1.921, 1.9409999999999998, 0.952, 1.951, 1.8559999999999999, 1.884, 1.8559999999999999, -0.026000000000000023, 1.956, 0.962, 0.966, 1.934, 1.4449999999999998, 1.3780000000000001, 1.795, 0.44099999999999984, 0.9159999999999999, 1.96, 1.443, 1.952, 1.9300000000000002, 1.926, 1.93, 1.9329999999999998, 1.438, 1.862, 1.9040000000000001, 1.401, 1.9529999999999998, 1.4409999999999998, 1.92, 1.905, 1.936, 1.436, 1.448, 1.958, 0.44500000000000006, 1.8780000000000001, 1.921, 1.4489999999999998, 1.952, 1.426, 1.943, 1.9100000000000001, 1.935, 1.9609999999999999, 1.899, 1.4260000000000002, 1.9209999999999998, 1.957, 1.3599999999999999, 0.43500000000000005, 1.917, 0.44799999999999995], "episode_lengths": [300, 21, 14, 19, 14, 14, 300, 18, 87, 35, 36, 15, 26, 20, 23, 16, 17, 23, 18, 16, 36, 24, 23, 14, 25, 17, 75, 30, 13, 22, 22, 28, 21, 17, 16, 16, 15, 12, 27, 18, 16, 31, 86, 23, 34, 93, 33, 19, 32, 19, 16, 14, 21, 300, 15, 17, 298, 17, 37, 58, 24, 137, 27, 31, 11, 16, 13, 18, 12, 26, 19, 14, 16, 47, 37, 44, 8, 14, 12, 11, 21, 18, 38, 64, 18, 27, 13, 18, 15, 23, 22, 22, 20, 20, 43, 29, 31, 15, 18, 25, 28, 20, 21, 17, 14, 17, 38, 25, 17, 15, 22, 18, 28, 20, 13, 32, 23, 24, 14, 45, 21, 26, 16], "policy_red_0_reward": [0.33799999999999986, 1.436, 1.458, 0.0, 0.5, 0.957, 0.46399999999999997, 1.444, 1.23, 0.0, 0.496, 1.455, 1.42, 1.44, 1.431, 0.498, -0.003, 1.431, 1.446, 1.452, 1.389, 1.427, 1.428, 0.958, -0.503, 1.447, -0.008, 0.499, -1.001, -1.002, 1.432, 1.415, 0.498, 0.5, 1.452, 1.452, 1.455, -0.501, -0.001, -0.5, 1.451, 1.4060000000000001, 1.23, 1.431, 1.396, 1.206, -0.501, -0.503, 0.499, 0.942, 1.452, 1.4569999999999999, 1.436, 0.476, 1.454, 1.4489999999999998, 0.5559999999999999, 1.4489999999999998, 0.886, 0.494, -0.503, -0.532, 1.4180000000000001, 0.497, -0.5, 1.452, 1.459, 1.446, 1.462, 0.499, 1.442, 1.4569999999999999, 1.452, 0.498, 0.498, 0.491, 0.975, 1.4569999999999999, 1.463, -0.5, 1.435, 1.446, -0.002, 0.493, 0.944, 1.419, 1.4609999999999999, 1.446, 1.454, 1.431, 1.432, 0.498, 1.439, 1.439, 0.495, 1.4100000000000001, -0.004, 1.454, 1.443, 1.424, 0.494, 1.44, 1.436, 1.4489999999999998, 1.458, 1.448, 0.497, 0.498, 1.4489999999999998, 1.4529999999999998, -0.006, 0.497, 0.498, 1.439, 1.4609999999999999, 1.403, -0.003, 0.498, 1.458, 1.363, 1.4369999999999998, 1.42, -1.002], "policy_blue_0_reward": [-0.028000000000000018, 0.497, 0.499, 1.443, 1.4569999999999999, -1.0, 0.46799999999999997, -0.505, 0.494, 1.3940000000000001, 1.387, 0.0, -0.5039999999999999, 0.498, 0.0, 1.452, 1.448, 0.498, 0.498, -0.003, -0.503, 0.497, 0.497, -1.005, 1.424, 0.5, 1.271, 1.407, 0.961, 0.9329999999999999, 0.497, -0.503, 1.435, 1.447, -0.001, 0.497, 0.498, 0.964, 1.417, 1.4449999999999998, 0.499, 0.496, 0.488, 0.496, -0.001, 0.489, 1.397, 0.942, 1.4020000000000001, -0.504, -0.001, 0.499, 0.497, 0.47, -0.502, 0.5, 0.473, 0.499, -0.503, 1.3210000000000002, 0.9259999999999999, 1.071, 0.498, 1.4020000000000001, 0.967, 0.499, -0.501, -0.5029999999999999, -0.5, 1.4220000000000002, 0.499, -0.505, 0.499, 1.358, 1.3860000000000001, 1.365, -1.001, 0.499, -0.501, 1.466, 0.499, -0.001, 1.38, 1.302, -0.503, -0.503, 0.499, -0.003, 0.498, 0.499, 0.494, 1.432, 0.494, -0.001, 1.367, 0.494, 1.405, 0.499, -0.002, 0.496, 1.411, 0.496, 0.0, -0.001, 0.5, -1.003, 1.381, 1.423, 0.0, 0.499, 1.432, 1.446, 1.412, 0.496, 0.5, 0.496, 1.429, 1.423, 0.499, -0.003, -1.002, 0.497, 1.45]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4024359116455098, "mean_inference_ms": 7.432598018163699, "mean_action_processing_ms": 0.3887475805909757, "mean_env_wait_ms": 0.5188800702392137, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15381642473422416, "StateBufferConnector_ms": 0.009852405486068106, "ViewRequirementAgentConnector_ms": 0.196097439866725}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 126.1829689060121, "num_env_steps_trained_throughput_per_sec": 126.1829689060121, "timesteps_total": 392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 30934.476, "sample_time_ms": 4001.53, "learn_time_ms": 26904.882, "learn_throughput": 148.672, "synch_weights_time_ms": 26.535}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "episodes_total": 6494, "training_iteration": 98, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-48-58", "timestamp": 1694839738, "time_this_iter_s": 31.718219995498657, "time_total_s": 3049.6649956703186, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219855a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3049.6649956703186, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 25.819565217391304, "ram_util_percent": 57.02826086956522}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5323741007194245, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.17266187050359713, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11510791366906475, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.17266187050359713, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16546762589928057, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.11510791366906475, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.17266187050359713, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11510791366906475, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5914904806452493, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04416408803493444, "policy_loss": -0.09139342252868422, "vf_loss": 0.039765631251308754, "vf_explained_var": 0.6802366467192769, "kl": 0.012505095302636467, "entropy": 1.1416518237441777, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 94560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6009753020169835, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05105061814186532, "policy_loss": -0.095782003478962, "vf_loss": 0.03807214263069909, "vf_explained_var": 0.5827234231556455, "kl": 0.01191983194015757, "entropy": 1.4595534278700748, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 94560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 792000, "num_agent_steps_trained": 792000}, "sampler_results": {"episode_reward_max": 1.96, "episode_reward_min": -0.12499999999999989, "episode_reward_mean": 1.415726618705036, "episode_len_mean": 28.381294964028775, "episode_media": {}, "episodes_this_iter": 139, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.006}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.458}, "policy_reward_mean": {"red_0": 0.9705035971223022, "blue_0": 0.4452230215827338}, "custom_metrics": {"red_0/door_open_done_mean": 0.5323741007194245, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.17266187050359713, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11510791366906475, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.17266187050359713, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16546762589928057, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.11510791366906475, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.17266187050359713, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11510791366906475, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.439, -0.03300000000000003, 1.93, 1.451, 1.909, 0.9550000000000001, 1.262, 0.39, 0.3799999999999999, 1.9209999999999998, 0.918, 1.936, 1.95, 0.45699999999999985, -0.09499999999999997, 1.924, 1.448, 1.4569999999999999, 1.446, 1.73, -0.03200000000000003, 1.9100000000000001, 1.944, 0.9339999999999999, 1.9369999999999998, 0.883, 1.9249999999999998, 1.936, 1.948, 0.944, 1.928, 1.916, 1.456, 1.9249999999999998, 0.861, 1.915, 1.956, 1.452, 1.921, 0.9369999999999999, -0.06700000000000006, 0.45599999999999996, 0.9209999999999998, -0.09299999999999986, 0.44099999999999995, 1.946, 1.452, 1.399, 0.9630000000000001, 1.947, 1.938, 1.4529999999999998, 0.871, 0.947, 1.929, 1.929, 1.917, 0.9500000000000002, 1.958, 1.454, 1.95, 0.46599999999999997, 1.93, 1.948, 1.94, 0.33899999999999997, 1.939, 1.9569999999999999, 0.964, 0.9790000000000001, 1.9540000000000002, 1.436, 1.908, 1.897, 1.45, 1.943, 0.9319999999999999, 1.9409999999999998, 0.9489999999999998, -0.09599999999999997, 1.943, 1.432, 1.947, 1.9569999999999999, 1.946, 1.917, 1.896, 1.4489999999999998, 0.9349999999999999, 1.945, 0.42300000000000004, 1.93, 1.96, 1.9529999999999998, 1.9220000000000002, 0.8109999999999999, 1.9529999999999998, 1.4260000000000002, 1.7890000000000001, -0.03399999999999992, 1.927, 1.936, -0.12499999999999989, 0.44699999999999995, 1.915, 1.434, 1.45, 1.903, 1.917, 0.9329999999999998, 1.944, 1.3940000000000001, 0.44399999999999995, 1.436, 1.948, 1.946, 0.07399999999999984, 1.916, 1.4569999999999999, 1.407, 0.3610000000000002, 1.905, 1.912, 1.448, 1.944, 1.8940000000000001, 1.4489999999999998, 0.33599999999999985, 0.9159999999999999, 1.9100000000000001, 1.9, 1.943, 1.4329999999999998, 1.444, 0.42500000000000004, 1.774, 1.946, 1.919, 1.916], "episode_lengths": [20, 11, 22, 16, 29, 15, 75, 34, 39, 24, 26, 20, 16, 13, 31, 24, 17, 14, 17, 85, 10, 28, 18, 300, 20, 37, 24, 21, 17, 18, 23, 26, 14, 24, 44, 27, 14, 15, 25, 300, 21, 14, 24, 28, 19, 17, 16, 31, 12, 17, 20, 15, 40, 17, 23, 22, 26, 16, 14, 15, 16, 11, 22, 17, 19, 51, 19, 14, 11, 7, 14, 20, 29, 32, 16, 18, 20, 19, 16, 30, 18, 22, 17, 14, 17, 26, 32, 17, 21, 17, 24, 22, 13, 15, 25, 60, 15, 23, 66, 11, 22, 20, 38, 17, 28, 21, 16, 29, 27, 22, 18, 35, 18, 21, 17, 17, 133, 27, 14, 28, 41, 30, 28, 17, 18, 34, 17, 51, 25, 29, 31, 18, 21, 17, 23, 70, 18, 26, 27], "policy_red_0_reward": [1.44, 0.967, 1.4329999999999998, 1.452, 1.411, 1.455, 1.2690000000000001, -1.004, 1.383, 1.426, -0.502, 1.438, 1.452, 0.961, -1.002, 1.426, 1.448, 1.458, 1.4489999999999998, 1.237, 0.97, 1.415, 1.4449999999999998, 0.45999999999999996, 1.44, -0.5, 1.427, 0.5, 0.5, 1.4449999999999998, 1.431, 1.4220000000000002, 1.458, 1.427, 1.366, 1.4180000000000001, 1.458, 1.455, 1.425, 0.46499999999999997, -1.001, -0.502, 1.423, -1.005, -0.501, 1.448, 1.452, -0.005, 1.464, 1.4489999999999998, 1.438, 1.454, 1.373, -0.501, 1.4300000000000002, 1.434, 1.4180000000000001, 1.452, 0.5, 1.455, 1.451, 1.467, 1.431, 1.4489999999999998, 0.499, 1.3399999999999999, 0.499, 1.4569999999999999, 1.4649999999999999, 1.479, 1.458, 1.438, 0.499, 0.497, 1.452, 1.444, -0.503, 0.499, 1.452, -1.001, 0.5, 1.4329999999999998, 0.5, 1.458, 0.498, 0.498, 1.399, 1.4489999999999998, -0.502, 1.448, 1.4249999999999998, 1.432, 1.4609999999999999, 1.454, 1.424, 1.313, 0.498, 1.4300000000000002, 1.298, 0.967, 1.431, 1.438, -1.001, -0.502, 0.5, -0.001, 1.452, 1.408, 1.4180000000000001, 1.434, 0.499, -0.001, -1.0, 1.4369999999999998, 1.4489999999999998, 1.4489999999999998, 0.587, 1.4180000000000001, 1.458, 1.4140000000000001, 0.869, 0.499, 1.413, 1.4489999999999998, 1.4449999999999998, 1.396, 1.4489999999999998, 1.342, 1.4220000000000002, 0.499, 1.4020000000000001, 1.446, 1.435, -0.005, -1.002, 1.284, 0.5, 0.498, 1.4180000000000001], "policy_blue_0_reward": [-0.001, -1.0, 0.497, -0.001, 0.498, -0.5, -0.007, 1.3940000000000001, -1.003, 0.495, 1.42, 0.498, 0.498, -0.504, 0.907, 0.498, 0.0, -0.001, -0.003, 0.493, -1.002, 0.495, 0.499, 0.474, 0.497, 1.383, 0.498, 1.436, 1.448, -0.501, 0.497, 0.494, -0.002, 0.498, -0.505, 0.497, 0.498, -0.003, 0.496, 0.472, 0.9339999999999999, 0.958, -0.502, 0.912, 0.942, 0.498, 0.0, 1.404, -0.501, 0.498, 0.5, -0.001, -0.502, 1.448, 0.499, 0.495, 0.499, -0.5019999999999999, 1.458, -0.001, 0.499, -1.001, 0.499, 0.499, 1.4409999999999998, -1.001, 1.44, 0.5, -0.501, -0.5, 0.496, -0.002, 1.409, 1.4, -0.002, 0.499, 1.435, 1.442, -0.503, 0.905, 1.443, -0.001, 1.447, 0.499, 1.448, 1.419, 0.497, 0.0, 1.4369999999999998, 0.497, -1.002, 0.498, 0.499, 0.499, 0.498, -0.502, 1.455, -0.004, 0.491, -1.001, 0.496, 0.498, 0.876, 0.949, 1.415, 1.435, -0.002, 0.495, 0.499, -0.501, 1.4449999999999998, 1.395, 1.444, -0.001, 0.499, 0.497, -0.513, 0.498, -0.001, -0.007, -0.5079999999999999, 1.4060000000000001, 0.499, -0.001, 0.499, 0.498, 0.0, -1.006, -0.506, 1.411, 0.498, 0.497, -0.002, 1.4489999999999998, 1.427, 0.49, 1.446, 1.421, 0.498]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4037561620015573, "mean_inference_ms": 7.436873200185817, "mean_action_processing_ms": 0.3894980011914989, "mean_env_wait_ms": 0.5194674238426437, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.154659645162898, "StateBufferConnector_ms": 0.009483570675198123, "ViewRequirementAgentConnector_ms": 0.19268046180121332}}, "episode_reward_max": 1.96, "episode_reward_min": -0.12499999999999989, "episode_reward_mean": 1.415726618705036, "episode_len_mean": 28.381294964028775, "episodes_this_iter": 139, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.006}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.458}, "policy_reward_mean": {"red_0": 0.9705035971223022, "blue_0": 0.4452230215827338}, "hist_stats": {"episode_reward": [1.439, -0.03300000000000003, 1.93, 1.451, 1.909, 0.9550000000000001, 1.262, 0.39, 0.3799999999999999, 1.9209999999999998, 0.918, 1.936, 1.95, 0.45699999999999985, -0.09499999999999997, 1.924, 1.448, 1.4569999999999999, 1.446, 1.73, -0.03200000000000003, 1.9100000000000001, 1.944, 0.9339999999999999, 1.9369999999999998, 0.883, 1.9249999999999998, 1.936, 1.948, 0.944, 1.928, 1.916, 1.456, 1.9249999999999998, 0.861, 1.915, 1.956, 1.452, 1.921, 0.9369999999999999, -0.06700000000000006, 0.45599999999999996, 0.9209999999999998, -0.09299999999999986, 0.44099999999999995, 1.946, 1.452, 1.399, 0.9630000000000001, 1.947, 1.938, 1.4529999999999998, 0.871, 0.947, 1.929, 1.929, 1.917, 0.9500000000000002, 1.958, 1.454, 1.95, 0.46599999999999997, 1.93, 1.948, 1.94, 0.33899999999999997, 1.939, 1.9569999999999999, 0.964, 0.9790000000000001, 1.9540000000000002, 1.436, 1.908, 1.897, 1.45, 1.943, 0.9319999999999999, 1.9409999999999998, 0.9489999999999998, -0.09599999999999997, 1.943, 1.432, 1.947, 1.9569999999999999, 1.946, 1.917, 1.896, 1.4489999999999998, 0.9349999999999999, 1.945, 0.42300000000000004, 1.93, 1.96, 1.9529999999999998, 1.9220000000000002, 0.8109999999999999, 1.9529999999999998, 1.4260000000000002, 1.7890000000000001, -0.03399999999999992, 1.927, 1.936, -0.12499999999999989, 0.44699999999999995, 1.915, 1.434, 1.45, 1.903, 1.917, 0.9329999999999998, 1.944, 1.3940000000000001, 0.44399999999999995, 1.436, 1.948, 1.946, 0.07399999999999984, 1.916, 1.4569999999999999, 1.407, 0.3610000000000002, 1.905, 1.912, 1.448, 1.944, 1.8940000000000001, 1.4489999999999998, 0.33599999999999985, 0.9159999999999999, 1.9100000000000001, 1.9, 1.943, 1.4329999999999998, 1.444, 0.42500000000000004, 1.774, 1.946, 1.919, 1.916], "episode_lengths": [20, 11, 22, 16, 29, 15, 75, 34, 39, 24, 26, 20, 16, 13, 31, 24, 17, 14, 17, 85, 10, 28, 18, 300, 20, 37, 24, 21, 17, 18, 23, 26, 14, 24, 44, 27, 14, 15, 25, 300, 21, 14, 24, 28, 19, 17, 16, 31, 12, 17, 20, 15, 40, 17, 23, 22, 26, 16, 14, 15, 16, 11, 22, 17, 19, 51, 19, 14, 11, 7, 14, 20, 29, 32, 16, 18, 20, 19, 16, 30, 18, 22, 17, 14, 17, 26, 32, 17, 21, 17, 24, 22, 13, 15, 25, 60, 15, 23, 66, 11, 22, 20, 38, 17, 28, 21, 16, 29, 27, 22, 18, 35, 18, 21, 17, 17, 133, 27, 14, 28, 41, 30, 28, 17, 18, 34, 17, 51, 25, 29, 31, 18, 21, 17, 23, 70, 18, 26, 27], "policy_red_0_reward": [1.44, 0.967, 1.4329999999999998, 1.452, 1.411, 1.455, 1.2690000000000001, -1.004, 1.383, 1.426, -0.502, 1.438, 1.452, 0.961, -1.002, 1.426, 1.448, 1.458, 1.4489999999999998, 1.237, 0.97, 1.415, 1.4449999999999998, 0.45999999999999996, 1.44, -0.5, 1.427, 0.5, 0.5, 1.4449999999999998, 1.431, 1.4220000000000002, 1.458, 1.427, 1.366, 1.4180000000000001, 1.458, 1.455, 1.425, 0.46499999999999997, -1.001, -0.502, 1.423, -1.005, -0.501, 1.448, 1.452, -0.005, 1.464, 1.4489999999999998, 1.438, 1.454, 1.373, -0.501, 1.4300000000000002, 1.434, 1.4180000000000001, 1.452, 0.5, 1.455, 1.451, 1.467, 1.431, 1.4489999999999998, 0.499, 1.3399999999999999, 0.499, 1.4569999999999999, 1.4649999999999999, 1.479, 1.458, 1.438, 0.499, 0.497, 1.452, 1.444, -0.503, 0.499, 1.452, -1.001, 0.5, 1.4329999999999998, 0.5, 1.458, 0.498, 0.498, 1.399, 1.4489999999999998, -0.502, 1.448, 1.4249999999999998, 1.432, 1.4609999999999999, 1.454, 1.424, 1.313, 0.498, 1.4300000000000002, 1.298, 0.967, 1.431, 1.438, -1.001, -0.502, 0.5, -0.001, 1.452, 1.408, 1.4180000000000001, 1.434, 0.499, -0.001, -1.0, 1.4369999999999998, 1.4489999999999998, 1.4489999999999998, 0.587, 1.4180000000000001, 1.458, 1.4140000000000001, 0.869, 0.499, 1.413, 1.4489999999999998, 1.4449999999999998, 1.396, 1.4489999999999998, 1.342, 1.4220000000000002, 0.499, 1.4020000000000001, 1.446, 1.435, -0.005, -1.002, 1.284, 0.5, 0.498, 1.4180000000000001], "policy_blue_0_reward": [-0.001, -1.0, 0.497, -0.001, 0.498, -0.5, -0.007, 1.3940000000000001, -1.003, 0.495, 1.42, 0.498, 0.498, -0.504, 0.907, 0.498, 0.0, -0.001, -0.003, 0.493, -1.002, 0.495, 0.499, 0.474, 0.497, 1.383, 0.498, 1.436, 1.448, -0.501, 0.497, 0.494, -0.002, 0.498, -0.505, 0.497, 0.498, -0.003, 0.496, 0.472, 0.9339999999999999, 0.958, -0.502, 0.912, 0.942, 0.498, 0.0, 1.404, -0.501, 0.498, 0.5, -0.001, -0.502, 1.448, 0.499, 0.495, 0.499, -0.5019999999999999, 1.458, -0.001, 0.499, -1.001, 0.499, 0.499, 1.4409999999999998, -1.001, 1.44, 0.5, -0.501, -0.5, 0.496, -0.002, 1.409, 1.4, -0.002, 0.499, 1.435, 1.442, -0.503, 0.905, 1.443, -0.001, 1.447, 0.499, 1.448, 1.419, 0.497, 0.0, 1.4369999999999998, 0.497, -1.002, 0.498, 0.499, 0.499, 0.498, -0.502, 1.455, -0.004, 0.491, -1.001, 0.496, 0.498, 0.876, 0.949, 1.415, 1.435, -0.002, 0.495, 0.499, -0.501, 1.4449999999999998, 1.395, 1.444, -0.001, 0.499, 0.497, -0.513, 0.498, -0.001, -0.007, -0.5079999999999999, 1.4060000000000001, 0.499, -0.001, 0.499, 0.498, 0.0, -1.006, -0.506, 1.411, 0.498, 0.497, -0.002, 1.4489999999999998, 1.427, 0.49, 1.446, 1.421, 0.498]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4037561620015573, "mean_inference_ms": 7.436873200185817, "mean_action_processing_ms": 0.3894980011914989, "mean_env_wait_ms": 0.5194674238426437, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.154659645162898, "StateBufferConnector_ms": 0.009483570675198123, "ViewRequirementAgentConnector_ms": 0.19268046180121332}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 792000, "num_agent_steps_trained": 792000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.73600898633583, "num_env_steps_trained_throughput_per_sec": 129.73600898633583, "timesteps_total": 396000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 792000, "timers": {"training_iteration_time_ms": 30986.22, "sample_time_ms": 4007.212, "learn_time_ms": 26951.282, "learn_throughput": 148.416, "synch_weights_time_ms": 26.178}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 792000, "num_agent_steps_trained": 792000}, "done": false, "episodes_total": 6633, "training_iteration": 99, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-49-30", "timestamp": 1694839770, "time_this_iter_s": 30.851649045944214, "time_total_s": 3080.516644716263, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21980160>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3080.516644716263, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 25.33555555555556, "ram_util_percent": 56.86666666666667}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5597014925373134, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.16417910447761194, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11194029850746269, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.16417910447761194, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.15671641791044777, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.11194029850746269, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.16417910447761194, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11194029850746269, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5864808082270125, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04246678737108596, "policy_loss": -0.08893052213194702, "vf_loss": 0.04029702180899524, "vf_explained_var": 0.6774363977213701, "kl": 0.012051715649525618, "entropy": 1.1400915329655013, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 95520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6021482229543229, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05780071023812828, "policy_loss": -0.10303075876436196, "vf_loss": 0.038310089589989126, "vf_explained_var": 0.5666690625871221, "kl": 0.012086069236132802, "entropy": 1.4585732000569502, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 95520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "sampler_results": {"episode_reward_max": 1.96, "episode_reward_min": -0.07099999999999995, "episode_reward_mean": 1.420492537313433, "episode_len_mean": 27.08955223880597, "episode_media": {}, "episodes_this_iter": 134, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.006}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 0.9842761194029851, "blue_0": 0.4362164179104478}, "custom_metrics": {"red_0/door_open_done_mean": 0.5597014925373134, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.16417910447761194, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11194029850746269, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.16417910447761194, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.15671641791044777, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.11194029850746269, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.16417910447761194, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11194029850746269, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9129999999999999, 1.95, 0.44799999999999995, 0.41400000000000015, 0.42700000000000005, 1.932, 0.961, 1.939, 0.44799999999999995, 1.916, 1.9329999999999998, 1.448, 1.421, 1.413, 1.459, 0.44199999999999995, 0.901, 1.383, 0.43099999999999994, 1.3279999999999998, 0.44099999999999984, 0.4630000000000001, 1.959, 1.846, 1.9060000000000001, 1.9329999999999998, 1.436, 1.907, 0.9590000000000001, 1.9529999999999998, 0.45699999999999985, 1.943, 0.474, 1.944, -0.05600000000000005, 1.9130000000000003, 1.94, 1.458, 1.952, 0.891, 1.943, 1.446, 0.8730000000000002, 1.892, 1.939, 0.47, 1.416, 1.9369999999999998, 1.432, 0.44999999999999996, 1.946, 1.952, 1.488, 1.435, 0.7889999999999999, 1.925, -0.050999999999999934, 0.45999999999999996, 1.9140000000000001, 1.947, 1.876, 1.435, 0.9550000000000001, 0.47, 1.4529999999999998, 1.944, 1.923, 1.917, 0.8089999999999999, 1.764, 1.954, 0.9249999999999999, 1.9569999999999999, 0.8980000000000001, 1.928, 0.43699999999999983, 1.934, 0.43000000000000005, 1.954, 1.939, 1.934, 1.4449999999999998, 1.4329999999999998, 1.4569999999999999, 0.931, 1.4369999999999998, 0.45299999999999996, 1.9369999999999998, 1.954, 1.908, 1.439, -0.04500000000000004, 1.427, 1.923, 1.4289999999999998, 1.899, -0.07099999999999995, 1.849, 1.917, 1.4529999999999998, 1.942, 1.926, 1.952, 1.942, 0.44899999999999984, 1.9569999999999999, 1.927, 1.9010000000000002, 1.955, 0.9569999999999999, 1.952, 1.452, 1.426, 1.917, 1.915, 1.438, 1.3860000000000001, 1.8980000000000001, 1.895, 1.454, 1.946, 1.943, 1.4369999999999998, 1.7189999999999999, 1.4329999999999998, 0.969, 1.96, 1.9329999999999998, 1.861, 1.9569999999999999, -0.05600000000000005, 1.9569999999999999, 0.3879999999999999, 1.4180000000000001], "episode_lengths": [300, 16, 17, 26, 21, 22, 13, 20, 15, 28, 21, 17, 23, 27, 13, 19, 32, 39, 21, 205, 19, 12, 13, 47, 29, 21, 21, 30, 13, 15, 13, 18, 8, 18, 18, 28, 19, 14, 16, 34, 18, 17, 40, 33, 20, 10, 27, 20, 22, 15, 17, 15, 159, 21, 65, 23, 16, 13, 27, 17, 39, 21, 14, 10, 15, 18, 25, 26, 55, 75, 15, 22, 14, 33, 23, 19, 21, 23, 15, 20, 21, 17, 21, 14, 22, 20, 14, 20, 15, 29, 19, 14, 23, 25, 22, 32, 23, 48, 26, 15, 19, 24, 15, 19, 17, 14, 23, 29, 15, 14, 15, 15, 24, 27, 26, 20, 35, 32, 33, 15, 18, 18, 20, 87, 21, 10, 13, 21, 44, 14, 18, 14, 35, 27], "policy_red_0_reward": [0.44299999999999995, 1.451, -1.0, 1.42, 0.9319999999999999, 0.5, -0.5, 1.44, -1.003, 1.416, 1.435, 1.4489999999999998, 1.428, -0.004, 1.4609999999999999, 1.442, -0.5, 1.383, -1.002, 0.859, 0.942, 1.463, 1.4609999999999999, 0.491, 1.411, 1.436, 1.4369999999999998, 0.498, 1.4609999999999999, 1.455, 1.46, 1.4449999999999998, 0.975, 1.446, 0.946, 1.416, 1.443, 1.458, 0.5, 1.395, 0.498, 1.4489999999999998, 1.379, 0.495, 1.439, 0.97, 1.419, 1.439, 1.434, -1.002, 1.4489999999999998, 0.498, 0.9989999999999999, -0.001, 1.297, 1.429, -1.001, -0.5, 0.497, 1.448, 1.381, 1.4369999999999998, 1.4569999999999999, 1.47, 1.455, 1.446, 0.499, 1.42, -0.51, 1.271, 1.454, -0.501, 1.458, 1.4, 1.431, 1.442, 1.436, -1.0, 1.455, 1.44, 0.498, 1.448, 1.434, 1.458, 1.432, 1.439, -0.502, 1.439, 0.5, 1.409, 1.443, 0.957, -0.002, 0.5, 1.4329999999999998, 0.499, -1.001, 0.495, 1.4220000000000002, 1.455, 1.443, 1.428, 1.455, 1.443, 1.4489999999999998, 1.458, 1.4300000000000002, 1.409, 0.5, 1.4569999999999999, 1.454, -0.002, 1.427, 1.417, 1.421, 1.438, 1.389, 1.4020000000000001, 1.396, 1.455, 1.446, 1.4449999999999998, 1.438, 0.489, -0.003, -0.5, 1.4609999999999999, 1.436, 1.366, 1.458, -1.001, 1.458, 1.391, 1.419], "policy_blue_0_reward": [0.47, 0.499, 1.448, -1.006, -0.505, 1.432, 1.4609999999999999, 0.499, 1.451, 0.5, 0.498, -0.001, -0.007, 1.417, -0.002, -1.0, 1.401, 0.0, 1.4329999999999998, 0.469, -0.501, -1.0, 0.498, 1.355, 0.495, 0.497, -0.001, 1.409, -0.502, 0.498, -1.003, 0.498, -0.501, 0.498, -1.002, 0.497, 0.497, 0.0, 1.452, -0.504, 1.4449999999999998, -0.003, -0.5059999999999999, 1.397, 0.5, -0.5, -0.003, 0.498, -0.002, 1.452, 0.497, 1.454, 0.489, 1.436, -0.508, 0.496, 0.95, 0.96, 1.417, 0.499, 0.495, -0.002, -0.502, -1.0, -0.002, 0.498, 1.424, 0.497, 1.319, 0.493, 0.5, 1.426, 0.499, -0.502, 0.497, -1.005, 0.498, 1.4300000000000002, 0.499, 0.499, 1.436, -0.003, -0.001, -0.001, -0.501, -0.002, 0.955, 0.498, 1.454, 0.499, -0.004, -1.002, 1.429, 1.423, -0.004, 1.4, 0.93, 1.354, 0.495, -0.002, 0.499, 0.498, 0.497, 0.499, -1.0, 0.499, 0.497, 0.492, 1.455, -0.5, 0.498, 1.454, -0.001, 0.5, 0.494, 0.0, -0.003, 0.496, 0.499, -0.001, 0.5, 0.498, -0.001, 1.23, 1.436, 1.4689999999999999, 0.499, 0.497, 0.495, 0.499, 0.945, 0.499, -1.003, -0.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4075011305692775, "mean_inference_ms": 7.434260661317491, "mean_action_processing_ms": 0.38894111050633157, "mean_env_wait_ms": 0.5200891327413785, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15339602285356663, "StateBufferConnector_ms": 0.010233227886370759, "ViewRequirementAgentConnector_ms": 0.20244859937411636}}, "episode_reward_max": 1.96, "episode_reward_min": -0.07099999999999995, "episode_reward_mean": 1.420492537313433, "episode_len_mean": 27.08955223880597, "episodes_this_iter": 134, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.006}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 0.9842761194029851, "blue_0": 0.4362164179104478}, "hist_stats": {"episode_reward": [0.9129999999999999, 1.95, 0.44799999999999995, 0.41400000000000015, 0.42700000000000005, 1.932, 0.961, 1.939, 0.44799999999999995, 1.916, 1.9329999999999998, 1.448, 1.421, 1.413, 1.459, 0.44199999999999995, 0.901, 1.383, 0.43099999999999994, 1.3279999999999998, 0.44099999999999984, 0.4630000000000001, 1.959, 1.846, 1.9060000000000001, 1.9329999999999998, 1.436, 1.907, 0.9590000000000001, 1.9529999999999998, 0.45699999999999985, 1.943, 0.474, 1.944, -0.05600000000000005, 1.9130000000000003, 1.94, 1.458, 1.952, 0.891, 1.943, 1.446, 0.8730000000000002, 1.892, 1.939, 0.47, 1.416, 1.9369999999999998, 1.432, 0.44999999999999996, 1.946, 1.952, 1.488, 1.435, 0.7889999999999999, 1.925, -0.050999999999999934, 0.45999999999999996, 1.9140000000000001, 1.947, 1.876, 1.435, 0.9550000000000001, 0.47, 1.4529999999999998, 1.944, 1.923, 1.917, 0.8089999999999999, 1.764, 1.954, 0.9249999999999999, 1.9569999999999999, 0.8980000000000001, 1.928, 0.43699999999999983, 1.934, 0.43000000000000005, 1.954, 1.939, 1.934, 1.4449999999999998, 1.4329999999999998, 1.4569999999999999, 0.931, 1.4369999999999998, 0.45299999999999996, 1.9369999999999998, 1.954, 1.908, 1.439, -0.04500000000000004, 1.427, 1.923, 1.4289999999999998, 1.899, -0.07099999999999995, 1.849, 1.917, 1.4529999999999998, 1.942, 1.926, 1.952, 1.942, 0.44899999999999984, 1.9569999999999999, 1.927, 1.9010000000000002, 1.955, 0.9569999999999999, 1.952, 1.452, 1.426, 1.917, 1.915, 1.438, 1.3860000000000001, 1.8980000000000001, 1.895, 1.454, 1.946, 1.943, 1.4369999999999998, 1.7189999999999999, 1.4329999999999998, 0.969, 1.96, 1.9329999999999998, 1.861, 1.9569999999999999, -0.05600000000000005, 1.9569999999999999, 0.3879999999999999, 1.4180000000000001], "episode_lengths": [300, 16, 17, 26, 21, 22, 13, 20, 15, 28, 21, 17, 23, 27, 13, 19, 32, 39, 21, 205, 19, 12, 13, 47, 29, 21, 21, 30, 13, 15, 13, 18, 8, 18, 18, 28, 19, 14, 16, 34, 18, 17, 40, 33, 20, 10, 27, 20, 22, 15, 17, 15, 159, 21, 65, 23, 16, 13, 27, 17, 39, 21, 14, 10, 15, 18, 25, 26, 55, 75, 15, 22, 14, 33, 23, 19, 21, 23, 15, 20, 21, 17, 21, 14, 22, 20, 14, 20, 15, 29, 19, 14, 23, 25, 22, 32, 23, 48, 26, 15, 19, 24, 15, 19, 17, 14, 23, 29, 15, 14, 15, 15, 24, 27, 26, 20, 35, 32, 33, 15, 18, 18, 20, 87, 21, 10, 13, 21, 44, 14, 18, 14, 35, 27], "policy_red_0_reward": [0.44299999999999995, 1.451, -1.0, 1.42, 0.9319999999999999, 0.5, -0.5, 1.44, -1.003, 1.416, 1.435, 1.4489999999999998, 1.428, -0.004, 1.4609999999999999, 1.442, -0.5, 1.383, -1.002, 0.859, 0.942, 1.463, 1.4609999999999999, 0.491, 1.411, 1.436, 1.4369999999999998, 0.498, 1.4609999999999999, 1.455, 1.46, 1.4449999999999998, 0.975, 1.446, 0.946, 1.416, 1.443, 1.458, 0.5, 1.395, 0.498, 1.4489999999999998, 1.379, 0.495, 1.439, 0.97, 1.419, 1.439, 1.434, -1.002, 1.4489999999999998, 0.498, 0.9989999999999999, -0.001, 1.297, 1.429, -1.001, -0.5, 0.497, 1.448, 1.381, 1.4369999999999998, 1.4569999999999999, 1.47, 1.455, 1.446, 0.499, 1.42, -0.51, 1.271, 1.454, -0.501, 1.458, 1.4, 1.431, 1.442, 1.436, -1.0, 1.455, 1.44, 0.498, 1.448, 1.434, 1.458, 1.432, 1.439, -0.502, 1.439, 0.5, 1.409, 1.443, 0.957, -0.002, 0.5, 1.4329999999999998, 0.499, -1.001, 0.495, 1.4220000000000002, 1.455, 1.443, 1.428, 1.455, 1.443, 1.4489999999999998, 1.458, 1.4300000000000002, 1.409, 0.5, 1.4569999999999999, 1.454, -0.002, 1.427, 1.417, 1.421, 1.438, 1.389, 1.4020000000000001, 1.396, 1.455, 1.446, 1.4449999999999998, 1.438, 0.489, -0.003, -0.5, 1.4609999999999999, 1.436, 1.366, 1.458, -1.001, 1.458, 1.391, 1.419], "policy_blue_0_reward": [0.47, 0.499, 1.448, -1.006, -0.505, 1.432, 1.4609999999999999, 0.499, 1.451, 0.5, 0.498, -0.001, -0.007, 1.417, -0.002, -1.0, 1.401, 0.0, 1.4329999999999998, 0.469, -0.501, -1.0, 0.498, 1.355, 0.495, 0.497, -0.001, 1.409, -0.502, 0.498, -1.003, 0.498, -0.501, 0.498, -1.002, 0.497, 0.497, 0.0, 1.452, -0.504, 1.4449999999999998, -0.003, -0.5059999999999999, 1.397, 0.5, -0.5, -0.003, 0.498, -0.002, 1.452, 0.497, 1.454, 0.489, 1.436, -0.508, 0.496, 0.95, 0.96, 1.417, 0.499, 0.495, -0.002, -0.502, -1.0, -0.002, 0.498, 1.424, 0.497, 1.319, 0.493, 0.5, 1.426, 0.499, -0.502, 0.497, -1.005, 0.498, 1.4300000000000002, 0.499, 0.499, 1.436, -0.003, -0.001, -0.001, -0.501, -0.002, 0.955, 0.498, 1.454, 0.499, -0.004, -1.002, 1.429, 1.423, -0.004, 1.4, 0.93, 1.354, 0.495, -0.002, 0.499, 0.498, 0.497, 0.499, -1.0, 0.499, 0.497, 0.492, 1.455, -0.5, 0.498, 1.454, -0.001, 0.5, 0.494, 0.0, -0.003, 0.496, 0.499, -0.001, 0.5, 0.498, -0.001, 1.23, 1.436, 1.4689999999999999, 0.499, 0.497, 0.495, 0.499, 0.945, 0.499, -1.003, -0.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4075011305692775, "mean_inference_ms": 7.434260661317491, "mean_action_processing_ms": 0.38894111050633157, "mean_env_wait_ms": 0.5200891327413785, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15339602285356663, "StateBufferConnector_ms": 0.010233227886370759, "ViewRequirementAgentConnector_ms": 0.20244859937411636}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 126.75962948252757, "num_env_steps_trained_throughput_per_sec": 126.75962948252757, "timesteps_total": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 31134.218, "sample_time_ms": 4055.961, "learn_time_ms": 27050.618, "learn_throughput": 147.871, "synch_weights_time_ms": 26.111}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "episodes_total": 6767, "training_iteration": 100, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-50-03", "timestamp": 1694839803, "time_this_iter_s": 31.573636770248413, "time_total_s": 3112.0902814865112, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219867a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3112.0902814865112, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 25.18913043478261, "ram_util_percent": 56.99130434782609}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5112781954887218, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.24060150375939848, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11278195488721804, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.24060150375939848, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11278195488721804, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.11278195488721804, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.24060150375939848, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11278195488721804, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5728121713114281, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.041345548283910225, "policy_loss": -0.08485033850059456, "vf_loss": 0.03879428915582442, "vf_explained_var": 0.68659082322071, "kl": 0.01109267218723744, "entropy": 1.1628490678345165, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 96480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.570260026678443, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05200722394608116, "policy_loss": -0.09757638394852014, "vf_loss": 0.04227877916321934, "vf_explained_var": 0.5468667312835653, "kl": 0.01136982902401388, "entropy": 1.4721222000817458, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 96480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 808000, "num_agent_steps_trained": 808000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.396, "episode_reward_mean": 1.314330827067669, "episode_len_mean": 32.54887218045113, "episode_media": {}, "episodes_this_iter": 133, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 1.012781954887218, "blue_0": 0.3015488721804511}, "custom_metrics": {"red_0/door_open_done_mean": 0.5112781954887218, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.24060150375939848, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11278195488721804, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.24060150375939848, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11278195488721804, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.11278195488721804, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.24060150375939848, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11278195488721804, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.94, 1.951, 1.44, 0.8879999999999999, 1.9220000000000002, 0.45299999999999996, 1.447, 1.9449999999999998, 0.45199999999999996, 1.9409999999999998, 0.42099999999999993, 1.9460000000000002, 1.905, 1.938, 1.447, 1.924, 1.948, 1.9080000000000001, 1.926, 1.351, 1.436, 1.959, -0.07400000000000007, 1.9489999999999998, 1.87, 1.445, 1.923, 1.9489999999999998, 1.913, 1.942, 0.44799999999999995, 0.958, 1.44, 1.9609999999999999, 1.939, 1.8599999999999999, 0.9529999999999998, 1.755, 1.444, 0.4630000000000001, 1.96, 1.95, 0.866, 1.025, 1.928, 1.947, 1.3770000000000002, 1.939, 1.9460000000000002, 1.446, 1.9449999999999998, 0.42700000000000005, 0.9689999999999999, 1.45, 1.96, 0.97, 1.9609999999999999, 1.935, 0.4500000000000002, -0.04200000000000004, 0.959, 1.895, 1.9249999999999998, 1.919, 1.946, -0.027000000000000024, 1.8239999999999998, 1.938, 1.904, 1.432, 1.943, 1.951, 1.953, 1.9409999999999998, 1.947, 0.9750000000000001, 1.4489999999999998, 0.44700000000000006, 0.46199999999999997, -0.03300000000000003, -0.08799999999999986, 0.4710000000000001, 0.9729999999999999, 1.95, 1.955, 1.946, 0.45499999999999996, 1.9369999999999998, 1.4569999999999999, 1.4449999999999998, 0.9100000000000001, 0.04999999999999982, 1.452, 0.895, 0.41200000000000014, 1.4080000000000001, 1.456, 0.967, 0.966, 1.947, 0.9449999999999998, 1.917, -0.396, 0.46899999999999986, 1.748, -0.15899999999999992, 1.931, 1.932, 0.45100000000000007, 1.92, 0.895, 1.46, 0.4710000000000001, 0.4149999999999999, 0.45199999999999996, 1.9, 1.924, 1.947, -0.15300000000000002, 0.42399999999999993, -0.07000000000000006, 0.47, 0.9489999999999998, 0.42500000000000004, 1.3439999999999999, 1.427, 0.45100000000000007, 1.915, 0.972, 1.888, 1.905, 1.951, 0.937], "episode_lengths": [300, 15, 20, 36, 25, 15, 17, 18, 15, 19, 300, 17, 29, 20, 17, 24, 17, 30, 24, 47, 20, 13, 24, 16, 41, 17, 24, 16, 27, 19, 17, 14, 20, 13, 20, 42, 15, 77, 18, 12, 13, 16, 39, 276, 23, 17, 40, 20, 17, 17, 17, 22, 10, 16, 13, 10, 13, 20, 16, 13, 13, 33, 24, 26, 17, 9, 55, 19, 29, 21, 18, 16, 14, 19, 17, 8, 16, 17, 12, 11, 27, 9, 9, 16, 15, 17, 15, 20, 14, 17, 29, 140, 15, 34, 28, 28, 14, 11, 11, 16, 18, 27, 281, 10, 79, 48, 22, 22, 15, 25, 32, 13, 9, 300, 15, 32, 24, 17, 45, 24, 21, 10, 15, 23, 47, 23, 16, 27, 9, 36, 31, 16, 20], "policy_red_0_reward": [0.46699999999999997, 1.454, 1.44, 1.3900000000000001, 1.425, -0.501, 1.448, 1.4449999999999998, -1.001, 1.443, 0.45699999999999996, 1.448, 0.495, 1.439, 1.447, 1.427, 1.4489999999999998, 1.409, 1.427, 1.3559999999999999, 1.438, 1.4609999999999999, -1.0, 1.452, 1.373, 1.448, 1.428, 1.451, 1.419, 1.443, 1.4489999999999998, -0.5, 1.44, 1.4609999999999999, 0.5, 1.365, 1.454, 1.264, 1.4449999999999998, 1.463, 1.4609999999999999, 0.499, -0.508, 0.5569999999999998, 1.4300000000000002, 0.499, 1.3780000000000001, 1.44, 1.4489999999999998, 1.4489999999999998, 1.4489999999999998, 1.432, 1.47, -0.002, 0.499, 1.47, 0.5, 0.497, 0.952, 0.96, -0.5, 1.397, 0.499, 1.42, 1.4489999999999998, 0.973, 1.327, 1.442, 1.413, 1.4329999999999998, 1.446, 1.452, 1.458, 1.442, 1.4489999999999998, -0.5009999999999999, 1.451, 1.4489999999999998, 1.463, 0.967, -1.002, 1.4729999999999999, 1.4729999999999999, 0.499, 1.455, 1.4489999999999998, -0.5, 1.439, 1.4569999999999999, 1.448, 1.411, 1.0659999999999998, 1.455, -0.5, 0.915, 1.4140000000000001, 1.458, -0.5, -0.501, 1.451, 1.446, 0.5, 0.136, 1.47, 1.251, -1.005, 1.4329999999999998, 1.4329999999999998, 1.454, 0.498, -0.503, 1.4609999999999999, 0.972, 0.45299999999999996, 1.455, 0.497, 1.4249999999999998, 1.4489999999999998, 0.856, -0.5, 0.9329999999999999, 0.97, 1.451, 0.927, 1.349, 1.4300000000000002, 1.452, 1.419, 1.4729999999999999, 1.389, 0.499, 0.499, 1.44], "policy_blue_0_reward": [0.473, 0.497, 0.0, -0.502, 0.497, 0.954, -0.001, 0.5, 1.4529999999999998, 0.498, -0.036000000000000025, 0.498, 1.4100000000000001, 0.499, 0.0, 0.497, 0.499, 0.499, 0.499, -0.005, -0.002, 0.498, 0.9259999999999999, 0.497, 0.497, -0.003, 0.495, 0.498, 0.494, 0.499, -1.001, 1.458, 0.0, 0.5, 1.439, 0.495, -0.501, 0.491, -0.001, -1.0, 0.499, 1.451, 1.374, 0.46799999999999997, 0.498, 1.448, -0.001, 0.499, 0.497, -0.003, 0.496, -1.005, -0.501, 1.452, 1.4609999999999999, -0.5, 1.4609999999999999, 1.438, -0.5019999999999999, -1.002, 1.459, 0.498, 1.426, 0.499, 0.497, -1.0, 0.497, 0.496, 0.491, -0.001, 0.497, 0.499, 0.495, 0.499, 0.498, 1.476, -0.002, -1.002, -1.001, -1.0, 0.914, -1.002, -0.5, 1.451, 0.5, 0.497, 0.955, 0.498, 0.0, -0.003, -0.501, -1.016, -0.003, 1.395, -0.5029999999999999, -0.006, -0.002, 1.467, 1.467, 0.496, -0.501, 1.417, -0.532, -1.001, 0.497, 0.846, 0.498, 0.499, -1.003, 1.4220000000000002, 1.3980000000000001, -0.001, -0.501, -0.03800000000000003, -1.003, 1.403, 0.499, 0.498, -1.009, 0.9239999999999999, -1.003, -0.5, -0.502, -0.502, -0.005, -0.003, -1.001, 0.496, -0.501, 0.499, 1.4060000000000001, 1.452, -0.5029999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4076909602026166, "mean_inference_ms": 7.448249543589085, "mean_action_processing_ms": 0.3902524019121416, "mean_env_wait_ms": 0.5206467523579378, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15158680148590775, "StateBufferConnector_ms": 0.010422118624350182, "ViewRequirementAgentConnector_ms": 0.19583110522506827}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.396, "episode_reward_mean": 1.314330827067669, "episode_len_mean": 32.54887218045113, "episodes_this_iter": 133, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 1.012781954887218, "blue_0": 0.3015488721804511}, "hist_stats": {"episode_reward": [0.94, 1.951, 1.44, 0.8879999999999999, 1.9220000000000002, 0.45299999999999996, 1.447, 1.9449999999999998, 0.45199999999999996, 1.9409999999999998, 0.42099999999999993, 1.9460000000000002, 1.905, 1.938, 1.447, 1.924, 1.948, 1.9080000000000001, 1.926, 1.351, 1.436, 1.959, -0.07400000000000007, 1.9489999999999998, 1.87, 1.445, 1.923, 1.9489999999999998, 1.913, 1.942, 0.44799999999999995, 0.958, 1.44, 1.9609999999999999, 1.939, 1.8599999999999999, 0.9529999999999998, 1.755, 1.444, 0.4630000000000001, 1.96, 1.95, 0.866, 1.025, 1.928, 1.947, 1.3770000000000002, 1.939, 1.9460000000000002, 1.446, 1.9449999999999998, 0.42700000000000005, 0.9689999999999999, 1.45, 1.96, 0.97, 1.9609999999999999, 1.935, 0.4500000000000002, -0.04200000000000004, 0.959, 1.895, 1.9249999999999998, 1.919, 1.946, -0.027000000000000024, 1.8239999999999998, 1.938, 1.904, 1.432, 1.943, 1.951, 1.953, 1.9409999999999998, 1.947, 0.9750000000000001, 1.4489999999999998, 0.44700000000000006, 0.46199999999999997, -0.03300000000000003, -0.08799999999999986, 0.4710000000000001, 0.9729999999999999, 1.95, 1.955, 1.946, 0.45499999999999996, 1.9369999999999998, 1.4569999999999999, 1.4449999999999998, 0.9100000000000001, 0.04999999999999982, 1.452, 0.895, 0.41200000000000014, 1.4080000000000001, 1.456, 0.967, 0.966, 1.947, 0.9449999999999998, 1.917, -0.396, 0.46899999999999986, 1.748, -0.15899999999999992, 1.931, 1.932, 0.45100000000000007, 1.92, 0.895, 1.46, 0.4710000000000001, 0.4149999999999999, 0.45199999999999996, 1.9, 1.924, 1.947, -0.15300000000000002, 0.42399999999999993, -0.07000000000000006, 0.47, 0.9489999999999998, 0.42500000000000004, 1.3439999999999999, 1.427, 0.45100000000000007, 1.915, 0.972, 1.888, 1.905, 1.951, 0.937], "episode_lengths": [300, 15, 20, 36, 25, 15, 17, 18, 15, 19, 300, 17, 29, 20, 17, 24, 17, 30, 24, 47, 20, 13, 24, 16, 41, 17, 24, 16, 27, 19, 17, 14, 20, 13, 20, 42, 15, 77, 18, 12, 13, 16, 39, 276, 23, 17, 40, 20, 17, 17, 17, 22, 10, 16, 13, 10, 13, 20, 16, 13, 13, 33, 24, 26, 17, 9, 55, 19, 29, 21, 18, 16, 14, 19, 17, 8, 16, 17, 12, 11, 27, 9, 9, 16, 15, 17, 15, 20, 14, 17, 29, 140, 15, 34, 28, 28, 14, 11, 11, 16, 18, 27, 281, 10, 79, 48, 22, 22, 15, 25, 32, 13, 9, 300, 15, 32, 24, 17, 45, 24, 21, 10, 15, 23, 47, 23, 16, 27, 9, 36, 31, 16, 20], "policy_red_0_reward": [0.46699999999999997, 1.454, 1.44, 1.3900000000000001, 1.425, -0.501, 1.448, 1.4449999999999998, -1.001, 1.443, 0.45699999999999996, 1.448, 0.495, 1.439, 1.447, 1.427, 1.4489999999999998, 1.409, 1.427, 1.3559999999999999, 1.438, 1.4609999999999999, -1.0, 1.452, 1.373, 1.448, 1.428, 1.451, 1.419, 1.443, 1.4489999999999998, -0.5, 1.44, 1.4609999999999999, 0.5, 1.365, 1.454, 1.264, 1.4449999999999998, 1.463, 1.4609999999999999, 0.499, -0.508, 0.5569999999999998, 1.4300000000000002, 0.499, 1.3780000000000001, 1.44, 1.4489999999999998, 1.4489999999999998, 1.4489999999999998, 1.432, 1.47, -0.002, 0.499, 1.47, 0.5, 0.497, 0.952, 0.96, -0.5, 1.397, 0.499, 1.42, 1.4489999999999998, 0.973, 1.327, 1.442, 1.413, 1.4329999999999998, 1.446, 1.452, 1.458, 1.442, 1.4489999999999998, -0.5009999999999999, 1.451, 1.4489999999999998, 1.463, 0.967, -1.002, 1.4729999999999999, 1.4729999999999999, 0.499, 1.455, 1.4489999999999998, -0.5, 1.439, 1.4569999999999999, 1.448, 1.411, 1.0659999999999998, 1.455, -0.5, 0.915, 1.4140000000000001, 1.458, -0.5, -0.501, 1.451, 1.446, 0.5, 0.136, 1.47, 1.251, -1.005, 1.4329999999999998, 1.4329999999999998, 1.454, 0.498, -0.503, 1.4609999999999999, 0.972, 0.45299999999999996, 1.455, 0.497, 1.4249999999999998, 1.4489999999999998, 0.856, -0.5, 0.9329999999999999, 0.97, 1.451, 0.927, 1.349, 1.4300000000000002, 1.452, 1.419, 1.4729999999999999, 1.389, 0.499, 0.499, 1.44], "policy_blue_0_reward": [0.473, 0.497, 0.0, -0.502, 0.497, 0.954, -0.001, 0.5, 1.4529999999999998, 0.498, -0.036000000000000025, 0.498, 1.4100000000000001, 0.499, 0.0, 0.497, 0.499, 0.499, 0.499, -0.005, -0.002, 0.498, 0.9259999999999999, 0.497, 0.497, -0.003, 0.495, 0.498, 0.494, 0.499, -1.001, 1.458, 0.0, 0.5, 1.439, 0.495, -0.501, 0.491, -0.001, -1.0, 0.499, 1.451, 1.374, 0.46799999999999997, 0.498, 1.448, -0.001, 0.499, 0.497, -0.003, 0.496, -1.005, -0.501, 1.452, 1.4609999999999999, -0.5, 1.4609999999999999, 1.438, -0.5019999999999999, -1.002, 1.459, 0.498, 1.426, 0.499, 0.497, -1.0, 0.497, 0.496, 0.491, -0.001, 0.497, 0.499, 0.495, 0.499, 0.498, 1.476, -0.002, -1.002, -1.001, -1.0, 0.914, -1.002, -0.5, 1.451, 0.5, 0.497, 0.955, 0.498, 0.0, -0.003, -0.501, -1.016, -0.003, 1.395, -0.5029999999999999, -0.006, -0.002, 1.467, 1.467, 0.496, -0.501, 1.417, -0.532, -1.001, 0.497, 0.846, 0.498, 0.499, -1.003, 1.4220000000000002, 1.3980000000000001, -0.001, -0.501, -0.03800000000000003, -1.003, 1.403, 0.499, 0.498, -1.009, 0.9239999999999999, -1.003, -0.5, -0.502, -0.502, -0.005, -0.003, -1.001, 0.496, -0.501, 0.499, 1.4060000000000001, 1.452, -0.5029999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4076909602026166, "mean_inference_ms": 7.448249543589085, "mean_action_processing_ms": 0.3902524019121416, "mean_env_wait_ms": 0.5206467523579378, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15158680148590775, "StateBufferConnector_ms": 0.010422118624350182, "ViewRequirementAgentConnector_ms": 0.19583110522506827}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 808000, "num_agent_steps_trained": 808000, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 112.9301780350919, "num_env_steps_trained_throughput_per_sec": 112.9301780350919, "timesteps_total": 404000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 808000, "timers": {"training_iteration_time_ms": 31449.147, "sample_time_ms": 4055.733, "learn_time_ms": 27365.79, "learn_throughput": 146.168, "synch_weights_time_ms": 26.082}, "counters": {"num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 808000, "num_agent_steps_trained": 808000}, "done": false, "episodes_total": 6900, "training_iteration": 101, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-50-39", "timestamp": 1694839839, "time_this_iter_s": 35.44305610656738, "time_total_s": 3147.5333375930786, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21983ac0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3147.5333375930786, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 33.400000000000006, "ram_util_percent": 57.035294117647055}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5921052631578947, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.17763157894736842, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07894736842105263, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.17763157894736842, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13815789473684212, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.07894736842105263, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.17763157894736842, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07894736842105263, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.553847206911693, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0401701664183444, "policy_loss": -0.08393871022854, "vf_loss": 0.0371346651527953, "vf_explained_var": 0.6960563169171413, "kl": 0.011527202068100451, "entropy": 1.059196247967581, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 97440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5786652742885053, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.050474995852952516, "policy_loss": -0.0964575343488832, "vf_loss": 0.04080150118485714, "vf_explained_var": 0.5440982734784484, "kl": 0.011855620542648163, "entropy": 1.4267978474497796, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 97440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "sampler_results": {"episode_reward_max": 1.959, "episode_reward_min": -0.123, "episode_reward_mean": 1.4673355263157895, "episode_len_mean": 24.44078947368421, "episode_media": {}, "episodes_this_iter": 152, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.008}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 1.0800986842105265, "blue_0": 0.38723684210526316}, "custom_metrics": {"red_0/door_open_done_mean": 0.5921052631578947, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.17763157894736842, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07894736842105263, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.17763157894736842, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13815789473684212, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.07894736842105263, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.17763157894736842, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07894736842105263, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.938, 1.9, 1.939, 0.9489999999999998, 0.949, 1.915, 1.95, 0.46599999999999997, 1.9500000000000002, 1.9020000000000001, 1.943, 0.44899999999999984, -0.123, 0.97, -0.03700000000000003, 1.9260000000000002, 0.46199999999999997, -0.04400000000000004, 1.9260000000000002, 1.94, 1.913, 0.41700000000000004, 1.936, 0.95, 1.947, 0.46599999999999997, 1.95, 1.948, 1.439, 1.959, 1.883, 0.473, 1.412, 1.9369999999999998, 0.942, 1.954, 1.954, 1.944, 1.935, 1.9489999999999998, 1.95, 1.899, 1.8860000000000001, 1.424, -0.03200000000000003, 1.9100000000000001, 1.9369999999999998, 0.42899999999999994, 1.9289999999999998, 1.432, 1.928, 1.955, 1.458, 1.94, 0.875, 1.9060000000000001, 1.943, 0.9649999999999999, 1.946, 1.9300000000000002, 0.4630000000000001, 1.9409999999999998, 1.439, 0.46499999999999986, 1.939, 1.9220000000000002, 1.9020000000000001, 0.42600000000000005, 1.951, 0.44200000000000017, 1.9569999999999999, 1.956, 0.9430000000000001, 1.946, 1.9449999999999998, 0.943, 1.938, 1.447, 1.436, 1.8319999999999999, 0.973, 1.944, 1.439, 1.4369999999999998, 1.921, 1.927, 1.942, 1.948, 1.866, 1.926, 1.936, 0.46099999999999985, 0.43399999999999994, 1.95, 0.37, 1.939, 1.403, 0.4630000000000001, 1.915, 1.9329999999999998, 1.387, 1.4569999999999999, 1.951, 1.9300000000000002, 1.9409999999999998, 0.44300000000000006, 0.4630000000000001, 1.946, 0.45199999999999996, -0.04500000000000004, 1.897, 1.9220000000000002, 1.957, -0.04200000000000004, 1.425, 1.951, 1.4060000000000001, 1.909, 1.951, 1.9449999999999998, 1.9180000000000001, 1.928, 1.9369999999999998, 1.4409999999999998, 0.30100000000000016, 1.9449999999999998, 1.412, 0.4750000000000001, 1.454, 1.955, 1.936, 1.913, 0.46699999999999997, 1.43, 1.948, 1.454, 1.942, 1.927, 0.9529999999999998, 1.4409999999999998, 1.9489999999999998, 1.887, 1.916, 1.947, 1.948, 0.47699999999999987, 1.44, 0.43799999999999994, 1.431, 0.238, 1.9409999999999998, 1.452], "episode_lengths": [19, 30, 20, 16, 16, 27, 16, 11, 16, 31, 19, 16, 37, 10, 11, 23, 12, 14, 23, 20, 27, 26, 21, 16, 17, 10, 16, 17, 20, 13, 37, 9, 28, 20, 19, 15, 15, 18, 21, 17, 16, 33, 35, 24, 10, 29, 20, 300, 21, 22, 23, 15, 14, 19, 40, 29, 18, 11, 17, 23, 12, 19, 20, 11, 19, 23, 31, 23, 16, 17, 14, 14, 18, 18, 17, 18, 20, 17, 20, 53, 9, 18, 19, 20, 25, 23, 19, 17, 43, 22, 20, 13, 21, 16, 41, 20, 31, 12, 27, 22, 36, 14, 16, 23, 19, 18, 11, 17, 16, 15, 33, 25, 13, 12, 23, 16, 29, 29, 15, 18, 26, 23, 20, 18, 62, 17, 27, 8, 15, 15, 21, 27, 11, 22, 17, 14, 18, 23, 15, 18, 16, 36, 26, 17, 17, 7, 19, 300, 20, 82, 19, 15], "policy_red_0_reward": [1.44, 0.497, 1.44, 1.451, -0.501, 1.416, 1.452, 1.467, 1.452, 0.498, 0.5, 1.451, 0.882, 1.47, 0.966, 1.4300000000000002, 1.464, 0.958, 1.4300000000000002, 1.44, 1.416, 1.419, 1.4369999999999998, 1.451, 1.4489999999999998, 0.968, 0.499, 0.5, -0.001, 1.4609999999999999, 1.3860000000000001, -0.5, 1.416, 1.44, 1.442, 1.455, 1.455, 1.446, 0.499, 1.4489999999999998, 1.451, 0.499, 0.495, 1.426, -1.001, 1.4100000000000001, 1.44, -0.04000000000000003, 1.435, 1.4329999999999998, 0.5, 1.455, 0.0, 1.443, -0.502, 1.4100000000000001, 1.446, 1.466, 1.448, 1.431, 1.464, 1.442, 1.44, 0.965, 1.44, 1.4300000000000002, 1.4060000000000001, -0.503, 1.452, 1.448, 1.458, 1.4569999999999999, 1.4449999999999998, 1.446, 1.447, -0.503, 1.44, 1.4489999999999998, 1.439, 1.337, -0.5, 1.4449999999999998, 1.442, 1.439, 1.4220000000000002, 0.498, 1.443, 1.4489999999999998, 1.369, 0.496, 1.4369999999999998, 0.961, -1.001, 1.452, -0.504, 1.44, 1.404, 1.464, 1.4180000000000001, 1.4329999999999998, 1.391, 1.458, 1.452, 1.431, 1.443, 1.446, 1.466, 1.4489999999999998, 1.452, 0.955, 1.399, 0.498, 1.4609999999999999, -1.001, 1.428, 0.499, 1.412, 1.411, 1.455, 1.4449999999999998, 1.42, 0.499, 1.44, -0.004, 1.3090000000000002, 0.498, 1.4140000000000001, 0.976, 1.454, 1.455, 1.436, 1.417, -0.5, 1.434, 1.4489999999999998, 1.458, 1.4449999999999998, 0.498, 1.455, -0.003, 1.452, 1.389, 1.4220000000000002, 0.498, 1.4489999999999998, 0.978, 1.442, -0.025000000000000015, 1.4369999999999998, -1.005, 1.443, 1.454], "policy_blue_0_reward": [0.498, 1.403, 0.499, -0.502, 1.45, 0.499, 0.498, -1.001, 0.498, 1.404, 1.443, -1.002, -1.005, -0.5, -1.003, 0.496, -1.002, -1.002, 0.496, 0.5, 0.497, -1.002, 0.499, -0.501, 0.498, -0.502, 1.451, 1.448, 1.44, 0.498, 0.497, 0.973, -0.004, 0.497, -0.5, 0.499, 0.499, 0.498, 1.436, 0.5, 0.499, 1.4, 1.391, -0.002, 0.969, 0.5, 0.497, 0.469, 0.494, -0.001, 1.428, 0.5, 1.458, 0.497, 1.377, 0.496, 0.497, -0.501, 0.498, 0.499, -1.001, 0.499, -0.001, -0.5, 0.499, 0.492, 0.496, 0.929, 0.499, -1.0059999999999998, 0.499, 0.499, -0.502, 0.5, 0.498, 1.446, 0.498, -0.002, -0.003, 0.495, 1.4729999999999999, 0.499, -0.003, -0.002, 0.499, 1.429, 0.499, 0.499, 0.497, 1.43, 0.499, -0.5, 1.435, 0.498, 0.874, 0.499, -0.001, -1.001, 0.497, 0.5, -0.004, -0.001, 0.499, 0.499, 0.498, -1.003, -1.003, 0.497, -1.0, -1.0, 0.498, 1.424, 0.496, 0.959, -0.003, 1.452, -0.006, 0.498, 0.496, 0.5, 0.498, 1.429, 0.497, 1.4449999999999998, -1.008, 1.447, -0.002, -0.5009999999999999, 0.0, 0.5, 0.5, 0.496, 0.967, -0.004, 0.499, -0.004, 0.497, 1.429, -0.502, 1.444, 0.497, 0.498, 0.494, 1.4489999999999998, 0.499, -0.501, -0.002, 0.46299999999999997, -0.006, 1.2429999999999999, 0.498, -0.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4080130545882767, "mean_inference_ms": 7.445330584599079, "mean_action_processing_ms": 0.3899777786675798, "mean_env_wait_ms": 0.5199459809348911, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.16110374739295558, "StateBufferConnector_ms": 0.010764520419271369, "ViewRequirementAgentConnector_ms": 0.22176088471161692}}, "episode_reward_max": 1.959, "episode_reward_min": -0.123, "episode_reward_mean": 1.4673355263157895, "episode_len_mean": 24.44078947368421, "episodes_this_iter": 152, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.008}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 1.0800986842105265, "blue_0": 0.38723684210526316}, "hist_stats": {"episode_reward": [1.938, 1.9, 1.939, 0.9489999999999998, 0.949, 1.915, 1.95, 0.46599999999999997, 1.9500000000000002, 1.9020000000000001, 1.943, 0.44899999999999984, -0.123, 0.97, -0.03700000000000003, 1.9260000000000002, 0.46199999999999997, -0.04400000000000004, 1.9260000000000002, 1.94, 1.913, 0.41700000000000004, 1.936, 0.95, 1.947, 0.46599999999999997, 1.95, 1.948, 1.439, 1.959, 1.883, 0.473, 1.412, 1.9369999999999998, 0.942, 1.954, 1.954, 1.944, 1.935, 1.9489999999999998, 1.95, 1.899, 1.8860000000000001, 1.424, -0.03200000000000003, 1.9100000000000001, 1.9369999999999998, 0.42899999999999994, 1.9289999999999998, 1.432, 1.928, 1.955, 1.458, 1.94, 0.875, 1.9060000000000001, 1.943, 0.9649999999999999, 1.946, 1.9300000000000002, 0.4630000000000001, 1.9409999999999998, 1.439, 0.46499999999999986, 1.939, 1.9220000000000002, 1.9020000000000001, 0.42600000000000005, 1.951, 0.44200000000000017, 1.9569999999999999, 1.956, 0.9430000000000001, 1.946, 1.9449999999999998, 0.943, 1.938, 1.447, 1.436, 1.8319999999999999, 0.973, 1.944, 1.439, 1.4369999999999998, 1.921, 1.927, 1.942, 1.948, 1.866, 1.926, 1.936, 0.46099999999999985, 0.43399999999999994, 1.95, 0.37, 1.939, 1.403, 0.4630000000000001, 1.915, 1.9329999999999998, 1.387, 1.4569999999999999, 1.951, 1.9300000000000002, 1.9409999999999998, 0.44300000000000006, 0.4630000000000001, 1.946, 0.45199999999999996, -0.04500000000000004, 1.897, 1.9220000000000002, 1.957, -0.04200000000000004, 1.425, 1.951, 1.4060000000000001, 1.909, 1.951, 1.9449999999999998, 1.9180000000000001, 1.928, 1.9369999999999998, 1.4409999999999998, 0.30100000000000016, 1.9449999999999998, 1.412, 0.4750000000000001, 1.454, 1.955, 1.936, 1.913, 0.46699999999999997, 1.43, 1.948, 1.454, 1.942, 1.927, 0.9529999999999998, 1.4409999999999998, 1.9489999999999998, 1.887, 1.916, 1.947, 1.948, 0.47699999999999987, 1.44, 0.43799999999999994, 1.431, 0.238, 1.9409999999999998, 1.452], "episode_lengths": [19, 30, 20, 16, 16, 27, 16, 11, 16, 31, 19, 16, 37, 10, 11, 23, 12, 14, 23, 20, 27, 26, 21, 16, 17, 10, 16, 17, 20, 13, 37, 9, 28, 20, 19, 15, 15, 18, 21, 17, 16, 33, 35, 24, 10, 29, 20, 300, 21, 22, 23, 15, 14, 19, 40, 29, 18, 11, 17, 23, 12, 19, 20, 11, 19, 23, 31, 23, 16, 17, 14, 14, 18, 18, 17, 18, 20, 17, 20, 53, 9, 18, 19, 20, 25, 23, 19, 17, 43, 22, 20, 13, 21, 16, 41, 20, 31, 12, 27, 22, 36, 14, 16, 23, 19, 18, 11, 17, 16, 15, 33, 25, 13, 12, 23, 16, 29, 29, 15, 18, 26, 23, 20, 18, 62, 17, 27, 8, 15, 15, 21, 27, 11, 22, 17, 14, 18, 23, 15, 18, 16, 36, 26, 17, 17, 7, 19, 300, 20, 82, 19, 15], "policy_red_0_reward": [1.44, 0.497, 1.44, 1.451, -0.501, 1.416, 1.452, 1.467, 1.452, 0.498, 0.5, 1.451, 0.882, 1.47, 0.966, 1.4300000000000002, 1.464, 0.958, 1.4300000000000002, 1.44, 1.416, 1.419, 1.4369999999999998, 1.451, 1.4489999999999998, 0.968, 0.499, 0.5, -0.001, 1.4609999999999999, 1.3860000000000001, -0.5, 1.416, 1.44, 1.442, 1.455, 1.455, 1.446, 0.499, 1.4489999999999998, 1.451, 0.499, 0.495, 1.426, -1.001, 1.4100000000000001, 1.44, -0.04000000000000003, 1.435, 1.4329999999999998, 0.5, 1.455, 0.0, 1.443, -0.502, 1.4100000000000001, 1.446, 1.466, 1.448, 1.431, 1.464, 1.442, 1.44, 0.965, 1.44, 1.4300000000000002, 1.4060000000000001, -0.503, 1.452, 1.448, 1.458, 1.4569999999999999, 1.4449999999999998, 1.446, 1.447, -0.503, 1.44, 1.4489999999999998, 1.439, 1.337, -0.5, 1.4449999999999998, 1.442, 1.439, 1.4220000000000002, 0.498, 1.443, 1.4489999999999998, 1.369, 0.496, 1.4369999999999998, 0.961, -1.001, 1.452, -0.504, 1.44, 1.404, 1.464, 1.4180000000000001, 1.4329999999999998, 1.391, 1.458, 1.452, 1.431, 1.443, 1.446, 1.466, 1.4489999999999998, 1.452, 0.955, 1.399, 0.498, 1.4609999999999999, -1.001, 1.428, 0.499, 1.412, 1.411, 1.455, 1.4449999999999998, 1.42, 0.499, 1.44, -0.004, 1.3090000000000002, 0.498, 1.4140000000000001, 0.976, 1.454, 1.455, 1.436, 1.417, -0.5, 1.434, 1.4489999999999998, 1.458, 1.4449999999999998, 0.498, 1.455, -0.003, 1.452, 1.389, 1.4220000000000002, 0.498, 1.4489999999999998, 0.978, 1.442, -0.025000000000000015, 1.4369999999999998, -1.005, 1.443, 1.454], "policy_blue_0_reward": [0.498, 1.403, 0.499, -0.502, 1.45, 0.499, 0.498, -1.001, 0.498, 1.404, 1.443, -1.002, -1.005, -0.5, -1.003, 0.496, -1.002, -1.002, 0.496, 0.5, 0.497, -1.002, 0.499, -0.501, 0.498, -0.502, 1.451, 1.448, 1.44, 0.498, 0.497, 0.973, -0.004, 0.497, -0.5, 0.499, 0.499, 0.498, 1.436, 0.5, 0.499, 1.4, 1.391, -0.002, 0.969, 0.5, 0.497, 0.469, 0.494, -0.001, 1.428, 0.5, 1.458, 0.497, 1.377, 0.496, 0.497, -0.501, 0.498, 0.499, -1.001, 0.499, -0.001, -0.5, 0.499, 0.492, 0.496, 0.929, 0.499, -1.0059999999999998, 0.499, 0.499, -0.502, 0.5, 0.498, 1.446, 0.498, -0.002, -0.003, 0.495, 1.4729999999999999, 0.499, -0.003, -0.002, 0.499, 1.429, 0.499, 0.499, 0.497, 1.43, 0.499, -0.5, 1.435, 0.498, 0.874, 0.499, -0.001, -1.001, 0.497, 0.5, -0.004, -0.001, 0.499, 0.499, 0.498, -1.003, -1.003, 0.497, -1.0, -1.0, 0.498, 1.424, 0.496, 0.959, -0.003, 1.452, -0.006, 0.498, 0.496, 0.5, 0.498, 1.429, 0.497, 1.4449999999999998, -1.008, 1.447, -0.002, -0.5009999999999999, 0.0, 0.5, 0.5, 0.496, 0.967, -0.004, 0.499, -0.004, 0.497, 1.429, -0.502, 1.444, 0.497, 0.498, 0.494, 1.4489999999999998, 0.499, -0.501, -0.002, 0.46299999999999997, -0.006, 1.2429999999999999, 0.498, -0.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4080130545882767, "mean_inference_ms": 7.445330584599079, "mean_action_processing_ms": 0.3899777786675798, "mean_env_wait_ms": 0.5199459809348911, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.16110374739295558, "StateBufferConnector_ms": 0.010764520419271369, "ViewRequirementAgentConnector_ms": 0.22176088471161692}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 125.28970490864435, "num_env_steps_trained_throughput_per_sec": 125.28970490864435, "timesteps_total": 408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 31568.898, "sample_time_ms": 4120.647, "learn_time_ms": 27420.612, "learn_throughput": 145.876, "synch_weights_time_ms": 26.112}, "counters": {"num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "episodes_total": 7052, "training_iteration": 102, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-51-12", "timestamp": 1694839872, "time_this_iter_s": 31.94518232345581, "time_total_s": 3179.4785199165344, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21987d00>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3179.4785199165344, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 25.80851063829787, "ram_util_percent": 57.03191489361702}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5733333333333334, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.15333333333333332, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09333333333333334, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.15333333333333332, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09333333333333334, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.15333333333333332, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09333333333333334, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6000652947152655, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04416386457839205, "policy_loss": -0.09084539991987792, "vf_loss": 0.03652877342052913, "vf_explained_var": 0.6938673810412487, "kl": 0.012940767516649935, "entropy": 1.0635383101801077, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 98400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5947113975572089, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.057392176950331004, "policy_loss": -0.10407632188289426, "vf_loss": 0.04028798961468662, "vf_explained_var": 0.5641390112539132, "kl": 0.012282617081678401, "entropy": 1.4411873761564493, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 98400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 824000, "num_agent_steps_trained": 824000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.10399999999999998, "episode_reward_mean": 1.4564933333333332, "episode_len_mean": 30.686666666666667, "episode_media": {}, "episodes_this_iter": 150, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.464}, "policy_reward_mean": {"red_0": 1.0192333333333332, "blue_0": 0.43726}, "custom_metrics": {"red_0/door_open_done_mean": 0.5733333333333334, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.15333333333333332, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09333333333333334, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.15333333333333332, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09333333333333334, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.15333333333333332, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09333333333333334, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.42199999999999993, 1.859, 0.43299999999999983, 1.855, 1.938, -0.07299999999999995, 1.413, 1.927, 1.942, 1.95, 1.948, 1.409, 1.955, 1.424, 1.4460000000000002, 1.428, 1.948, 0.96, 1.96, 0.43399999999999994, 1.952, 1.9529999999999998, 0.9569999999999999, 0.954, 0.44299999999999995, 1.901, 1.9060000000000001, 1.415, 1.9329999999999998, 1.948, 1.419, 1.443, 1.932, 0.958, 1.903, 1.42, 1.2690000000000001, 1.455, 0.3729999999999999, 1.432, 1.2479999999999998, -0.04999999999999993, 0.43900000000000006, 1.934, 1.9529999999999998, 1.958, 1.458, 0.905, 0.41900000000000004, 1.955, 1.954, 1.877, 1.9369999999999998, 1.946, 1.8860000000000001, 1.851, 1.9529999999999998, 0.45699999999999996, 1.904, 0.8500000000000001, 1.944, 1.442, 1.95, 1.954, 1.9449999999999998, 1.951, 0.945, 1.9369999999999998, -0.10399999999999998, 1.8900000000000001, 0.44799999999999995, 0.472, 0.4570000000000001, -0.04899999999999993, 1.451, 0.46899999999999986, 0.9569999999999999, 1.9210000000000003, 1.444, 0.908, 1.892, 1.951, 1.451, 1.945, 0.41100000000000003, 1.837, 1.931, 1.958, 1.954, 1.904, 1.9369999999999998, 1.454, 1.9329999999999998, 1.9369999999999998, 1.419, 0.4590000000000001, 1.913, 0.46899999999999986, 0.9430000000000001, 1.8719999999999999, 1.943, 0.919, 1.9409999999999998, 1.95, 1.4449999999999998, 0.46599999999999997, 1.773, 1.944, 1.885, 1.958, 1.9449999999999998, 1.399, 0.9309999999999999, 1.452, 1.92, 1.912, -0.025000000000000022, 1.92, 1.954, 0.45799999999999996, -0.05499999999999994, -0.04399999999999993, 1.958, 1.946, 1.934, 1.9569999999999999, 1.9369999999999998, 1.908, 1.663, 1.893, 0.46199999999999997, 0.962, 1.458, -0.06000000000000005, 1.644, 1.9500000000000002, 1.4249999999999998, 1.9489999999999998, 1.682, 1.9209999999999998, 0.365, 1.948, 1.834, 1.927, 1.8050000000000002, 1.9580000000000002, 1.948, 1.9140000000000001, 1.9609999999999999, 1.954], "episode_lengths": [300, 44, 21, 45, 20, 23, 27, 23, 19, 16, 16, 28, 15, 23, 16, 23, 16, 13, 13, 21, 16, 15, 13, 14, 18, 31, 30, 27, 21, 17, 25, 18, 22, 13, 31, 24, 75, 14, 300, 21, 224, 15, 19, 21, 15, 13, 14, 27, 26, 14, 15, 40, 20, 17, 36, 47, 15, 300, 31, 46, 18, 18, 16, 15, 18, 16, 17, 21, 32, 36, 17, 9, 14, 16, 15, 10, 14, 25, 17, 27, 35, 15, 16, 18, 27, 53, 21, 14, 15, 31, 20, 15, 21, 21, 25, 13, 28, 10, 19, 40, 18, 25, 19, 16, 17, 11, 73, 18, 35, 14, 17, 31, 22, 15, 26, 28, 8, 26, 15, 14, 17, 13, 14, 17, 21, 14, 19, 28, 105, 33, 12, 12, 14, 19, 112, 16, 24, 16, 100, 24, 42, 17, 51, 23, 58, 13, 16, 27, 13, 15], "policy_red_0_reward": [0.44599999999999995, 0.496, 0.9349999999999999, 0.496, 1.439, 0.931, 1.4180000000000001, 0.496, 1.443, 0.499, 1.452, -0.002, 0.5, 1.4300000000000002, 1.451, 1.428, 1.452, -0.5, 1.4609999999999999, -0.5, 1.452, 1.454, 1.4609999999999999, -0.501, -0.502, 1.404, 0.499, 1.4180000000000001, 1.436, 0.5, 1.425, 1.4449999999999998, 0.499, -0.5, 0.498, 1.427, 1.2730000000000001, 1.4569999999999999, 0.3949999999999999, 1.436, 0.7839999999999999, -1.002, 0.942, 1.435, 1.455, 1.4609999999999999, 1.458, 1.411, -1.001, 1.4569999999999999, 1.455, 0.499, 1.439, 1.447, 1.3900000000000001, 1.357, 1.455, 0.484, 1.407, 1.3559999999999999, 0.5, 1.446, 1.452, 1.454, 1.446, 1.452, -0.502, 1.4369999999999998, 0.9, 1.3900000000000001, -0.5, 0.973, 0.958, -1.0, 1.455, 1.4689999999999999, 1.458, 1.425, 1.4489999999999998, -0.504, 1.3940000000000001, 1.454, 1.451, 1.446, -0.506, 0.5, 1.436, 0.5, 1.455, 0.499, 1.44, 1.455, 1.435, 1.4369999999999998, -0.003, 1.4609999999999999, 1.415, 1.47, 1.443, 1.375, 1.4449999999999998, 1.421, 1.4409999999999998, 1.452, -0.003, 1.467, 1.2759999999999998, 0.5, 1.3900000000000001, 1.458, 0.499, 1.404, -0.501, 1.455, 1.421, 1.4140000000000001, 0.976, 1.4220000000000002, 1.455, 1.458, 0.947, 0.959, 1.458, 1.4489999999999998, 1.435, 1.458, 0.498, 1.415, 0.49, 1.4, 0.963, -0.502, 1.458, 0.941, 1.157, 1.452, 1.427, 0.497, 1.194, 1.424, 1.37, 1.4489999999999998, 1.3439999999999999, 1.4300000000000002, 0.483, 1.4609999999999999, 1.45, 1.416, 1.4609999999999999, 0.5], "policy_blue_0_reward": [-0.024000000000000014, 1.363, -0.502, 1.359, 0.499, -1.004, -0.005, 1.431, 0.499, 1.451, 0.496, 1.411, 1.455, -0.006, -0.005, 0.0, 0.496, 1.46, 0.499, 0.9339999999999999, 0.5, 0.499, -0.504, 1.455, 0.945, 0.497, 1.407, -0.003, 0.497, 1.448, -0.006, -0.002, 1.4329999999999998, 1.458, 1.405, -0.007, -0.004, -0.002, -0.022000000000000013, -0.004, 0.46399999999999997, 0.952, -0.503, 0.499, 0.498, 0.497, 0.0, -0.506, 1.42, 0.498, 0.499, 1.3780000000000001, 0.498, 0.499, 0.496, 0.494, 0.498, -0.027000000000000017, 0.497, -0.5059999999999999, 1.444, -0.004, 0.498, 0.5, 0.499, 0.499, 1.447, 0.5, -1.004, 0.5, 0.948, -0.5009999999999999, -0.5009999999999999, 0.951, -0.004, -1.0, -0.501, 0.496, -0.005, 1.412, 0.498, 0.497, 0.0, 0.499, 0.917, 1.337, 0.495, 1.458, 0.499, 1.405, 0.497, -0.001, 0.498, 0.5, 1.4220000000000002, -1.002, 0.498, -1.001, -0.5, 0.497, 0.498, -0.502, 0.5, 0.498, 1.448, -1.001, 0.497, 1.444, 0.495, 0.5, 1.446, -0.005, 1.432, -0.003, 0.499, 0.498, -1.001, 0.498, 0.499, -1.0, -1.0019999999999998, -1.003, 0.5, 0.497, 0.499, 0.499, 1.439, 0.493, 1.173, 0.493, -0.501, 1.464, 0.0, -1.001, 0.487, 0.498, -0.002, 1.452, 0.488, 0.497, -1.005, 0.499, 0.49, 0.497, 1.322, 0.497, 0.498, 0.498, 0.5, 1.454]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4111987318625006, "mean_inference_ms": 7.439472876334788, "mean_action_processing_ms": 0.39071144072431574, "mean_env_wait_ms": 0.5206468961499708, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1432489554087321, "StateBufferConnector_ms": 0.009464104970296225, "ViewRequirementAgentConnector_ms": 0.18927979469299316}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.10399999999999998, "episode_reward_mean": 1.4564933333333332, "episode_len_mean": 30.686666666666667, "episodes_this_iter": 150, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.464}, "policy_reward_mean": {"red_0": 1.0192333333333332, "blue_0": 0.43726}, "hist_stats": {"episode_reward": [0.42199999999999993, 1.859, 0.43299999999999983, 1.855, 1.938, -0.07299999999999995, 1.413, 1.927, 1.942, 1.95, 1.948, 1.409, 1.955, 1.424, 1.4460000000000002, 1.428, 1.948, 0.96, 1.96, 0.43399999999999994, 1.952, 1.9529999999999998, 0.9569999999999999, 0.954, 0.44299999999999995, 1.901, 1.9060000000000001, 1.415, 1.9329999999999998, 1.948, 1.419, 1.443, 1.932, 0.958, 1.903, 1.42, 1.2690000000000001, 1.455, 0.3729999999999999, 1.432, 1.2479999999999998, -0.04999999999999993, 0.43900000000000006, 1.934, 1.9529999999999998, 1.958, 1.458, 0.905, 0.41900000000000004, 1.955, 1.954, 1.877, 1.9369999999999998, 1.946, 1.8860000000000001, 1.851, 1.9529999999999998, 0.45699999999999996, 1.904, 0.8500000000000001, 1.944, 1.442, 1.95, 1.954, 1.9449999999999998, 1.951, 0.945, 1.9369999999999998, -0.10399999999999998, 1.8900000000000001, 0.44799999999999995, 0.472, 0.4570000000000001, -0.04899999999999993, 1.451, 0.46899999999999986, 0.9569999999999999, 1.9210000000000003, 1.444, 0.908, 1.892, 1.951, 1.451, 1.945, 0.41100000000000003, 1.837, 1.931, 1.958, 1.954, 1.904, 1.9369999999999998, 1.454, 1.9329999999999998, 1.9369999999999998, 1.419, 0.4590000000000001, 1.913, 0.46899999999999986, 0.9430000000000001, 1.8719999999999999, 1.943, 0.919, 1.9409999999999998, 1.95, 1.4449999999999998, 0.46599999999999997, 1.773, 1.944, 1.885, 1.958, 1.9449999999999998, 1.399, 0.9309999999999999, 1.452, 1.92, 1.912, -0.025000000000000022, 1.92, 1.954, 0.45799999999999996, -0.05499999999999994, -0.04399999999999993, 1.958, 1.946, 1.934, 1.9569999999999999, 1.9369999999999998, 1.908, 1.663, 1.893, 0.46199999999999997, 0.962, 1.458, -0.06000000000000005, 1.644, 1.9500000000000002, 1.4249999999999998, 1.9489999999999998, 1.682, 1.9209999999999998, 0.365, 1.948, 1.834, 1.927, 1.8050000000000002, 1.9580000000000002, 1.948, 1.9140000000000001, 1.9609999999999999, 1.954], "episode_lengths": [300, 44, 21, 45, 20, 23, 27, 23, 19, 16, 16, 28, 15, 23, 16, 23, 16, 13, 13, 21, 16, 15, 13, 14, 18, 31, 30, 27, 21, 17, 25, 18, 22, 13, 31, 24, 75, 14, 300, 21, 224, 15, 19, 21, 15, 13, 14, 27, 26, 14, 15, 40, 20, 17, 36, 47, 15, 300, 31, 46, 18, 18, 16, 15, 18, 16, 17, 21, 32, 36, 17, 9, 14, 16, 15, 10, 14, 25, 17, 27, 35, 15, 16, 18, 27, 53, 21, 14, 15, 31, 20, 15, 21, 21, 25, 13, 28, 10, 19, 40, 18, 25, 19, 16, 17, 11, 73, 18, 35, 14, 17, 31, 22, 15, 26, 28, 8, 26, 15, 14, 17, 13, 14, 17, 21, 14, 19, 28, 105, 33, 12, 12, 14, 19, 112, 16, 24, 16, 100, 24, 42, 17, 51, 23, 58, 13, 16, 27, 13, 15], "policy_red_0_reward": [0.44599999999999995, 0.496, 0.9349999999999999, 0.496, 1.439, 0.931, 1.4180000000000001, 0.496, 1.443, 0.499, 1.452, -0.002, 0.5, 1.4300000000000002, 1.451, 1.428, 1.452, -0.5, 1.4609999999999999, -0.5, 1.452, 1.454, 1.4609999999999999, -0.501, -0.502, 1.404, 0.499, 1.4180000000000001, 1.436, 0.5, 1.425, 1.4449999999999998, 0.499, -0.5, 0.498, 1.427, 1.2730000000000001, 1.4569999999999999, 0.3949999999999999, 1.436, 0.7839999999999999, -1.002, 0.942, 1.435, 1.455, 1.4609999999999999, 1.458, 1.411, -1.001, 1.4569999999999999, 1.455, 0.499, 1.439, 1.447, 1.3900000000000001, 1.357, 1.455, 0.484, 1.407, 1.3559999999999999, 0.5, 1.446, 1.452, 1.454, 1.446, 1.452, -0.502, 1.4369999999999998, 0.9, 1.3900000000000001, -0.5, 0.973, 0.958, -1.0, 1.455, 1.4689999999999999, 1.458, 1.425, 1.4489999999999998, -0.504, 1.3940000000000001, 1.454, 1.451, 1.446, -0.506, 0.5, 1.436, 0.5, 1.455, 0.499, 1.44, 1.455, 1.435, 1.4369999999999998, -0.003, 1.4609999999999999, 1.415, 1.47, 1.443, 1.375, 1.4449999999999998, 1.421, 1.4409999999999998, 1.452, -0.003, 1.467, 1.2759999999999998, 0.5, 1.3900000000000001, 1.458, 0.499, 1.404, -0.501, 1.455, 1.421, 1.4140000000000001, 0.976, 1.4220000000000002, 1.455, 1.458, 0.947, 0.959, 1.458, 1.4489999999999998, 1.435, 1.458, 0.498, 1.415, 0.49, 1.4, 0.963, -0.502, 1.458, 0.941, 1.157, 1.452, 1.427, 0.497, 1.194, 1.424, 1.37, 1.4489999999999998, 1.3439999999999999, 1.4300000000000002, 0.483, 1.4609999999999999, 1.45, 1.416, 1.4609999999999999, 0.5], "policy_blue_0_reward": [-0.024000000000000014, 1.363, -0.502, 1.359, 0.499, -1.004, -0.005, 1.431, 0.499, 1.451, 0.496, 1.411, 1.455, -0.006, -0.005, 0.0, 0.496, 1.46, 0.499, 0.9339999999999999, 0.5, 0.499, -0.504, 1.455, 0.945, 0.497, 1.407, -0.003, 0.497, 1.448, -0.006, -0.002, 1.4329999999999998, 1.458, 1.405, -0.007, -0.004, -0.002, -0.022000000000000013, -0.004, 0.46399999999999997, 0.952, -0.503, 0.499, 0.498, 0.497, 0.0, -0.506, 1.42, 0.498, 0.499, 1.3780000000000001, 0.498, 0.499, 0.496, 0.494, 0.498, -0.027000000000000017, 0.497, -0.5059999999999999, 1.444, -0.004, 0.498, 0.5, 0.499, 0.499, 1.447, 0.5, -1.004, 0.5, 0.948, -0.5009999999999999, -0.5009999999999999, 0.951, -0.004, -1.0, -0.501, 0.496, -0.005, 1.412, 0.498, 0.497, 0.0, 0.499, 0.917, 1.337, 0.495, 1.458, 0.499, 1.405, 0.497, -0.001, 0.498, 0.5, 1.4220000000000002, -1.002, 0.498, -1.001, -0.5, 0.497, 0.498, -0.502, 0.5, 0.498, 1.448, -1.001, 0.497, 1.444, 0.495, 0.5, 1.446, -0.005, 1.432, -0.003, 0.499, 0.498, -1.001, 0.498, 0.499, -1.0, -1.0019999999999998, -1.003, 0.5, 0.497, 0.499, 0.499, 1.439, 0.493, 1.173, 0.493, -0.501, 1.464, 0.0, -1.001, 0.487, 0.498, -0.002, 1.452, 0.488, 0.497, -1.005, 0.499, 0.49, 0.497, 1.322, 0.497, 0.498, 0.498, 0.5, 1.454]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4111987318625006, "mean_inference_ms": 7.439472876334788, "mean_action_processing_ms": 0.39071144072431574, "mean_env_wait_ms": 0.5206468961499708, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1432489554087321, "StateBufferConnector_ms": 0.009464104970296225, "ViewRequirementAgentConnector_ms": 0.18927979469299316}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 824000, "num_agent_steps_trained": 824000, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 125.79290799557532, "num_env_steps_trained_throughput_per_sec": 125.79290799557532, "timesteps_total": 412000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 824000, "timers": {"training_iteration_time_ms": 31691.207, "sample_time_ms": 4122.463, "learn_time_ms": 27541.308, "learn_throughput": 145.236, "synch_weights_time_ms": 25.929}, "counters": {"num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 824000, "num_agent_steps_trained": 824000}, "done": false, "episodes_total": 7202, "training_iteration": 103, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-51-45", "timestamp": 1694839905, "time_this_iter_s": 31.818844079971313, "time_total_s": 3211.2973639965057, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21983400>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3211.2973639965057, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 26.4804347826087, "ram_util_percent": 57.147826086956485}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6299212598425197, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.10236220472440945, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08661417322834646, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.10236220472440945, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14960629921259844, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08661417322834646, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.10236220472440945, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08661417322834646, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5547846352681518, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03229621476105725, "policy_loss": -0.06890373165224446, "vf_loss": 0.02928774566098582, "vf_explained_var": 0.7501913777242104, "kl": 0.010121586964587417, "entropy": 1.0945963801195224, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 99360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5624038716157277, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05068081572050384, "policy_loss": -0.08712864341844882, "vf_loss": 0.027033364973613062, "vf_explained_var": 0.6062307673816879, "kl": 0.010711336250973062, "entropy": 1.4706183028717836, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 99360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.04799999999999993, "episode_reward_mean": 1.539527559055118, "episode_len_mean": 28.724409448818896, "episode_media": {}, "episodes_this_iter": 127, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.475}, "policy_reward_mean": {"red_0": 1.0451181102362206, "blue_0": 0.4944094488188976}, "custom_metrics": {"red_0/door_open_done_mean": 0.6299212598425197, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.10236220472440945, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08661417322834646, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.10236220472440945, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14960629921259844, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08661417322834646, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.10236220472440945, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08661417322834646, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.458, 1.943, 0.46899999999999986, 1.434, 1.8890000000000002, 1.952, 1.452, 1.959, 1.947, 1.954, 1.947, 1.4609999999999999, 1.942, 1.943, 1.9329999999999998, 1.413, 1.429, 1.9609999999999999, 1.944, 1.9569999999999999, 1.955, 1.46, 0.42099999999999993, 1.901, 1.927, 1.426, 1.9100000000000001, 0.45399999999999996, 1.9449999999999998, 0.9510000000000001, 1.438, 1.908, 1.442, 0.406, 1.931, -0.04799999999999993, 1.955, 1.959, 0.476, 1.954, 1.8980000000000001, 1.928, 0.972, 1.867, 1.908, -0.02200000000000002, 1.409, 1.459, 0.9319999999999999, 1.917, 1.893, 0.9590000000000001, 1.9569999999999999, 1.923, 1.956, 1.9209999999999998, 1.93, 1.9489999999999998, 1.9369999999999998, 1.9409999999999998, 1.946, 1.9449999999999998, 1.435, 1.9460000000000002, 1.94, 1.943, 1.399, 1.948, 1.4489999999999998, 0.969, 0.9449999999999998, 1.9609999999999999, 1.413, 1.4220000000000002, -0.040000000000000036, 1.903, 1.923, 1.395, 0.4169999999999999, 1.923, 1.923, 1.4289999999999998, 1.422, 1.9329999999999998, 1.95, 1.9569999999999999, 1.923, 1.942, 1.842, 1.944, 1.416, 0.42999999999999994, 1.939, 0.469, 0.954, 1.9289999999999998, 1.947, 1.942, 1.9569999999999999, 1.9609999999999999, 0.967, 1.944, 1.896, 0.961, 1.947, 0.975, 1.94, 0.43700000000000006, 0.44999999999999996, 0.905, 1.4489999999999998, 0.43799999999999994, 1.9489999999999998, 1.448, 1.3239999999999998, 1.9529999999999998, 1.939, 0.912, 1.9289999999999998, 0.41500000000000004, 1.95, 1.9340000000000002, -0.026999999999999913, 1.9449999999999998, 1.952, 1.4529999999999998, 1.952], "episode_lengths": [14, 18, 10, 20, 35, 16, 15, 13, 17, 15, 16, 13, 18, 18, 22, 27, 23, 13, 18, 14, 14, 13, 300, 31, 23, 24, 28, 14, 18, 16, 19, 30, 18, 29, 22, 15, 14, 13, 8, 15, 32, 23, 9, 42, 28, 7, 29, 13, 300, 27, 34, 13, 14, 25, 14, 24, 22, 16, 20, 18, 18, 18, 20, 17, 19, 19, 31, 17, 16, 10, 18, 13, 27, 25, 13, 30, 24, 32, 300, 25, 25, 22, 24, 21, 16, 14, 24, 19, 51, 18, 27, 21, 19, 10, 15, 22, 17, 18, 14, 13, 11, 18, 33, 300, 17, 8, 19, 20, 16, 30, 17, 19, 16, 17, 57, 15, 18, 27, 22, 27, 16, 21, 8, 18, 16, 15, 16], "policy_red_0_reward": [1.458, 1.446, 1.47, 1.4369999999999998, 1.393, 0.5, 1.455, 1.4609999999999999, 1.4489999999999998, 1.455, 1.452, 1.4609999999999999, 1.446, 1.4449999999999998, 0.499, 1.416, -0.001, 1.4609999999999999, 0.499, 1.458, 1.458, -0.001, 0.44699999999999995, 0.499, 1.429, 1.428, 1.415, -0.501, 1.446, 1.452, 1.442, 1.409, 1.446, -1.003, 1.4329999999999998, 0.954, 1.4569999999999999, 1.4609999999999999, 0.976, 1.455, 1.403, 1.431, 1.4729999999999999, 1.369, 0.498, 0.979, 1.411, 1.4609999999999999, 0.473, 1.4180000000000001, 1.396, 1.4609999999999999, 1.458, 1.425, 1.458, 0.497, 0.497, 1.45, 1.44, 1.444, 1.446, 0.5, 1.439, 1.4489999999999998, 1.442, 1.443, -0.004, 1.4489999999999998, 1.452, -0.5, 1.4449999999999998, 1.4609999999999999, 1.416, 1.425, 0.96, 1.4060000000000001, 1.426, 1.403, -0.036000000000000025, 1.424, 1.425, 1.434, 1.428, 1.434, 1.452, 1.458, 1.426, 0.499, 1.346, 0.499, 1.419, -1.004, 1.442, -0.5, 1.455, 1.434, 0.499, 1.444, 0.499, 1.4609999999999999, -0.5, 1.4449999999999998, 1.399, 0.486, 1.4489999999999998, -0.5, 0.499, 1.44, -1.0, 1.408, 1.4489999999999998, 0.94, 1.452, 1.4489999999999998, -0.003, 1.455, 1.444, -0.504, 1.4329999999999998, -0.501, 1.452, 1.4369999999999998, -1.0, 1.446, 0.5, 1.455, 0.5], "policy_blue_0_reward": [0.0, 0.497, -1.001, -0.003, 0.496, 1.452, -0.003, 0.498, 0.498, 0.499, 0.495, 0.0, 0.496, 0.498, 1.434, -0.003, 1.4300000000000002, 0.5, 1.4449999999999998, 0.499, 0.497, 1.4609999999999999, -0.026000000000000016, 1.4020000000000001, 0.498, -0.002, 0.495, 0.955, 0.499, -0.501, -0.004, 0.499, -0.004, 1.409, 0.498, -1.0019999999999998, 0.498, 0.498, -0.5, 0.499, 0.495, 0.497, -0.5009999999999999, 0.498, 1.4100000000000001, -1.001, -0.002, -0.002, 0.45899999999999996, 0.499, 0.497, -0.502, 0.499, 0.498, 0.498, 1.424, 1.4329999999999998, 0.499, 0.497, 0.497, 0.5, 1.4449999999999998, -0.004, 0.497, 0.498, 0.5, 1.403, 0.499, -0.003, 1.4689999999999999, -0.5, 0.5, -0.003, -0.003, -1.0, 0.497, 0.497, -0.008, 0.45299999999999996, 0.499, 0.498, -0.005, -0.006, 0.499, 0.498, 0.499, 0.497, 1.443, 0.496, 1.4449999999999998, -0.003, 1.434, 0.497, 0.969, -0.501, 0.495, 1.448, 0.498, 1.458, 0.5, 1.467, 0.499, 0.497, 0.475, 0.498, 1.475, 1.4409999999999998, -1.003, 1.45, -0.503, 0.0, -0.502, 0.497, -0.001, 1.327, 0.498, 0.495, 1.416, 0.496, 0.916, 0.498, 0.497, 0.973, 0.499, 1.452, -0.002, 1.452]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4120544959187218, "mean_inference_ms": 7.438581984875093, "mean_action_processing_ms": 0.3905489804623161, "mean_env_wait_ms": 0.5213807523552645, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14922299722986898, "StateBufferConnector_ms": 0.00980529259508989, "ViewRequirementAgentConnector_ms": 0.19096408303328385}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.04799999999999993, "episode_reward_mean": 1.539527559055118, "episode_len_mean": 28.724409448818896, "episodes_this_iter": 127, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.475}, "policy_reward_mean": {"red_0": 1.0451181102362206, "blue_0": 0.4944094488188976}, "hist_stats": {"episode_reward": [1.458, 1.943, 0.46899999999999986, 1.434, 1.8890000000000002, 1.952, 1.452, 1.959, 1.947, 1.954, 1.947, 1.4609999999999999, 1.942, 1.943, 1.9329999999999998, 1.413, 1.429, 1.9609999999999999, 1.944, 1.9569999999999999, 1.955, 1.46, 0.42099999999999993, 1.901, 1.927, 1.426, 1.9100000000000001, 0.45399999999999996, 1.9449999999999998, 0.9510000000000001, 1.438, 1.908, 1.442, 0.406, 1.931, -0.04799999999999993, 1.955, 1.959, 0.476, 1.954, 1.8980000000000001, 1.928, 0.972, 1.867, 1.908, -0.02200000000000002, 1.409, 1.459, 0.9319999999999999, 1.917, 1.893, 0.9590000000000001, 1.9569999999999999, 1.923, 1.956, 1.9209999999999998, 1.93, 1.9489999999999998, 1.9369999999999998, 1.9409999999999998, 1.946, 1.9449999999999998, 1.435, 1.9460000000000002, 1.94, 1.943, 1.399, 1.948, 1.4489999999999998, 0.969, 0.9449999999999998, 1.9609999999999999, 1.413, 1.4220000000000002, -0.040000000000000036, 1.903, 1.923, 1.395, 0.4169999999999999, 1.923, 1.923, 1.4289999999999998, 1.422, 1.9329999999999998, 1.95, 1.9569999999999999, 1.923, 1.942, 1.842, 1.944, 1.416, 0.42999999999999994, 1.939, 0.469, 0.954, 1.9289999999999998, 1.947, 1.942, 1.9569999999999999, 1.9609999999999999, 0.967, 1.944, 1.896, 0.961, 1.947, 0.975, 1.94, 0.43700000000000006, 0.44999999999999996, 0.905, 1.4489999999999998, 0.43799999999999994, 1.9489999999999998, 1.448, 1.3239999999999998, 1.9529999999999998, 1.939, 0.912, 1.9289999999999998, 0.41500000000000004, 1.95, 1.9340000000000002, -0.026999999999999913, 1.9449999999999998, 1.952, 1.4529999999999998, 1.952], "episode_lengths": [14, 18, 10, 20, 35, 16, 15, 13, 17, 15, 16, 13, 18, 18, 22, 27, 23, 13, 18, 14, 14, 13, 300, 31, 23, 24, 28, 14, 18, 16, 19, 30, 18, 29, 22, 15, 14, 13, 8, 15, 32, 23, 9, 42, 28, 7, 29, 13, 300, 27, 34, 13, 14, 25, 14, 24, 22, 16, 20, 18, 18, 18, 20, 17, 19, 19, 31, 17, 16, 10, 18, 13, 27, 25, 13, 30, 24, 32, 300, 25, 25, 22, 24, 21, 16, 14, 24, 19, 51, 18, 27, 21, 19, 10, 15, 22, 17, 18, 14, 13, 11, 18, 33, 300, 17, 8, 19, 20, 16, 30, 17, 19, 16, 17, 57, 15, 18, 27, 22, 27, 16, 21, 8, 18, 16, 15, 16], "policy_red_0_reward": [1.458, 1.446, 1.47, 1.4369999999999998, 1.393, 0.5, 1.455, 1.4609999999999999, 1.4489999999999998, 1.455, 1.452, 1.4609999999999999, 1.446, 1.4449999999999998, 0.499, 1.416, -0.001, 1.4609999999999999, 0.499, 1.458, 1.458, -0.001, 0.44699999999999995, 0.499, 1.429, 1.428, 1.415, -0.501, 1.446, 1.452, 1.442, 1.409, 1.446, -1.003, 1.4329999999999998, 0.954, 1.4569999999999999, 1.4609999999999999, 0.976, 1.455, 1.403, 1.431, 1.4729999999999999, 1.369, 0.498, 0.979, 1.411, 1.4609999999999999, 0.473, 1.4180000000000001, 1.396, 1.4609999999999999, 1.458, 1.425, 1.458, 0.497, 0.497, 1.45, 1.44, 1.444, 1.446, 0.5, 1.439, 1.4489999999999998, 1.442, 1.443, -0.004, 1.4489999999999998, 1.452, -0.5, 1.4449999999999998, 1.4609999999999999, 1.416, 1.425, 0.96, 1.4060000000000001, 1.426, 1.403, -0.036000000000000025, 1.424, 1.425, 1.434, 1.428, 1.434, 1.452, 1.458, 1.426, 0.499, 1.346, 0.499, 1.419, -1.004, 1.442, -0.5, 1.455, 1.434, 0.499, 1.444, 0.499, 1.4609999999999999, -0.5, 1.4449999999999998, 1.399, 0.486, 1.4489999999999998, -0.5, 0.499, 1.44, -1.0, 1.408, 1.4489999999999998, 0.94, 1.452, 1.4489999999999998, -0.003, 1.455, 1.444, -0.504, 1.4329999999999998, -0.501, 1.452, 1.4369999999999998, -1.0, 1.446, 0.5, 1.455, 0.5], "policy_blue_0_reward": [0.0, 0.497, -1.001, -0.003, 0.496, 1.452, -0.003, 0.498, 0.498, 0.499, 0.495, 0.0, 0.496, 0.498, 1.434, -0.003, 1.4300000000000002, 0.5, 1.4449999999999998, 0.499, 0.497, 1.4609999999999999, -0.026000000000000016, 1.4020000000000001, 0.498, -0.002, 0.495, 0.955, 0.499, -0.501, -0.004, 0.499, -0.004, 1.409, 0.498, -1.0019999999999998, 0.498, 0.498, -0.5, 0.499, 0.495, 0.497, -0.5009999999999999, 0.498, 1.4100000000000001, -1.001, -0.002, -0.002, 0.45899999999999996, 0.499, 0.497, -0.502, 0.499, 0.498, 0.498, 1.424, 1.4329999999999998, 0.499, 0.497, 0.497, 0.5, 1.4449999999999998, -0.004, 0.497, 0.498, 0.5, 1.403, 0.499, -0.003, 1.4689999999999999, -0.5, 0.5, -0.003, -0.003, -1.0, 0.497, 0.497, -0.008, 0.45299999999999996, 0.499, 0.498, -0.005, -0.006, 0.499, 0.498, 0.499, 0.497, 1.443, 0.496, 1.4449999999999998, -0.003, 1.434, 0.497, 0.969, -0.501, 0.495, 1.448, 0.498, 1.458, 0.5, 1.467, 0.499, 0.497, 0.475, 0.498, 1.475, 1.4409999999999998, -1.003, 1.45, -0.503, 0.0, -0.502, 0.497, -0.001, 1.327, 0.498, 0.495, 1.416, 0.496, 0.916, 0.498, 0.497, 0.973, 0.499, 1.452, -0.002, 1.452]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4120544959187218, "mean_inference_ms": 7.438581984875093, "mean_action_processing_ms": 0.3905489804623161, "mean_env_wait_ms": 0.5213807523552645, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14922299722986898, "StateBufferConnector_ms": 0.00980529259508989, "ViewRequirementAgentConnector_ms": 0.19096408303328385}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.67865058866353, "num_env_steps_trained_throughput_per_sec": 127.67865058866353, "timesteps_total": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 31688.72, "sample_time_ms": 4133.102, "learn_time_ms": 27527.774, "learn_throughput": 145.308, "synch_weights_time_ms": 26.331}, "counters": {"num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "episodes_total": 7329, "training_iteration": 104, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-52-17", "timestamp": 1694839937, "time_this_iter_s": 31.349595069885254, "time_total_s": 3242.646959066391, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219b51b0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3242.646959066391, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 25.54888888888889, "ram_util_percent": 57.09111111111111}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5660377358490566, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.1761006289308176, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1069182389937107, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.1761006289308176, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1320754716981132, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1069182389937107, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.1761006289308176, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1069182389937107, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5440889336789648, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03716998211360381, "policy_loss": -0.08114507530602472, "vf_loss": 0.04051652452035341, "vf_explained_var": 0.7055565914139151, "kl": 0.01086447673216829, "entropy": 1.033804814144969, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 100320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5717438348258536, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05028905160240053, "policy_loss": -0.09805926885746885, "vf_loss": 0.04488379183070113, "vf_explained_var": 0.529952350196739, "kl": 0.011734277435641616, "entropy": 1.4038301965842643, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 100320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 840000, "num_agent_steps_trained": 840000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.05600000000000005, "episode_reward_mean": 1.4354779874213837, "episode_len_mean": 27.433962264150942, "episode_media": {}, "episodes_this_iter": 159, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 1.0275471698113208, "blue_0": 0.40793081761006283}, "custom_metrics": {"red_0/door_open_done_mean": 0.5660377358490566, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.1761006289308176, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1069182389937107, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.1761006289308176, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1320754716981132, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.1069182389937107, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.1761006289308176, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1069182389937107, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.4010000000000002, 1.831, -0.040000000000000036, 1.721, 1.94, 1.912, 1.958, 1.939, 1.935, 1.4420000000000002, 1.9409999999999998, 0.43100000000000005, -0.039999999999999925, 1.952, 1.96, 0.42299999999999993, 1.455, 1.9609999999999999, 1.454, 0.476, 0.44999999999999996, 1.8860000000000001, 0.956, 1.9449999999999998, 1.943, 1.9569999999999999, 1.948, 1.948, -0.05400000000000005, -0.05600000000000005, 1.443, 0.41700000000000004, 1.93, 0.942, 0.469, 1.459, 1.888, 1.9180000000000001, 0.8440000000000001, 1.923, 0.9219999999999999, 1.4369999999999998, 1.947, 0.45399999999999996, 1.786, 1.94, 1.952, 1.935, 0.45999999999999996, 1.944, 1.449, 1.3699999999999999, 1.956, 0.43500000000000005, 1.948, 1.9489999999999998, 0.956, 0.43900000000000006, 0.9449999999999998, 1.407, 1.9140000000000001, 0.44899999999999995, 1.8940000000000001, 1.9569999999999999, 1.944, 1.375, 1.426, 0.45799999999999996, 1.935, 1.958, 1.939, 0.42300000000000004, 1.951, 1.955, 1.95, 1.921, 0.41800000000000015, 1.444, 0.47, 1.839, 1.944, 1.865, 1.94, 1.915, 1.952, 1.9220000000000002, 1.919, 1.419, 1.952, 0.31899999999999984, 0.953, 1.951, 1.4220000000000002, 0.9199999999999999, 1.9100000000000001, 1.65, 1.3679999999999999, 1.42, 0.45100000000000007, 1.939, -0.03600000000000003, 1.9340000000000002, 0.946, 1.94, -0.027000000000000024, 1.957, 1.9409999999999998, 0.946, 1.4609999999999999, 1.446, 0.41400000000000015, 1.9449999999999998, 0.46099999999999985, 1.4569999999999999, 1.459, 1.9249999999999998, 0.943, 0.946, 1.927, 0.44999999999999996, 1.811, 0.972, 0.45499999999999996, 0.9540000000000002, 0.9339999999999999, 1.9569999999999999, 1.9569999999999999, 1.443, 1.458, 1.923, 1.9489999999999998, 1.93, 0.96, 1.938, 1.927, 0.935, 1.955, 0.41600000000000004, 1.436, 1.944, 0.42600000000000005, 1.936, 1.9529999999999998, 1.95, 1.924, 1.946, 1.954, 0.964, 1.9369999999999998, 1.422, 1.9609999999999999, 1.9449999999999998, 1.954, 1.9409999999999998, -0.03600000000000003, 1.951, 1.948, 1.932, 1.954], "episode_lengths": [31, 54, 12, 87, 19, 29, 14, 19, 21, 18, 19, 21, 13, 16, 13, 24, 15, 13, 15, 8, 16, 36, 13, 17, 19, 14, 17, 16, 17, 18, 18, 25, 22, 19, 10, 13, 34, 26, 47, 24, 300, 20, 17, 15, 67, 19, 15, 19, 13, 18, 16, 191, 14, 20, 17, 16, 300, 20, 16, 31, 28, 16, 33, 14, 18, 41, 24, 13, 21, 14, 20, 23, 16, 15, 16, 26, 26, 18, 9, 48, 17, 42, 18, 26, 15, 25, 26, 26, 15, 300, 15, 16, 25, 26, 28, 109, 41, 25, 16, 20, 12, 21, 17, 19, 9, 14, 18, 17, 13, 17, 27, 18, 12, 14, 13, 24, 18, 18, 23, 16, 60, 9, 14, 14, 22, 14, 14, 18, 14, 24, 17, 22, 13, 20, 22, 20, 15, 26, 20, 18, 23, 20, 15, 16, 24, 17, 15, 12, 19, 24, 13, 17, 15, 19, 12, 16, 17, 21, 15], "policy_red_0_reward": [1.404, 1.3359999999999999, -1.0, 1.2309999999999999, 1.442, 1.413, 1.458, 1.443, 1.436, 1.444, 1.443, 1.434, -1.0, 1.452, 0.499, 0.9249999999999999, 1.455, 0.5, 1.455, -0.5, 0.951, 1.3900000000000001, 1.46, 1.448, 1.443, 1.4569999999999999, 0.5, 1.45, 0.948, -1.001, 1.444, -0.505, 0.496, -0.5, -0.5, 1.4609999999999999, 1.393, 1.421, 1.3519999999999999, 1.4249999999999998, 0.45699999999999996, 1.439, 1.4489999999999998, -1.001, 1.29, 1.4409999999999998, 1.455, 1.44, 1.46, 0.5, 1.452, 0.46599999999999997, 1.458, 1.438, 1.4489999999999998, 1.451, 0.485, 1.44, 1.452, 0.0, 1.4140000000000001, -1.002, 1.397, 1.458, 0.5, 1.376, 0.0, 0.96, 1.4369999999999998, 1.458, 0.5, 1.428, 1.452, 1.455, 1.452, 1.421, 1.42, 1.444, 1.4729999999999999, 0.497, 1.448, 1.373, 1.4449999999999998, 1.419, 1.455, 1.424, 0.499, -0.001, 1.455, 0.34799999999999986, -0.5, 1.452, 1.425, 1.42, 1.412, 1.1640000000000001, 1.371, 1.425, 1.451, 0.5, 0.964, 1.435, 1.448, 0.5, -1.0, 1.458, 1.444, 1.4489999999999998, 1.4609999999999999, 1.448, 1.419, 1.446, 1.464, 1.458, 1.4609999999999999, 1.427, -0.501, 1.446, 1.431, 0.951, 1.317, 1.4729999999999999, -1.001, 1.458, -0.5, 1.4569999999999999, 0.499, 1.446, 1.458, 0.498, 1.4489999999999998, 1.4329999999999998, -0.5, 1.44, 1.4329999999999998, 1.439, 1.455, -0.502, 1.439, 0.5, -1.001, 1.44, 1.455, 1.452, 0.499, 1.4489999999999998, 1.455, 1.464, 1.44, 1.426, 1.4609999999999999, 1.448, 0.5, 1.442, 0.964, 1.452, 1.4489999999999998, 1.4369999999999998, 0.499], "policy_blue_0_reward": [-0.003, 0.495, 0.96, 0.49, 0.498, 0.499, 0.5, 0.496, 0.499, -0.002, 0.498, -1.003, 0.96, 0.5, 1.4609999999999999, -0.502, 0.0, 1.4609999999999999, -0.001, 0.976, -0.501, 0.496, -0.5039999999999999, 0.497, 0.5, 0.5, 1.448, 0.498, -1.002, 0.945, -0.001, 0.922, 1.434, 1.442, 0.969, -0.002, 0.495, 0.497, -0.5079999999999999, 0.498, 0.46499999999999997, -0.002, 0.498, 1.455, 0.496, 0.499, 0.497, 0.495, -1.0, 1.444, -0.003, 0.9039999999999999, 0.498, -1.003, 0.499, 0.498, 0.471, -1.001, -0.507, 1.407, 0.5, 1.451, 0.497, 0.499, 1.444, -0.001, 1.426, -0.502, 0.498, 0.5, 1.439, -1.005, 0.499, 0.5, 0.498, 0.5, -1.002, 0.0, -1.003, 1.342, 0.496, 0.492, 0.495, 0.496, 0.497, 0.498, 1.42, 1.42, 0.497, -0.02900000000000002, 1.4529999999999998, 0.499, -0.003, -0.5, 0.498, 0.486, -0.003, -0.005, -1.0, 1.439, -1.0, 0.499, -0.502, 1.44, 0.973, 0.499, 0.497, -0.503, 0.0, -0.002, -1.005, 0.499, -1.003, -0.001, -0.002, 0.498, 1.444, -0.5, 0.496, -0.501, 0.494, -0.501, 1.456, -0.5039999999999999, 1.434, 0.5, 1.458, -0.003, 0.0, 1.4249999999999998, 0.5, 0.497, 1.46, 0.498, 0.494, -0.504, 0.5, 0.918, -0.003, 1.444, 1.427, 0.496, 0.498, 0.498, 1.4249999999999998, 0.497, 0.499, -0.5, 0.497, -0.004, 0.5, 0.497, 1.454, 0.499, -1.0, 0.499, 0.499, 0.495, 1.455]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.412177053606111, "mean_inference_ms": 7.445302075210685, "mean_action_processing_ms": 0.390055627089968, "mean_env_wait_ms": 0.5210866976024507, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1490490991364485, "StateBufferConnector_ms": 0.011071319100241991, "ViewRequirementAgentConnector_ms": 0.19515355428059897}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.05600000000000005, "episode_reward_mean": 1.4354779874213837, "episode_len_mean": 27.433962264150942, "episodes_this_iter": 159, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 1.0275471698113208, "blue_0": 0.40793081761006283}, "hist_stats": {"episode_reward": [1.4010000000000002, 1.831, -0.040000000000000036, 1.721, 1.94, 1.912, 1.958, 1.939, 1.935, 1.4420000000000002, 1.9409999999999998, 0.43100000000000005, -0.039999999999999925, 1.952, 1.96, 0.42299999999999993, 1.455, 1.9609999999999999, 1.454, 0.476, 0.44999999999999996, 1.8860000000000001, 0.956, 1.9449999999999998, 1.943, 1.9569999999999999, 1.948, 1.948, -0.05400000000000005, -0.05600000000000005, 1.443, 0.41700000000000004, 1.93, 0.942, 0.469, 1.459, 1.888, 1.9180000000000001, 0.8440000000000001, 1.923, 0.9219999999999999, 1.4369999999999998, 1.947, 0.45399999999999996, 1.786, 1.94, 1.952, 1.935, 0.45999999999999996, 1.944, 1.449, 1.3699999999999999, 1.956, 0.43500000000000005, 1.948, 1.9489999999999998, 0.956, 0.43900000000000006, 0.9449999999999998, 1.407, 1.9140000000000001, 0.44899999999999995, 1.8940000000000001, 1.9569999999999999, 1.944, 1.375, 1.426, 0.45799999999999996, 1.935, 1.958, 1.939, 0.42300000000000004, 1.951, 1.955, 1.95, 1.921, 0.41800000000000015, 1.444, 0.47, 1.839, 1.944, 1.865, 1.94, 1.915, 1.952, 1.9220000000000002, 1.919, 1.419, 1.952, 0.31899999999999984, 0.953, 1.951, 1.4220000000000002, 0.9199999999999999, 1.9100000000000001, 1.65, 1.3679999999999999, 1.42, 0.45100000000000007, 1.939, -0.03600000000000003, 1.9340000000000002, 0.946, 1.94, -0.027000000000000024, 1.957, 1.9409999999999998, 0.946, 1.4609999999999999, 1.446, 0.41400000000000015, 1.9449999999999998, 0.46099999999999985, 1.4569999999999999, 1.459, 1.9249999999999998, 0.943, 0.946, 1.927, 0.44999999999999996, 1.811, 0.972, 0.45499999999999996, 0.9540000000000002, 0.9339999999999999, 1.9569999999999999, 1.9569999999999999, 1.443, 1.458, 1.923, 1.9489999999999998, 1.93, 0.96, 1.938, 1.927, 0.935, 1.955, 0.41600000000000004, 1.436, 1.944, 0.42600000000000005, 1.936, 1.9529999999999998, 1.95, 1.924, 1.946, 1.954, 0.964, 1.9369999999999998, 1.422, 1.9609999999999999, 1.9449999999999998, 1.954, 1.9409999999999998, -0.03600000000000003, 1.951, 1.948, 1.932, 1.954], "episode_lengths": [31, 54, 12, 87, 19, 29, 14, 19, 21, 18, 19, 21, 13, 16, 13, 24, 15, 13, 15, 8, 16, 36, 13, 17, 19, 14, 17, 16, 17, 18, 18, 25, 22, 19, 10, 13, 34, 26, 47, 24, 300, 20, 17, 15, 67, 19, 15, 19, 13, 18, 16, 191, 14, 20, 17, 16, 300, 20, 16, 31, 28, 16, 33, 14, 18, 41, 24, 13, 21, 14, 20, 23, 16, 15, 16, 26, 26, 18, 9, 48, 17, 42, 18, 26, 15, 25, 26, 26, 15, 300, 15, 16, 25, 26, 28, 109, 41, 25, 16, 20, 12, 21, 17, 19, 9, 14, 18, 17, 13, 17, 27, 18, 12, 14, 13, 24, 18, 18, 23, 16, 60, 9, 14, 14, 22, 14, 14, 18, 14, 24, 17, 22, 13, 20, 22, 20, 15, 26, 20, 18, 23, 20, 15, 16, 24, 17, 15, 12, 19, 24, 13, 17, 15, 19, 12, 16, 17, 21, 15], "policy_red_0_reward": [1.404, 1.3359999999999999, -1.0, 1.2309999999999999, 1.442, 1.413, 1.458, 1.443, 1.436, 1.444, 1.443, 1.434, -1.0, 1.452, 0.499, 0.9249999999999999, 1.455, 0.5, 1.455, -0.5, 0.951, 1.3900000000000001, 1.46, 1.448, 1.443, 1.4569999999999999, 0.5, 1.45, 0.948, -1.001, 1.444, -0.505, 0.496, -0.5, -0.5, 1.4609999999999999, 1.393, 1.421, 1.3519999999999999, 1.4249999999999998, 0.45699999999999996, 1.439, 1.4489999999999998, -1.001, 1.29, 1.4409999999999998, 1.455, 1.44, 1.46, 0.5, 1.452, 0.46599999999999997, 1.458, 1.438, 1.4489999999999998, 1.451, 0.485, 1.44, 1.452, 0.0, 1.4140000000000001, -1.002, 1.397, 1.458, 0.5, 1.376, 0.0, 0.96, 1.4369999999999998, 1.458, 0.5, 1.428, 1.452, 1.455, 1.452, 1.421, 1.42, 1.444, 1.4729999999999999, 0.497, 1.448, 1.373, 1.4449999999999998, 1.419, 1.455, 1.424, 0.499, -0.001, 1.455, 0.34799999999999986, -0.5, 1.452, 1.425, 1.42, 1.412, 1.1640000000000001, 1.371, 1.425, 1.451, 0.5, 0.964, 1.435, 1.448, 0.5, -1.0, 1.458, 1.444, 1.4489999999999998, 1.4609999999999999, 1.448, 1.419, 1.446, 1.464, 1.458, 1.4609999999999999, 1.427, -0.501, 1.446, 1.431, 0.951, 1.317, 1.4729999999999999, -1.001, 1.458, -0.5, 1.4569999999999999, 0.499, 1.446, 1.458, 0.498, 1.4489999999999998, 1.4329999999999998, -0.5, 1.44, 1.4329999999999998, 1.439, 1.455, -0.502, 1.439, 0.5, -1.001, 1.44, 1.455, 1.452, 0.499, 1.4489999999999998, 1.455, 1.464, 1.44, 1.426, 1.4609999999999999, 1.448, 0.5, 1.442, 0.964, 1.452, 1.4489999999999998, 1.4369999999999998, 0.499], "policy_blue_0_reward": [-0.003, 0.495, 0.96, 0.49, 0.498, 0.499, 0.5, 0.496, 0.499, -0.002, 0.498, -1.003, 0.96, 0.5, 1.4609999999999999, -0.502, 0.0, 1.4609999999999999, -0.001, 0.976, -0.501, 0.496, -0.5039999999999999, 0.497, 0.5, 0.5, 1.448, 0.498, -1.002, 0.945, -0.001, 0.922, 1.434, 1.442, 0.969, -0.002, 0.495, 0.497, -0.5079999999999999, 0.498, 0.46499999999999997, -0.002, 0.498, 1.455, 0.496, 0.499, 0.497, 0.495, -1.0, 1.444, -0.003, 0.9039999999999999, 0.498, -1.003, 0.499, 0.498, 0.471, -1.001, -0.507, 1.407, 0.5, 1.451, 0.497, 0.499, 1.444, -0.001, 1.426, -0.502, 0.498, 0.5, 1.439, -1.005, 0.499, 0.5, 0.498, 0.5, -1.002, 0.0, -1.003, 1.342, 0.496, 0.492, 0.495, 0.496, 0.497, 0.498, 1.42, 1.42, 0.497, -0.02900000000000002, 1.4529999999999998, 0.499, -0.003, -0.5, 0.498, 0.486, -0.003, -0.005, -1.0, 1.439, -1.0, 0.499, -0.502, 1.44, 0.973, 0.499, 0.497, -0.503, 0.0, -0.002, -1.005, 0.499, -1.003, -0.001, -0.002, 0.498, 1.444, -0.5, 0.496, -0.501, 0.494, -0.501, 1.456, -0.5039999999999999, 1.434, 0.5, 1.458, -0.003, 0.0, 1.4249999999999998, 0.5, 0.497, 1.46, 0.498, 0.494, -0.504, 0.5, 0.918, -0.003, 1.444, 1.427, 0.496, 0.498, 0.498, 1.4249999999999998, 0.497, 0.499, -0.5, 0.497, -0.004, 0.5, 0.497, 1.454, 0.499, -1.0, 0.499, 0.499, 0.495, 1.455]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.412177053606111, "mean_inference_ms": 7.445302075210685, "mean_action_processing_ms": 0.390055627089968, "mean_env_wait_ms": 0.5210866976024507, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1490490991364485, "StateBufferConnector_ms": 0.011071319100241991, "ViewRequirementAgentConnector_ms": 0.19515355428059897}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 840000, "num_agent_steps_trained": 840000, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 126.12896070247476, "num_env_steps_trained_throughput_per_sec": 126.12896070247476, "timesteps_total": 420000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 840000, "timers": {"training_iteration_time_ms": 31838.675, "sample_time_ms": 4124.695, "learn_time_ms": 27685.935, "learn_throughput": 144.478, "synch_weights_time_ms": 26.538}, "counters": {"num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 840000, "num_agent_steps_trained": 840000}, "done": false, "episodes_total": 7488, "training_iteration": 105, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-52-50", "timestamp": 1694839970, "time_this_iter_s": 31.735187768936157, "time_total_s": 3274.382146835327, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21980d30>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3274.382146835327, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 24.736170212765952, "ram_util_percent": 57.151063829787205}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5793650793650794, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.15079365079365079, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0873015873015873, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.15079365079365079, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16666666666666666, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.0873015873015873, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.15079365079365079, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0873015873015873, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5496287265482048, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03503025097888894, "policy_loss": -0.0733647265980835, "vf_loss": 0.03005612160486635, "vf_explained_var": 0.7293760777140658, "kl": 0.010736819509982115, "entropy": 1.1534023996442557, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 101280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5641483992959062, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05080298132088501, "policy_loss": -0.0904888774981373, "vf_loss": 0.03123002692203348, "vf_explained_var": 0.573845433567961, "kl": 0.011194056555205683, "entropy": 1.4305778509626785, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 101280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.062000000000000055, "episode_reward_mean": 1.451261904761905, "episode_len_mean": 27.46825396825397, "episode_media": {}, "episodes_this_iter": 126, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 1.007063492063492, "blue_0": 0.44419841269841276}, "custom_metrics": {"red_0/door_open_done_mean": 0.5793650793650794, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.15079365079365079, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0873015873015873, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.15079365079365079, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.16666666666666666, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.0873015873015873, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.15079365079365079, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0873015873015873, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.939, 1.722, 1.458, 1.932, -0.04499999999999993, 1.9220000000000002, 1.311, -0.03600000000000003, 0.949, 0.45999999999999996, 0.946, 0.46899999999999986, 0.45899999999999996, 1.9529999999999998, 1.945, 1.926, 1.9369999999999998, -0.03700000000000003, 1.952, 1.434, 0.45199999999999996, 1.424, 1.936, 1.442, 1.0470000000000002, 0.44099999999999984, 1.942, 1.954, 1.451, 1.38, 0.9529999999999998, 0.4500000000000002, 1.948, 0.42499999999999993, 1.4180000000000001, 1.95, -0.018000000000000016, 1.939, 1.913, 1.8940000000000001, 1.926, 1.455, 1.958, 1.943, 1.935, 1.4609999999999999, 1.954, 1.444, 1.9609999999999999, 0.07099999999999995, -0.04200000000000004, 1.451, 1.958, 1.942, 1.958, 1.913, 1.76, 0.473, 1.4609999999999999, 1.429, 1.8940000000000001, 1.9529999999999998, -0.062000000000000055, 0.964, 0.4710000000000001, 0.388, 1.448, 1.8559999999999999, 0.9540000000000002, -0.027000000000000024, 0.44799999999999995, 1.927, 0.949, 1.917, 1.9569999999999999, 1.938, 1.9569999999999999, -0.062000000000000055, 1.4449999999999998, 1.421, 1.935, 0.969, 1.948, 0.954, 1.955, 1.9529999999999998, 1.915, 1.923, 1.839, 1.9140000000000001, 0.42900000000000005, 1.951, 1.911, 1.877, 1.435, 0.45799999999999996, 1.955, 1.9569999999999999, 1.907, 1.94, 1.455, 1.944, 1.916, 0.9570000000000001, 1.923, 1.938, 1.958, 1.947, 1.94, 1.952, 1.8940000000000001, 1.401, 1.946, 1.9609999999999999, 1.416, 1.9409999999999998, 1.448, 1.9489999999999998, 1.9529999999999998, 1.896, 1.95, 1.187, 1.936, 1.927, 1.9489999999999998, -0.03400000000000003], "episode_lengths": [19, 89, 14, 22, 14, 26, 60, 11, 16, 13, 17, 10, 13, 15, 18, 22, 20, 12, 16, 21, 15, 24, 21, 19, 142, 19, 18, 15, 16, 38, 15, 15, 17, 300, 27, 16, 6, 19, 27, 32, 24, 14, 14, 18, 21, 13, 15, 18, 13, 134, 14, 16, 14, 18, 14, 28, 74, 9, 13, 23, 33, 15, 19, 12, 9, 33, 16, 43, 15, 8, 300, 23, 16, 26, 14, 20, 14, 20, 18, 26, 21, 10, 16, 15, 14, 15, 28, 24, 50, 27, 23, 16, 29, 39, 21, 13, 14, 14, 29, 19, 15, 18, 28, 13, 24, 20, 14, 16, 20, 16, 34, 32, 17, 13, 26, 18, 17, 16, 15, 33, 16, 95, 21, 23, 17, 11], "policy_red_0_reward": [1.443, 0.495, 1.458, 1.4329999999999998, -1.001, 1.4220000000000002, 1.3159999999999998, 0.965, -0.501, -0.5, -0.5, 1.47, -0.5, 1.454, 1.446, 0.495, 1.44, 0.964, 0.5, 1.4369999999999998, -1.002, 1.427, 1.4369999999999998, 1.443, 1.058, 1.443, 1.446, 1.455, 1.452, -0.005, 1.454, 1.4529999999999998, 1.4489999999999998, 0.45099999999999996, 1.419, 0.499, 0.982, 1.442, 1.417, 0.497, 1.428, -0.002, 1.458, 1.446, 1.4369999999999998, 1.4609999999999999, 1.455, 1.446, 1.4609999999999999, 0.591, 0.958, 1.452, 1.458, 1.446, 1.458, 1.415, 1.271, -1.0, 1.4609999999999999, 1.431, 1.396, 1.455, 0.941, 1.464, 0.973, 0.896, 1.45, 1.362, 1.455, 0.975, -0.027000000000000017, 0.499, -0.5, 0.498, 1.458, 0.5, 1.4569999999999999, -1.001, 1.446, 1.421, 1.4369999999999998, -0.501, 0.498, 1.454, 1.458, 1.455, 1.416, 1.426, 0.497, 1.416, 0.93, 0.499, 0.5, 0.495, 0.0, -1.001, 1.458, 1.458, 0.497, 1.442, 0.0, 1.4449999999999998, 1.416, 1.4609999999999999, 1.426, 1.439, 1.458, 1.451, 1.44, 1.452, 1.397, 1.403, 0.498, 1.4609999999999999, 1.419, 1.444, 1.448, 1.452, 1.455, 0.498, 1.451, 1.194, 0.5, 1.4300000000000002, 1.4489999999999998, 0.967], "policy_blue_0_reward": [0.496, 1.2269999999999999, 0.0, 0.499, 0.956, 0.5, -0.005, -1.001, 1.45, 0.96, 1.446, -1.001, 0.959, 0.499, 0.499, 1.431, 0.497, -1.001, 1.452, -0.003, 1.454, -0.003, 0.499, -0.001, -0.011000000000000003, -1.002, 0.496, 0.499, -0.001, 1.385, -0.501, -1.003, 0.499, -0.026000000000000016, -0.001, 1.451, -1.0, 0.497, 0.496, 1.397, 0.498, 1.4569999999999999, 0.5, 0.497, 0.498, 0.0, 0.499, -0.002, 0.5, -0.52, -1.0, -0.001, 0.5, 0.496, 0.5, 0.498, 0.489, 1.4729999999999999, 0.0, -0.002, 0.498, 0.498, -1.003, -0.5, -0.5019999999999999, -0.508, -0.002, 0.494, -0.5009999999999999, -1.002, 0.475, 1.428, 1.4489999999999998, 1.419, 0.499, 1.438, 0.5, 0.939, -0.001, 0.0, 0.498, 1.47, 1.45, -0.5, 0.497, 0.498, 0.499, 0.497, 1.342, 0.498, -0.501, 1.452, 1.411, 1.3820000000000001, 1.435, 1.459, 0.497, 0.499, 1.4100000000000001, 0.498, 1.455, 0.499, 0.5, -0.5039999999999999, 0.497, 0.499, 0.5, 0.496, 0.5, 0.5, 0.497, -0.002, 1.448, 0.5, -0.003, 0.497, 0.0, 0.497, 0.498, 1.3980000000000001, 0.499, -0.007, 1.436, 0.497, 0.5, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4131249069905718, "mean_inference_ms": 7.450164346172496, "mean_action_processing_ms": 0.39031205539798014, "mean_env_wait_ms": 0.5209518657182343, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14634037774706643, "StateBufferConnector_ms": 0.009900804549928695, "ViewRequirementAgentConnector_ms": 0.18851359685262045}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.062000000000000055, "episode_reward_mean": 1.451261904761905, "episode_len_mean": 27.46825396825397, "episodes_this_iter": 126, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 1.007063492063492, "blue_0": 0.44419841269841276}, "hist_stats": {"episode_reward": [1.939, 1.722, 1.458, 1.932, -0.04499999999999993, 1.9220000000000002, 1.311, -0.03600000000000003, 0.949, 0.45999999999999996, 0.946, 0.46899999999999986, 0.45899999999999996, 1.9529999999999998, 1.945, 1.926, 1.9369999999999998, -0.03700000000000003, 1.952, 1.434, 0.45199999999999996, 1.424, 1.936, 1.442, 1.0470000000000002, 0.44099999999999984, 1.942, 1.954, 1.451, 1.38, 0.9529999999999998, 0.4500000000000002, 1.948, 0.42499999999999993, 1.4180000000000001, 1.95, -0.018000000000000016, 1.939, 1.913, 1.8940000000000001, 1.926, 1.455, 1.958, 1.943, 1.935, 1.4609999999999999, 1.954, 1.444, 1.9609999999999999, 0.07099999999999995, -0.04200000000000004, 1.451, 1.958, 1.942, 1.958, 1.913, 1.76, 0.473, 1.4609999999999999, 1.429, 1.8940000000000001, 1.9529999999999998, -0.062000000000000055, 0.964, 0.4710000000000001, 0.388, 1.448, 1.8559999999999999, 0.9540000000000002, -0.027000000000000024, 0.44799999999999995, 1.927, 0.949, 1.917, 1.9569999999999999, 1.938, 1.9569999999999999, -0.062000000000000055, 1.4449999999999998, 1.421, 1.935, 0.969, 1.948, 0.954, 1.955, 1.9529999999999998, 1.915, 1.923, 1.839, 1.9140000000000001, 0.42900000000000005, 1.951, 1.911, 1.877, 1.435, 0.45799999999999996, 1.955, 1.9569999999999999, 1.907, 1.94, 1.455, 1.944, 1.916, 0.9570000000000001, 1.923, 1.938, 1.958, 1.947, 1.94, 1.952, 1.8940000000000001, 1.401, 1.946, 1.9609999999999999, 1.416, 1.9409999999999998, 1.448, 1.9489999999999998, 1.9529999999999998, 1.896, 1.95, 1.187, 1.936, 1.927, 1.9489999999999998, -0.03400000000000003], "episode_lengths": [19, 89, 14, 22, 14, 26, 60, 11, 16, 13, 17, 10, 13, 15, 18, 22, 20, 12, 16, 21, 15, 24, 21, 19, 142, 19, 18, 15, 16, 38, 15, 15, 17, 300, 27, 16, 6, 19, 27, 32, 24, 14, 14, 18, 21, 13, 15, 18, 13, 134, 14, 16, 14, 18, 14, 28, 74, 9, 13, 23, 33, 15, 19, 12, 9, 33, 16, 43, 15, 8, 300, 23, 16, 26, 14, 20, 14, 20, 18, 26, 21, 10, 16, 15, 14, 15, 28, 24, 50, 27, 23, 16, 29, 39, 21, 13, 14, 14, 29, 19, 15, 18, 28, 13, 24, 20, 14, 16, 20, 16, 34, 32, 17, 13, 26, 18, 17, 16, 15, 33, 16, 95, 21, 23, 17, 11], "policy_red_0_reward": [1.443, 0.495, 1.458, 1.4329999999999998, -1.001, 1.4220000000000002, 1.3159999999999998, 0.965, -0.501, -0.5, -0.5, 1.47, -0.5, 1.454, 1.446, 0.495, 1.44, 0.964, 0.5, 1.4369999999999998, -1.002, 1.427, 1.4369999999999998, 1.443, 1.058, 1.443, 1.446, 1.455, 1.452, -0.005, 1.454, 1.4529999999999998, 1.4489999999999998, 0.45099999999999996, 1.419, 0.499, 0.982, 1.442, 1.417, 0.497, 1.428, -0.002, 1.458, 1.446, 1.4369999999999998, 1.4609999999999999, 1.455, 1.446, 1.4609999999999999, 0.591, 0.958, 1.452, 1.458, 1.446, 1.458, 1.415, 1.271, -1.0, 1.4609999999999999, 1.431, 1.396, 1.455, 0.941, 1.464, 0.973, 0.896, 1.45, 1.362, 1.455, 0.975, -0.027000000000000017, 0.499, -0.5, 0.498, 1.458, 0.5, 1.4569999999999999, -1.001, 1.446, 1.421, 1.4369999999999998, -0.501, 0.498, 1.454, 1.458, 1.455, 1.416, 1.426, 0.497, 1.416, 0.93, 0.499, 0.5, 0.495, 0.0, -1.001, 1.458, 1.458, 0.497, 1.442, 0.0, 1.4449999999999998, 1.416, 1.4609999999999999, 1.426, 1.439, 1.458, 1.451, 1.44, 1.452, 1.397, 1.403, 0.498, 1.4609999999999999, 1.419, 1.444, 1.448, 1.452, 1.455, 0.498, 1.451, 1.194, 0.5, 1.4300000000000002, 1.4489999999999998, 0.967], "policy_blue_0_reward": [0.496, 1.2269999999999999, 0.0, 0.499, 0.956, 0.5, -0.005, -1.001, 1.45, 0.96, 1.446, -1.001, 0.959, 0.499, 0.499, 1.431, 0.497, -1.001, 1.452, -0.003, 1.454, -0.003, 0.499, -0.001, -0.011000000000000003, -1.002, 0.496, 0.499, -0.001, 1.385, -0.501, -1.003, 0.499, -0.026000000000000016, -0.001, 1.451, -1.0, 0.497, 0.496, 1.397, 0.498, 1.4569999999999999, 0.5, 0.497, 0.498, 0.0, 0.499, -0.002, 0.5, -0.52, -1.0, -0.001, 0.5, 0.496, 0.5, 0.498, 0.489, 1.4729999999999999, 0.0, -0.002, 0.498, 0.498, -1.003, -0.5, -0.5019999999999999, -0.508, -0.002, 0.494, -0.5009999999999999, -1.002, 0.475, 1.428, 1.4489999999999998, 1.419, 0.499, 1.438, 0.5, 0.939, -0.001, 0.0, 0.498, 1.47, 1.45, -0.5, 0.497, 0.498, 0.499, 0.497, 1.342, 0.498, -0.501, 1.452, 1.411, 1.3820000000000001, 1.435, 1.459, 0.497, 0.499, 1.4100000000000001, 0.498, 1.455, 0.499, 0.5, -0.5039999999999999, 0.497, 0.499, 0.5, 0.496, 0.5, 0.5, 0.497, -0.002, 1.448, 0.5, -0.003, 0.497, 0.0, 0.497, 0.498, 1.3980000000000001, 0.499, -0.007, 1.436, 0.497, 0.5, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4131249069905718, "mean_inference_ms": 7.450164346172496, "mean_action_processing_ms": 0.39031205539798014, "mean_env_wait_ms": 0.5209518657182343, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14634037774706643, "StateBufferConnector_ms": 0.009900804549928695, "ViewRequirementAgentConnector_ms": 0.18851359685262045}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.89740312914796, "num_env_steps_trained_throughput_per_sec": 128.89740312914796, "timesteps_total": 424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 31869.427, "sample_time_ms": 4120.205, "learn_time_ms": 27721.147, "learn_throughput": 144.294, "synch_weights_time_ms": 26.526}, "counters": {"num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "episodes_total": 7614, "training_iteration": 106, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-53-22", "timestamp": 1694840002, "time_this_iter_s": 31.0509831905365, "time_total_s": 3305.4331300258636, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219b4160>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3305.4331300258636, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 25.193333333333335, "ram_util_percent": 57.06666666666667}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6506849315068494, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.1643835616438356, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0273972602739726, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.1643835616438356, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.136986301369863, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.0273972602739726, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.1643835616438356, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0273972602739726, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.555957566263775, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04365827614480319, "policy_loss": -0.08238580866285096, "vf_loss": 0.02853974023698053, "vf_explained_var": 0.729656309261918, "kl": 0.011195439503267963, "entropy": 1.046948206735154, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 102240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5630916236589353, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.053898997933235174, "policy_loss": -0.09516854421817697, "vf_loss": 0.03295869186113123, "vf_explained_var": 0.5763031839082638, "kl": 0.011490702271940689, "entropy": 1.3870565007130304, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 102240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 856000, "num_agent_steps_trained": 856000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.135, "episode_reward_mean": 1.5503904109589044, "episode_len_mean": 29.84931506849315, "episode_media": {}, "episodes_this_iter": 146, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.18863698630137, "blue_0": 0.3617534246575343}, "custom_metrics": {"red_0/door_open_done_mean": 0.6506849315068494, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.1643835616438356, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0273972602739726, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.1643835616438356, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.136986301369863, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.0273972602739726, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.1643835616438356, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0273972602739726, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.942, 1.9489999999999998, 0.43100000000000005, 1.946, 1.943, 0.724, 0.4780000000000002, 0.4710000000000001, 1.946, 1.415, 1.959, 0.473, 1.9, 0.375, 1.96, 1.944, 1.455, 1.952, 1.958, 1.926, 1.45, 1.442, 1.432, 0.979, 1.936, 1.936, 1.942, 1.929, 1.955, 1.958, 0.4670000000000001, 1.953, 0.46599999999999997, 1.905, 1.909, 1.92, 1.95, 1.9180000000000001, 1.952, 1.507, 1.9080000000000001, 1.917, 1.387, 1.313, 1.431, 1.958, 1.892, 1.9369999999999998, 1.424, 1.952, 1.4260000000000002, 1.4369999999999998, 1.926, 1.95, 0.9289999999999998, 0.45399999999999996, 1.842, 1.94, 1.455, 1.948, 1.936, 1.9609999999999999, 1.4460000000000002, 0.9729999999999999, 1.9569999999999999, 0.43399999999999994, 1.9369999999999998, 0.4710000000000001, 1.4569999999999999, 0.42099999999999993, 1.9180000000000001, 1.9569999999999999, 0.44399999999999995, 1.931, 1.439, 1.942, 1.936, 1.4460000000000002, 0.9249999999999999, 0.482, 1.42, 1.927, 1.435, 1.954, 1.9409999999999998, 1.44, 1.8079999999999998, -0.135, 1.9, 0.45699999999999985, 1.939, 1.892, 1.959, 1.95, 0.06099999999999994, 1.947, 1.9369999999999998, 1.891, 1.922, 1.938, 1.9609999999999999, 1.958, 1.952, 0.905, 1.943, 1.432, 1.951, 1.9569999999999999, 1.4100000000000001, 1.407, 1.9609999999999999, 0.9299999999999999, -0.07899999999999996, 1.942, 1.96, 1.911, 0.9670000000000001, 1.9329999999999998, 1.749, 1.949, 1.955, 1.954, 0.44200000000000017, 0.43199999999999994, 1.9609999999999999, 1.948, 0.43100000000000005, 1.942, 1.931, 1.946, 1.923, 1.956, 1.9569999999999999, 0.952, 1.862, 1.851, 1.956, 1.907, 1.9369999999999998, 1.439, 0.43799999999999994, 1.4609999999999999, 1.934, 1.888, 0.43000000000000016, 1.9500000000000002], "episode_lengths": [18, 17, 21, 17, 18, 87, 7, 9, 17, 27, 13, 9, 32, 40, 13, 18, 15, 15, 14, 24, 16, 19, 21, 7, 20, 20, 18, 23, 15, 14, 11, 15, 11, 30, 29, 26, 16, 26, 16, 152, 29, 26, 35, 57, 22, 14, 34, 20, 24, 15, 23, 20, 24, 16, 22, 14, 47, 19, 14, 17, 21, 13, 17, 9, 14, 21, 20, 9, 14, 300, 25, 14, 18, 22, 20, 19, 20, 16, 300, 6, 25, 22, 21, 15, 19, 19, 59, 43, 32, 14, 18, 35, 13, 16, 296, 17, 19, 34, 24, 20, 13, 14, 15, 30, 18, 21, 16, 14, 28, 29, 13, 300, 25, 19, 13, 29, 11, 22, 78, 16, 15, 15, 19, 22, 13, 16, 20, 19, 22, 18, 24, 14, 14, 15, 43, 47, 14, 30, 20, 20, 20, 13, 21, 36, 22, 15], "policy_red_0_reward": [1.444, 1.4489999999999998, 1.436, 0.497, 1.444, 1.2309999999999999, 1.479, 0.973, 1.4489999999999998, 1.415, 1.4609999999999999, -0.5, 1.404, 1.377, 1.4609999999999999, 1.4449999999999998, 1.455, 1.454, 1.458, 1.427, 1.451, 1.443, 1.435, -0.5, 1.439, 1.438, 1.4449999999999998, 1.4300000000000002, 1.455, 1.458, 1.467, 1.454, 1.467, 1.408, 1.411, 1.4220000000000002, 1.452, 0.498, 1.452, 1.032, 1.413, 1.421, 1.392, 1.322, 1.4329999999999998, 1.458, 1.395, 1.439, 1.426, 1.4529999999999998, 1.429, 1.439, 0.5, 1.452, 1.432, 1.458, 0.495, 1.44, 1.458, 1.4489999999999998, 1.436, 0.5, 1.4489999999999998, 1.4729999999999999, 1.458, 0.9349999999999999, 1.439, 1.4729999999999999, -0.001, -0.03400000000000002, 0.496, 1.458, -0.501, 0.499, 1.44, 1.443, 1.44, 1.451, 0.46399999999999997, 0.982, 1.423, 1.4329999999999998, -0.001, 1.455, 1.443, 1.4409999999999998, 0.495, -1.0, 1.4020000000000001, 1.458, 1.444, 1.3940000000000001, 1.4609999999999999, 0.499, 0.586, 0.5, 1.44, 1.391, 1.426, 1.44, 0.5, 1.458, 1.455, 1.4100000000000001, 1.446, 1.434, 1.452, 1.4569999999999999, 1.4140000000000001, -0.003, 1.4609999999999999, 0.46299999999999997, 0.924, 1.442, 1.4609999999999999, 1.413, 1.467, 1.434, 0.494, 1.451, 0.5, 1.455, 1.443, 1.432, 0.5, 1.452, 0.9369999999999999, 1.443, 1.4329999999999998, 1.446, 1.4249999999999998, 1.458, 0.5, 1.455, 1.367, 1.355, 1.4569999999999999, 1.408, 0.5, 1.44, 1.438, 0.0, 1.4369999999999998, 1.3900000000000001, 1.432, 1.455], "policy_blue_0_reward": [0.498, 0.5, -1.005, 1.4489999999999998, 0.499, -0.507, -1.001, -0.502, 0.497, 0.0, 0.498, 0.973, 0.496, -1.002, 0.499, 0.499, 0.0, 0.498, 0.5, 0.499, -0.001, -0.001, -0.003, 1.479, 0.497, 0.498, 0.497, 0.499, 0.5, 0.5, -1.0, 0.499, -1.001, 0.497, 0.498, 0.498, 0.498, 1.42, 0.5, 0.475, 0.495, 0.496, -0.005, -0.009000000000000001, -0.002, 0.5, 0.497, 0.498, -0.002, 0.499, -0.003, -0.002, 1.426, 0.498, -0.503, -1.004, 1.347, 0.5, -0.003, 0.499, 0.5, 1.4609999999999999, -0.003, -0.5, 0.499, -0.501, 0.498, -1.002, 1.458, 0.45499999999999996, 1.4220000000000002, 0.499, 0.945, 1.432, -0.001, 0.499, 0.496, -0.005, 0.46099999999999997, -0.5, -0.003, 0.494, 1.436, 0.499, 0.498, -0.001, 1.313, 0.865, 0.498, -1.001, 0.495, 0.498, 0.498, 1.451, -0.525, 1.447, 0.497, 0.5, 0.496, 0.498, 1.4609999999999999, 0.5, 0.497, -0.505, 0.497, -0.002, 0.499, 0.5, -0.004, 1.4100000000000001, 0.5, 0.46699999999999997, -1.003, 0.5, 0.499, 0.498, -0.5, 0.499, 1.255, 0.498, 1.455, 0.499, -1.001, -1.0, 1.4609999999999999, 0.496, -0.5059999999999999, 0.499, 0.498, 0.5, 0.498, 0.498, 1.4569999999999999, -0.503, 0.495, 0.496, 0.499, 0.499, 1.4369999999999998, -0.001, -1.0, 1.4609999999999999, 0.497, 0.498, -1.0019999999999998, 0.495]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4122386004769718, "mean_inference_ms": 7.440330608745155, "mean_action_processing_ms": 0.3899798425479984, "mean_env_wait_ms": 0.5201754906824074, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1469092009818717, "StateBufferConnector_ms": 0.009640520566130338, "ViewRequirementAgentConnector_ms": 0.18527875207874872}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.135, "episode_reward_mean": 1.5503904109589044, "episode_len_mean": 29.84931506849315, "episodes_this_iter": 146, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.18863698630137, "blue_0": 0.3617534246575343}, "hist_stats": {"episode_reward": [1.942, 1.9489999999999998, 0.43100000000000005, 1.946, 1.943, 0.724, 0.4780000000000002, 0.4710000000000001, 1.946, 1.415, 1.959, 0.473, 1.9, 0.375, 1.96, 1.944, 1.455, 1.952, 1.958, 1.926, 1.45, 1.442, 1.432, 0.979, 1.936, 1.936, 1.942, 1.929, 1.955, 1.958, 0.4670000000000001, 1.953, 0.46599999999999997, 1.905, 1.909, 1.92, 1.95, 1.9180000000000001, 1.952, 1.507, 1.9080000000000001, 1.917, 1.387, 1.313, 1.431, 1.958, 1.892, 1.9369999999999998, 1.424, 1.952, 1.4260000000000002, 1.4369999999999998, 1.926, 1.95, 0.9289999999999998, 0.45399999999999996, 1.842, 1.94, 1.455, 1.948, 1.936, 1.9609999999999999, 1.4460000000000002, 0.9729999999999999, 1.9569999999999999, 0.43399999999999994, 1.9369999999999998, 0.4710000000000001, 1.4569999999999999, 0.42099999999999993, 1.9180000000000001, 1.9569999999999999, 0.44399999999999995, 1.931, 1.439, 1.942, 1.936, 1.4460000000000002, 0.9249999999999999, 0.482, 1.42, 1.927, 1.435, 1.954, 1.9409999999999998, 1.44, 1.8079999999999998, -0.135, 1.9, 0.45699999999999985, 1.939, 1.892, 1.959, 1.95, 0.06099999999999994, 1.947, 1.9369999999999998, 1.891, 1.922, 1.938, 1.9609999999999999, 1.958, 1.952, 0.905, 1.943, 1.432, 1.951, 1.9569999999999999, 1.4100000000000001, 1.407, 1.9609999999999999, 0.9299999999999999, -0.07899999999999996, 1.942, 1.96, 1.911, 0.9670000000000001, 1.9329999999999998, 1.749, 1.949, 1.955, 1.954, 0.44200000000000017, 0.43199999999999994, 1.9609999999999999, 1.948, 0.43100000000000005, 1.942, 1.931, 1.946, 1.923, 1.956, 1.9569999999999999, 0.952, 1.862, 1.851, 1.956, 1.907, 1.9369999999999998, 1.439, 0.43799999999999994, 1.4609999999999999, 1.934, 1.888, 0.43000000000000016, 1.9500000000000002], "episode_lengths": [18, 17, 21, 17, 18, 87, 7, 9, 17, 27, 13, 9, 32, 40, 13, 18, 15, 15, 14, 24, 16, 19, 21, 7, 20, 20, 18, 23, 15, 14, 11, 15, 11, 30, 29, 26, 16, 26, 16, 152, 29, 26, 35, 57, 22, 14, 34, 20, 24, 15, 23, 20, 24, 16, 22, 14, 47, 19, 14, 17, 21, 13, 17, 9, 14, 21, 20, 9, 14, 300, 25, 14, 18, 22, 20, 19, 20, 16, 300, 6, 25, 22, 21, 15, 19, 19, 59, 43, 32, 14, 18, 35, 13, 16, 296, 17, 19, 34, 24, 20, 13, 14, 15, 30, 18, 21, 16, 14, 28, 29, 13, 300, 25, 19, 13, 29, 11, 22, 78, 16, 15, 15, 19, 22, 13, 16, 20, 19, 22, 18, 24, 14, 14, 15, 43, 47, 14, 30, 20, 20, 20, 13, 21, 36, 22, 15], "policy_red_0_reward": [1.444, 1.4489999999999998, 1.436, 0.497, 1.444, 1.2309999999999999, 1.479, 0.973, 1.4489999999999998, 1.415, 1.4609999999999999, -0.5, 1.404, 1.377, 1.4609999999999999, 1.4449999999999998, 1.455, 1.454, 1.458, 1.427, 1.451, 1.443, 1.435, -0.5, 1.439, 1.438, 1.4449999999999998, 1.4300000000000002, 1.455, 1.458, 1.467, 1.454, 1.467, 1.408, 1.411, 1.4220000000000002, 1.452, 0.498, 1.452, 1.032, 1.413, 1.421, 1.392, 1.322, 1.4329999999999998, 1.458, 1.395, 1.439, 1.426, 1.4529999999999998, 1.429, 1.439, 0.5, 1.452, 1.432, 1.458, 0.495, 1.44, 1.458, 1.4489999999999998, 1.436, 0.5, 1.4489999999999998, 1.4729999999999999, 1.458, 0.9349999999999999, 1.439, 1.4729999999999999, -0.001, -0.03400000000000002, 0.496, 1.458, -0.501, 0.499, 1.44, 1.443, 1.44, 1.451, 0.46399999999999997, 0.982, 1.423, 1.4329999999999998, -0.001, 1.455, 1.443, 1.4409999999999998, 0.495, -1.0, 1.4020000000000001, 1.458, 1.444, 1.3940000000000001, 1.4609999999999999, 0.499, 0.586, 0.5, 1.44, 1.391, 1.426, 1.44, 0.5, 1.458, 1.455, 1.4100000000000001, 1.446, 1.434, 1.452, 1.4569999999999999, 1.4140000000000001, -0.003, 1.4609999999999999, 0.46299999999999997, 0.924, 1.442, 1.4609999999999999, 1.413, 1.467, 1.434, 0.494, 1.451, 0.5, 1.455, 1.443, 1.432, 0.5, 1.452, 0.9369999999999999, 1.443, 1.4329999999999998, 1.446, 1.4249999999999998, 1.458, 0.5, 1.455, 1.367, 1.355, 1.4569999999999999, 1.408, 0.5, 1.44, 1.438, 0.0, 1.4369999999999998, 1.3900000000000001, 1.432, 1.455], "policy_blue_0_reward": [0.498, 0.5, -1.005, 1.4489999999999998, 0.499, -0.507, -1.001, -0.502, 0.497, 0.0, 0.498, 0.973, 0.496, -1.002, 0.499, 0.499, 0.0, 0.498, 0.5, 0.499, -0.001, -0.001, -0.003, 1.479, 0.497, 0.498, 0.497, 0.499, 0.5, 0.5, -1.0, 0.499, -1.001, 0.497, 0.498, 0.498, 0.498, 1.42, 0.5, 0.475, 0.495, 0.496, -0.005, -0.009000000000000001, -0.002, 0.5, 0.497, 0.498, -0.002, 0.499, -0.003, -0.002, 1.426, 0.498, -0.503, -1.004, 1.347, 0.5, -0.003, 0.499, 0.5, 1.4609999999999999, -0.003, -0.5, 0.499, -0.501, 0.498, -1.002, 1.458, 0.45499999999999996, 1.4220000000000002, 0.499, 0.945, 1.432, -0.001, 0.499, 0.496, -0.005, 0.46099999999999997, -0.5, -0.003, 0.494, 1.436, 0.499, 0.498, -0.001, 1.313, 0.865, 0.498, -1.001, 0.495, 0.498, 0.498, 1.451, -0.525, 1.447, 0.497, 0.5, 0.496, 0.498, 1.4609999999999999, 0.5, 0.497, -0.505, 0.497, -0.002, 0.499, 0.5, -0.004, 1.4100000000000001, 0.5, 0.46699999999999997, -1.003, 0.5, 0.499, 0.498, -0.5, 0.499, 1.255, 0.498, 1.455, 0.499, -1.001, -1.0, 1.4609999999999999, 0.496, -0.5059999999999999, 0.499, 0.498, 0.5, 0.498, 0.498, 1.4569999999999999, -0.503, 0.495, 0.496, 0.499, 0.499, 1.4369999999999998, -0.001, -1.0, 1.4609999999999999, 0.497, 0.498, -1.0019999999999998, 0.495]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4122386004769718, "mean_inference_ms": 7.440330608745155, "mean_action_processing_ms": 0.3899798425479984, "mean_env_wait_ms": 0.5201754906824074, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1469092009818717, "StateBufferConnector_ms": 0.009640520566130338, "ViewRequirementAgentConnector_ms": 0.18527875207874872}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 856000, "num_agent_steps_trained": 856000, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 125.75837839698413, "num_env_steps_trained_throughput_per_sec": 125.75837839698413, "timesteps_total": 428000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 856000, "timers": {"training_iteration_time_ms": 31911.343, "sample_time_ms": 4114.428, "learn_time_ms": 27768.703, "learn_throughput": 144.047, "synch_weights_time_ms": 26.635}, "counters": {"num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 856000, "num_agent_steps_trained": 856000}, "done": false, "episodes_total": 7760, "training_iteration": 107, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-53-55", "timestamp": 1694840035, "time_this_iter_s": 31.82622528076172, "time_total_s": 3337.2593553066254, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219816c0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3337.2593553066254, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 26.395652173913046, "ram_util_percent": 57.16521739130432}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6048387096774194, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.14516129032258066, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08064516129032258, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.14516129032258066, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1532258064516129, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08064516129032258, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.14516129032258066, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08064516129032258, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5121298561493556, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04091732243759907, "policy_loss": -0.07641167396019834, "vf_loss": 0.0270877184617954, "vf_explained_var": 0.767168325309952, "kl": 0.01013411174502907, "entropy": 1.13628169229875, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 103200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5408508885962268, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05284267231230236, "policy_loss": -0.0919971183820356, "vf_loss": 0.03153892454429297, "vf_explained_var": 0.5639433827251196, "kl": 0.010902726030063073, "entropy": 1.4527894337972005, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 103200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.07100000000000006, "episode_reward_mean": 1.4829193548387096, "episode_len_mean": 29.153225806451612, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {"red_0": -1.008, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.466, "blue_0": 1.475}, "policy_reward_mean": {"red_0": 1.055258064516129, "blue_0": 0.4276612903225807}, "custom_metrics": {"red_0/door_open_done_mean": 0.6048387096774194, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.14516129032258066, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08064516129032258, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.14516129032258066, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1532258064516129, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08064516129032258, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.14516129032258066, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08064516129032258, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.3719999999999999, 1.9569999999999999, 1.4300000000000002, 0.956, 1.9489999999999998, 1.9569999999999999, 1.9280000000000002, 1.944, 1.904, 0.46799999999999997, 1.95, 1.956, 1.9300000000000002, 0.43799999999999994, -0.049000000000000044, 0.975, 1.938, 0.4249999999999998, 0.43599999999999994, 1.926, 1.424, 0.45100000000000007, 1.802, -0.06300000000000006, 1.95, -0.05699999999999994, 1.9489999999999998, 1.442, 1.393, 1.4609999999999999, 1.9569999999999999, 0.9279999999999999, 1.934, 0.47299999999999986, 1.926, 1.938, 0.5539999999999999, 1.942, 1.935, 1.955, 1.403, -0.07100000000000006, 1.954, 0.964, 0.4540000000000002, 1.9500000000000002, 1.887, 1.9489999999999998, 1.446, 1.427, 1.946, 1.4449999999999998, 0.45399999999999996, 0.43500000000000005, -0.03699999999999992, 1.942, 0.954, 1.935, 1.953, 1.424, 1.9449999999999998, 0.9489999999999998, 1.944, 1.95, 1.954, 0.5390000000000001, 1.9529999999999998, 1.9489999999999998, 0.96, -0.03200000000000003, 1.9449999999999998, 1.9569999999999999, 1.94, 1.951, 1.935, 1.417, 1.439, 1.935, 1.951, 1.951, 1.955, 1.915, 1.9380000000000002, 1.936, 1.948, 1.935, 1.96, 1.926, 1.44, 1.4409999999999998, 1.9529999999999998, -0.04800000000000004, 1.448, 0.964, 1.9609999999999999, 1.9489999999999998, 1.9529999999999998, 1.442, 1.952, 1.454, 0.962, 1.8820000000000001, 1.444, 1.929, 1.942, 1.431, 1.445, 1.952, 1.942, 1.444, -0.030000000000000027, 1.9569999999999999, 1.9180000000000001, 1.416, 1.952, 0.44299999999999995, 0.44799999999999995, 0.965, 1.954, 1.884, 1.9449999999999998, 1.951, 1.9300000000000002, 1.924], "episode_lengths": [41, 14, 23, 14, 17, 14, 23, 18, 30, 10, 16, 14, 23, 19, 16, 8, 20, 24, 20, 24, 179, 16, 61, 20, 16, 17, 16, 19, 33, 13, 14, 300, 21, 9, 24, 20, 291, 18, 21, 15, 31, 21, 15, 11, 14, 16, 35, 16, 18, 24, 18, 18, 15, 20, 12, 19, 14, 21, 15, 24, 18, 17, 18, 16, 15, 148, 15, 16, 300, 10, 18, 14, 20, 15, 21, 27, 20, 21, 16, 16, 15, 27, 18, 21, 17, 21, 13, 24, 19, 19, 15, 15, 17, 11, 13, 17, 15, 19, 15, 15, 12, 36, 18, 23, 18, 22, 17, 16, 19, 173, 10, 14, 25, 26, 16, 18, 16, 11, 15, 35, 18, 16, 23, 23], "policy_red_0_reward": [-0.004, 1.458, 1.4300000000000002, 1.458, 1.4489999999999998, 1.458, 1.431, 0.498, 1.4060000000000001, -1.001, 1.452, 1.458, 1.431, 1.443, 0.952, -0.5, 1.44, 1.428, -0.503, 1.427, 0.478, 1.452, 1.3119999999999998, 0.939, 1.452, 0.948, 1.451, 1.443, -0.002, 1.4609999999999999, 1.458, 0.45399999999999996, 1.436, 0.973, 0.5, 0.498, 0.581, 1.4449999999999998, 1.435, 1.455, -0.003, -1.008, 1.455, -0.501, 1.456, 1.451, 1.3940000000000001, 1.451, 1.446, 1.428, 0.5, 1.446, 1.455, 1.44, -1.0, 1.443, -0.501, 1.4369999999999998, 1.455, -0.001, 1.4449999999999998, 1.4489999999999998, 1.4449999999999998, 1.452, 0.5, 1.048, 1.455, 1.452, 0.49, 0.969, 1.4449999999999998, 1.458, 1.44, 1.455, 0.5, 1.4180000000000001, 1.439, 0.5, 1.452, 1.451, 1.455, 1.416, 1.443, 1.4369999999999998, 1.4489999999999998, 1.4369999999999998, 1.4609999999999999, 1.427, 1.443, 1.442, 0.498, 0.954, 1.4489999999999998, 1.466, 1.4609999999999999, 1.4489999999999998, 0.498, 1.442, 1.455, 1.455, -0.501, 1.3860000000000001, 1.4449999999999998, 1.4300000000000002, 1.446, 1.434, 1.4489999999999998, 1.452, 1.443, 0.478, 0.97, 0.499, 0.497, -0.004, 1.452, -0.5, 1.452, -0.502, 1.455, 0.492, 1.446, 1.451, 1.431, 1.428], "policy_blue_0_reward": [1.376, 0.499, 0.0, -0.5019999999999999, 0.5, 0.499, 0.497, 1.446, 0.498, 1.4689999999999999, 0.498, 0.498, 0.499, -1.005, -1.001, 1.475, 0.498, -1.003, 0.939, 0.499, 0.946, -1.001, 0.49, -1.002, 0.498, -1.005, 0.498, -0.001, 1.395, 0.0, 0.499, 0.474, 0.498, -0.5, 1.426, 1.44, -0.027000000000000017, 0.497, 0.5, 0.5, 1.4060000000000001, 0.9369999999999999, 0.499, 1.4649999999999999, -1.0019999999999998, 0.499, 0.493, 0.498, 0.0, -0.001, 1.446, -0.001, -1.001, -1.005, 0.963, 0.499, 1.455, 0.498, 0.498, 1.4249999999999998, 0.5, -0.5, 0.499, 0.498, 1.454, -0.5089999999999999, 0.498, 0.497, 0.47, -1.001, 0.5, 0.499, 0.5, 0.496, 1.435, -0.001, 0.0, 1.435, 0.499, 0.5, 0.5, 0.499, 0.495, 0.499, 0.499, 0.498, 0.499, 0.499, -0.003, -0.001, 1.455, -1.002, -0.001, -0.502, 0.5, 0.5, 1.455, 0.0, 0.497, -0.001, 1.463, 0.496, -0.001, 0.499, 0.496, -0.003, -0.004, 0.5, 0.499, 0.966, -1.0, 1.458, 1.421, 1.42, 0.5, 0.943, -1.004, 1.467, 0.499, 1.392, 0.499, 0.5, 0.499, 0.496]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4135041898519969, "mean_inference_ms": 7.446828819779107, "mean_action_processing_ms": 0.38922011051456806, "mean_env_wait_ms": 0.5212673838687504, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14238607498907274, "StateBufferConnector_ms": 0.009326108040348176, "ViewRequirementAgentConnector_ms": 0.18573643699769052}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.07100000000000006, "episode_reward_mean": 1.4829193548387096, "episode_len_mean": 29.153225806451612, "episodes_this_iter": 124, "policy_reward_min": {"red_0": -1.008, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.466, "blue_0": 1.475}, "policy_reward_mean": {"red_0": 1.055258064516129, "blue_0": 0.4276612903225807}, "hist_stats": {"episode_reward": [1.3719999999999999, 1.9569999999999999, 1.4300000000000002, 0.956, 1.9489999999999998, 1.9569999999999999, 1.9280000000000002, 1.944, 1.904, 0.46799999999999997, 1.95, 1.956, 1.9300000000000002, 0.43799999999999994, -0.049000000000000044, 0.975, 1.938, 0.4249999999999998, 0.43599999999999994, 1.926, 1.424, 0.45100000000000007, 1.802, -0.06300000000000006, 1.95, -0.05699999999999994, 1.9489999999999998, 1.442, 1.393, 1.4609999999999999, 1.9569999999999999, 0.9279999999999999, 1.934, 0.47299999999999986, 1.926, 1.938, 0.5539999999999999, 1.942, 1.935, 1.955, 1.403, -0.07100000000000006, 1.954, 0.964, 0.4540000000000002, 1.9500000000000002, 1.887, 1.9489999999999998, 1.446, 1.427, 1.946, 1.4449999999999998, 0.45399999999999996, 0.43500000000000005, -0.03699999999999992, 1.942, 0.954, 1.935, 1.953, 1.424, 1.9449999999999998, 0.9489999999999998, 1.944, 1.95, 1.954, 0.5390000000000001, 1.9529999999999998, 1.9489999999999998, 0.96, -0.03200000000000003, 1.9449999999999998, 1.9569999999999999, 1.94, 1.951, 1.935, 1.417, 1.439, 1.935, 1.951, 1.951, 1.955, 1.915, 1.9380000000000002, 1.936, 1.948, 1.935, 1.96, 1.926, 1.44, 1.4409999999999998, 1.9529999999999998, -0.04800000000000004, 1.448, 0.964, 1.9609999999999999, 1.9489999999999998, 1.9529999999999998, 1.442, 1.952, 1.454, 0.962, 1.8820000000000001, 1.444, 1.929, 1.942, 1.431, 1.445, 1.952, 1.942, 1.444, -0.030000000000000027, 1.9569999999999999, 1.9180000000000001, 1.416, 1.952, 0.44299999999999995, 0.44799999999999995, 0.965, 1.954, 1.884, 1.9449999999999998, 1.951, 1.9300000000000002, 1.924], "episode_lengths": [41, 14, 23, 14, 17, 14, 23, 18, 30, 10, 16, 14, 23, 19, 16, 8, 20, 24, 20, 24, 179, 16, 61, 20, 16, 17, 16, 19, 33, 13, 14, 300, 21, 9, 24, 20, 291, 18, 21, 15, 31, 21, 15, 11, 14, 16, 35, 16, 18, 24, 18, 18, 15, 20, 12, 19, 14, 21, 15, 24, 18, 17, 18, 16, 15, 148, 15, 16, 300, 10, 18, 14, 20, 15, 21, 27, 20, 21, 16, 16, 15, 27, 18, 21, 17, 21, 13, 24, 19, 19, 15, 15, 17, 11, 13, 17, 15, 19, 15, 15, 12, 36, 18, 23, 18, 22, 17, 16, 19, 173, 10, 14, 25, 26, 16, 18, 16, 11, 15, 35, 18, 16, 23, 23], "policy_red_0_reward": [-0.004, 1.458, 1.4300000000000002, 1.458, 1.4489999999999998, 1.458, 1.431, 0.498, 1.4060000000000001, -1.001, 1.452, 1.458, 1.431, 1.443, 0.952, -0.5, 1.44, 1.428, -0.503, 1.427, 0.478, 1.452, 1.3119999999999998, 0.939, 1.452, 0.948, 1.451, 1.443, -0.002, 1.4609999999999999, 1.458, 0.45399999999999996, 1.436, 0.973, 0.5, 0.498, 0.581, 1.4449999999999998, 1.435, 1.455, -0.003, -1.008, 1.455, -0.501, 1.456, 1.451, 1.3940000000000001, 1.451, 1.446, 1.428, 0.5, 1.446, 1.455, 1.44, -1.0, 1.443, -0.501, 1.4369999999999998, 1.455, -0.001, 1.4449999999999998, 1.4489999999999998, 1.4449999999999998, 1.452, 0.5, 1.048, 1.455, 1.452, 0.49, 0.969, 1.4449999999999998, 1.458, 1.44, 1.455, 0.5, 1.4180000000000001, 1.439, 0.5, 1.452, 1.451, 1.455, 1.416, 1.443, 1.4369999999999998, 1.4489999999999998, 1.4369999999999998, 1.4609999999999999, 1.427, 1.443, 1.442, 0.498, 0.954, 1.4489999999999998, 1.466, 1.4609999999999999, 1.4489999999999998, 0.498, 1.442, 1.455, 1.455, -0.501, 1.3860000000000001, 1.4449999999999998, 1.4300000000000002, 1.446, 1.434, 1.4489999999999998, 1.452, 1.443, 0.478, 0.97, 0.499, 0.497, -0.004, 1.452, -0.5, 1.452, -0.502, 1.455, 0.492, 1.446, 1.451, 1.431, 1.428], "policy_blue_0_reward": [1.376, 0.499, 0.0, -0.5019999999999999, 0.5, 0.499, 0.497, 1.446, 0.498, 1.4689999999999999, 0.498, 0.498, 0.499, -1.005, -1.001, 1.475, 0.498, -1.003, 0.939, 0.499, 0.946, -1.001, 0.49, -1.002, 0.498, -1.005, 0.498, -0.001, 1.395, 0.0, 0.499, 0.474, 0.498, -0.5, 1.426, 1.44, -0.027000000000000017, 0.497, 0.5, 0.5, 1.4060000000000001, 0.9369999999999999, 0.499, 1.4649999999999999, -1.0019999999999998, 0.499, 0.493, 0.498, 0.0, -0.001, 1.446, -0.001, -1.001, -1.005, 0.963, 0.499, 1.455, 0.498, 0.498, 1.4249999999999998, 0.5, -0.5, 0.499, 0.498, 1.454, -0.5089999999999999, 0.498, 0.497, 0.47, -1.001, 0.5, 0.499, 0.5, 0.496, 1.435, -0.001, 0.0, 1.435, 0.499, 0.5, 0.5, 0.499, 0.495, 0.499, 0.499, 0.498, 0.499, 0.499, -0.003, -0.001, 1.455, -1.002, -0.001, -0.502, 0.5, 0.5, 1.455, 0.0, 0.497, -0.001, 1.463, 0.496, -0.001, 0.499, 0.496, -0.003, -0.004, 0.5, 0.499, 0.966, -1.0, 1.458, 1.421, 1.42, 0.5, 0.943, -1.004, 1.467, 0.499, 1.392, 0.499, 0.5, 0.499, 0.496]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4135041898519969, "mean_inference_ms": 7.446828819779107, "mean_action_processing_ms": 0.38922011051456806, "mean_env_wait_ms": 0.5212673838687504, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14238607498907274, "StateBufferConnector_ms": 0.009326108040348176, "ViewRequirementAgentConnector_ms": 0.18573643699769052}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.49197303449972, "num_env_steps_trained_throughput_per_sec": 131.49197303449972, "timesteps_total": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 31783.353, "sample_time_ms": 4087.063, "learn_time_ms": 27667.928, "learn_throughput": 144.572, "synch_weights_time_ms": 26.831}, "counters": {"num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "episodes_total": 7884, "training_iteration": 108, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-54-26", "timestamp": 1694840066, "time_this_iter_s": 30.43829607963562, "time_total_s": 3367.697651386261, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219b57e0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3367.697651386261, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 24.35454545454545, "ram_util_percent": 57.12954545454545}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6074074074074074, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.1111111111111111, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07407407407407407, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.1111111111111111, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.17777777777777778, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.07407407407407407, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.1111111111111111, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07407407407407407, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5356070787956317, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04314060433001335, "policy_loss": -0.08246387864298109, "vf_loss": 0.030253058457553075, "vf_explained_var": 0.736709228095909, "kl": 0.011101464694633079, "entropy": 1.0937796272337437, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 104160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5545939558806519, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.050780447252327575, "policy_loss": -0.09161916984885465, "vf_loss": 0.032600917873787695, "vf_explained_var": 0.5573856875300407, "kl": 0.011393501954147697, "entropy": 1.417557748903831, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 104160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 872000, "num_agent_steps_trained": 872000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.18900000000000006, "episode_reward_mean": 1.556562962962963, "episode_len_mean": 30.266666666666666, "episode_media": {}, "episodes_this_iter": 135, "policy_reward_min": {"red_0": -1.021, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.467, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 1.0352962962962962, "blue_0": 0.5212666666666668}, "custom_metrics": {"red_0/door_open_done_mean": 0.6074074074074074, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.1111111111111111, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07407407407407407, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.1111111111111111, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.17777777777777778, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.07407407407407407, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.1111111111111111, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07407407407407407, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.43099999999999994, 1.409, 1.942, 1.4529999999999998, 1.958, 1.916, 1.96, 0.9630000000000001, 1.8980000000000001, 1.9289999999999998, 1.455, 1.9569999999999999, 1.948, 1.95, 0.45399999999999996, 1.938, 1.947, 1.932, 0.45799999999999996, 0.44699999999999995, 1.941, 1.389, 1.952, 1.958, 1.954, 1.954, 1.896, 0.9069999999999999, 1.8119999999999998, 1.444, 1.442, 1.428, 0.9489999999999998, 1.412, 1.3860000000000001, 1.935, 1.448, 1.899, 1.958, 1.926, 1.954, 1.9489999999999998, 1.96, 1.9300000000000002, 0.47, 0.969, 1.9220000000000002, 0.45299999999999996, 1.9409999999999998, 1.9449999999999998, 0.9650000000000001, 1.9409999999999998, 1.4609999999999999, 1.443, 1.955, 1.857, -0.15200000000000002, 1.944, 1.923, 0.909, 0.942, 1.947, 1.952, 1.948, 1.839, 0.45999999999999996, 1.96, 1.944, 1.954, 1.944, 1.396, 1.941, 0.9199999999999999, 1.955, 1.452, 1.454, 1.938, 1.444, 1.4329999999999998, 0.46799999999999997, 1.9130000000000003, 0.9510000000000001, 1.95, -0.02199999999999991, 1.4529999999999998, 0.46599999999999997, 1.93, 1.934, 1.944, 1.88, 1.952, 1.9569999999999999, 1.45, 1.947, 1.451, 1.923, 1.9609999999999999, 1.94, 1.443, 1.95, 1.944, 1.935, 1.944, 1.892, 1.917, 0.44799999999999995, -0.18900000000000006, 0.45699999999999996, 0.946, 1.9569999999999999, 1.4369999999999998, 1.901, 1.9020000000000001, 1.95, 1.948, 0.43699999999999983, 0.9329999999999999, 1.926, 1.8940000000000001, 0.9020000000000001, 0.476, 0.389, 1.952, 1.954, 1.9529999999999998, 1.954, 1.9369999999999998, 1.94, 1.9569999999999999, 1.258, 1.931, 1.952, 1.917, 1.9409999999999998, 1.4060000000000001], "episode_lengths": [300, 28, 18, 15, 14, 26, 13, 12, 32, 22, 15, 14, 17, 16, 15, 20, 17, 22, 14, 16, 19, 35, 16, 14, 15, 15, 32, 300, 59, 17, 19, 23, 17, 28, 36, 21, 17, 32, 14, 24, 15, 17, 13, 22, 10, 10, 25, 15, 19, 18, 11, 19, 13, 17, 14, 45, 203, 18, 24, 28, 300, 17, 15, 17, 51, 13, 13, 18, 15, 18, 33, 18, 26, 14, 15, 15, 19, 17, 22, 10, 27, 16, 16, 7, 15, 11, 22, 21, 18, 38, 16, 14, 16, 17, 15, 24, 13, 19, 18, 16, 18, 21, 17, 35, 26, 17, 60, 14, 17, 14, 20, 31, 31, 16, 17, 20, 300, 24, 34, 30, 8, 35, 15, 15, 15, 15, 20, 19, 14, 75, 22, 15, 27, 19, 30], "policy_red_0_reward": [-0.03200000000000002, -0.003, 1.4449999999999998, 1.454, 1.458, 1.42, 1.4609999999999999, 1.464, 1.403, 1.432, 0.0, 1.458, 1.4489999999999998, 1.45, 1.455, 1.438, 1.4489999999999998, 0.498, -1.0, -0.502, 1.442, 1.393, 1.452, 1.458, 1.455, 1.455, 0.497, 0.45099999999999996, 0.494, 1.447, 1.442, 1.431, 1.4489999999999998, -0.001, 1.388, 1.4369999999999998, 1.4489999999999998, 1.401, 0.5, 0.5, 1.455, 1.4489999999999998, 1.4609999999999999, 1.4329999999999998, -1.0, -0.5, 0.5, -0.5, 0.499, 0.5, 1.467, 1.443, 1.4609999999999999, 1.4489999999999998, 1.458, 1.363, -1.021, 1.4449999999999998, 1.427, 1.412, 0.469, 1.4489999999999998, 1.455, 1.4489999999999998, 1.3439999999999999, 0.96, 1.4609999999999999, 1.4449999999999998, 1.455, 1.4449999999999998, 1.4, 1.446, 1.421, 1.458, 1.455, 1.455, 1.4409999999999998, -0.004, 1.434, 0.97, 1.4180000000000001, 1.452, 1.452, -1.0, 1.455, -0.5, 1.43, 1.4369999999999998, 1.4449999999999998, 1.381, 1.452, 0.499, 1.451, 1.4489999999999998, 1.4529999999999998, 0.498, 0.5, 0.498, 1.446, 1.452, 1.4449999999999998, 1.4369999999999998, 0.498, 0.5, 1.419, 1.4489999999999998, 0.816, -0.501, -0.503, 1.4569999999999999, -0.001, 1.4060000000000001, 1.407, 1.452, 1.448, 0.939, 0.45599999999999996, 1.427, 1.395, 1.408, 0.976, 0.891, 0.498, 1.455, 1.455, 0.5, 1.439, 0.498, 1.458, -0.010000000000000002, 1.432, 1.455, 0.5, 1.442, 1.408], "policy_blue_0_reward": [0.46299999999999997, 1.412, 0.497, -0.001, 0.5, 0.496, 0.499, -0.501, 0.495, 0.497, 1.455, 0.499, 0.499, 0.5, -1.001, 0.5, 0.498, 1.434, 1.458, 0.949, 0.499, -0.004, 0.5, 0.5, 0.499, 0.499, 1.399, 0.45599999999999996, 1.318, -0.003, 0.0, -0.003, -0.5, 1.413, -0.002, 0.498, -0.001, 0.498, 1.458, 1.426, 0.499, 0.5, 0.499, 0.497, 1.47, 1.4689999999999999, 1.4220000000000002, 0.953, 1.442, 1.4449999999999998, -0.5019999999999999, 0.498, 0.0, -0.006, 0.497, 0.494, 0.869, 0.499, 0.496, -0.503, 0.473, 0.498, 0.497, 0.499, 0.495, -0.5, 0.499, 0.499, 0.499, 0.499, -0.004, 0.495, -0.501, 0.497, -0.003, -0.001, 0.497, 1.448, -0.001, -0.502, 0.495, -0.501, 0.498, 0.978, -0.002, 0.966, 0.5, 0.497, 0.499, 0.499, 0.5, 1.458, -0.001, 0.498, -0.002, 1.4249999999999998, 1.4609999999999999, 1.442, -0.003, 0.498, 0.499, 0.498, 1.446, 1.392, 0.498, -1.001, -1.005, 0.958, 1.4489999999999998, 0.5, 1.438, 0.495, 0.495, 0.498, 0.5, -0.502, 0.477, 0.499, 0.499, -0.506, -0.5, -0.502, 1.454, 0.499, 0.498, 1.454, 0.498, 1.442, 0.499, 1.268, 0.499, 0.497, 1.417, 0.499, -0.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4151823351278132, "mean_inference_ms": 7.444009468856679, "mean_action_processing_ms": 0.3905782608229723, "mean_env_wait_ms": 0.5203441055387272, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15551258016515662, "StateBufferConnector_ms": 0.010258356730143229, "ViewRequirementAgentConnector_ms": 0.2180098604272913}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.18900000000000006, "episode_reward_mean": 1.556562962962963, "episode_len_mean": 30.266666666666666, "episodes_this_iter": 135, "policy_reward_min": {"red_0": -1.021, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.467, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 1.0352962962962962, "blue_0": 0.5212666666666668}, "hist_stats": {"episode_reward": [0.43099999999999994, 1.409, 1.942, 1.4529999999999998, 1.958, 1.916, 1.96, 0.9630000000000001, 1.8980000000000001, 1.9289999999999998, 1.455, 1.9569999999999999, 1.948, 1.95, 0.45399999999999996, 1.938, 1.947, 1.932, 0.45799999999999996, 0.44699999999999995, 1.941, 1.389, 1.952, 1.958, 1.954, 1.954, 1.896, 0.9069999999999999, 1.8119999999999998, 1.444, 1.442, 1.428, 0.9489999999999998, 1.412, 1.3860000000000001, 1.935, 1.448, 1.899, 1.958, 1.926, 1.954, 1.9489999999999998, 1.96, 1.9300000000000002, 0.47, 0.969, 1.9220000000000002, 0.45299999999999996, 1.9409999999999998, 1.9449999999999998, 0.9650000000000001, 1.9409999999999998, 1.4609999999999999, 1.443, 1.955, 1.857, -0.15200000000000002, 1.944, 1.923, 0.909, 0.942, 1.947, 1.952, 1.948, 1.839, 0.45999999999999996, 1.96, 1.944, 1.954, 1.944, 1.396, 1.941, 0.9199999999999999, 1.955, 1.452, 1.454, 1.938, 1.444, 1.4329999999999998, 0.46799999999999997, 1.9130000000000003, 0.9510000000000001, 1.95, -0.02199999999999991, 1.4529999999999998, 0.46599999999999997, 1.93, 1.934, 1.944, 1.88, 1.952, 1.9569999999999999, 1.45, 1.947, 1.451, 1.923, 1.9609999999999999, 1.94, 1.443, 1.95, 1.944, 1.935, 1.944, 1.892, 1.917, 0.44799999999999995, -0.18900000000000006, 0.45699999999999996, 0.946, 1.9569999999999999, 1.4369999999999998, 1.901, 1.9020000000000001, 1.95, 1.948, 0.43699999999999983, 0.9329999999999999, 1.926, 1.8940000000000001, 0.9020000000000001, 0.476, 0.389, 1.952, 1.954, 1.9529999999999998, 1.954, 1.9369999999999998, 1.94, 1.9569999999999999, 1.258, 1.931, 1.952, 1.917, 1.9409999999999998, 1.4060000000000001], "episode_lengths": [300, 28, 18, 15, 14, 26, 13, 12, 32, 22, 15, 14, 17, 16, 15, 20, 17, 22, 14, 16, 19, 35, 16, 14, 15, 15, 32, 300, 59, 17, 19, 23, 17, 28, 36, 21, 17, 32, 14, 24, 15, 17, 13, 22, 10, 10, 25, 15, 19, 18, 11, 19, 13, 17, 14, 45, 203, 18, 24, 28, 300, 17, 15, 17, 51, 13, 13, 18, 15, 18, 33, 18, 26, 14, 15, 15, 19, 17, 22, 10, 27, 16, 16, 7, 15, 11, 22, 21, 18, 38, 16, 14, 16, 17, 15, 24, 13, 19, 18, 16, 18, 21, 17, 35, 26, 17, 60, 14, 17, 14, 20, 31, 31, 16, 17, 20, 300, 24, 34, 30, 8, 35, 15, 15, 15, 15, 20, 19, 14, 75, 22, 15, 27, 19, 30], "policy_red_0_reward": [-0.03200000000000002, -0.003, 1.4449999999999998, 1.454, 1.458, 1.42, 1.4609999999999999, 1.464, 1.403, 1.432, 0.0, 1.458, 1.4489999999999998, 1.45, 1.455, 1.438, 1.4489999999999998, 0.498, -1.0, -0.502, 1.442, 1.393, 1.452, 1.458, 1.455, 1.455, 0.497, 0.45099999999999996, 0.494, 1.447, 1.442, 1.431, 1.4489999999999998, -0.001, 1.388, 1.4369999999999998, 1.4489999999999998, 1.401, 0.5, 0.5, 1.455, 1.4489999999999998, 1.4609999999999999, 1.4329999999999998, -1.0, -0.5, 0.5, -0.5, 0.499, 0.5, 1.467, 1.443, 1.4609999999999999, 1.4489999999999998, 1.458, 1.363, -1.021, 1.4449999999999998, 1.427, 1.412, 0.469, 1.4489999999999998, 1.455, 1.4489999999999998, 1.3439999999999999, 0.96, 1.4609999999999999, 1.4449999999999998, 1.455, 1.4449999999999998, 1.4, 1.446, 1.421, 1.458, 1.455, 1.455, 1.4409999999999998, -0.004, 1.434, 0.97, 1.4180000000000001, 1.452, 1.452, -1.0, 1.455, -0.5, 1.43, 1.4369999999999998, 1.4449999999999998, 1.381, 1.452, 0.499, 1.451, 1.4489999999999998, 1.4529999999999998, 0.498, 0.5, 0.498, 1.446, 1.452, 1.4449999999999998, 1.4369999999999998, 0.498, 0.5, 1.419, 1.4489999999999998, 0.816, -0.501, -0.503, 1.4569999999999999, -0.001, 1.4060000000000001, 1.407, 1.452, 1.448, 0.939, 0.45599999999999996, 1.427, 1.395, 1.408, 0.976, 0.891, 0.498, 1.455, 1.455, 0.5, 1.439, 0.498, 1.458, -0.010000000000000002, 1.432, 1.455, 0.5, 1.442, 1.408], "policy_blue_0_reward": [0.46299999999999997, 1.412, 0.497, -0.001, 0.5, 0.496, 0.499, -0.501, 0.495, 0.497, 1.455, 0.499, 0.499, 0.5, -1.001, 0.5, 0.498, 1.434, 1.458, 0.949, 0.499, -0.004, 0.5, 0.5, 0.499, 0.499, 1.399, 0.45599999999999996, 1.318, -0.003, 0.0, -0.003, -0.5, 1.413, -0.002, 0.498, -0.001, 0.498, 1.458, 1.426, 0.499, 0.5, 0.499, 0.497, 1.47, 1.4689999999999999, 1.4220000000000002, 0.953, 1.442, 1.4449999999999998, -0.5019999999999999, 0.498, 0.0, -0.006, 0.497, 0.494, 0.869, 0.499, 0.496, -0.503, 0.473, 0.498, 0.497, 0.499, 0.495, -0.5, 0.499, 0.499, 0.499, 0.499, -0.004, 0.495, -0.501, 0.497, -0.003, -0.001, 0.497, 1.448, -0.001, -0.502, 0.495, -0.501, 0.498, 0.978, -0.002, 0.966, 0.5, 0.497, 0.499, 0.499, 0.5, 1.458, -0.001, 0.498, -0.002, 1.4249999999999998, 1.4609999999999999, 1.442, -0.003, 0.498, 0.499, 0.498, 1.446, 1.392, 0.498, -1.001, -1.005, 0.958, 1.4489999999999998, 0.5, 1.438, 0.495, 0.495, 0.498, 0.5, -0.502, 0.477, 0.499, 0.499, -0.506, -0.5, -0.502, 1.454, 0.499, 0.498, 1.454, 0.498, 1.442, 0.499, 1.268, 0.499, 0.497, 1.417, 0.499, -0.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4151823351278132, "mean_inference_ms": 7.444009468856679, "mean_action_processing_ms": 0.3905782608229723, "mean_env_wait_ms": 0.5203441055387272, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15551258016515662, "StateBufferConnector_ms": 0.010258356730143229, "ViewRequirementAgentConnector_ms": 0.2180098604272913}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 872000, "num_agent_steps_trained": 872000, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.31727819152388, "num_env_steps_trained_throughput_per_sec": 127.31727819152388, "timesteps_total": 436000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 872000, "timers": {"training_iteration_time_ms": 31841.927, "sample_time_ms": 4123.928, "learn_time_ms": 27688.752, "learn_throughput": 144.463, "synch_weights_time_ms": 27.699}, "counters": {"num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 872000, "num_agent_steps_trained": 872000}, "done": false, "episodes_total": 8019, "training_iteration": 109, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-54-58", "timestamp": 1694840098, "time_this_iter_s": 31.439574003219604, "time_total_s": 3399.1372253894806, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f5d80>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3399.1372253894806, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 25.26086956521739, "ram_util_percent": 57.160869565217375}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.575, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.16875, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09375, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.16875, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1375, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09375, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.16875, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09375, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5246205435755352, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.030486596569729348, "policy_loss": -0.07339964083002996, "vf_loss": 0.042206336962408386, "vf_explained_var": 0.6903583727777004, "kl": 0.010006361662544806, "entropy": 0.9858674154306452, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 105120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5539959169613818, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.047048824828137485, "policy_loss": -0.09175163304850381, "vf_loss": 0.041757891658926384, "vf_explained_var": 0.5222559303045273, "kl": 0.011066296900510527, "entropy": 1.386545236284534, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 105120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06200000000000005, "episode_reward_mean": 1.42071875, "episode_len_mean": 27.31875, "episode_media": {}, "episodes_this_iter": 160, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 1.03445, "blue_0": 0.38626875}, "custom_metrics": {"red_0/door_open_done_mean": 0.575, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.16875, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09375, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.16875, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1375, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09375, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.16875, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09375, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.45199999999999996, 1.9609999999999999, 1.954, 1.94, 0.44899999999999995, 1.958, 1.424, -0.06200000000000005, 1.451, 1.9180000000000001, 1.952, 1.937, 1.955, 1.455, 1.9609999999999999, 0.9609999999999999, 0.46299999999999997, 1.956, 1.956, 1.917, 0.44700000000000006, 1.432, 0.45499999999999996, 1.932, 0.41500000000000004, 1.431, 1.321, -0.04700000000000004, 1.916, 1.4369999999999998, 1.96, 1.4409999999999998, 1.9449999999999998, 0.962, 1.452, 1.93, 0.9630000000000001, 1.939, 1.9569999999999999, 1.929, 1.9529999999999998, 1.4329999999999998, 1.9569999999999999, 1.958, 0.4750000000000001, 1.903, 1.4489999999999998, 0.913, 1.8679999999999999, 1.916, 0.5429999999999999, 1.9449999999999998, 0.9710000000000001, 1.956, 0.9420000000000001, 0.44699999999999995, 1.959, 1.458, 1.912, 0.9630000000000001, 0.976, 1.943, 1.438, 1.9489999999999998, 1.952, 1.9100000000000001, 1.458, 0.9609999999999999, 1.923, 0.923, 1.955, -0.029000000000000026, 0.944, 1.44, 1.934, 0.946, 0.44199999999999995, 1.946, 1.955, 0.9550000000000001, 1.887, 1.905, 1.939, 1.9220000000000002, 0.46199999999999997, 0.918, 0.45999999999999996, 1.4609999999999999, 1.4540000000000002, 1.924, -0.039000000000000035, 0.96, 1.9569999999999999, 1.947, 1.409, 1.447, 1.8780000000000001, 1.451, 1.96, 0.45399999999999996, 0.978, 1.935, 1.411, 1.853, 1.392, 0.45799999999999996, 1.949, -0.030000000000000027, 1.9449999999999998, 0.9689999999999999, 1.951, 1.396, 0.9249999999999999, 1.211, 0.46199999999999997, 1.429, 1.442, 1.9569999999999999, 1.458, 1.955, 1.955, 1.9409999999999998, 1.423, 1.447, 1.94, 1.96, 1.9609999999999999, 1.452, 0.45500000000000007, 1.954, 1.948, 1.912, 1.395, 1.4180000000000001, 0.1280000000000001, 1.9369999999999998, -0.05000000000000004, 1.947, 1.4609999999999999, 1.4529999999999998, 1.951, 1.952, 1.9609999999999999, 1.921, 1.9609999999999999, 1.943, 1.923, -0.051000000000000045, 1.9180000000000001, 1.4529999999999998, 0.482, 1.447, 1.947, 0.44300000000000006, 1.443, -0.02199999999999991, 1.935, 1.927, -0.03200000000000003, 1.9569999999999999], "episode_lengths": [300, 13, 14, 19, 16, 14, 23, 300, 16, 26, 15, 20, 15, 14, 13, 13, 12, 14, 14, 26, 17, 22, 15, 22, 27, 22, 57, 14, 27, 20, 13, 19, 18, 12, 16, 22, 12, 19, 14, 23, 15, 22, 14, 14, 8, 31, 17, 29, 42, 27, 143, 18, 9, 14, 18, 17, 13, 14, 28, 12, 8, 18, 20, 16, 16, 29, 13, 13, 25, 25, 15, 9, 18, 19, 20, 17, 17, 18, 15, 14, 36, 30, 20, 25, 12, 26, 13, 13, 13, 24, 12, 13, 14, 17, 29, 17, 38, 15, 13, 15, 7, 21, 27, 44, 33, 12, 16, 10, 18, 10, 16, 32, 300, 89, 12, 23, 18, 14, 14, 14, 15, 19, 25, 17, 19, 13, 13, 16, 15, 15, 17, 28, 34, 26, 116, 20, 300, 17, 13, 15, 16, 16, 13, 25, 13, 18, 25, 15, 26, 15, 6, 17, 17, 18, 19, 7, 21, 24, 10, 14], "policy_red_0_reward": [-0.02100000000000001, 1.4609999999999999, 0.496, 1.442, -0.502, 1.458, 1.428, -0.024000000000000014, 1.452, 1.4220000000000002, 1.454, 1.439, 1.455, 1.458, 0.5, 1.4609999999999999, -0.5, 1.458, 1.458, 1.4220000000000002, -0.5009999999999999, 0.0, -0.5, 1.432, 1.4180000000000001, 1.434, -0.005, 0.958, 1.4180000000000001, 1.439, 1.4609999999999999, 1.443, 1.4449999999999998, 1.464, 0.0, 0.497, 1.464, 1.443, 0.499, 1.429, 1.455, 1.434, 1.458, 0.5, 0.975, 1.4060000000000001, 1.4489999999999998, -0.5, 1.373, 1.417, 1.053, 1.446, 1.472, 1.458, -0.5019999999999999, -0.5, 1.4609999999999999, 1.458, 1.415, 1.464, 1.476, 1.444, 1.439, 0.499, 1.452, 1.413, 1.4609999999999999, 1.4609999999999999, 1.424, -0.501, 1.455, 0.973, 1.4449999999999998, 1.442, 1.44, -0.501, 1.446, 0.5, 1.455, 1.458, 1.3900000000000001, 1.408, 1.44, 1.425, 0.963, -0.501, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.426, 0.963, 1.4609999999999999, 1.458, 1.4489999999999998, -0.004, 1.448, 0.496, 1.4529999999999998, 1.4609999999999999, 1.454, 1.479, 1.436, 1.413, 0.492, 1.397, -0.501, 1.451, 0.97, 1.446, 1.47, 1.452, -0.003, 0.45499999999999996, 1.2229999999999999, 1.464, 1.431, 1.4449999999999998, 1.458, 1.458, 1.4569999999999999, 1.455, 1.443, 1.425, 1.448, 1.443, 1.4609999999999999, 1.4609999999999999, 1.452, 0.955, 1.455, 1.4489999999999998, 1.415, 1.397, -0.001, 0.639, 0.499, -0.025000000000000015, 1.4489999999999998, 1.4609999999999999, 1.455, 1.452, 0.5, 1.4609999999999999, 0.499, 1.4609999999999999, 1.446, 0.499, -1.004, 1.421, 1.455, -0.5, 0.0, 1.448, 0.945, 1.443, -1.0, 0.499, 0.5, -1.001, 1.458], "policy_blue_0_reward": [0.473, 0.5, 1.458, 0.498, 0.951, 0.5, -0.004, -0.03800000000000003, -0.001, 0.496, 0.498, 0.498, 0.5, -0.003, 1.4609999999999999, -0.5, 0.963, 0.498, 0.498, 0.495, 0.948, 1.432, 0.955, 0.5, -1.003, -0.003, 1.326, -1.005, 0.498, -0.002, 0.499, -0.002, 0.5, -0.502, 1.452, 1.4329999999999998, -0.501, 0.496, 1.458, 0.5, 0.498, -0.001, 0.499, 1.458, -0.5, 0.497, 0.0, 1.413, 0.495, 0.499, -0.51, 0.499, -0.501, 0.498, 1.444, 0.947, 0.498, 0.0, 0.497, -0.501, -0.5, 0.499, -0.001, 1.45, 0.5, 0.497, -0.003, -0.5, 0.499, 1.424, 0.5, -1.002, -0.501, -0.002, 0.494, 1.447, -1.004, 1.446, 0.5, -0.503, 0.497, 0.497, 0.499, 0.497, -0.501, 1.419, -1.001, 0.0, -0.007, 0.498, -1.002, -0.5009999999999999, 0.499, 0.498, 1.413, -0.001, 1.3820000000000001, -0.002, 0.499, -1.0, -0.501, 0.499, -0.002, 1.361, -0.005, 0.959, 0.498, -1.0, 0.499, -0.501, 0.499, 1.399, 0.47, -0.012000000000000004, -1.002, -0.002, -0.003, 0.499, 0.0, 0.498, 0.5, 0.498, -0.002, -0.001, 0.497, 0.499, 0.5, 0.0, -0.5, 0.499, 0.499, 0.497, -0.002, 1.419, -0.511, 1.438, -0.025000000000000015, 0.498, 0.0, -0.002, 0.499, 1.452, 0.5, 1.4220000000000002, 0.5, 0.497, 1.424, 0.953, 0.497, -0.002, 0.982, 1.447, 0.499, -0.502, 0.0, 0.978, 1.436, 1.427, 0.969, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4156061168020524, "mean_inference_ms": 7.453381001159566, "mean_action_processing_ms": 0.38955347511199995, "mean_env_wait_ms": 0.5209986868128121, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14243222773075104, "StateBufferConnector_ms": 0.00969327986240387, "ViewRequirementAgentConnector_ms": 0.1913405954837799}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06200000000000005, "episode_reward_mean": 1.42071875, "episode_len_mean": 27.31875, "episodes_this_iter": 160, "policy_reward_min": {"red_0": -1.004, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 1.03445, "blue_0": 0.38626875}, "hist_stats": {"episode_reward": [0.45199999999999996, 1.9609999999999999, 1.954, 1.94, 0.44899999999999995, 1.958, 1.424, -0.06200000000000005, 1.451, 1.9180000000000001, 1.952, 1.937, 1.955, 1.455, 1.9609999999999999, 0.9609999999999999, 0.46299999999999997, 1.956, 1.956, 1.917, 0.44700000000000006, 1.432, 0.45499999999999996, 1.932, 0.41500000000000004, 1.431, 1.321, -0.04700000000000004, 1.916, 1.4369999999999998, 1.96, 1.4409999999999998, 1.9449999999999998, 0.962, 1.452, 1.93, 0.9630000000000001, 1.939, 1.9569999999999999, 1.929, 1.9529999999999998, 1.4329999999999998, 1.9569999999999999, 1.958, 0.4750000000000001, 1.903, 1.4489999999999998, 0.913, 1.8679999999999999, 1.916, 0.5429999999999999, 1.9449999999999998, 0.9710000000000001, 1.956, 0.9420000000000001, 0.44699999999999995, 1.959, 1.458, 1.912, 0.9630000000000001, 0.976, 1.943, 1.438, 1.9489999999999998, 1.952, 1.9100000000000001, 1.458, 0.9609999999999999, 1.923, 0.923, 1.955, -0.029000000000000026, 0.944, 1.44, 1.934, 0.946, 0.44199999999999995, 1.946, 1.955, 0.9550000000000001, 1.887, 1.905, 1.939, 1.9220000000000002, 0.46199999999999997, 0.918, 0.45999999999999996, 1.4609999999999999, 1.4540000000000002, 1.924, -0.039000000000000035, 0.96, 1.9569999999999999, 1.947, 1.409, 1.447, 1.8780000000000001, 1.451, 1.96, 0.45399999999999996, 0.978, 1.935, 1.411, 1.853, 1.392, 0.45799999999999996, 1.949, -0.030000000000000027, 1.9449999999999998, 0.9689999999999999, 1.951, 1.396, 0.9249999999999999, 1.211, 0.46199999999999997, 1.429, 1.442, 1.9569999999999999, 1.458, 1.955, 1.955, 1.9409999999999998, 1.423, 1.447, 1.94, 1.96, 1.9609999999999999, 1.452, 0.45500000000000007, 1.954, 1.948, 1.912, 1.395, 1.4180000000000001, 0.1280000000000001, 1.9369999999999998, -0.05000000000000004, 1.947, 1.4609999999999999, 1.4529999999999998, 1.951, 1.952, 1.9609999999999999, 1.921, 1.9609999999999999, 1.943, 1.923, -0.051000000000000045, 1.9180000000000001, 1.4529999999999998, 0.482, 1.447, 1.947, 0.44300000000000006, 1.443, -0.02199999999999991, 1.935, 1.927, -0.03200000000000003, 1.9569999999999999], "episode_lengths": [300, 13, 14, 19, 16, 14, 23, 300, 16, 26, 15, 20, 15, 14, 13, 13, 12, 14, 14, 26, 17, 22, 15, 22, 27, 22, 57, 14, 27, 20, 13, 19, 18, 12, 16, 22, 12, 19, 14, 23, 15, 22, 14, 14, 8, 31, 17, 29, 42, 27, 143, 18, 9, 14, 18, 17, 13, 14, 28, 12, 8, 18, 20, 16, 16, 29, 13, 13, 25, 25, 15, 9, 18, 19, 20, 17, 17, 18, 15, 14, 36, 30, 20, 25, 12, 26, 13, 13, 13, 24, 12, 13, 14, 17, 29, 17, 38, 15, 13, 15, 7, 21, 27, 44, 33, 12, 16, 10, 18, 10, 16, 32, 300, 89, 12, 23, 18, 14, 14, 14, 15, 19, 25, 17, 19, 13, 13, 16, 15, 15, 17, 28, 34, 26, 116, 20, 300, 17, 13, 15, 16, 16, 13, 25, 13, 18, 25, 15, 26, 15, 6, 17, 17, 18, 19, 7, 21, 24, 10, 14], "policy_red_0_reward": [-0.02100000000000001, 1.4609999999999999, 0.496, 1.442, -0.502, 1.458, 1.428, -0.024000000000000014, 1.452, 1.4220000000000002, 1.454, 1.439, 1.455, 1.458, 0.5, 1.4609999999999999, -0.5, 1.458, 1.458, 1.4220000000000002, -0.5009999999999999, 0.0, -0.5, 1.432, 1.4180000000000001, 1.434, -0.005, 0.958, 1.4180000000000001, 1.439, 1.4609999999999999, 1.443, 1.4449999999999998, 1.464, 0.0, 0.497, 1.464, 1.443, 0.499, 1.429, 1.455, 1.434, 1.458, 0.5, 0.975, 1.4060000000000001, 1.4489999999999998, -0.5, 1.373, 1.417, 1.053, 1.446, 1.472, 1.458, -0.5019999999999999, -0.5, 1.4609999999999999, 1.458, 1.415, 1.464, 1.476, 1.444, 1.439, 0.499, 1.452, 1.413, 1.4609999999999999, 1.4609999999999999, 1.424, -0.501, 1.455, 0.973, 1.4449999999999998, 1.442, 1.44, -0.501, 1.446, 0.5, 1.455, 1.458, 1.3900000000000001, 1.408, 1.44, 1.425, 0.963, -0.501, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.426, 0.963, 1.4609999999999999, 1.458, 1.4489999999999998, -0.004, 1.448, 0.496, 1.4529999999999998, 1.4609999999999999, 1.454, 1.479, 1.436, 1.413, 0.492, 1.397, -0.501, 1.451, 0.97, 1.446, 1.47, 1.452, -0.003, 0.45499999999999996, 1.2229999999999999, 1.464, 1.431, 1.4449999999999998, 1.458, 1.458, 1.4569999999999999, 1.455, 1.443, 1.425, 1.448, 1.443, 1.4609999999999999, 1.4609999999999999, 1.452, 0.955, 1.455, 1.4489999999999998, 1.415, 1.397, -0.001, 0.639, 0.499, -0.025000000000000015, 1.4489999999999998, 1.4609999999999999, 1.455, 1.452, 0.5, 1.4609999999999999, 0.499, 1.4609999999999999, 1.446, 0.499, -1.004, 1.421, 1.455, -0.5, 0.0, 1.448, 0.945, 1.443, -1.0, 0.499, 0.5, -1.001, 1.458], "policy_blue_0_reward": [0.473, 0.5, 1.458, 0.498, 0.951, 0.5, -0.004, -0.03800000000000003, -0.001, 0.496, 0.498, 0.498, 0.5, -0.003, 1.4609999999999999, -0.5, 0.963, 0.498, 0.498, 0.495, 0.948, 1.432, 0.955, 0.5, -1.003, -0.003, 1.326, -1.005, 0.498, -0.002, 0.499, -0.002, 0.5, -0.502, 1.452, 1.4329999999999998, -0.501, 0.496, 1.458, 0.5, 0.498, -0.001, 0.499, 1.458, -0.5, 0.497, 0.0, 1.413, 0.495, 0.499, -0.51, 0.499, -0.501, 0.498, 1.444, 0.947, 0.498, 0.0, 0.497, -0.501, -0.5, 0.499, -0.001, 1.45, 0.5, 0.497, -0.003, -0.5, 0.499, 1.424, 0.5, -1.002, -0.501, -0.002, 0.494, 1.447, -1.004, 1.446, 0.5, -0.503, 0.497, 0.497, 0.499, 0.497, -0.501, 1.419, -1.001, 0.0, -0.007, 0.498, -1.002, -0.5009999999999999, 0.499, 0.498, 1.413, -0.001, 1.3820000000000001, -0.002, 0.499, -1.0, -0.501, 0.499, -0.002, 1.361, -0.005, 0.959, 0.498, -1.0, 0.499, -0.501, 0.499, 1.399, 0.47, -0.012000000000000004, -1.002, -0.002, -0.003, 0.499, 0.0, 0.498, 0.5, 0.498, -0.002, -0.001, 0.497, 0.499, 0.5, 0.0, -0.5, 0.499, 0.499, 0.497, -0.002, 1.419, -0.511, 1.438, -0.025000000000000015, 0.498, 0.0, -0.002, 0.499, 1.452, 0.5, 1.4220000000000002, 0.5, 0.497, 1.424, 0.953, 0.497, -0.002, 0.982, 1.447, 0.499, -0.502, 0.0, 0.978, 1.436, 1.427, 0.969, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4156061168020524, "mean_inference_ms": 7.453381001159566, "mean_action_processing_ms": 0.38955347511199995, "mean_env_wait_ms": 0.5209986868128121, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14243222773075104, "StateBufferConnector_ms": 0.00969327986240387, "ViewRequirementAgentConnector_ms": 0.1913405954837799}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 124.01689949294838, "num_env_steps_trained_throughput_per_sec": 124.01689949294838, "timesteps_total": 440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 31911.715, "sample_time_ms": 4086.816, "learn_time_ms": 27795.328, "learn_throughput": 143.909, "synch_weights_time_ms": 28.024}, "counters": {"num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "episodes_total": 8179, "training_iteration": 110, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-55-32", "timestamp": 1694840132, "time_this_iter_s": 32.27814197540283, "time_total_s": 3431.4153673648834, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219b7880>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3431.4153673648834, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 27.213043478260868, "ram_util_percent": 57.054347826086946}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6435643564356436, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0891089108910891, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09900990099009901, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.0891089108910891, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1188118811881188, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09900990099009901, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.0891089108910891, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09900990099009901, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4981171258570006, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0320435407101589, "policy_loss": -0.06306126037670765, "vf_loss": 0.024669296868281284, "vf_explained_var": 0.7595154779031873, "kl": 0.008715152200550472, "entropy": 1.171135089546442, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 106080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5095077593034755, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.052854613100741216, "policy_loss": -0.08486477426364823, "vf_loss": 0.02114577794369931, "vf_explained_var": 0.5658275827765464, "kl": 0.010068920467419504, "entropy": 1.500988556817174, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 106080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 888000, "num_agent_steps_trained": 888000}, "sampler_results": {"episode_reward_max": 1.96, "episode_reward_min": -0.05699999999999994, "episode_reward_mean": 1.484316831683168, "episode_len_mean": 34.73267326732673, "episode_media": {}, "episodes_this_iter": 101, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4649999999999999}, "policy_reward_mean": {"red_0": 1.0305544554455444, "blue_0": 0.45376237623762383}, "custom_metrics": {"red_0/door_open_done_mean": 0.6435643564356436, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0891089108910891, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09900990099009901, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.0891089108910891, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1188118811881188, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09900990099009901, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.0891089108910891, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09900990099009901, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.052000000000000046, 0.43599999999999994, 1.451, 1.9489999999999998, 1.959, 1.948, 1.459, 1.919, 1.417, 0.9670000000000001, 1.9569999999999999, 1.951, 1.931, 1.42, 1.454, -0.027000000000000024, 1.9449999999999998, 1.9060000000000001, 1.439, 1.951, 1.438, 1.952, 1.455, 1.9300000000000002, 1.927, 1.939, 1.943, 1.956, 1.9329999999999998, 1.946, 0.45299999999999985, 1.879, 1.946, 1.951, 1.442, 1.944, 1.8119999999999998, 1.9529999999999998, 1.421, 1.9489999999999998, 1.438, 1.939, 0.45899999999999996, 1.45, 1.459, 1.907, -0.02499999999999991, 0.912, 1.9300000000000002, 0.9219999999999999, 0.95, 1.456, 1.9449999999999998, 1.455, 1.9529999999999998, 0.42100000000000004, 0.968, 1.4489999999999998, 1.96, 1.939, 1.8980000000000001, 1.956, 0.46499999999999997, 1.947, 1.4569999999999999, 0.8200000000000002, 0.45299999999999996, 1.944, 1.4, 0.95, 1.953, -0.04600000000000004, -0.027999999999999914, 1.9409999999999998, 0.941, 1.454, 1.943, 1.94, 0.961, 1.9489999999999998, 1.432, 1.9100000000000001, 1.924, 1.933, 1.4529999999999998, 1.888, 1.931, 0.9269999999999999, -0.05699999999999994, 1.436, 1.448, 1.954, 1.44, 1.909, 0.96, 1.942, 1.943, 1.95, 1.446, 1.956, 0.45699999999999996], "episode_lengths": [176, 20, 16, 17, 13, 15, 13, 25, 27, 11, 14, 16, 22, 26, 15, 9, 18, 30, 19, 16, 20, 15, 14, 22, 23, 20, 18, 14, 22, 18, 15, 39, 18, 16, 18, 18, 59, 15, 25, 16, 20, 19, 13, 16, 13, 28, 8, 28, 23, 300, 16, 14, 18, 15, 15, 26, 10, 17, 13, 19, 33, 14, 11, 17, 14, 58, 15, 18, 31, 16, 15, 15, 9, 19, 300, 15, 18, 19, 300, 16, 22, 29, 24, 21, 15, 35, 22, 300, 18, 19, 17, 15, 19, 29, 13, 19, 17, 16, 17, 14, 300], "policy_red_0_reward": [0.957, 1.439, 1.452, 1.4489999999999998, 1.4609999999999999, 1.454, 1.4609999999999999, 1.423, -0.002, 1.467, 0.499, 1.452, 1.434, 1.4220000000000002, 1.455, 0.973, 1.4449999999999998, 1.408, 1.442, 1.452, 1.439, 1.455, 1.4569999999999999, 1.4329999999999998, 0.5, 1.44, 1.446, 1.458, 1.434, 1.446, 1.454, 1.383, 1.446, 1.452, 1.444, 1.4449999999999998, 0.493, 0.499, 1.423, 1.452, -0.001, 1.443, -0.501, 1.452, -0.002, 1.416, -1.0, -0.502, 1.431, 0.45799999999999996, -0.5, 1.4569999999999999, 1.446, 0.0, 1.455, 1.4220000000000002, 1.47, 1.4489999999999998, 0.499, 1.443, 1.399, 1.458, -1.0, 1.4489999999999998, 1.458, -0.5019999999999999, -0.501, 1.446, 1.405, 1.45, 1.455, 0.954, -1.0, 1.442, 0.471, 1.455, 1.4449999999999998, 1.442, 0.49, 1.452, 1.434, 1.413, 1.426, 1.436, 1.454, 1.3940000000000001, 0.499, 0.44399999999999995, -1.001, 1.44, 1.4489999999999998, 1.455, 1.443, 1.412, -0.5, 0.5, 1.446, 1.452, -0.001, 1.4569999999999999, 0.489], "policy_blue_0_reward": [-1.009, -1.003, -0.001, 0.5, 0.498, 0.494, -0.002, 0.496, 1.419, -0.5, 1.458, 0.499, 0.497, -0.002, -0.001, -1.0, 0.5, 0.498, -0.003, 0.499, -0.001, 0.497, -0.002, 0.497, 1.427, 0.499, 0.497, 0.498, 0.499, 0.5, -1.001, 0.496, 0.5, 0.499, -0.002, 0.499, 1.319, 1.454, -0.002, 0.497, 1.439, 0.496, 0.96, -0.002, 1.4609999999999999, 0.491, 0.975, 1.4140000000000001, 0.499, 0.46399999999999997, 1.45, -0.001, 0.499, 1.455, 0.498, -1.001, -0.502, 0.0, 1.4609999999999999, 0.496, 0.499, 0.498, 1.4649999999999999, 0.498, -0.001, 1.322, 0.954, 0.498, -0.005, -0.5, 0.498, -1.0, 0.972, 0.499, 0.47, -0.001, 0.498, 0.498, 0.471, 0.497, -0.002, 0.497, 0.498, 0.497, -0.001, 0.494, 1.432, 0.483, 0.944, -0.004, -0.001, 0.499, -0.003, 0.497, 1.46, 1.442, 0.497, 0.498, 1.447, 0.499, -0.03200000000000002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4157575312596746, "mean_inference_ms": 7.455337570617016, "mean_action_processing_ms": 0.39177982552532475, "mean_env_wait_ms": 0.5211836340327928, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1753634745531743, "StateBufferConnector_ms": 0.010784427718360825, "ViewRequirementAgentConnector_ms": 0.22860352355654878}}, "episode_reward_max": 1.96, "episode_reward_min": -0.05699999999999994, "episode_reward_mean": 1.484316831683168, "episode_len_mean": 34.73267326732673, "episodes_this_iter": 101, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4649999999999999}, "policy_reward_mean": {"red_0": 1.0305544554455444, "blue_0": 0.45376237623762383}, "hist_stats": {"episode_reward": [-0.052000000000000046, 0.43599999999999994, 1.451, 1.9489999999999998, 1.959, 1.948, 1.459, 1.919, 1.417, 0.9670000000000001, 1.9569999999999999, 1.951, 1.931, 1.42, 1.454, -0.027000000000000024, 1.9449999999999998, 1.9060000000000001, 1.439, 1.951, 1.438, 1.952, 1.455, 1.9300000000000002, 1.927, 1.939, 1.943, 1.956, 1.9329999999999998, 1.946, 0.45299999999999985, 1.879, 1.946, 1.951, 1.442, 1.944, 1.8119999999999998, 1.9529999999999998, 1.421, 1.9489999999999998, 1.438, 1.939, 0.45899999999999996, 1.45, 1.459, 1.907, -0.02499999999999991, 0.912, 1.9300000000000002, 0.9219999999999999, 0.95, 1.456, 1.9449999999999998, 1.455, 1.9529999999999998, 0.42100000000000004, 0.968, 1.4489999999999998, 1.96, 1.939, 1.8980000000000001, 1.956, 0.46499999999999997, 1.947, 1.4569999999999999, 0.8200000000000002, 0.45299999999999996, 1.944, 1.4, 0.95, 1.953, -0.04600000000000004, -0.027999999999999914, 1.9409999999999998, 0.941, 1.454, 1.943, 1.94, 0.961, 1.9489999999999998, 1.432, 1.9100000000000001, 1.924, 1.933, 1.4529999999999998, 1.888, 1.931, 0.9269999999999999, -0.05699999999999994, 1.436, 1.448, 1.954, 1.44, 1.909, 0.96, 1.942, 1.943, 1.95, 1.446, 1.956, 0.45699999999999996], "episode_lengths": [176, 20, 16, 17, 13, 15, 13, 25, 27, 11, 14, 16, 22, 26, 15, 9, 18, 30, 19, 16, 20, 15, 14, 22, 23, 20, 18, 14, 22, 18, 15, 39, 18, 16, 18, 18, 59, 15, 25, 16, 20, 19, 13, 16, 13, 28, 8, 28, 23, 300, 16, 14, 18, 15, 15, 26, 10, 17, 13, 19, 33, 14, 11, 17, 14, 58, 15, 18, 31, 16, 15, 15, 9, 19, 300, 15, 18, 19, 300, 16, 22, 29, 24, 21, 15, 35, 22, 300, 18, 19, 17, 15, 19, 29, 13, 19, 17, 16, 17, 14, 300], "policy_red_0_reward": [0.957, 1.439, 1.452, 1.4489999999999998, 1.4609999999999999, 1.454, 1.4609999999999999, 1.423, -0.002, 1.467, 0.499, 1.452, 1.434, 1.4220000000000002, 1.455, 0.973, 1.4449999999999998, 1.408, 1.442, 1.452, 1.439, 1.455, 1.4569999999999999, 1.4329999999999998, 0.5, 1.44, 1.446, 1.458, 1.434, 1.446, 1.454, 1.383, 1.446, 1.452, 1.444, 1.4449999999999998, 0.493, 0.499, 1.423, 1.452, -0.001, 1.443, -0.501, 1.452, -0.002, 1.416, -1.0, -0.502, 1.431, 0.45799999999999996, -0.5, 1.4569999999999999, 1.446, 0.0, 1.455, 1.4220000000000002, 1.47, 1.4489999999999998, 0.499, 1.443, 1.399, 1.458, -1.0, 1.4489999999999998, 1.458, -0.5019999999999999, -0.501, 1.446, 1.405, 1.45, 1.455, 0.954, -1.0, 1.442, 0.471, 1.455, 1.4449999999999998, 1.442, 0.49, 1.452, 1.434, 1.413, 1.426, 1.436, 1.454, 1.3940000000000001, 0.499, 0.44399999999999995, -1.001, 1.44, 1.4489999999999998, 1.455, 1.443, 1.412, -0.5, 0.5, 1.446, 1.452, -0.001, 1.4569999999999999, 0.489], "policy_blue_0_reward": [-1.009, -1.003, -0.001, 0.5, 0.498, 0.494, -0.002, 0.496, 1.419, -0.5, 1.458, 0.499, 0.497, -0.002, -0.001, -1.0, 0.5, 0.498, -0.003, 0.499, -0.001, 0.497, -0.002, 0.497, 1.427, 0.499, 0.497, 0.498, 0.499, 0.5, -1.001, 0.496, 0.5, 0.499, -0.002, 0.499, 1.319, 1.454, -0.002, 0.497, 1.439, 0.496, 0.96, -0.002, 1.4609999999999999, 0.491, 0.975, 1.4140000000000001, 0.499, 0.46399999999999997, 1.45, -0.001, 0.499, 1.455, 0.498, -1.001, -0.502, 0.0, 1.4609999999999999, 0.496, 0.499, 0.498, 1.4649999999999999, 0.498, -0.001, 1.322, 0.954, 0.498, -0.005, -0.5, 0.498, -1.0, 0.972, 0.499, 0.47, -0.001, 0.498, 0.498, 0.471, 0.497, -0.002, 0.497, 0.498, 0.497, -0.001, 0.494, 1.432, 0.483, 0.944, -0.004, -0.001, 0.499, -0.003, 0.497, 1.46, 1.442, 0.497, 0.498, 1.447, 0.499, -0.03200000000000002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4157575312596746, "mean_inference_ms": 7.455337570617016, "mean_action_processing_ms": 0.39177982552532475, "mean_env_wait_ms": 0.5211836340327928, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1753634745531743, "StateBufferConnector_ms": 0.010784427718360825, "ViewRequirementAgentConnector_ms": 0.22860352355654878}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 888000, "num_agent_steps_trained": 888000, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 109.8108194761711, "num_env_steps_trained_throughput_per_sec": 109.8108194761711, "timesteps_total": 444000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 888000, "timers": {"training_iteration_time_ms": 32012.331, "sample_time_ms": 4134.916, "learn_time_ms": 27847.399, "learn_throughput": 143.64, "synch_weights_time_ms": 28.433}, "counters": {"num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 888000, "num_agent_steps_trained": 888000}, "done": false, "episodes_total": 8280, "training_iteration": 111, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-56-09", "timestamp": 1694840169, "time_this_iter_s": 36.44402003288269, "time_total_s": 3467.859387397766, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb218f53f0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3467.859387397766, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 31.248148148148147, "ram_util_percent": 57.17592592592592}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5645161290322581, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.10483870967741936, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0967741935483871, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.10483870967741936, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.18548387096774194, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.0967741935483871, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.10483870967741936, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0967741935483871, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.522847989636163, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03893685895212305, "policy_loss": -0.07586353579414815, "vf_loss": 0.03059073896535362, "vf_explained_var": 0.7389274129644037, "kl": 0.010004625621244637, "entropy": 1.1604800527915358, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 107040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5295040100502472, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.047574380034347996, "policy_loss": -0.08441441910351083, "vf_loss": 0.028496427537174896, "vf_explained_var": 0.5895533155029019, "kl": 0.01053532642271792, "entropy": 1.4089648760855198, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 107040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.08399999999999996, "episode_reward_mean": 1.4724758064516128, "episode_len_mean": 35.08870967741935, "episode_media": {}, "episodes_this_iter": 124, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 0.9524919354838709, "blue_0": 0.519983870967742}, "custom_metrics": {"red_0/door_open_done_mean": 0.5645161290322581, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.10483870967741936, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0967741935483871, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.10483870967741936, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.18548387096774194, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.0967741935483871, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.10483870967741936, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0967741935483871, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.9489999999999998, 0.9059999999999999, 1.9329999999999998, -0.031000000000000028, 1.935, 0.9299999999999999, 0.42999999999999994, 1.455, 1.434, 1.938, 1.924, 1.955, 1.955, 1.447, 0.46899999999999986, 1.427, 1.422, 1.9329999999999998, 0.46599999999999997, 1.456, 1.951, 1.946, 1.869, 1.436, 1.955, 1.96, 1.95, 1.376, 1.427, 1.8599999999999999, 1.956, 1.9300000000000002, 1.236, 1.249, 0.43499999999999994, 1.96, 0.895, 1.417, 1.93, -0.04100000000000003, 1.904, 1.9180000000000001, 0.9729999999999999, 0.9329999999999999, 1.9529999999999998, 1.9449999999999998, 1.945, 0.46399999999999997, 1.845, 1.9449999999999998, 1.955, 1.958, 1.748, 1.955, 1.417, 1.404, 1.943, 1.452, 1.397, 1.43, 1.912, 0.96, 1.947, 1.455, 1.435, 1.954, 1.9449999999999998, 0.44999999999999996, 1.926, 1.46, 1.431, 1.4449999999999998, 1.95, -0.05799999999999994, 1.439, 1.896, 0.4750000000000001, 1.9609999999999999, 1.9100000000000001, 1.395, 1.958, 1.959, 1.9300000000000002, 1.951, 0.44700000000000006, 1.9569999999999999, 1.944, 1.4100000000000001, 0.44999999999999996, 1.9569999999999999, 1.888, 0.861, 1.8730000000000002, 1.94, 0.9590000000000001, 0.9229999999999999, -0.08399999999999996, -0.03399999999999992, 1.4369999999999998, 1.958, 1.9609999999999999, 0.43699999999999983, 1.944, 1.912, 1.9529999999999998, 1.419, 1.924, 1.9540000000000002, 1.443, 0.978, 0.46699999999999997, 1.924, 0.97, 0.9129999999999999, 1.9529999999999998, 1.4449999999999998, 1.943, 1.931, 1.949, 0.849, 0.96, 1.95, -0.02499999999999991, 1.947], "episode_lengths": [17, 300, 21, 9, 21, 22, 300, 14, 22, 19, 25, 15, 15, 17, 10, 24, 24, 22, 11, 14, 16, 18, 42, 21, 15, 13, 15, 40, 23, 44, 14, 23, 85, 81, 300, 13, 33, 27, 22, 300, 31, 26, 9, 21, 15, 18, 17, 12, 48, 18, 15, 14, 80, 15, 26, 30, 18, 16, 34, 22, 26, 13, 17, 15, 21, 15, 17, 16, 24, 13, 22, 18, 16, 19, 20, 32, 8, 13, 29, 33, 14, 13, 23, 16, 17, 14, 18, 29, 16, 14, 35, 42, 40, 19, 13, 300, 27, 11, 19, 14, 13, 20, 18, 27, 15, 26, 24, 15, 18, 7, 10, 25, 10, 300, 15, 17, 18, 22, 16, 48, 13, 16, 8, 17], "policy_red_0_reward": [1.4489999999999998, 0.43899999999999995, 1.436, 0.971, 0.5, 1.4329999999999998, -0.03800000000000003, 1.4569999999999999, 1.434, 1.443, 1.425, 1.455, 0.5, 1.4489999999999998, 1.47, 1.428, 1.428, 1.434, -0.501, 1.458, 1.452, 0.5, 0.497, 1.4369999999999998, 1.455, 1.4609999999999999, 1.454, -0.003, -0.003, 1.3679999999999999, 1.458, 1.4300000000000002, -0.007, -0.003, -0.028000000000000018, 1.4609999999999999, -0.502, 1.419, 1.432, -0.023000000000000013, 1.4060000000000001, 1.4220000000000002, 1.4729999999999999, -0.502, 0.499, 1.446, 1.4489999999999998, 1.464, 0.496, 1.446, 1.455, 1.458, 1.255, 1.455, 1.4220000000000002, 1.407, 1.446, 1.452, 1.3980000000000001, 1.432, 1.417, 1.4609999999999999, 1.448, 1.455, 0.0, 1.454, 1.447, -0.5, 1.427, -0.001, -0.002, 1.4449999999999998, 1.451, -1.0, 1.439, 0.497, 1.476, 1.4609999999999999, 1.412, 1.3980000000000001, 0.5, 1.4609999999999999, 1.431, 0.499, 1.447, 0.499, 1.446, 1.412, -1.001, 1.458, 1.391, -0.506, 1.376, 1.442, 1.46, 0.45899999999999996, 0.918, -1.001, 1.4409999999999998, 0.5, 1.4609999999999999, 1.439, 1.4449999999999998, 1.4180000000000001, 0.499, 1.4220000000000002, 1.426, 1.455, -0.002, 1.479, -1.002, 1.425, -0.5, 0.45899999999999996, 0.499, -0.002, 1.446, 0.498, 1.451, -0.505, -0.5, 1.452, 0.976, 1.4489999999999998], "policy_blue_0_reward": [0.5, 0.46699999999999997, 0.497, -1.002, 1.435, -0.503, 0.46799999999999997, -0.002, 0.0, 0.495, 0.499, 0.5, 1.455, -0.002, -1.001, -0.001, -0.006, 0.499, 0.967, -0.002, 0.499, 1.446, 1.3719999999999999, -0.001, 0.5, 0.499, 0.496, 1.379, 1.4300000000000002, 0.492, 0.498, 0.5, 1.2429999999999999, 1.252, 0.46299999999999997, 0.499, 1.397, -0.002, 0.498, -0.01800000000000001, 0.498, 0.496, -0.5, 1.435, 1.454, 0.499, 0.496, -1.0, 1.349, 0.499, 0.5, 0.5, 0.493, 0.5, -0.005, -0.003, 0.497, 0.0, -0.001, -0.002, 0.495, -0.501, 0.499, 0.0, 1.435, 0.5, 0.498, 0.95, 0.499, 1.4609999999999999, 1.4329999999999998, 0.0, 0.499, 0.942, 0.0, 1.399, -1.001, 0.5, 0.498, -0.003, 1.458, 0.498, 0.499, 1.452, -1.0, 1.458, 0.498, -0.002, 1.451, 0.499, 0.497, 1.367, 0.497, 0.498, -0.501, 0.46399999999999997, -1.002, 0.967, -0.004, 1.458, 0.5, -1.002, 0.499, 0.494, 1.454, -0.003, 0.498, 0.499, 1.4449999999999998, -0.501, 1.4689999999999999, 0.499, 1.47, 0.45399999999999996, 1.454, 1.447, 0.497, 1.4329999999999998, 0.498, 1.354, 1.46, 0.498, -1.001, 0.498]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4171143673030333, "mean_inference_ms": 7.467447840692469, "mean_action_processing_ms": 0.38934083802619296, "mean_env_wait_ms": 0.5213478324874282, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.27435402716359786, "StateBufferConnector_ms": 0.01049570498927947, "ViewRequirementAgentConnector_ms": 0.20172086454206897}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.08399999999999996, "episode_reward_mean": 1.4724758064516128, "episode_len_mean": 35.08870967741935, "episodes_this_iter": 124, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 0.9524919354838709, "blue_0": 0.519983870967742}, "hist_stats": {"episode_reward": [1.9489999999999998, 0.9059999999999999, 1.9329999999999998, -0.031000000000000028, 1.935, 0.9299999999999999, 0.42999999999999994, 1.455, 1.434, 1.938, 1.924, 1.955, 1.955, 1.447, 0.46899999999999986, 1.427, 1.422, 1.9329999999999998, 0.46599999999999997, 1.456, 1.951, 1.946, 1.869, 1.436, 1.955, 1.96, 1.95, 1.376, 1.427, 1.8599999999999999, 1.956, 1.9300000000000002, 1.236, 1.249, 0.43499999999999994, 1.96, 0.895, 1.417, 1.93, -0.04100000000000003, 1.904, 1.9180000000000001, 0.9729999999999999, 0.9329999999999999, 1.9529999999999998, 1.9449999999999998, 1.945, 0.46399999999999997, 1.845, 1.9449999999999998, 1.955, 1.958, 1.748, 1.955, 1.417, 1.404, 1.943, 1.452, 1.397, 1.43, 1.912, 0.96, 1.947, 1.455, 1.435, 1.954, 1.9449999999999998, 0.44999999999999996, 1.926, 1.46, 1.431, 1.4449999999999998, 1.95, -0.05799999999999994, 1.439, 1.896, 0.4750000000000001, 1.9609999999999999, 1.9100000000000001, 1.395, 1.958, 1.959, 1.9300000000000002, 1.951, 0.44700000000000006, 1.9569999999999999, 1.944, 1.4100000000000001, 0.44999999999999996, 1.9569999999999999, 1.888, 0.861, 1.8730000000000002, 1.94, 0.9590000000000001, 0.9229999999999999, -0.08399999999999996, -0.03399999999999992, 1.4369999999999998, 1.958, 1.9609999999999999, 0.43699999999999983, 1.944, 1.912, 1.9529999999999998, 1.419, 1.924, 1.9540000000000002, 1.443, 0.978, 0.46699999999999997, 1.924, 0.97, 0.9129999999999999, 1.9529999999999998, 1.4449999999999998, 1.943, 1.931, 1.949, 0.849, 0.96, 1.95, -0.02499999999999991, 1.947], "episode_lengths": [17, 300, 21, 9, 21, 22, 300, 14, 22, 19, 25, 15, 15, 17, 10, 24, 24, 22, 11, 14, 16, 18, 42, 21, 15, 13, 15, 40, 23, 44, 14, 23, 85, 81, 300, 13, 33, 27, 22, 300, 31, 26, 9, 21, 15, 18, 17, 12, 48, 18, 15, 14, 80, 15, 26, 30, 18, 16, 34, 22, 26, 13, 17, 15, 21, 15, 17, 16, 24, 13, 22, 18, 16, 19, 20, 32, 8, 13, 29, 33, 14, 13, 23, 16, 17, 14, 18, 29, 16, 14, 35, 42, 40, 19, 13, 300, 27, 11, 19, 14, 13, 20, 18, 27, 15, 26, 24, 15, 18, 7, 10, 25, 10, 300, 15, 17, 18, 22, 16, 48, 13, 16, 8, 17], "policy_red_0_reward": [1.4489999999999998, 0.43899999999999995, 1.436, 0.971, 0.5, 1.4329999999999998, -0.03800000000000003, 1.4569999999999999, 1.434, 1.443, 1.425, 1.455, 0.5, 1.4489999999999998, 1.47, 1.428, 1.428, 1.434, -0.501, 1.458, 1.452, 0.5, 0.497, 1.4369999999999998, 1.455, 1.4609999999999999, 1.454, -0.003, -0.003, 1.3679999999999999, 1.458, 1.4300000000000002, -0.007, -0.003, -0.028000000000000018, 1.4609999999999999, -0.502, 1.419, 1.432, -0.023000000000000013, 1.4060000000000001, 1.4220000000000002, 1.4729999999999999, -0.502, 0.499, 1.446, 1.4489999999999998, 1.464, 0.496, 1.446, 1.455, 1.458, 1.255, 1.455, 1.4220000000000002, 1.407, 1.446, 1.452, 1.3980000000000001, 1.432, 1.417, 1.4609999999999999, 1.448, 1.455, 0.0, 1.454, 1.447, -0.5, 1.427, -0.001, -0.002, 1.4449999999999998, 1.451, -1.0, 1.439, 0.497, 1.476, 1.4609999999999999, 1.412, 1.3980000000000001, 0.5, 1.4609999999999999, 1.431, 0.499, 1.447, 0.499, 1.446, 1.412, -1.001, 1.458, 1.391, -0.506, 1.376, 1.442, 1.46, 0.45899999999999996, 0.918, -1.001, 1.4409999999999998, 0.5, 1.4609999999999999, 1.439, 1.4449999999999998, 1.4180000000000001, 0.499, 1.4220000000000002, 1.426, 1.455, -0.002, 1.479, -1.002, 1.425, -0.5, 0.45899999999999996, 0.499, -0.002, 1.446, 0.498, 1.451, -0.505, -0.5, 1.452, 0.976, 1.4489999999999998], "policy_blue_0_reward": [0.5, 0.46699999999999997, 0.497, -1.002, 1.435, -0.503, 0.46799999999999997, -0.002, 0.0, 0.495, 0.499, 0.5, 1.455, -0.002, -1.001, -0.001, -0.006, 0.499, 0.967, -0.002, 0.499, 1.446, 1.3719999999999999, -0.001, 0.5, 0.499, 0.496, 1.379, 1.4300000000000002, 0.492, 0.498, 0.5, 1.2429999999999999, 1.252, 0.46299999999999997, 0.499, 1.397, -0.002, 0.498, -0.01800000000000001, 0.498, 0.496, -0.5, 1.435, 1.454, 0.499, 0.496, -1.0, 1.349, 0.499, 0.5, 0.5, 0.493, 0.5, -0.005, -0.003, 0.497, 0.0, -0.001, -0.002, 0.495, -0.501, 0.499, 0.0, 1.435, 0.5, 0.498, 0.95, 0.499, 1.4609999999999999, 1.4329999999999998, 0.0, 0.499, 0.942, 0.0, 1.399, -1.001, 0.5, 0.498, -0.003, 1.458, 0.498, 0.499, 1.452, -1.0, 1.458, 0.498, -0.002, 1.451, 0.499, 0.497, 1.367, 0.497, 0.498, -0.501, 0.46399999999999997, -1.002, 0.967, -0.004, 1.458, 0.5, -1.002, 0.499, 0.494, 1.454, -0.003, 0.498, 0.499, 1.4449999999999998, -0.501, 1.4689999999999999, 0.499, 1.47, 0.45399999999999996, 1.454, 1.447, 0.497, 1.4329999999999998, 0.498, 1.354, 1.46, 0.498, -1.001, 0.498]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4171143673030333, "mean_inference_ms": 7.467447840692469, "mean_action_processing_ms": 0.38934083802619296, "mean_env_wait_ms": 0.5213478324874282, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.27435402716359786, "StateBufferConnector_ms": 0.01049570498927947, "ViewRequirementAgentConnector_ms": 0.20172086454206897}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 119.71317785438758, "num_env_steps_trained_throughput_per_sec": 119.71317785438758, "timesteps_total": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 32161.05, "sample_time_ms": 4141.727, "learn_time_ms": 27989.284, "learn_throughput": 142.912, "synch_weights_time_ms": 28.361}, "counters": {"num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "episodes_total": 8404, "training_iteration": 112, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-56-44", "timestamp": 1694840204, "time_this_iter_s": 33.43076205253601, "time_total_s": 3501.290149450302, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219b79a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3501.290149450302, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 27.15833333333333, "ram_util_percent": 57.13958333333333}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6551724137931034, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.1310344827586207, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06206896551724138, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.1310344827586207, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13793103448275862, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.06206896551724138, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.1310344827586207, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06206896551724138, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4920700540455679, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03778622945440778, "policy_loss": -0.07312209291994805, "vf_loss": 0.027323268611507957, "vf_explained_var": 0.7753088187426329, "kl": 0.009953593192991087, "entropy": 1.001300595079859, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 108000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5229462742805481, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04914805253210943, "policy_loss": -0.0883658450045914, "vf_loss": 0.030312101926150112, "vf_explained_var": 0.6007385733847816, "kl": 0.011176879123774996, "entropy": 1.4005876764655114, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 108000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 904000, "num_agent_steps_trained": 904000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.061000000000000054, "episode_reward_mean": 1.562103448275862, "episode_len_mean": 23.63448275862069, "episode_media": {}, "episodes_this_iter": 145, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.4809999999999999}, "policy_reward_mean": {"red_0": 1.124903448275862, "blue_0": 0.4372}, "custom_metrics": {"red_0/door_open_done_mean": 0.6551724137931034, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.1310344827586207, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06206896551724138, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.1310344827586207, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13793103448275862, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.06206896551724138, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.1310344827586207, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06206896551724138, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.943, 1.821, 1.9569999999999999, 1.947, 1.959, 1.4569999999999999, 1.452, 1.434, 1.9369999999999998, 1.948, 1.9369999999999998, 1.935, 1.954, 1.954, 1.954, -0.028000000000000025, 0.45899999999999996, 0.916, 1.938, 1.383, 1.46, 1.441, 0.9689999999999999, 0.972, 1.9449999999999998, 1.44, 1.9180000000000001, 1.943, 1.755, 1.95, 1.955, 1.9329999999999998, 1.954, 0.45499999999999996, 0.41100000000000003, 0.938, 1.917, 0.40300000000000014, 0.481, 0.45299999999999985, 1.9529999999999998, 1.935, 1.446, 1.9369999999999998, 0.95, -0.061000000000000054, -0.03500000000000003, 1.4529999999999998, 1.929, 1.9569999999999999, 1.452, -0.018000000000000016, 1.438, 1.954, 1.954, 1.96, 0.948, 1.939, 1.93, 1.943, 1.93, 1.439, 1.9409999999999998, 1.932, 1.9449999999999998, 1.6560000000000001, 1.8940000000000001, 0.391, 1.94, 1.4529999999999998, 1.952, 1.9609999999999999, 0.45399999999999996, 1.4409999999999998, 1.946, 0.9189999999999999, 1.9289999999999998, 1.451, 1.454, 1.443, 1.9449999999999998, 1.917, 0.965, 1.9449999999999998, 1.375, 1.917, 1.948, 1.95, 1.954, 0.47, 1.958, 1.935, 0.953, 1.9120000000000001, 1.929, 1.945, 1.9369999999999998, 1.455, 0.958, 1.9489999999999998, 1.937, 1.9449999999999998, 1.9489999999999998, 1.442, 1.9409999999999998, 1.4060000000000001, 1.456, 1.936, 1.9609999999999999, 1.96, 0.47, 1.951, 1.956, 1.915, 1.9289999999999998, 1.905, 1.9580000000000002, 1.908, 1.909, 1.95, 1.9489999999999998, -0.050000000000000044, 1.954, 1.947, 1.45, 1.947, 0.9550000000000001, 1.8820000000000001, 1.913, -0.051000000000000045, 1.946, 1.9609999999999999, 1.4569999999999999, 1.4609999999999999, 1.954, 0.9590000000000001, 0.904, 1.905, 1.363, 1.959, 1.9569999999999999, 1.958, 1.9449999999999998, 1.435, 0.9590000000000001], "episode_lengths": [17, 55, 14, 17, 13, 14, 16, 21, 20, 17, 21, 21, 15, 15, 15, 9, 13, 26, 20, 33, 13, 19, 10, 9, 18, 20, 26, 19, 73, 16, 15, 21, 15, 15, 29, 19, 27, 30, 6, 15, 15, 20, 18, 20, 16, 20, 11, 15, 23, 14, 15, 6, 20, 15, 15, 13, 300, 19, 22, 18, 21, 19, 19, 21, 18, 110, 33, 35, 19, 15, 16, 13, 15, 19, 17, 300, 22, 16, 15, 19, 17, 27, 11, 18, 39, 26, 17, 16, 15, 9, 14, 20, 15, 28, 23, 18, 21, 15, 14, 16, 19, 17, 17, 18, 19, 31, 14, 21, 13, 13, 9, 16, 14, 27, 22, 30, 13, 29, 29, 16, 17, 16, 15, 16, 16, 17, 14, 38, 27, 17, 17, 13, 14, 13, 15, 13, 31, 30, 45, 13, 14, 14, 18, 21, 13], "policy_red_0_reward": [1.448, 0.491, 1.458, 1.448, 1.4609999999999999, 1.4569999999999999, 1.452, 1.436, 1.438, 1.4489999999999998, 1.4369999999999998, 1.436, 1.455, 0.5, 1.455, 0.973, -0.5, -0.502, 1.44, 1.3980000000000001, 1.4609999999999999, 1.442, 1.47, 1.4729999999999999, 0.499, 1.44, 1.421, 0.5, 1.271, 1.452, 1.455, 1.435, 1.455, -1.0, 0.913, 1.442, 1.419, -0.5039999999999999, -1.0, 1.455, 0.5, 1.439, 1.446, 1.439, 1.452, 0.939, 0.967, 1.455, 1.431, 0.5, 1.455, 0.982, -0.002, 1.455, 1.455, 1.4609999999999999, 0.485, 1.443, 1.431, 0.499, 0.498, 1.442, 1.442, 1.4369999999999998, 0.5, 1.163, 1.397, 0.894, 1.443, 1.455, 1.452, 1.4609999999999999, -0.5, 1.443, 1.448, 0.45499999999999996, 1.432, 1.451, 1.455, 1.443, 1.447, 1.419, -0.5, 0.5, 1.379, 0.499, 0.5, 1.452, 1.455, 1.471, 1.458, 1.44, -0.501, 1.415, 1.431, 1.446, 1.4369999999999998, 1.455, 1.458, 1.452, 1.4409999999999998, 0.498, 1.4489999999999998, 1.446, 1.443, 0.0, -0.002, 1.4369999999999998, 1.4609999999999999, 1.4609999999999999, 1.472, 1.452, 1.458, 1.416, 1.434, 1.409, 1.4609999999999999, 1.413, 1.413, 1.451, 1.4489999999999998, 0.951, 1.455, 1.451, 1.452, 1.4489999999999998, 1.4569999999999999, 1.384, 1.419, 0.949, 1.448, 1.4609999999999999, 0.0, 1.4609999999999999, 1.455, 1.4609999999999999, -0.501, 1.409, -0.001, 1.4609999999999999, 0.5, 0.5, 1.446, 1.436, 1.4609999999999999], "policy_blue_0_reward": [0.495, 1.33, 0.499, 0.499, 0.498, 0.0, 0.0, -0.002, 0.499, 0.499, 0.5, 0.499, 0.499, 1.454, 0.499, -1.001, 0.959, 1.4180000000000001, 0.498, -0.015000000000000006, -0.001, -0.001, -0.501, -0.501, 1.446, 0.0, 0.497, 1.443, 0.484, 0.498, 0.5, 0.498, 0.499, 1.455, -0.502, -0.504, 0.498, 0.907, 1.4809999999999999, -1.002, 1.4529999999999998, 0.496, 0.0, 0.498, -0.502, -1.0, -1.002, -0.002, 0.498, 1.4569999999999999, -0.003, -1.0, 1.44, 0.499, 0.499, 0.499, 0.46299999999999997, 0.496, 0.499, 1.444, 1.432, -0.003, 0.499, 0.495, 1.4449999999999998, 0.493, 0.497, -0.503, 0.497, -0.002, 0.5, 0.5, 0.954, -0.002, 0.498, 0.46399999999999997, 0.497, 0.0, -0.001, 0.0, 0.498, 0.498, 1.4649999999999999, 1.4449999999999998, -0.004, 1.4180000000000001, 1.448, 0.498, 0.499, -1.001, 0.5, 0.495, 1.454, 0.497, 0.498, 0.499, 0.5, 0.0, -0.5, 0.497, 0.496, 1.447, 0.5, -0.004, 0.498, 1.4060000000000001, 1.458, 0.499, 0.5, 0.499, -1.002, 0.499, 0.498, 0.499, 0.495, 0.496, 0.497, 0.495, 0.496, 0.499, 0.5, -1.001, 0.499, 0.496, -0.002, 0.498, -0.5019999999999999, 0.498, 0.494, -1.0, 0.498, 0.5, 1.4569999999999999, 0.0, 0.499, -0.502, 1.405, 0.496, 1.3639999999999999, 0.498, 1.4569999999999999, 1.458, 0.499, -0.001, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4194056248675753, "mean_inference_ms": 7.4684122281451435, "mean_action_processing_ms": 0.3913006612313951, "mean_env_wait_ms": 0.5220215543589447, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.19001516802557583, "StateBufferConnector_ms": 0.01021048118328226, "ViewRequirementAgentConnector_ms": 0.19424660452480974}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.061000000000000054, "episode_reward_mean": 1.562103448275862, "episode_len_mean": 23.63448275862069, "episodes_this_iter": 145, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.4809999999999999}, "policy_reward_mean": {"red_0": 1.124903448275862, "blue_0": 0.4372}, "hist_stats": {"episode_reward": [1.943, 1.821, 1.9569999999999999, 1.947, 1.959, 1.4569999999999999, 1.452, 1.434, 1.9369999999999998, 1.948, 1.9369999999999998, 1.935, 1.954, 1.954, 1.954, -0.028000000000000025, 0.45899999999999996, 0.916, 1.938, 1.383, 1.46, 1.441, 0.9689999999999999, 0.972, 1.9449999999999998, 1.44, 1.9180000000000001, 1.943, 1.755, 1.95, 1.955, 1.9329999999999998, 1.954, 0.45499999999999996, 0.41100000000000003, 0.938, 1.917, 0.40300000000000014, 0.481, 0.45299999999999985, 1.9529999999999998, 1.935, 1.446, 1.9369999999999998, 0.95, -0.061000000000000054, -0.03500000000000003, 1.4529999999999998, 1.929, 1.9569999999999999, 1.452, -0.018000000000000016, 1.438, 1.954, 1.954, 1.96, 0.948, 1.939, 1.93, 1.943, 1.93, 1.439, 1.9409999999999998, 1.932, 1.9449999999999998, 1.6560000000000001, 1.8940000000000001, 0.391, 1.94, 1.4529999999999998, 1.952, 1.9609999999999999, 0.45399999999999996, 1.4409999999999998, 1.946, 0.9189999999999999, 1.9289999999999998, 1.451, 1.454, 1.443, 1.9449999999999998, 1.917, 0.965, 1.9449999999999998, 1.375, 1.917, 1.948, 1.95, 1.954, 0.47, 1.958, 1.935, 0.953, 1.9120000000000001, 1.929, 1.945, 1.9369999999999998, 1.455, 0.958, 1.9489999999999998, 1.937, 1.9449999999999998, 1.9489999999999998, 1.442, 1.9409999999999998, 1.4060000000000001, 1.456, 1.936, 1.9609999999999999, 1.96, 0.47, 1.951, 1.956, 1.915, 1.9289999999999998, 1.905, 1.9580000000000002, 1.908, 1.909, 1.95, 1.9489999999999998, -0.050000000000000044, 1.954, 1.947, 1.45, 1.947, 0.9550000000000001, 1.8820000000000001, 1.913, -0.051000000000000045, 1.946, 1.9609999999999999, 1.4569999999999999, 1.4609999999999999, 1.954, 0.9590000000000001, 0.904, 1.905, 1.363, 1.959, 1.9569999999999999, 1.958, 1.9449999999999998, 1.435, 0.9590000000000001], "episode_lengths": [17, 55, 14, 17, 13, 14, 16, 21, 20, 17, 21, 21, 15, 15, 15, 9, 13, 26, 20, 33, 13, 19, 10, 9, 18, 20, 26, 19, 73, 16, 15, 21, 15, 15, 29, 19, 27, 30, 6, 15, 15, 20, 18, 20, 16, 20, 11, 15, 23, 14, 15, 6, 20, 15, 15, 13, 300, 19, 22, 18, 21, 19, 19, 21, 18, 110, 33, 35, 19, 15, 16, 13, 15, 19, 17, 300, 22, 16, 15, 19, 17, 27, 11, 18, 39, 26, 17, 16, 15, 9, 14, 20, 15, 28, 23, 18, 21, 15, 14, 16, 19, 17, 17, 18, 19, 31, 14, 21, 13, 13, 9, 16, 14, 27, 22, 30, 13, 29, 29, 16, 17, 16, 15, 16, 16, 17, 14, 38, 27, 17, 17, 13, 14, 13, 15, 13, 31, 30, 45, 13, 14, 14, 18, 21, 13], "policy_red_0_reward": [1.448, 0.491, 1.458, 1.448, 1.4609999999999999, 1.4569999999999999, 1.452, 1.436, 1.438, 1.4489999999999998, 1.4369999999999998, 1.436, 1.455, 0.5, 1.455, 0.973, -0.5, -0.502, 1.44, 1.3980000000000001, 1.4609999999999999, 1.442, 1.47, 1.4729999999999999, 0.499, 1.44, 1.421, 0.5, 1.271, 1.452, 1.455, 1.435, 1.455, -1.0, 0.913, 1.442, 1.419, -0.5039999999999999, -1.0, 1.455, 0.5, 1.439, 1.446, 1.439, 1.452, 0.939, 0.967, 1.455, 1.431, 0.5, 1.455, 0.982, -0.002, 1.455, 1.455, 1.4609999999999999, 0.485, 1.443, 1.431, 0.499, 0.498, 1.442, 1.442, 1.4369999999999998, 0.5, 1.163, 1.397, 0.894, 1.443, 1.455, 1.452, 1.4609999999999999, -0.5, 1.443, 1.448, 0.45499999999999996, 1.432, 1.451, 1.455, 1.443, 1.447, 1.419, -0.5, 0.5, 1.379, 0.499, 0.5, 1.452, 1.455, 1.471, 1.458, 1.44, -0.501, 1.415, 1.431, 1.446, 1.4369999999999998, 1.455, 1.458, 1.452, 1.4409999999999998, 0.498, 1.4489999999999998, 1.446, 1.443, 0.0, -0.002, 1.4369999999999998, 1.4609999999999999, 1.4609999999999999, 1.472, 1.452, 1.458, 1.416, 1.434, 1.409, 1.4609999999999999, 1.413, 1.413, 1.451, 1.4489999999999998, 0.951, 1.455, 1.451, 1.452, 1.4489999999999998, 1.4569999999999999, 1.384, 1.419, 0.949, 1.448, 1.4609999999999999, 0.0, 1.4609999999999999, 1.455, 1.4609999999999999, -0.501, 1.409, -0.001, 1.4609999999999999, 0.5, 0.5, 1.446, 1.436, 1.4609999999999999], "policy_blue_0_reward": [0.495, 1.33, 0.499, 0.499, 0.498, 0.0, 0.0, -0.002, 0.499, 0.499, 0.5, 0.499, 0.499, 1.454, 0.499, -1.001, 0.959, 1.4180000000000001, 0.498, -0.015000000000000006, -0.001, -0.001, -0.501, -0.501, 1.446, 0.0, 0.497, 1.443, 0.484, 0.498, 0.5, 0.498, 0.499, 1.455, -0.502, -0.504, 0.498, 0.907, 1.4809999999999999, -1.002, 1.4529999999999998, 0.496, 0.0, 0.498, -0.502, -1.0, -1.002, -0.002, 0.498, 1.4569999999999999, -0.003, -1.0, 1.44, 0.499, 0.499, 0.499, 0.46299999999999997, 0.496, 0.499, 1.444, 1.432, -0.003, 0.499, 0.495, 1.4449999999999998, 0.493, 0.497, -0.503, 0.497, -0.002, 0.5, 0.5, 0.954, -0.002, 0.498, 0.46399999999999997, 0.497, 0.0, -0.001, 0.0, 0.498, 0.498, 1.4649999999999999, 1.4449999999999998, -0.004, 1.4180000000000001, 1.448, 0.498, 0.499, -1.001, 0.5, 0.495, 1.454, 0.497, 0.498, 0.499, 0.5, 0.0, -0.5, 0.497, 0.496, 1.447, 0.5, -0.004, 0.498, 1.4060000000000001, 1.458, 0.499, 0.5, 0.499, -1.002, 0.499, 0.498, 0.499, 0.495, 0.496, 0.497, 0.495, 0.496, 0.499, 0.5, -1.001, 0.499, 0.496, -0.002, 0.498, -0.5019999999999999, 0.498, 0.494, -1.0, 0.498, 0.5, 1.4569999999999999, 0.0, 0.499, -0.502, 1.405, 0.496, 1.3639999999999999, 0.498, 1.4569999999999999, 1.458, 0.499, -0.001, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4194056248675753, "mean_inference_ms": 7.4684122281451435, "mean_action_processing_ms": 0.3913006612313951, "mean_env_wait_ms": 0.5220215543589447, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.19001516802557583, "StateBufferConnector_ms": 0.01021048118328226, "ViewRequirementAgentConnector_ms": 0.19424660452480974}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 904000, "num_agent_steps_trained": 904000, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.60601720073804, "num_env_steps_trained_throughput_per_sec": 127.60601720073804, "timesteps_total": 452000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 904000, "timers": {"training_iteration_time_ms": 32115.868, "sample_time_ms": 4169.002, "learn_time_ms": 27916.703, "learn_throughput": 143.283, "synch_weights_time_ms": 28.499}, "counters": {"num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 904000, "num_agent_steps_trained": 904000}, "done": false, "episodes_total": 8549, "training_iteration": 113, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-57-16", "timestamp": 1694840236, "time_this_iter_s": 31.365435123443604, "time_total_s": 3532.6555845737457, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219b4d30>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3532.6555845737457, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 23.956521739130444, "ram_util_percent": 57.12826086956521}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5637583892617449, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.174496644295302, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09395973154362416, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.174496644295302, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12751677852348994, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09395973154362416, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.174496644295302, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09395973154362416, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4906981077045202, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03724415125216183, "policy_loss": -0.07483544352047224, "vf_loss": 0.030903208045735178, "vf_explained_var": 0.7744538253794114, "kl": 0.010155587638764408, "entropy": 0.9960106303294499, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 108960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5167489807276676, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.047306614877985945, "policy_loss": -0.08936198033916298, "vf_loss": 0.03895425035637648, "vf_explained_var": 0.5667889961972833, "kl": 0.010533888060850382, "entropy": 1.4192738637328148, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 108960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.05500000000000005, "episode_reward_mean": 1.4516979865771813, "episode_len_mean": 31.100671140939596, "episode_media": {}, "episodes_this_iter": 149, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.4689999999999999, "blue_0": 1.467}, "policy_reward_mean": {"red_0": 1.0600939597315437, "blue_0": 0.3916040268456376}, "custom_metrics": {"red_0/door_open_done_mean": 0.5637583892617449, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.174496644295302, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09395973154362416, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.174496644295302, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12751677852348994, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09395973154362416, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.174496644295302, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09395973154362416, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.943, 0.46599999999999997, 1.946, 1.946, 1.944, 1.9300000000000002, 0.9630000000000001, 0.9470000000000001, 0.46699999999999997, 1.9569999999999999, 1.9369999999999998, 1.959, 1.4569999999999999, 1.931, 1.956, 1.4569999999999999, 1.9529999999999998, 1.948, 1.443, 1.946, -0.030999999999999917, 0.9210000000000003, 1.9100000000000001, 1.958, 1.45, 1.95, 0.9259999999999999, 1.924, 1.907, 1.9289999999999998, 1.928, 1.956, 1.936, 0.954, -0.05499999999999994, 1.9489999999999998, 1.952, 1.955, 0.956, -0.05500000000000005, 1.434, 1.96, 0.45699999999999996, 1.955, 0.9510000000000001, 1.944, 1.957, 1.9569999999999999, 1.954, 1.9569999999999999, 0.946, 1.87, 1.955, 1.897, 1.456, 1.912, 1.9609999999999999, 0.4670000000000001, 1.448, 1.951, 1.947, 1.94, 0.46599999999999997, 0.941, -0.04700000000000004, 0.96, 0.954, 0.835, 1.96, 1.955, 1.944, 1.454, 0.364, 1.952, 1.9529999999999998, 0.46099999999999997, 1.923, 1.433, 1.9609999999999999, 1.938, 0.9239999999999999, 0.30700000000000005, 0.964, 1.889, 0.962, 1.946, 1.917, 1.931, 1.952, 1.959, -0.027000000000000024, 1.955, 0.46399999999999997, 1.951, 1.443, 1.942, 1.879, 0.962, 1.948, 0.45699999999999985, 1.447, 0.477, 1.9529999999999998, 1.9380000000000002, 1.951, 1.4569999999999999, 1.8399999999999999, -0.04500000000000004, 1.913, 1.4489999999999998, 0.9229999999999999, 1.9609999999999999, 1.458, 0.46899999999999986, 1.452, 1.942, 1.942, -0.05400000000000005, 1.9449999999999998, 1.947, 1.709, 1.444, 0.42799999999999994, 1.4380000000000002, 1.4529999999999998, 1.936, 1.9489999999999998, 1.951, 1.9449999999999998, 0.951, 1.452, 1.9609999999999999, 1.951, 0.41999999999999993, 0.4590000000000001, 1.94, 0.958, 1.438, 0.45099999999999996, 1.944, 0.956, 0.46099999999999985, 1.9340000000000002, 1.946, 1.9409999999999998, 1.943, 0.44700000000000006, 1.4569999999999999, 1.451], "episode_lengths": [300, 11, 17, 18, 18, 23, 12, 17, 11, 14, 20, 13, 14, 21, 14, 14, 15, 16, 18, 16, 10, 26, 28, 14, 16, 16, 24, 23, 29, 22, 23, 14, 20, 15, 16, 16, 15, 15, 14, 177, 21, 13, 14, 15, 16, 18, 14, 14, 15, 14, 17, 40, 15, 33, 14, 28, 13, 11, 17, 16, 17, 19, 11, 18, 15, 13, 15, 48, 13, 15, 18, 15, 44, 16, 15, 13, 25, 21, 13, 20, 24, 62, 12, 35, 12, 18, 27, 23, 15, 13, 9, 14, 300, 15, 19, 18, 40, 300, 16, 14, 17, 7, 15, 20, 16, 14, 47, 15, 28, 17, 300, 13, 14, 10, 15, 19, 19, 18, 18, 17, 91, 18, 300, 20, 15, 20, 16, 16, 18, 16, 16, 13, 16, 26, 13, 19, 300, 20, 16, 17, 14, 12, 20, 17, 19, 18, 16, 14, 16], "policy_red_0_reward": [0.473, -1.001, 1.4489999999999998, 0.5, 1.446, 1.431, 1.463, 1.4489999999999998, -0.5, 1.458, 1.44, 1.4609999999999999, 1.4569999999999999, 1.4369999999999998, 1.458, -0.001, 1.455, 1.451, 1.446, 1.452, -1.0, 1.4220000000000002, 1.415, 0.5, 1.451, 1.451, 1.427, 0.495, 1.412, 1.431, 0.5, 1.458, 0.499, 1.455, 0.949, 1.451, 1.4529999999999998, 1.455, 1.456, 0.954, 1.434, 1.4609999999999999, -0.5, 0.5, 1.451, 1.4449999999999998, 1.458, 1.458, 1.455, 1.458, 1.448, 1.3780000000000001, 1.455, 1.401, 1.458, 1.415, 1.4609999999999999, 1.467, 1.4489999999999998, 1.452, 1.4489999999999998, 1.443, 1.467, -0.503, -1.0, 1.4609999999999999, 1.455, -0.506, 1.4609999999999999, 0.5, 1.446, 1.454, -1.002, 1.452, 1.455, -0.5, 1.424, 1.436, 0.5, 1.439, 1.427, -1.003, 1.464, 0.497, 1.464, 1.446, 0.499, 0.5, 1.455, 1.4609999999999999, 0.973, 1.4569999999999999, 0.485, 1.454, 1.443, 1.446, 1.38, 0.487, 1.452, 1.4569999999999999, 1.447, -0.5, 1.455, 1.439, 1.452, 1.4569999999999999, 1.349, 0.955, 0.498, 1.4489999999999998, 0.46699999999999997, 0.5, 1.458, 1.4689999999999999, 1.455, 1.443, 1.443, 0.946, 0.499, 1.4489999999999998, 0.486, 1.446, -0.03400000000000002, 1.44, 1.455, 1.439, 1.451, 1.452, 0.5, -0.5, 1.452, 0.5, 1.452, 1.4220000000000002, 0.96, 1.442, 0.489, 1.44, -0.501, 1.448, -0.501, 1.464, 1.439, 0.5, 1.4409999999999998, 1.4449999999999998, 1.45, 1.458, 1.452], "policy_blue_0_reward": [0.47, 1.467, 0.497, 1.446, 0.498, 0.499, -0.5, -0.502, 0.967, 0.499, 0.497, 0.498, 0.0, 0.494, 0.498, 1.458, 0.498, 0.497, -0.003, 0.494, 0.969, -0.5009999999999999, 0.495, 1.458, -0.001, 0.499, -0.501, 1.429, 0.495, 0.498, 1.428, 0.498, 1.4369999999999998, -0.501, -1.0039999999999998, 0.498, 0.499, 0.5, -0.5, -1.009, 0.0, 0.499, 0.957, 1.455, -0.5, 0.499, 0.499, 0.499, 0.499, 0.499, -0.502, 0.492, 0.5, 0.496, -0.002, 0.497, 0.5, -1.0, -0.001, 0.499, 0.498, 0.497, -1.001, 1.444, 0.953, -0.501, -0.501, 1.341, 0.499, 1.455, 0.498, 0.0, 1.366, 0.5, 0.498, 0.961, 0.499, -0.003, 1.4609999999999999, 0.499, -0.503, 1.31, -0.5, 1.392, -0.502, 0.5, 1.4180000000000001, 1.431, 0.497, 0.498, -1.0, 0.498, -0.02100000000000001, 0.497, 0.0, 0.496, 0.499, 0.475, 0.496, -1.0, 0.0, 0.977, 0.498, 0.499, 0.499, 0.0, 0.491, -1.0, 1.415, 0.0, 0.45599999999999996, 1.4609999999999999, 0.0, -1.0, -0.003, 0.499, 0.499, -1.0, 1.446, 0.498, 1.2229999999999999, -0.002, 0.46199999999999997, -0.002, -0.002, 0.497, 0.498, 0.499, 1.4449999999999998, 1.451, 0.0, 1.4609999999999999, 0.499, -1.002, -0.501, 0.498, 0.469, -0.002, 0.952, 0.496, 1.4569999999999999, -1.003, 0.495, 1.446, 0.5, 0.498, -1.003, -0.001, -0.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4207434436163975, "mean_inference_ms": 7.471151020586648, "mean_action_processing_ms": 0.39121752958063993, "mean_env_wait_ms": 0.5217324295244522, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14666790930216744, "StateBufferConnector_ms": 0.009439855613964517, "ViewRequirementAgentConnector_ms": 0.18781495574336723}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.05500000000000005, "episode_reward_mean": 1.4516979865771813, "episode_len_mean": 31.100671140939596, "episodes_this_iter": 149, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.4689999999999999, "blue_0": 1.467}, "policy_reward_mean": {"red_0": 1.0600939597315437, "blue_0": 0.3916040268456376}, "hist_stats": {"episode_reward": [0.943, 0.46599999999999997, 1.946, 1.946, 1.944, 1.9300000000000002, 0.9630000000000001, 0.9470000000000001, 0.46699999999999997, 1.9569999999999999, 1.9369999999999998, 1.959, 1.4569999999999999, 1.931, 1.956, 1.4569999999999999, 1.9529999999999998, 1.948, 1.443, 1.946, -0.030999999999999917, 0.9210000000000003, 1.9100000000000001, 1.958, 1.45, 1.95, 0.9259999999999999, 1.924, 1.907, 1.9289999999999998, 1.928, 1.956, 1.936, 0.954, -0.05499999999999994, 1.9489999999999998, 1.952, 1.955, 0.956, -0.05500000000000005, 1.434, 1.96, 0.45699999999999996, 1.955, 0.9510000000000001, 1.944, 1.957, 1.9569999999999999, 1.954, 1.9569999999999999, 0.946, 1.87, 1.955, 1.897, 1.456, 1.912, 1.9609999999999999, 0.4670000000000001, 1.448, 1.951, 1.947, 1.94, 0.46599999999999997, 0.941, -0.04700000000000004, 0.96, 0.954, 0.835, 1.96, 1.955, 1.944, 1.454, 0.364, 1.952, 1.9529999999999998, 0.46099999999999997, 1.923, 1.433, 1.9609999999999999, 1.938, 0.9239999999999999, 0.30700000000000005, 0.964, 1.889, 0.962, 1.946, 1.917, 1.931, 1.952, 1.959, -0.027000000000000024, 1.955, 0.46399999999999997, 1.951, 1.443, 1.942, 1.879, 0.962, 1.948, 0.45699999999999985, 1.447, 0.477, 1.9529999999999998, 1.9380000000000002, 1.951, 1.4569999999999999, 1.8399999999999999, -0.04500000000000004, 1.913, 1.4489999999999998, 0.9229999999999999, 1.9609999999999999, 1.458, 0.46899999999999986, 1.452, 1.942, 1.942, -0.05400000000000005, 1.9449999999999998, 1.947, 1.709, 1.444, 0.42799999999999994, 1.4380000000000002, 1.4529999999999998, 1.936, 1.9489999999999998, 1.951, 1.9449999999999998, 0.951, 1.452, 1.9609999999999999, 1.951, 0.41999999999999993, 0.4590000000000001, 1.94, 0.958, 1.438, 0.45099999999999996, 1.944, 0.956, 0.46099999999999985, 1.9340000000000002, 1.946, 1.9409999999999998, 1.943, 0.44700000000000006, 1.4569999999999999, 1.451], "episode_lengths": [300, 11, 17, 18, 18, 23, 12, 17, 11, 14, 20, 13, 14, 21, 14, 14, 15, 16, 18, 16, 10, 26, 28, 14, 16, 16, 24, 23, 29, 22, 23, 14, 20, 15, 16, 16, 15, 15, 14, 177, 21, 13, 14, 15, 16, 18, 14, 14, 15, 14, 17, 40, 15, 33, 14, 28, 13, 11, 17, 16, 17, 19, 11, 18, 15, 13, 15, 48, 13, 15, 18, 15, 44, 16, 15, 13, 25, 21, 13, 20, 24, 62, 12, 35, 12, 18, 27, 23, 15, 13, 9, 14, 300, 15, 19, 18, 40, 300, 16, 14, 17, 7, 15, 20, 16, 14, 47, 15, 28, 17, 300, 13, 14, 10, 15, 19, 19, 18, 18, 17, 91, 18, 300, 20, 15, 20, 16, 16, 18, 16, 16, 13, 16, 26, 13, 19, 300, 20, 16, 17, 14, 12, 20, 17, 19, 18, 16, 14, 16], "policy_red_0_reward": [0.473, -1.001, 1.4489999999999998, 0.5, 1.446, 1.431, 1.463, 1.4489999999999998, -0.5, 1.458, 1.44, 1.4609999999999999, 1.4569999999999999, 1.4369999999999998, 1.458, -0.001, 1.455, 1.451, 1.446, 1.452, -1.0, 1.4220000000000002, 1.415, 0.5, 1.451, 1.451, 1.427, 0.495, 1.412, 1.431, 0.5, 1.458, 0.499, 1.455, 0.949, 1.451, 1.4529999999999998, 1.455, 1.456, 0.954, 1.434, 1.4609999999999999, -0.5, 0.5, 1.451, 1.4449999999999998, 1.458, 1.458, 1.455, 1.458, 1.448, 1.3780000000000001, 1.455, 1.401, 1.458, 1.415, 1.4609999999999999, 1.467, 1.4489999999999998, 1.452, 1.4489999999999998, 1.443, 1.467, -0.503, -1.0, 1.4609999999999999, 1.455, -0.506, 1.4609999999999999, 0.5, 1.446, 1.454, -1.002, 1.452, 1.455, -0.5, 1.424, 1.436, 0.5, 1.439, 1.427, -1.003, 1.464, 0.497, 1.464, 1.446, 0.499, 0.5, 1.455, 1.4609999999999999, 0.973, 1.4569999999999999, 0.485, 1.454, 1.443, 1.446, 1.38, 0.487, 1.452, 1.4569999999999999, 1.447, -0.5, 1.455, 1.439, 1.452, 1.4569999999999999, 1.349, 0.955, 0.498, 1.4489999999999998, 0.46699999999999997, 0.5, 1.458, 1.4689999999999999, 1.455, 1.443, 1.443, 0.946, 0.499, 1.4489999999999998, 0.486, 1.446, -0.03400000000000002, 1.44, 1.455, 1.439, 1.451, 1.452, 0.5, -0.5, 1.452, 0.5, 1.452, 1.4220000000000002, 0.96, 1.442, 0.489, 1.44, -0.501, 1.448, -0.501, 1.464, 1.439, 0.5, 1.4409999999999998, 1.4449999999999998, 1.45, 1.458, 1.452], "policy_blue_0_reward": [0.47, 1.467, 0.497, 1.446, 0.498, 0.499, -0.5, -0.502, 0.967, 0.499, 0.497, 0.498, 0.0, 0.494, 0.498, 1.458, 0.498, 0.497, -0.003, 0.494, 0.969, -0.5009999999999999, 0.495, 1.458, -0.001, 0.499, -0.501, 1.429, 0.495, 0.498, 1.428, 0.498, 1.4369999999999998, -0.501, -1.0039999999999998, 0.498, 0.499, 0.5, -0.5, -1.009, 0.0, 0.499, 0.957, 1.455, -0.5, 0.499, 0.499, 0.499, 0.499, 0.499, -0.502, 0.492, 0.5, 0.496, -0.002, 0.497, 0.5, -1.0, -0.001, 0.499, 0.498, 0.497, -1.001, 1.444, 0.953, -0.501, -0.501, 1.341, 0.499, 1.455, 0.498, 0.0, 1.366, 0.5, 0.498, 0.961, 0.499, -0.003, 1.4609999999999999, 0.499, -0.503, 1.31, -0.5, 1.392, -0.502, 0.5, 1.4180000000000001, 1.431, 0.497, 0.498, -1.0, 0.498, -0.02100000000000001, 0.497, 0.0, 0.496, 0.499, 0.475, 0.496, -1.0, 0.0, 0.977, 0.498, 0.499, 0.499, 0.0, 0.491, -1.0, 1.415, 0.0, 0.45599999999999996, 1.4609999999999999, 0.0, -1.0, -0.003, 0.499, 0.499, -1.0, 1.446, 0.498, 1.2229999999999999, -0.002, 0.46199999999999997, -0.002, -0.002, 0.497, 0.498, 0.499, 1.4449999999999998, 1.451, 0.0, 1.4609999999999999, 0.499, -1.002, -0.501, 0.498, 0.469, -0.002, 0.952, 0.496, 1.4569999999999999, -1.003, 0.495, 1.446, 0.5, 0.498, -1.003, -0.001, -0.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4207434436163975, "mean_inference_ms": 7.471151020586648, "mean_action_processing_ms": 0.39121752958063993, "mean_env_wait_ms": 0.5217324295244522, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14666790930216744, "StateBufferConnector_ms": 0.009439855613964517, "ViewRequirementAgentConnector_ms": 0.18781495574336723}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 123.06998929597566, "num_env_steps_trained_throughput_per_sec": 123.06998929597566, "timesteps_total": 456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 32233.186, "sample_time_ms": 4157.699, "learn_time_ms": 28045.694, "learn_throughput": 142.624, "synch_weights_time_ms": 28.114}, "counters": {"num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "episodes_total": 8698, "training_iteration": 114, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-57-49", "timestamp": 1694840269, "time_this_iter_s": 32.522085189819336, "time_total_s": 3565.177669763565, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219b76d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3565.177669763565, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 26.71914893617021, "ram_util_percent": 57.19574468085105}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6580645161290323, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.09032258064516129, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09032258064516129, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.09032258064516129, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12903225806451613, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09032258064516129, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.09032258064516129, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09032258064516129, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4655953715244929, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03560975703488414, "policy_loss": -0.0699790444784109, "vf_loss": 0.030918563850961315, "vf_explained_var": 0.768133720693489, "kl": 0.008747188149825055, "entropy": 1.0171825094769398, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 109920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5042487509393444, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.051973216196347496, "policy_loss": -0.09001461822723893, "vf_loss": 0.03010105123394169, "vf_explained_var": 0.6020244663581252, "kl": 0.010699751685008271, "entropy": 1.3844958903888862, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 109920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 920000, "num_agent_steps_trained": 920000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.050000000000000044, "episode_reward_mean": 1.548283870967742, "episode_len_mean": 26.45806451612903, "episode_media": {}, "episodes_this_iter": 155, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.0610838709677421, "blue_0": 0.48719999999999997}, "custom_metrics": {"red_0/door_open_done_mean": 0.6580645161290323, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.09032258064516129, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09032258064516129, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.09032258064516129, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.12903225806451613, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09032258064516129, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.09032258064516129, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09032258064516129, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.9569999999999999, 1.9409999999999998, 1.9489999999999998, 0.4109999999999999, 1.928, 1.9329999999999998, 1.9529999999999998, 1.9609999999999999, 1.96, 0.9329999999999999, 1.952, 1.909, 0.9249999999999999, 1.9569999999999999, 1.96, 1.444, 1.9569999999999999, 0.46699999999999997, 0.44799999999999995, 0.44599999999999995, 1.9540000000000002, 1.9489999999999998, 1.893, 1.9609999999999999, -0.040999999999999925, 1.921, 0.479, 1.9609999999999999, 1.948, 1.917, 1.94, 1.946, 1.944, 1.912, 1.9569999999999999, 1.956, 1.951, 1.942, 1.438, 1.944, 1.954, 1.451, 1.951, 1.44, 1.459, 1.955, 1.948, 1.96, 1.95, 1.458, 1.9329999999999998, 1.452, 0.46099999999999997, 1.9529999999999998, 0.47, 1.9489999999999998, 0.43900000000000006, 1.908, 1.4609999999999999, -0.025999999999999912, 0.948, 1.9289999999999998, 1.955, 1.9529999999999998, 1.8130000000000002, 1.955, 1.436, 1.9569999999999999, -0.03500000000000003, 1.439, 0.43299999999999983, 1.4220000000000002, 1.9500000000000002, 1.9369999999999998, 1.439, 1.9529999999999998, -0.031000000000000028, 1.9529999999999998, 1.938, 1.952, 1.9329999999999998, 1.953, 1.954, 1.458, 1.942, 1.934, 1.4489999999999998, 1.952, 1.939, 1.958, 1.9569999999999999, 1.9609999999999999, 1.439, 1.452, 1.9529999999999998, 1.4369999999999998, 0.4660000000000002, 1.946, -0.027999999999999914, 1.9489999999999998, 1.955, 1.96, 1.9569999999999999, 0.43099999999999994, 1.936, 1.936, 1.9569999999999999, 1.425, 1.442, 1.931, 1.4329999999999998, 1.96, 1.959, 0.8079999999999998, -0.050000000000000044, 1.958, 0.42099999999999993, 1.96, 1.903, 1.451, 1.948, 1.96, 1.9369999999999998, 1.443, 1.951, 0.967, 1.935, 0.965, 0.44799999999999995, 1.951, 1.9489999999999998, 1.951, 1.458, 0.935, 1.9449999999999998, 0.45499999999999996, -0.03199999999999992, 1.954, 1.951, 1.452, 1.959, 0.44799999999999995, 1.942, 1.935, 1.948, 1.924, 0.4089999999999999, 1.9489999999999998, 1.9609999999999999, 0.9359999999999999, 1.8980000000000001, 0.4630000000000001, 1.956, 1.4449999999999998, 0.46599999999999997], "episode_lengths": [14, 18, 16, 300, 23, 21, 15, 13, 13, 300, 16, 28, 300, 14, 13, 18, 14, 11, 17, 17, 14, 17, 34, 13, 13, 26, 7, 13, 17, 27, 19, 17, 18, 27, 14, 14, 16, 18, 20, 18, 15, 16, 16, 20, 13, 14, 17, 13, 16, 14, 21, 16, 13, 15, 10, 17, 20, 28, 13, 8, 16, 22, 15, 15, 59, 15, 20, 14, 11, 20, 21, 25, 16, 20, 19, 15, 10, 15, 19, 16, 21, 15, 15, 14, 18, 21, 16, 16, 20, 14, 14, 13, 19, 16, 15, 20, 11, 17, 9, 16, 15, 13, 14, 22, 20, 21, 14, 23, 18, 22, 21, 13, 13, 60, 16, 14, 300, 13, 30, 16, 17, 13, 20, 18, 16, 11, 21, 11, 16, 16, 17, 16, 14, 21, 17, 14, 10, 15, 16, 16, 13, 16, 19, 21, 17, 24, 300, 17, 13, 20, 32, 12, 14, 18, 11], "policy_red_0_reward": [1.458, 1.444, 1.452, 0.43799999999999994, 1.4300000000000002, 1.434, 1.455, 1.4609999999999999, 1.4609999999999999, 0.46399999999999997, 0.5, 0.496, 0.45599999999999996, 1.4569999999999999, 1.4609999999999999, 1.446, 1.4569999999999999, -1.0, -0.5, 0.948, 1.4569999999999999, 1.4489999999999998, 1.396, 1.4609999999999999, 0.961, 1.4220000000000002, -1.0, 0.5, 0.499, 1.419, 1.442, 1.4489999999999998, 1.446, 1.416, 1.458, 1.4569999999999999, 1.452, 0.497, 1.44, 1.446, 0.499, 1.452, 1.452, 1.44, 1.4609999999999999, 1.458, 0.5, 1.4609999999999999, 1.451, 1.458, 1.436, 1.452, -1.0, 1.455, 1.47, 1.4489999999999998, 1.439, 0.496, 0.0, 0.976, 1.452, 1.431, 1.455, 1.454, 1.322, 1.455, 1.438, 0.499, 0.967, 1.44, 1.435, 1.424, 1.452, 1.439, 1.442, 1.4529999999999998, 0.97, 1.455, 1.443, 1.452, 0.499, 1.455, 1.455, 1.458, 0.498, 1.435, 1.451, 0.5, 1.439, 0.5, 1.458, 0.5, -0.001, 1.452, 1.454, 1.44, 0.967, 1.4489999999999998, -1.0, 1.452, 1.455, 0.499, 1.458, -0.502, 1.44, 0.499, 1.458, 1.429, 1.446, 1.431, 1.436, 1.4609999999999999, 1.4609999999999999, 1.315, -1.001, 1.458, -0.04100000000000003, 1.4609999999999999, 1.405, 1.452, 1.4489999999999998, 1.4609999999999999, 1.439, 1.4449999999999998, 1.452, -0.5, 1.436, -0.501, -0.502, 1.452, 1.4489999999999998, 1.452, 1.458, 1.436, 1.4489999999999998, -0.502, 0.969, 1.454, 1.452, 1.452, 1.4609999999999999, -1.003, 1.442, 0.499, 1.4489999999999998, 1.4249999999999998, 0.42899999999999994, 1.4489999999999998, 0.5, -0.502, 1.4020000000000001, 1.464, 1.458, 1.446, -1.0], "policy_blue_0_reward": [0.499, 0.497, 0.497, -0.027000000000000017, 0.498, 0.499, 0.498, 0.5, 0.499, 0.469, 1.452, 1.413, 0.469, 0.5, 0.499, -0.002, 0.5, 1.467, 0.948, -0.502, 0.497, 0.5, 0.497, 0.5, -1.0019999999999998, 0.499, 1.479, 1.4609999999999999, 1.4489999999999998, 0.498, 0.498, 0.497, 0.498, 0.496, 0.499, 0.499, 0.499, 1.4449999999999998, -0.002, 0.498, 1.455, -0.001, 0.499, 0.0, -0.002, 0.497, 1.448, 0.499, 0.499, 0.0, 0.497, 0.0, 1.4609999999999999, 0.498, -1.0, 0.5, -1.0, 1.412, 1.4609999999999999, -1.0019999999999998, -0.504, 0.498, 0.5, 0.499, 0.491, 0.5, -0.002, 1.458, -1.002, -0.001, -1.002, -0.002, 0.498, 0.498, -0.003, 0.5, -1.001, 0.498, 0.495, 0.5, 1.434, 0.498, 0.499, 0.0, 1.444, 0.499, -0.002, 1.452, 0.5, 1.458, 0.499, 1.4609999999999999, 1.44, 0.0, 0.499, -0.003, -0.5009999999999999, 0.497, 0.972, 0.497, 0.5, 1.4609999999999999, 0.499, 0.9329999999999999, 0.496, 1.4369999999999998, 0.499, -0.004, -0.004, 0.5, -0.003, 0.499, 0.498, -0.507, 0.951, 0.5, 0.46199999999999997, 0.499, 0.498, -0.001, 0.499, 0.499, 0.498, -0.002, 0.499, 1.467, 0.499, 1.466, 0.95, 0.499, 0.5, 0.499, 0.0, -0.501, 0.496, 0.957, -1.001, 0.5, 0.499, 0.0, 0.498, 1.451, 0.5, 1.436, 0.499, 0.499, -0.02000000000000001, 0.5, 1.4609999999999999, 1.438, 0.496, -1.001, 0.498, -0.001, 1.466]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4223933554541095, "mean_inference_ms": 7.468368872671189, "mean_action_processing_ms": 0.39000094581313466, "mean_env_wait_ms": 0.5219439602264607, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14485628374161258, "StateBufferConnector_ms": 0.009501672560168851, "ViewRequirementAgentConnector_ms": 0.18568700359713647}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.050000000000000044, "episode_reward_mean": 1.548283870967742, "episode_len_mean": 26.45806451612903, "episodes_this_iter": 155, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.0610838709677421, "blue_0": 0.48719999999999997}, "hist_stats": {"episode_reward": [1.9569999999999999, 1.9409999999999998, 1.9489999999999998, 0.4109999999999999, 1.928, 1.9329999999999998, 1.9529999999999998, 1.9609999999999999, 1.96, 0.9329999999999999, 1.952, 1.909, 0.9249999999999999, 1.9569999999999999, 1.96, 1.444, 1.9569999999999999, 0.46699999999999997, 0.44799999999999995, 0.44599999999999995, 1.9540000000000002, 1.9489999999999998, 1.893, 1.9609999999999999, -0.040999999999999925, 1.921, 0.479, 1.9609999999999999, 1.948, 1.917, 1.94, 1.946, 1.944, 1.912, 1.9569999999999999, 1.956, 1.951, 1.942, 1.438, 1.944, 1.954, 1.451, 1.951, 1.44, 1.459, 1.955, 1.948, 1.96, 1.95, 1.458, 1.9329999999999998, 1.452, 0.46099999999999997, 1.9529999999999998, 0.47, 1.9489999999999998, 0.43900000000000006, 1.908, 1.4609999999999999, -0.025999999999999912, 0.948, 1.9289999999999998, 1.955, 1.9529999999999998, 1.8130000000000002, 1.955, 1.436, 1.9569999999999999, -0.03500000000000003, 1.439, 0.43299999999999983, 1.4220000000000002, 1.9500000000000002, 1.9369999999999998, 1.439, 1.9529999999999998, -0.031000000000000028, 1.9529999999999998, 1.938, 1.952, 1.9329999999999998, 1.953, 1.954, 1.458, 1.942, 1.934, 1.4489999999999998, 1.952, 1.939, 1.958, 1.9569999999999999, 1.9609999999999999, 1.439, 1.452, 1.9529999999999998, 1.4369999999999998, 0.4660000000000002, 1.946, -0.027999999999999914, 1.9489999999999998, 1.955, 1.96, 1.9569999999999999, 0.43099999999999994, 1.936, 1.936, 1.9569999999999999, 1.425, 1.442, 1.931, 1.4329999999999998, 1.96, 1.959, 0.8079999999999998, -0.050000000000000044, 1.958, 0.42099999999999993, 1.96, 1.903, 1.451, 1.948, 1.96, 1.9369999999999998, 1.443, 1.951, 0.967, 1.935, 0.965, 0.44799999999999995, 1.951, 1.9489999999999998, 1.951, 1.458, 0.935, 1.9449999999999998, 0.45499999999999996, -0.03199999999999992, 1.954, 1.951, 1.452, 1.959, 0.44799999999999995, 1.942, 1.935, 1.948, 1.924, 0.4089999999999999, 1.9489999999999998, 1.9609999999999999, 0.9359999999999999, 1.8980000000000001, 0.4630000000000001, 1.956, 1.4449999999999998, 0.46599999999999997], "episode_lengths": [14, 18, 16, 300, 23, 21, 15, 13, 13, 300, 16, 28, 300, 14, 13, 18, 14, 11, 17, 17, 14, 17, 34, 13, 13, 26, 7, 13, 17, 27, 19, 17, 18, 27, 14, 14, 16, 18, 20, 18, 15, 16, 16, 20, 13, 14, 17, 13, 16, 14, 21, 16, 13, 15, 10, 17, 20, 28, 13, 8, 16, 22, 15, 15, 59, 15, 20, 14, 11, 20, 21, 25, 16, 20, 19, 15, 10, 15, 19, 16, 21, 15, 15, 14, 18, 21, 16, 16, 20, 14, 14, 13, 19, 16, 15, 20, 11, 17, 9, 16, 15, 13, 14, 22, 20, 21, 14, 23, 18, 22, 21, 13, 13, 60, 16, 14, 300, 13, 30, 16, 17, 13, 20, 18, 16, 11, 21, 11, 16, 16, 17, 16, 14, 21, 17, 14, 10, 15, 16, 16, 13, 16, 19, 21, 17, 24, 300, 17, 13, 20, 32, 12, 14, 18, 11], "policy_red_0_reward": [1.458, 1.444, 1.452, 0.43799999999999994, 1.4300000000000002, 1.434, 1.455, 1.4609999999999999, 1.4609999999999999, 0.46399999999999997, 0.5, 0.496, 0.45599999999999996, 1.4569999999999999, 1.4609999999999999, 1.446, 1.4569999999999999, -1.0, -0.5, 0.948, 1.4569999999999999, 1.4489999999999998, 1.396, 1.4609999999999999, 0.961, 1.4220000000000002, -1.0, 0.5, 0.499, 1.419, 1.442, 1.4489999999999998, 1.446, 1.416, 1.458, 1.4569999999999999, 1.452, 0.497, 1.44, 1.446, 0.499, 1.452, 1.452, 1.44, 1.4609999999999999, 1.458, 0.5, 1.4609999999999999, 1.451, 1.458, 1.436, 1.452, -1.0, 1.455, 1.47, 1.4489999999999998, 1.439, 0.496, 0.0, 0.976, 1.452, 1.431, 1.455, 1.454, 1.322, 1.455, 1.438, 0.499, 0.967, 1.44, 1.435, 1.424, 1.452, 1.439, 1.442, 1.4529999999999998, 0.97, 1.455, 1.443, 1.452, 0.499, 1.455, 1.455, 1.458, 0.498, 1.435, 1.451, 0.5, 1.439, 0.5, 1.458, 0.5, -0.001, 1.452, 1.454, 1.44, 0.967, 1.4489999999999998, -1.0, 1.452, 1.455, 0.499, 1.458, -0.502, 1.44, 0.499, 1.458, 1.429, 1.446, 1.431, 1.436, 1.4609999999999999, 1.4609999999999999, 1.315, -1.001, 1.458, -0.04100000000000003, 1.4609999999999999, 1.405, 1.452, 1.4489999999999998, 1.4609999999999999, 1.439, 1.4449999999999998, 1.452, -0.5, 1.436, -0.501, -0.502, 1.452, 1.4489999999999998, 1.452, 1.458, 1.436, 1.4489999999999998, -0.502, 0.969, 1.454, 1.452, 1.452, 1.4609999999999999, -1.003, 1.442, 0.499, 1.4489999999999998, 1.4249999999999998, 0.42899999999999994, 1.4489999999999998, 0.5, -0.502, 1.4020000000000001, 1.464, 1.458, 1.446, -1.0], "policy_blue_0_reward": [0.499, 0.497, 0.497, -0.027000000000000017, 0.498, 0.499, 0.498, 0.5, 0.499, 0.469, 1.452, 1.413, 0.469, 0.5, 0.499, -0.002, 0.5, 1.467, 0.948, -0.502, 0.497, 0.5, 0.497, 0.5, -1.0019999999999998, 0.499, 1.479, 1.4609999999999999, 1.4489999999999998, 0.498, 0.498, 0.497, 0.498, 0.496, 0.499, 0.499, 0.499, 1.4449999999999998, -0.002, 0.498, 1.455, -0.001, 0.499, 0.0, -0.002, 0.497, 1.448, 0.499, 0.499, 0.0, 0.497, 0.0, 1.4609999999999999, 0.498, -1.0, 0.5, -1.0, 1.412, 1.4609999999999999, -1.0019999999999998, -0.504, 0.498, 0.5, 0.499, 0.491, 0.5, -0.002, 1.458, -1.002, -0.001, -1.002, -0.002, 0.498, 0.498, -0.003, 0.5, -1.001, 0.498, 0.495, 0.5, 1.434, 0.498, 0.499, 0.0, 1.444, 0.499, -0.002, 1.452, 0.5, 1.458, 0.499, 1.4609999999999999, 1.44, 0.0, 0.499, -0.003, -0.5009999999999999, 0.497, 0.972, 0.497, 0.5, 1.4609999999999999, 0.499, 0.9329999999999999, 0.496, 1.4369999999999998, 0.499, -0.004, -0.004, 0.5, -0.003, 0.499, 0.498, -0.507, 0.951, 0.5, 0.46199999999999997, 0.499, 0.498, -0.001, 0.499, 0.499, 0.498, -0.002, 0.499, 1.467, 0.499, 1.466, 0.95, 0.499, 0.5, 0.499, 0.0, -0.501, 0.496, 0.957, -1.001, 0.5, 0.499, 0.0, 0.498, 1.451, 0.5, 1.436, 0.499, 0.499, -0.02000000000000001, 0.5, 1.4609999999999999, 1.438, 0.496, -1.001, 0.498, -0.001, 1.466]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4223933554541095, "mean_inference_ms": 7.468368872671189, "mean_action_processing_ms": 0.39000094581313466, "mean_env_wait_ms": 0.5219439602264607, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14485628374161258, "StateBufferConnector_ms": 0.009501672560168851, "ViewRequirementAgentConnector_ms": 0.18568700359713647}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 920000, "num_agent_steps_trained": 920000, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.93901823220511, "num_env_steps_trained_throughput_per_sec": 128.93901823220511, "timesteps_total": 460000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 920000, "timers": {"training_iteration_time_ms": 32164.071, "sample_time_ms": 4142.659, "learn_time_ms": 27991.709, "learn_throughput": 142.899, "synch_weights_time_ms": 28.022}, "counters": {"num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 920000, "num_agent_steps_trained": 920000}, "done": false, "episodes_total": 8853, "training_iteration": 115, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-58-21", "timestamp": 1694840301, "time_this_iter_s": 31.042479991912842, "time_total_s": 3596.220149755478, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a21eb00>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3596.220149755478, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 24.37111111111111, "ram_util_percent": 57.17111111111111}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6976744186046512, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0872093023255814, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09883720930232558, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.0872093023255814, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.10465116279069768, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09883720930232558, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.0872093023255814, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09883720930232558, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5176154199211548, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.030650854435710546, "policy_loss": -0.07391376332088839, "vf_loss": 0.04169272217453302, "vf_explained_var": 0.7042209545771281, "kl": 0.010248086528840275, "entropy": 0.9298748736580212, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 110880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5380323446976641, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04525047730906711, "policy_loss": -0.08710499035514659, "vf_loss": 0.0363579299650155, "vf_explained_var": 0.5312946279222767, "kl": 0.010971468895779277, "entropy": 1.3188291703661283, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 110880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.10599999999999998, "episode_reward_mean": 1.5874941860465115, "episode_len_mean": 23.488372093023255, "episode_media": {}, "episodes_this_iter": 172, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.478}, "policy_reward_mean": {"red_0": 1.1026686046511627, "blue_0": 0.4848255813953489}, "custom_metrics": {"red_0/door_open_done_mean": 0.6976744186046512, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0872093023255814, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.09883720930232558, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.0872093023255814, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.10465116279069768, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.09883720930232558, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.0872093023255814, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.09883720930232558, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.442, 0.95, 1.448, 0.472, 1.943, 1.96, 1.9449999999999998, 0.46199999999999997, 1.96, 1.904, 1.949, 1.954, 0.942, 1.447, 1.4609999999999999, 1.948, 0.476, 0.863, 1.929, 1.935, 1.9609999999999999, 0.975, 1.954, 1.9260000000000002, 1.951, 1.907, 1.958, 1.9409999999999998, 1.4489999999999998, 1.454, 1.942, 0.95, 1.9569999999999999, 1.948, 1.952, 1.9260000000000002, 1.4300000000000002, 1.92, 1.9449999999999998, 1.4609999999999999, 1.955, 1.4529999999999998, 1.958, 1.9609999999999999, 1.928, 1.9449999999999998, 1.9489999999999998, 0.5939999999999999, 1.954, 1.958, 1.9409999999999998, 1.944, 1.451, 1.955, 1.454, 1.922, 1.9300000000000002, 1.9369999999999998, 1.951, 0.9339999999999999, 1.4369999999999998, 1.9609999999999999, 0.45299999999999996, 0.9329999999999999, 1.9569999999999999, 1.9329999999999998, 1.958, 1.947, 1.438, 1.436, 1.9300000000000002, 1.947, 1.927, 1.946, 1.4140000000000001, 1.96, 1.946, 1.923, 1.9100000000000001, 0.978, 0.46899999999999986, 1.9260000000000002, 1.446, 1.451, 0.44899999999999995, 1.938, 1.173, 0.97, 1.951, 1.959, 1.448, 1.459, 1.9140000000000001, 1.958, 1.9569999999999999, 1.94, -0.10599999999999998, 1.9180000000000001, 0.469, 1.9409999999999998, 0.45500000000000007, 1.9300000000000002, 1.9209999999999998, 1.9449999999999998, 0.45899999999999996, 0.9080000000000001, 1.927, 1.455, -0.027999999999999914, 1.954, 1.959, 1.96, 1.944, 1.895, 1.9409999999999998, 1.909, 0.9729999999999999, 1.905, 1.958, 1.8639999999999999, 0.41000000000000003, 1.951, -0.050000000000000044, 0.97, 1.455, 1.4489999999999998, 1.416, 0.46599999999999997, 1.916, 1.958, 0.96, 1.952, 1.459, 0.9609999999999999, 1.459, 1.451, 1.399, 1.948, 1.9160000000000001, 1.954, 1.4260000000000002, 1.951, 1.944, 1.948, 1.955, 1.958, 1.4569999999999999, 1.9489999999999998, 1.939, 1.934, 1.9369999999999998, 1.923, 1.9489999999999998, 1.9489999999999998, 1.955, 0.952, 1.942, 0.9329999999999999, 1.9140000000000001, 0.475, 1.951, 1.412, 0.43399999999999994, 1.451, 1.919, 1.905, 1.943, 1.94, 0.941, 0.9239999999999999, 1.95, 1.92], "episode_lengths": [19, 16, 17, 9, 18, 13, 18, 12, 13, 31, 16, 15, 18, 17, 13, 16, 8, 44, 23, 20, 13, 8, 15, 23, 16, 29, 14, 19, 16, 14, 18, 16, 14, 17, 16, 23, 23, 26, 18, 13, 13, 15, 13, 13, 23, 18, 17, 274, 14, 14, 19, 18, 16, 14, 15, 24, 22, 20, 15, 300, 20, 13, 15, 22, 14, 21, 14, 17, 20, 20, 23, 17, 23, 17, 28, 13, 16, 25, 28, 7, 10, 23, 18, 16, 16, 20, 98, 10, 16, 13, 17, 13, 27, 14, 14, 19, 34, 25, 10, 18, 15, 23, 24, 18, 13, 29, 24, 15, 9, 15, 13, 13, 18, 34, 18, 29, 9, 30, 14, 42, 29, 16, 16, 10, 15, 16, 27, 10, 27, 14, 13, 16, 13, 12, 13, 16, 32, 17, 26, 15, 24, 16, 18, 17, 15, 14, 14, 16, 19, 20, 20, 24, 16, 16, 15, 16, 18, 20, 28, 8, 16, 29, 300, 16, 27, 30, 19, 19, 19, 23, 16, 26], "policy_red_0_reward": [1.442, 1.45, 1.4489999999999998, 0.972, 1.446, 1.4609999999999999, 0.5, -0.501, 1.4609999999999999, 1.407, 1.452, 1.455, 1.444, 1.448, 1.4609999999999999, 0.497, -1.0, 1.3679999999999999, 1.431, 1.439, 1.4609999999999999, -0.501, 1.455, 1.4300000000000002, 1.452, 1.412, 1.458, 1.443, 1.451, 1.458, 0.498, 1.451, 1.4569999999999999, 1.4489999999999998, 0.5, 0.499, 1.431, 1.421, 1.446, 1.4609999999999999, 1.4609999999999999, 1.455, 1.4609999999999999, 1.4609999999999999, 1.431, 1.4449999999999998, 1.4489999999999998, -0.037000000000000026, 1.4569999999999999, 1.458, 1.443, 0.499, 1.452, 1.4569999999999999, 1.455, 1.427, 1.4329999999999998, 1.438, 1.454, 0.46799999999999997, 1.44, 0.5, -1.002, -0.5, 1.458, 1.4369999999999998, 1.458, 1.4489999999999998, 1.44, 1.438, 1.431, 1.4489999999999998, 1.429, 1.447, 1.415, 1.4609999999999999, 1.451, 1.423, 1.416, -0.5, 0.97, 1.429, 1.446, 1.451, -0.5, 1.44, -0.012000000000000004, 1.47, 1.452, 1.4609999999999999, 1.4489999999999998, 1.4609999999999999, 1.415, 1.458, 1.458, 1.4409999999999998, 0.897, 1.4220000000000002, -0.5, 1.446, 1.455, 1.4300000000000002, 1.424, 1.446, -1.0, -0.5039999999999999, 1.428, 1.455, -1.0, 0.499, 1.4609999999999999, 1.4609999999999999, 0.499, 1.396, 1.444, 1.412, 1.4729999999999999, 1.409, 1.458, 1.371, 0.911, 1.452, 0.951, -0.5, 1.455, 1.4489999999999998, 1.4180000000000001, -1.003, 1.4180000000000001, 1.458, 1.4609999999999999, 1.452, 1.4609999999999999, 1.463, 1.4609999999999999, 1.452, 1.399, 1.4489999999999998, 1.421, 1.455, 1.428, 1.452, 1.446, 1.4489999999999998, 1.455, 0.5, 1.458, 1.452, 1.443, 1.439, 0.498, 1.427, 1.452, 1.452, 0.5, -0.5, 1.444, -0.501, 1.4140000000000001, -1.0, 1.451, 1.413, 0.46299999999999997, 1.451, 1.419, 0.499, 0.5, 0.498, -0.5, 1.431, 1.451, 0.5], "policy_blue_0_reward": [0.0, -0.5, -0.001, -0.5, 0.497, 0.499, 1.4449999999999998, 0.963, 0.499, 0.497, 0.497, 0.499, -0.502, -0.001, 0.0, 1.451, 1.476, -0.505, 0.498, 0.496, 0.5, 1.476, 0.499, 0.496, 0.499, 0.495, 0.5, 0.498, -0.002, -0.004, 1.444, -0.501, 0.5, 0.499, 1.452, 1.427, -0.001, 0.499, 0.499, 0.0, 0.494, -0.002, 0.497, 0.5, 0.497, 0.5, 0.5, 0.6309999999999999, 0.497, 0.5, 0.498, 1.4449999999999998, -0.001, 0.498, -0.001, 0.495, 0.497, 0.499, 0.497, 0.46599999999999997, -0.003, 1.4609999999999999, 1.455, 1.4329999999999998, 0.499, 0.496, 0.5, 0.498, -0.002, -0.002, 0.499, 0.498, 0.498, 0.499, -0.001, 0.499, 0.495, 0.5, 0.494, 1.478, -0.501, 0.497, 0.0, 0.0, 0.949, 0.498, 1.185, -0.5, 0.499, 0.498, -0.001, -0.002, 0.499, 0.5, 0.499, 0.499, -1.003, 0.496, 0.969, 0.495, -1.0, 0.5, 0.497, 0.499, 1.459, 1.412, 0.499, 0.0, 0.972, 1.455, 0.498, 0.499, 1.4449999999999998, 0.499, 0.497, 0.497, -0.5, 0.496, 0.5, 0.493, -0.501, 0.499, -1.001, 1.47, 0.0, 0.0, -0.002, 1.4689999999999999, 0.498, 0.5, -0.501, 0.5, -0.002, -0.502, -0.002, -0.001, 0.0, 0.499, 0.495, 0.499, -0.002, 0.499, 0.498, 0.499, 0.5, 1.458, -0.001, 0.497, 0.496, 0.495, 1.439, 0.496, 0.497, 0.497, 1.455, 1.452, 0.498, 1.434, 0.5, 1.475, 0.5, -0.001, -0.02900000000000002, 0.0, 0.5, 1.4060000000000001, 1.443, 1.442, 1.4409999999999998, -0.507, 0.499, 1.42]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4232111784542665, "mean_inference_ms": 7.462477296270549, "mean_action_processing_ms": 0.3904186718557017, "mean_env_wait_ms": 0.5224886835058625, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1524295917777128, "StateBufferConnector_ms": 0.009678962618805641, "ViewRequirementAgentConnector_ms": 0.19361383693162784}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.10599999999999998, "episode_reward_mean": 1.5874941860465115, "episode_len_mean": 23.488372093023255, "episodes_this_iter": 172, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.478}, "policy_reward_mean": {"red_0": 1.1026686046511627, "blue_0": 0.4848255813953489}, "hist_stats": {"episode_reward": [1.442, 0.95, 1.448, 0.472, 1.943, 1.96, 1.9449999999999998, 0.46199999999999997, 1.96, 1.904, 1.949, 1.954, 0.942, 1.447, 1.4609999999999999, 1.948, 0.476, 0.863, 1.929, 1.935, 1.9609999999999999, 0.975, 1.954, 1.9260000000000002, 1.951, 1.907, 1.958, 1.9409999999999998, 1.4489999999999998, 1.454, 1.942, 0.95, 1.9569999999999999, 1.948, 1.952, 1.9260000000000002, 1.4300000000000002, 1.92, 1.9449999999999998, 1.4609999999999999, 1.955, 1.4529999999999998, 1.958, 1.9609999999999999, 1.928, 1.9449999999999998, 1.9489999999999998, 0.5939999999999999, 1.954, 1.958, 1.9409999999999998, 1.944, 1.451, 1.955, 1.454, 1.922, 1.9300000000000002, 1.9369999999999998, 1.951, 0.9339999999999999, 1.4369999999999998, 1.9609999999999999, 0.45299999999999996, 0.9329999999999999, 1.9569999999999999, 1.9329999999999998, 1.958, 1.947, 1.438, 1.436, 1.9300000000000002, 1.947, 1.927, 1.946, 1.4140000000000001, 1.96, 1.946, 1.923, 1.9100000000000001, 0.978, 0.46899999999999986, 1.9260000000000002, 1.446, 1.451, 0.44899999999999995, 1.938, 1.173, 0.97, 1.951, 1.959, 1.448, 1.459, 1.9140000000000001, 1.958, 1.9569999999999999, 1.94, -0.10599999999999998, 1.9180000000000001, 0.469, 1.9409999999999998, 0.45500000000000007, 1.9300000000000002, 1.9209999999999998, 1.9449999999999998, 0.45899999999999996, 0.9080000000000001, 1.927, 1.455, -0.027999999999999914, 1.954, 1.959, 1.96, 1.944, 1.895, 1.9409999999999998, 1.909, 0.9729999999999999, 1.905, 1.958, 1.8639999999999999, 0.41000000000000003, 1.951, -0.050000000000000044, 0.97, 1.455, 1.4489999999999998, 1.416, 0.46599999999999997, 1.916, 1.958, 0.96, 1.952, 1.459, 0.9609999999999999, 1.459, 1.451, 1.399, 1.948, 1.9160000000000001, 1.954, 1.4260000000000002, 1.951, 1.944, 1.948, 1.955, 1.958, 1.4569999999999999, 1.9489999999999998, 1.939, 1.934, 1.9369999999999998, 1.923, 1.9489999999999998, 1.9489999999999998, 1.955, 0.952, 1.942, 0.9329999999999999, 1.9140000000000001, 0.475, 1.951, 1.412, 0.43399999999999994, 1.451, 1.919, 1.905, 1.943, 1.94, 0.941, 0.9239999999999999, 1.95, 1.92], "episode_lengths": [19, 16, 17, 9, 18, 13, 18, 12, 13, 31, 16, 15, 18, 17, 13, 16, 8, 44, 23, 20, 13, 8, 15, 23, 16, 29, 14, 19, 16, 14, 18, 16, 14, 17, 16, 23, 23, 26, 18, 13, 13, 15, 13, 13, 23, 18, 17, 274, 14, 14, 19, 18, 16, 14, 15, 24, 22, 20, 15, 300, 20, 13, 15, 22, 14, 21, 14, 17, 20, 20, 23, 17, 23, 17, 28, 13, 16, 25, 28, 7, 10, 23, 18, 16, 16, 20, 98, 10, 16, 13, 17, 13, 27, 14, 14, 19, 34, 25, 10, 18, 15, 23, 24, 18, 13, 29, 24, 15, 9, 15, 13, 13, 18, 34, 18, 29, 9, 30, 14, 42, 29, 16, 16, 10, 15, 16, 27, 10, 27, 14, 13, 16, 13, 12, 13, 16, 32, 17, 26, 15, 24, 16, 18, 17, 15, 14, 14, 16, 19, 20, 20, 24, 16, 16, 15, 16, 18, 20, 28, 8, 16, 29, 300, 16, 27, 30, 19, 19, 19, 23, 16, 26], "policy_red_0_reward": [1.442, 1.45, 1.4489999999999998, 0.972, 1.446, 1.4609999999999999, 0.5, -0.501, 1.4609999999999999, 1.407, 1.452, 1.455, 1.444, 1.448, 1.4609999999999999, 0.497, -1.0, 1.3679999999999999, 1.431, 1.439, 1.4609999999999999, -0.501, 1.455, 1.4300000000000002, 1.452, 1.412, 1.458, 1.443, 1.451, 1.458, 0.498, 1.451, 1.4569999999999999, 1.4489999999999998, 0.5, 0.499, 1.431, 1.421, 1.446, 1.4609999999999999, 1.4609999999999999, 1.455, 1.4609999999999999, 1.4609999999999999, 1.431, 1.4449999999999998, 1.4489999999999998, -0.037000000000000026, 1.4569999999999999, 1.458, 1.443, 0.499, 1.452, 1.4569999999999999, 1.455, 1.427, 1.4329999999999998, 1.438, 1.454, 0.46799999999999997, 1.44, 0.5, -1.002, -0.5, 1.458, 1.4369999999999998, 1.458, 1.4489999999999998, 1.44, 1.438, 1.431, 1.4489999999999998, 1.429, 1.447, 1.415, 1.4609999999999999, 1.451, 1.423, 1.416, -0.5, 0.97, 1.429, 1.446, 1.451, -0.5, 1.44, -0.012000000000000004, 1.47, 1.452, 1.4609999999999999, 1.4489999999999998, 1.4609999999999999, 1.415, 1.458, 1.458, 1.4409999999999998, 0.897, 1.4220000000000002, -0.5, 1.446, 1.455, 1.4300000000000002, 1.424, 1.446, -1.0, -0.5039999999999999, 1.428, 1.455, -1.0, 0.499, 1.4609999999999999, 1.4609999999999999, 0.499, 1.396, 1.444, 1.412, 1.4729999999999999, 1.409, 1.458, 1.371, 0.911, 1.452, 0.951, -0.5, 1.455, 1.4489999999999998, 1.4180000000000001, -1.003, 1.4180000000000001, 1.458, 1.4609999999999999, 1.452, 1.4609999999999999, 1.463, 1.4609999999999999, 1.452, 1.399, 1.4489999999999998, 1.421, 1.455, 1.428, 1.452, 1.446, 1.4489999999999998, 1.455, 0.5, 1.458, 1.452, 1.443, 1.439, 0.498, 1.427, 1.452, 1.452, 0.5, -0.5, 1.444, -0.501, 1.4140000000000001, -1.0, 1.451, 1.413, 0.46299999999999997, 1.451, 1.419, 0.499, 0.5, 0.498, -0.5, 1.431, 1.451, 0.5], "policy_blue_0_reward": [0.0, -0.5, -0.001, -0.5, 0.497, 0.499, 1.4449999999999998, 0.963, 0.499, 0.497, 0.497, 0.499, -0.502, -0.001, 0.0, 1.451, 1.476, -0.505, 0.498, 0.496, 0.5, 1.476, 0.499, 0.496, 0.499, 0.495, 0.5, 0.498, -0.002, -0.004, 1.444, -0.501, 0.5, 0.499, 1.452, 1.427, -0.001, 0.499, 0.499, 0.0, 0.494, -0.002, 0.497, 0.5, 0.497, 0.5, 0.5, 0.6309999999999999, 0.497, 0.5, 0.498, 1.4449999999999998, -0.001, 0.498, -0.001, 0.495, 0.497, 0.499, 0.497, 0.46599999999999997, -0.003, 1.4609999999999999, 1.455, 1.4329999999999998, 0.499, 0.496, 0.5, 0.498, -0.002, -0.002, 0.499, 0.498, 0.498, 0.499, -0.001, 0.499, 0.495, 0.5, 0.494, 1.478, -0.501, 0.497, 0.0, 0.0, 0.949, 0.498, 1.185, -0.5, 0.499, 0.498, -0.001, -0.002, 0.499, 0.5, 0.499, 0.499, -1.003, 0.496, 0.969, 0.495, -1.0, 0.5, 0.497, 0.499, 1.459, 1.412, 0.499, 0.0, 0.972, 1.455, 0.498, 0.499, 1.4449999999999998, 0.499, 0.497, 0.497, -0.5, 0.496, 0.5, 0.493, -0.501, 0.499, -1.001, 1.47, 0.0, 0.0, -0.002, 1.4689999999999999, 0.498, 0.5, -0.501, 0.5, -0.002, -0.502, -0.002, -0.001, 0.0, 0.499, 0.495, 0.499, -0.002, 0.499, 0.498, 0.499, 0.5, 1.458, -0.001, 0.497, 0.496, 0.495, 1.439, 0.496, 0.497, 0.497, 1.455, 1.452, 0.498, 1.434, 0.5, 1.475, 0.5, -0.001, -0.02900000000000002, 0.0, 0.5, 1.4060000000000001, 1.443, 1.442, 1.4409999999999998, -0.507, 0.499, 1.42]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4232111784542665, "mean_inference_ms": 7.462477296270549, "mean_action_processing_ms": 0.3904186718557017, "mean_env_wait_ms": 0.5224886835058625, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1524295917777128, "StateBufferConnector_ms": 0.009678962618805641, "ViewRequirementAgentConnector_ms": 0.19361383693162784}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 125.60495315411823, "num_env_steps_trained_throughput_per_sec": 125.60495315411823, "timesteps_total": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 32245.415, "sample_time_ms": 4147.341, "learn_time_ms": 28068.423, "learn_throughput": 142.509, "synch_weights_time_ms": 28.018}, "counters": {"num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "episodes_total": 9025, "training_iteration": 116, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-58-54", "timestamp": 1694840334, "time_this_iter_s": 31.867835760116577, "time_total_s": 3628.0879855155945, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a255480>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3628.0879855155945, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 26.94565217391304, "ram_util_percent": 57.12173913043478}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6503496503496503, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.13986013986013987, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06993006993006994, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.13986013986013987, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11888111888111888, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.06993006993006994, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.13986013986013987, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06993006993006994, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47390423896722494, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03611244277029376, "policy_loss": -0.0730126258417537, "vf_loss": 0.03134318755376929, "vf_explained_var": 0.7438944911584258, "kl": 0.009785592719833525, "entropy": 1.0642142549157143, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 111840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5089548231257747, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04953667765609377, "policy_loss": -0.08788173768892496, "vf_loss": 0.0339995169750182, "vf_explained_var": 0.5629779721299807, "kl": 0.009985175206207475, "entropy": 1.4021761571367581, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 111840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 936000, "num_agent_steps_trained": 936000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.08199999999999996, "episode_reward_mean": 1.5412167832167833, "episode_len_mean": 25.06993006993007, "episode_media": {}, "episodes_this_iter": 143, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.004}, "policy_reward_max": {"red_0": 1.467, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 1.1358881118881117, "blue_0": 0.40532867132867134}, "custom_metrics": {"red_0/door_open_done_mean": 0.6503496503496503, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.13986013986013987, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06993006993006994, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.13986013986013987, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11888111888111888, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.06993006993006994, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.13986013986013987, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06993006993006994, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9199999999999999, 1.451, 0.9630000000000001, 1.96, 1.455, 1.9609999999999999, 1.9609999999999999, 1.9250000000000003, 1.948, 1.4369999999999998, 1.955, 1.955, 1.95, 1.4569999999999999, 1.915, 1.955, 0.46599999999999997, 1.9569999999999999, 1.932, 1.938, 1.9489999999999998, 1.915, 1.951, 0.9489999999999998, 1.954, 1.956, 0.964, 1.954, 1.43, 1.9609999999999999, 1.4209999999999998, 1.944, 1.948, 1.9609999999999999, 0.955, 1.451, 1.955, 1.955, 1.439, 1.453, 1.9449999999999998, 1.9409999999999998, 1.955, 1.9609999999999999, 1.9540000000000002, 1.958, 1.9180000000000001, 1.915, 1.95, 1.923, 0.9609999999999999, 1.951, 1.9529999999999998, 1.9249999999999998, 1.9529999999999998, 1.959, 1.459, 1.952, 0.95, 1.959, 1.944, 0.479, 1.946, 1.9569999999999999, 1.948, 1.928, -0.08199999999999996, 1.434, 0.9590000000000001, 1.9, 1.954, -0.038000000000000034, -0.02200000000000002, 0.9569999999999999, 0.46599999999999997, 0.9489999999999998, 1.954, 1.9569999999999999, 1.9609999999999999, 1.959, -0.05700000000000005, 1.9210000000000003, -0.04200000000000004, 1.944, 1.459, 1.946, 0.951, 1.9409999999999998, 1.459, 1.919, 1.454, 1.934, 1.9529999999999998, 1.958, -0.039000000000000035, 1.95, 1.9609999999999999, 1.954, 1.943, 0.9660000000000002, 1.453, 1.933, 1.953, 1.919, 0.31599999999999984, 0.45399999999999996, 1.947, 1.451, 0.961, 1.946, 1.9300000000000002, 1.954, 1.95, 0.43699999999999994, 1.4529999999999998, -0.049000000000000044, 0.9279999999999999, 0.45799999999999996, 1.96, 1.413, 0.45299999999999996, 1.952, 1.924, 1.96, -0.05800000000000005, 1.46, 0.9229999999999999, 1.935, 1.92, 1.4609999999999999, 1.952, 1.025, 1.9529999999999998, 1.921, 0.973, 1.911, 1.95, 1.9489999999999998, 1.4489999999999998, 0.44500000000000006, 1.435, 1.9329999999999998, 1.448], "episode_lengths": [300, 16, 12, 13, 14, 13, 13, 23, 16, 20, 15, 15, 16, 14, 28, 15, 11, 14, 22, 20, 17, 28, 16, 17, 15, 14, 12, 15, 22, 13, 24, 18, 17, 13, 14, 16, 15, 15, 20, 15, 17, 19, 15, 13, 14, 14, 26, 27, 16, 24, 13, 16, 15, 24, 15, 13, 13, 16, 16, 13, 18, 7, 18, 14, 17, 23, 26, 21, 13, 32, 15, 12, 7, 13, 11, 16, 15, 14, 13, 13, 18, 25, 13, 18, 13, 17, 15, 19, 13, 26, 15, 21, 15, 14, 13, 16, 13, 15, 19, 11, 15, 21, 15, 26, 214, 14, 17, 16, 13, 17, 23, 15, 16, 20, 15, 16, 300, 14, 13, 28, 15, 15, 25, 13, 18, 13, 300, 20, 26, 13, 15, 149, 15, 25, 9, 28, 16, 17, 17, 17, 20, 22, 17], "policy_red_0_reward": [0.45199999999999996, 1.452, 1.463, 1.4609999999999999, 1.458, 1.4609999999999999, 1.4609999999999999, 1.429, 1.452, 1.44, 0.5, 1.455, 1.452, -0.001, 1.416, 0.5, 1.467, 0.5, 1.434, 1.439, 1.4489999999999998, 1.415, 1.451, 1.4489999999999998, 0.499, 1.458, 1.464, 1.455, 1.434, 1.4609999999999999, 1.427, 1.4449999999999998, 1.4489999999999998, 0.5, -0.501, 1.451, 1.455, 1.455, 1.439, 1.455, 1.448, 1.442, 0.5, 1.4609999999999999, 1.4569999999999999, 1.458, 1.421, 1.416, 1.452, 0.5, 1.4609999999999999, 0.5, 1.454, 1.427, 1.454, 1.4609999999999999, 1.4609999999999999, 0.5, -0.5, 1.4609999999999999, 1.446, -0.5, 1.446, 0.5, 1.4489999999999998, 1.4300000000000002, 0.922, 1.435, 1.46, 0.499, 1.455, -1.0, 0.979, 1.46, 0.967, 1.451, 1.455, 1.458, 1.4609999999999999, 1.4609999999999999, 0.944, 1.424, 0.961, 1.446, 1.4609999999999999, 1.4489999999999998, -0.503, 1.442, 1.4609999999999999, 1.42, 1.455, 0.499, 0.498, 1.458, 0.961, 1.45, 1.4609999999999999, 1.455, 0.5, 1.467, 1.455, 1.436, 1.455, 1.421, 0.836, -0.501, 1.448, 1.452, -0.5, 1.4489999999999998, 1.431, 1.454, 1.452, -0.502, 1.455, 0.952, 0.47, 1.458, 1.4609999999999999, 1.413, -0.5, 1.455, 1.425, 1.4609999999999999, 0.945, 1.4609999999999999, 0.46499999999999997, 1.439, 1.421, 1.4609999999999999, 1.455, -0.007, 1.454, 1.424, -0.5, 1.4140000000000001, 1.452, 1.4489999999999998, 1.4489999999999998, 1.448, 1.439, 0.5, 1.4489999999999998], "policy_blue_0_reward": [0.46799999999999997, -0.001, -0.5, 0.499, -0.003, 0.5, 0.5, 0.496, 0.496, -0.003, 1.455, 0.5, 0.498, 1.458, 0.499, 1.455, -1.001, 1.4569999999999999, 0.498, 0.499, 0.5, 0.5, 0.5, -0.5, 1.455, 0.498, -0.5, 0.499, -0.004, 0.5, -0.006, 0.499, 0.499, 1.4609999999999999, 1.456, 0.0, 0.5, 0.5, 0.0, -0.002, 0.497, 0.499, 1.455, 0.5, 0.497, 0.5, 0.497, 0.499, 0.498, 1.423, -0.5, 1.451, 0.499, 0.498, 0.499, 0.498, -0.002, 1.452, 1.45, 0.498, 0.498, 0.979, 0.5, 1.4569999999999999, 0.499, 0.498, -1.004, -0.001, -0.501, 1.401, 0.499, 0.962, -1.001, -0.503, -0.501, -0.502, 0.499, 0.499, 0.5, 0.498, -1.001, 0.497, -1.003, 0.498, -0.002, 0.497, 1.454, 0.499, -0.002, 0.499, -0.001, 1.435, 1.455, 0.5, -1.0, 0.5, 0.5, 0.499, 1.443, -0.5009999999999999, -0.002, 0.497, 0.498, 0.498, -0.52, 0.955, 0.499, -0.001, 1.4609999999999999, 0.497, 0.499, 0.5, 0.498, 0.939, -0.002, -1.001, 0.45799999999999996, -1.0, 0.499, 0.0, 0.953, 0.497, 0.499, 0.499, -1.003, -0.001, 0.45799999999999996, 0.496, 0.499, 0.0, 0.497, 1.032, 0.499, 0.497, 1.4729999999999999, 0.497, 0.498, 0.5, 0.0, -1.003, -0.004, 1.4329999999999998, -0.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4202962468306575, "mean_inference_ms": 7.475744953429142, "mean_action_processing_ms": 0.3912974602531623, "mean_env_wait_ms": 0.5214378828616953, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14331224081399557, "StateBufferConnector_ms": 0.00946980256300706, "ViewRequirementAgentConnector_ms": 0.1881586088167204}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.08199999999999996, "episode_reward_mean": 1.5412167832167833, "episode_len_mean": 25.06993006993007, "episodes_this_iter": 143, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.004}, "policy_reward_max": {"red_0": 1.467, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 1.1358881118881117, "blue_0": 0.40532867132867134}, "hist_stats": {"episode_reward": [0.9199999999999999, 1.451, 0.9630000000000001, 1.96, 1.455, 1.9609999999999999, 1.9609999999999999, 1.9250000000000003, 1.948, 1.4369999999999998, 1.955, 1.955, 1.95, 1.4569999999999999, 1.915, 1.955, 0.46599999999999997, 1.9569999999999999, 1.932, 1.938, 1.9489999999999998, 1.915, 1.951, 0.9489999999999998, 1.954, 1.956, 0.964, 1.954, 1.43, 1.9609999999999999, 1.4209999999999998, 1.944, 1.948, 1.9609999999999999, 0.955, 1.451, 1.955, 1.955, 1.439, 1.453, 1.9449999999999998, 1.9409999999999998, 1.955, 1.9609999999999999, 1.9540000000000002, 1.958, 1.9180000000000001, 1.915, 1.95, 1.923, 0.9609999999999999, 1.951, 1.9529999999999998, 1.9249999999999998, 1.9529999999999998, 1.959, 1.459, 1.952, 0.95, 1.959, 1.944, 0.479, 1.946, 1.9569999999999999, 1.948, 1.928, -0.08199999999999996, 1.434, 0.9590000000000001, 1.9, 1.954, -0.038000000000000034, -0.02200000000000002, 0.9569999999999999, 0.46599999999999997, 0.9489999999999998, 1.954, 1.9569999999999999, 1.9609999999999999, 1.959, -0.05700000000000005, 1.9210000000000003, -0.04200000000000004, 1.944, 1.459, 1.946, 0.951, 1.9409999999999998, 1.459, 1.919, 1.454, 1.934, 1.9529999999999998, 1.958, -0.039000000000000035, 1.95, 1.9609999999999999, 1.954, 1.943, 0.9660000000000002, 1.453, 1.933, 1.953, 1.919, 0.31599999999999984, 0.45399999999999996, 1.947, 1.451, 0.961, 1.946, 1.9300000000000002, 1.954, 1.95, 0.43699999999999994, 1.4529999999999998, -0.049000000000000044, 0.9279999999999999, 0.45799999999999996, 1.96, 1.413, 0.45299999999999996, 1.952, 1.924, 1.96, -0.05800000000000005, 1.46, 0.9229999999999999, 1.935, 1.92, 1.4609999999999999, 1.952, 1.025, 1.9529999999999998, 1.921, 0.973, 1.911, 1.95, 1.9489999999999998, 1.4489999999999998, 0.44500000000000006, 1.435, 1.9329999999999998, 1.448], "episode_lengths": [300, 16, 12, 13, 14, 13, 13, 23, 16, 20, 15, 15, 16, 14, 28, 15, 11, 14, 22, 20, 17, 28, 16, 17, 15, 14, 12, 15, 22, 13, 24, 18, 17, 13, 14, 16, 15, 15, 20, 15, 17, 19, 15, 13, 14, 14, 26, 27, 16, 24, 13, 16, 15, 24, 15, 13, 13, 16, 16, 13, 18, 7, 18, 14, 17, 23, 26, 21, 13, 32, 15, 12, 7, 13, 11, 16, 15, 14, 13, 13, 18, 25, 13, 18, 13, 17, 15, 19, 13, 26, 15, 21, 15, 14, 13, 16, 13, 15, 19, 11, 15, 21, 15, 26, 214, 14, 17, 16, 13, 17, 23, 15, 16, 20, 15, 16, 300, 14, 13, 28, 15, 15, 25, 13, 18, 13, 300, 20, 26, 13, 15, 149, 15, 25, 9, 28, 16, 17, 17, 17, 20, 22, 17], "policy_red_0_reward": [0.45199999999999996, 1.452, 1.463, 1.4609999999999999, 1.458, 1.4609999999999999, 1.4609999999999999, 1.429, 1.452, 1.44, 0.5, 1.455, 1.452, -0.001, 1.416, 0.5, 1.467, 0.5, 1.434, 1.439, 1.4489999999999998, 1.415, 1.451, 1.4489999999999998, 0.499, 1.458, 1.464, 1.455, 1.434, 1.4609999999999999, 1.427, 1.4449999999999998, 1.4489999999999998, 0.5, -0.501, 1.451, 1.455, 1.455, 1.439, 1.455, 1.448, 1.442, 0.5, 1.4609999999999999, 1.4569999999999999, 1.458, 1.421, 1.416, 1.452, 0.5, 1.4609999999999999, 0.5, 1.454, 1.427, 1.454, 1.4609999999999999, 1.4609999999999999, 0.5, -0.5, 1.4609999999999999, 1.446, -0.5, 1.446, 0.5, 1.4489999999999998, 1.4300000000000002, 0.922, 1.435, 1.46, 0.499, 1.455, -1.0, 0.979, 1.46, 0.967, 1.451, 1.455, 1.458, 1.4609999999999999, 1.4609999999999999, 0.944, 1.424, 0.961, 1.446, 1.4609999999999999, 1.4489999999999998, -0.503, 1.442, 1.4609999999999999, 1.42, 1.455, 0.499, 0.498, 1.458, 0.961, 1.45, 1.4609999999999999, 1.455, 0.5, 1.467, 1.455, 1.436, 1.455, 1.421, 0.836, -0.501, 1.448, 1.452, -0.5, 1.4489999999999998, 1.431, 1.454, 1.452, -0.502, 1.455, 0.952, 0.47, 1.458, 1.4609999999999999, 1.413, -0.5, 1.455, 1.425, 1.4609999999999999, 0.945, 1.4609999999999999, 0.46499999999999997, 1.439, 1.421, 1.4609999999999999, 1.455, -0.007, 1.454, 1.424, -0.5, 1.4140000000000001, 1.452, 1.4489999999999998, 1.4489999999999998, 1.448, 1.439, 0.5, 1.4489999999999998], "policy_blue_0_reward": [0.46799999999999997, -0.001, -0.5, 0.499, -0.003, 0.5, 0.5, 0.496, 0.496, -0.003, 1.455, 0.5, 0.498, 1.458, 0.499, 1.455, -1.001, 1.4569999999999999, 0.498, 0.499, 0.5, 0.5, 0.5, -0.5, 1.455, 0.498, -0.5, 0.499, -0.004, 0.5, -0.006, 0.499, 0.499, 1.4609999999999999, 1.456, 0.0, 0.5, 0.5, 0.0, -0.002, 0.497, 0.499, 1.455, 0.5, 0.497, 0.5, 0.497, 0.499, 0.498, 1.423, -0.5, 1.451, 0.499, 0.498, 0.499, 0.498, -0.002, 1.452, 1.45, 0.498, 0.498, 0.979, 0.5, 1.4569999999999999, 0.499, 0.498, -1.004, -0.001, -0.501, 1.401, 0.499, 0.962, -1.001, -0.503, -0.501, -0.502, 0.499, 0.499, 0.5, 0.498, -1.001, 0.497, -1.003, 0.498, -0.002, 0.497, 1.454, 0.499, -0.002, 0.499, -0.001, 1.435, 1.455, 0.5, -1.0, 0.5, 0.5, 0.499, 1.443, -0.5009999999999999, -0.002, 0.497, 0.498, 0.498, -0.52, 0.955, 0.499, -0.001, 1.4609999999999999, 0.497, 0.499, 0.5, 0.498, 0.939, -0.002, -1.001, 0.45799999999999996, -1.0, 0.499, 0.0, 0.953, 0.497, 0.499, 0.499, -1.003, -0.001, 0.45799999999999996, 0.496, 0.499, 0.0, 0.497, 1.032, 0.499, 0.497, 1.4729999999999999, 0.497, 0.498, 0.5, 0.0, -1.003, -0.004, 1.4329999999999998, -0.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4202962468306575, "mean_inference_ms": 7.475744953429142, "mean_action_processing_ms": 0.3912974602531623, "mean_env_wait_ms": 0.5214378828616953, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14331224081399557, "StateBufferConnector_ms": 0.00946980256300706, "ViewRequirementAgentConnector_ms": 0.1881586088167204}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 936000, "num_agent_steps_trained": 936000, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 134.2853627029204, "num_env_steps_trained_throughput_per_sec": 134.2853627029204, "timesteps_total": 468000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 936000, "timers": {"training_iteration_time_ms": 32043.443, "sample_time_ms": 4140.137, "learn_time_ms": 27873.342, "learn_throughput": 143.506, "synch_weights_time_ms": 28.343}, "counters": {"num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 936000, "num_agent_steps_trained": 936000}, "done": false, "episodes_total": 9168, "training_iteration": 117, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-59-25", "timestamp": 1694840365, "time_this_iter_s": 29.806553840637207, "time_total_s": 3657.8945393562317, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219b76d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3657.8945393562317, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 22.65909090909091, "ram_util_percent": 56.97727272727273}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6730769230769231, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.11538461538461539, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.057692307692307696, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.11538461538461539, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11538461538461539, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.057692307692307696, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.11538461538461539, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.057692307692307696, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4574643595144153, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.044437448116756664, "policy_loss": -0.07526654869531436, "vf_loss": 0.02000140325059571, "vf_explained_var": 0.8065257360537846, "kl": 0.009638236925738028, "entropy": 1.1287095888828238, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 112800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5194211557817956, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05291734855660858, "policy_loss": -0.08571789753623307, "vf_loss": 0.023112716978842703, "vf_explained_var": 0.5744538597762585, "kl": 0.00997979927691913, "entropy": 1.4910400131096442, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 112800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.20899999999999996, "episode_reward_mean": 1.5158557692307693, "episode_len_mean": 31.634615384615383, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 1.1109807692307692, "blue_0": 0.404875}, "custom_metrics": {"red_0/door_open_done_mean": 0.6730769230769231, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.11538461538461539, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.057692307692307696, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.11538461538461539, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11538461538461539, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.057692307692307696, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.11538461538461539, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.057692307692307696, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9189999999999999, 1.439, 1.923, 1.9409999999999998, 0.4630000000000001, 1.4569999999999999, 1.922, 1.4569999999999999, -0.20899999999999996, 1.9569999999999999, 1.948, 1.935, 1.44, 1.444, 1.775, 1.958, 0.389, 1.951, 1.46, 1.924, 1.955, 1.951, 1.459, 1.919, 1.95, 1.9609999999999999, 1.43, 1.939, 1.436, 1.9329999999999998, 0.903, 0.43000000000000016, 1.4609999999999999, 1.4449999999999998, 1.954, 0.95, 1.451, 1.446, 1.831, 1.96, 1.951, 1.931, 1.9180000000000001, 0.44499999999999984, 1.929, 0.9149999999999999, 1.4489999999999998, 1.443, 1.951, 1.912, 0.4670000000000001, 1.827, 1.9449999999999998, 0.955, 1.9449999999999998, -0.04899999999999993, 1.939, 1.932, 0.30299999999999994, 0.44099999999999984, 1.9609999999999999, 1.7799999999999998, 1.459, 1.955, 1.9609999999999999, 1.953, 1.8860000000000001, 1.4609999999999999, 1.9329999999999998, 1.45, 1.959, 1.931, 0.9630000000000001, 1.947, 1.948, 1.9529999999999998, 0.46099999999999997, 1.4529999999999998, 1.912, 1.934, 1.956, 0.398, 1.9609999999999999, 1.891, 1.451, 1.434, -0.06799999999999995, 1.416, 1.955, 0.973, 0.939, 0.45299999999999985, 1.451, 1.4489999999999998, 1.955, 1.9569999999999999, 1.9489999999999998, 1.446, 1.946, 1.401, 1.946, 1.934, 1.948, 0.44199999999999995], "episode_lengths": [300, 20, 24, 19, 12, 14, 24, 14, 66, 14, 17, 21, 19, 18, 71, 14, 33, 16, 13, 23, 15, 16, 13, 25, 16, 13, 22, 20, 20, 21, 30, 21, 13, 17, 15, 300, 16, 17, 51, 13, 15, 22, 26, 18, 23, 300, 17, 19, 16, 28, 10, 54, 17, 300, 17, 15, 19, 21, 60, 18, 13, 69, 13, 15, 13, 15, 36, 13, 21, 16, 13, 22, 12, 17, 17, 15, 13, 15, 28, 21, 14, 33, 13, 33, 16, 21, 21, 27, 15, 9, 19, 15, 15, 17, 15, 14, 16, 17, 17, 32, 17, 21, 17, 18], "policy_red_0_reward": [0.44999999999999996, 1.44, 1.426, 0.5, 1.464, -0.001, 1.428, 1.458, 0.796, 1.458, 1.4489999999999998, 1.4369999999999998, 1.443, 1.4449999999999998, 1.279, 0.5, 1.3980000000000001, 0.5, 1.4609999999999999, 1.429, 1.455, 1.452, 1.4609999999999999, 1.4220000000000002, 1.452, 1.4609999999999999, 1.4329999999999998, 1.44, 1.438, 1.4369999999999998, 1.407, 0.9349999999999999, 1.4609999999999999, 1.448, 1.455, 0.485, 1.452, 1.448, 1.337, 1.4609999999999999, 1.4529999999999998, 1.432, 1.42, 0.945, 0.5, 0.45399999999999996, 1.4489999999999998, 0.0, 1.451, 1.4140000000000001, 1.47, 1.335, 1.447, 0.491, 1.448, 0.955, 0.498, 1.435, 1.311, 1.4449999999999998, 1.4609999999999999, 1.2879999999999998, 1.4609999999999999, 1.455, 1.4609999999999999, 1.455, 1.3900000000000001, 1.4609999999999999, 1.436, -0.001, 1.4609999999999999, 1.434, 1.463, 1.4489999999999998, 1.4489999999999998, 1.455, -1.0, -0.001, 1.413, 0.498, 1.458, -1.003, 1.4609999999999999, 1.397, 1.452, 1.436, -1.003, -0.001, 1.455, -0.5, -0.501, 0.954, 1.454, 1.4489999999999998, 1.455, 1.458, 1.452, 1.4489999999999998, 1.448, -0.002, 1.448, 1.4369999999999998, 1.4489999999999998, -0.501], "policy_blue_0_reward": [0.469, -0.001, 0.497, 1.4409999999999998, -1.001, 1.458, 0.494, -0.001, -1.005, 0.499, 0.499, 0.498, -0.003, -0.001, 0.496, 1.458, -1.009, 1.451, -0.001, 0.495, 0.5, 0.499, -0.002, 0.497, 0.498, 0.5, -0.003, 0.499, -0.002, 0.496, -0.504, -0.5049999999999999, 0.0, -0.003, 0.499, 0.46499999999999997, -0.001, -0.002, 0.494, 0.499, 0.498, 0.499, 0.498, -0.5, 1.429, 0.46099999999999997, 0.0, 1.443, 0.5, 0.498, -1.003, 0.492, 0.498, 0.46399999999999997, 0.497, -1.0039999999999998, 1.4409999999999998, 0.497, -1.008, -1.004, 0.5, 0.492, -0.002, 0.5, 0.5, 0.498, 0.496, 0.0, 0.497, 1.451, 0.498, 0.497, -0.5, 0.498, 0.499, 0.498, 1.4609999999999999, 1.454, 0.499, 1.436, 0.498, 1.401, 0.5, 0.494, -0.001, -0.002, 0.9349999999999999, 1.417, 0.5, 1.4729999999999999, 1.44, -0.501, -0.003, 0.0, 0.5, 0.499, 0.497, -0.003, 0.498, 1.403, 0.498, 0.497, 0.499, 0.943]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4224366038085807, "mean_inference_ms": 7.466857957370366, "mean_action_processing_ms": 0.3906455705200728, "mean_env_wait_ms": 0.5227962198101296, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.16128982488925642, "StateBufferConnector_ms": 0.009885201087364784, "ViewRequirementAgentConnector_ms": 0.19778838524451622}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.20899999999999996, "episode_reward_mean": 1.5158557692307693, "episode_len_mean": 31.634615384615383, "episodes_this_iter": 104, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.009}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 1.1109807692307692, "blue_0": 0.404875}, "hist_stats": {"episode_reward": [0.9189999999999999, 1.439, 1.923, 1.9409999999999998, 0.4630000000000001, 1.4569999999999999, 1.922, 1.4569999999999999, -0.20899999999999996, 1.9569999999999999, 1.948, 1.935, 1.44, 1.444, 1.775, 1.958, 0.389, 1.951, 1.46, 1.924, 1.955, 1.951, 1.459, 1.919, 1.95, 1.9609999999999999, 1.43, 1.939, 1.436, 1.9329999999999998, 0.903, 0.43000000000000016, 1.4609999999999999, 1.4449999999999998, 1.954, 0.95, 1.451, 1.446, 1.831, 1.96, 1.951, 1.931, 1.9180000000000001, 0.44499999999999984, 1.929, 0.9149999999999999, 1.4489999999999998, 1.443, 1.951, 1.912, 0.4670000000000001, 1.827, 1.9449999999999998, 0.955, 1.9449999999999998, -0.04899999999999993, 1.939, 1.932, 0.30299999999999994, 0.44099999999999984, 1.9609999999999999, 1.7799999999999998, 1.459, 1.955, 1.9609999999999999, 1.953, 1.8860000000000001, 1.4609999999999999, 1.9329999999999998, 1.45, 1.959, 1.931, 0.9630000000000001, 1.947, 1.948, 1.9529999999999998, 0.46099999999999997, 1.4529999999999998, 1.912, 1.934, 1.956, 0.398, 1.9609999999999999, 1.891, 1.451, 1.434, -0.06799999999999995, 1.416, 1.955, 0.973, 0.939, 0.45299999999999985, 1.451, 1.4489999999999998, 1.955, 1.9569999999999999, 1.9489999999999998, 1.446, 1.946, 1.401, 1.946, 1.934, 1.948, 0.44199999999999995], "episode_lengths": [300, 20, 24, 19, 12, 14, 24, 14, 66, 14, 17, 21, 19, 18, 71, 14, 33, 16, 13, 23, 15, 16, 13, 25, 16, 13, 22, 20, 20, 21, 30, 21, 13, 17, 15, 300, 16, 17, 51, 13, 15, 22, 26, 18, 23, 300, 17, 19, 16, 28, 10, 54, 17, 300, 17, 15, 19, 21, 60, 18, 13, 69, 13, 15, 13, 15, 36, 13, 21, 16, 13, 22, 12, 17, 17, 15, 13, 15, 28, 21, 14, 33, 13, 33, 16, 21, 21, 27, 15, 9, 19, 15, 15, 17, 15, 14, 16, 17, 17, 32, 17, 21, 17, 18], "policy_red_0_reward": [0.44999999999999996, 1.44, 1.426, 0.5, 1.464, -0.001, 1.428, 1.458, 0.796, 1.458, 1.4489999999999998, 1.4369999999999998, 1.443, 1.4449999999999998, 1.279, 0.5, 1.3980000000000001, 0.5, 1.4609999999999999, 1.429, 1.455, 1.452, 1.4609999999999999, 1.4220000000000002, 1.452, 1.4609999999999999, 1.4329999999999998, 1.44, 1.438, 1.4369999999999998, 1.407, 0.9349999999999999, 1.4609999999999999, 1.448, 1.455, 0.485, 1.452, 1.448, 1.337, 1.4609999999999999, 1.4529999999999998, 1.432, 1.42, 0.945, 0.5, 0.45399999999999996, 1.4489999999999998, 0.0, 1.451, 1.4140000000000001, 1.47, 1.335, 1.447, 0.491, 1.448, 0.955, 0.498, 1.435, 1.311, 1.4449999999999998, 1.4609999999999999, 1.2879999999999998, 1.4609999999999999, 1.455, 1.4609999999999999, 1.455, 1.3900000000000001, 1.4609999999999999, 1.436, -0.001, 1.4609999999999999, 1.434, 1.463, 1.4489999999999998, 1.4489999999999998, 1.455, -1.0, -0.001, 1.413, 0.498, 1.458, -1.003, 1.4609999999999999, 1.397, 1.452, 1.436, -1.003, -0.001, 1.455, -0.5, -0.501, 0.954, 1.454, 1.4489999999999998, 1.455, 1.458, 1.452, 1.4489999999999998, 1.448, -0.002, 1.448, 1.4369999999999998, 1.4489999999999998, -0.501], "policy_blue_0_reward": [0.469, -0.001, 0.497, 1.4409999999999998, -1.001, 1.458, 0.494, -0.001, -1.005, 0.499, 0.499, 0.498, -0.003, -0.001, 0.496, 1.458, -1.009, 1.451, -0.001, 0.495, 0.5, 0.499, -0.002, 0.497, 0.498, 0.5, -0.003, 0.499, -0.002, 0.496, -0.504, -0.5049999999999999, 0.0, -0.003, 0.499, 0.46499999999999997, -0.001, -0.002, 0.494, 0.499, 0.498, 0.499, 0.498, -0.5, 1.429, 0.46099999999999997, 0.0, 1.443, 0.5, 0.498, -1.003, 0.492, 0.498, 0.46399999999999997, 0.497, -1.0039999999999998, 1.4409999999999998, 0.497, -1.008, -1.004, 0.5, 0.492, -0.002, 0.5, 0.5, 0.498, 0.496, 0.0, 0.497, 1.451, 0.498, 0.497, -0.5, 0.498, 0.499, 0.498, 1.4609999999999999, 1.454, 0.499, 1.436, 0.498, 1.401, 0.5, 0.494, -0.001, -0.002, 0.9349999999999999, 1.417, 0.5, 1.4729999999999999, 1.44, -0.501, -0.003, 0.0, 0.5, 0.499, 0.497, -0.003, 0.498, 1.403, 0.498, 0.497, 0.499, 0.943]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4224366038085807, "mean_inference_ms": 7.466857957370366, "mean_action_processing_ms": 0.3906455705200728, "mean_env_wait_ms": 0.5227962198101296, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.16128982488925642, "StateBufferConnector_ms": 0.009885201087364784, "ViewRequirementAgentConnector_ms": 0.19778838524451622}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 123.84627884296894, "num_env_steps_trained_throughput_per_sec": 123.84627884296894, "timesteps_total": 472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 32231.243, "sample_time_ms": 4189.629, "learn_time_ms": 28011.687, "learn_throughput": 142.798, "synch_weights_time_ms": 28.284}, "counters": {"num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "episodes_total": 9272, "training_iteration": 118, "trial_id": "fbd9b_00000", "date": "2023-09-16_00-59-58", "timestamp": 1694840398, "time_this_iter_s": 32.314900159835815, "time_total_s": 3690.2094395160675, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a2eb400>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3690.2094395160675, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 26.30217391304348, "ram_util_percent": 57.10652173913043}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6356589147286822, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.05426356589147287, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10852713178294573, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.05426356589147287, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14728682170542637, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10852713178294573, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.05426356589147287, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10852713178294573, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.44764483706094327, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03768346240297736, "policy_loss": -0.07176185063532708, "vf_loss": 0.028667296289737958, "vf_explained_var": 0.760669686148564, "kl": 0.009134570328142763, "entropy": 1.064953737022976, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 113760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5051907600214084, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.046040514219203035, "policy_loss": -0.07878559523038954, "vf_loss": 0.02517364137553765, "vf_explained_var": 0.597949935309589, "kl": 0.009479146509429014, "entropy": 1.4364211179316044, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 113760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 952000, "num_agent_steps_trained": 952000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.274, "episode_reward_mean": 1.5161937984496123, "episode_len_mean": 35.98449612403101, "episode_media": {}, "episodes_this_iter": 129, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.472}, "policy_reward_mean": {"red_0": 0.9626744186046512, "blue_0": 0.5535193798449612}, "custom_metrics": {"red_0/door_open_done_mean": 0.6356589147286822, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.05426356589147287, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10852713178294573, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.05426356589147287, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14728682170542637, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10852713178294573, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.05426356589147287, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10852713178294573, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.956, 1.869, 1.934, 0.45899999999999996, 1.909, 1.954, 1.413, 1.955, 1.4529999999999998, 1.954, 1.9060000000000001, 1.9609999999999999, 1.448, -0.274, 1.95, 1.942, 1.958, 1.9449999999999998, 1.454, 1.9329999999999998, 1.46, 1.947, 1.96, 1.454, 1.949, 1.452, 1.434, 0.957, 1.9180000000000001, 1.955, 1.9489999999999998, 1.373, 0.44899999999999995, 0.9489999999999998, -0.028000000000000025, 1.94, 0.47, 0.9470000000000001, 0.946, 1.9529999999999998, 1.911, 1.95, 1.9569999999999999, 1.938, 1.9409999999999998, 1.4449999999999998, 1.934, 1.923, 1.952, 1.929, 1.9609999999999999, 1.951, 1.954, 1.955, 0.9329999999999999, 1.946, 1.955, 1.952, 1.9369999999999998, 1.4409999999999998, 1.9569999999999999, 1.96, 1.954, 1.94, 1.907, 1.405, 0.43199999999999994, 0.972, -0.04899999999999993, 1.444, 1.436, 1.3820000000000001, 1.9609999999999999, 1.95, 1.4500000000000002, 1.4489999999999998, 1.958, 1.9569999999999999, -0.026000000000000023, 1.9569999999999999, 1.873, 1.935, 1.448, 0.963, 1.956, 1.9380000000000002, 1.9100000000000001, 1.4609999999999999, 1.96, 0.955, 0.9239999999999999, 1.9489999999999998, 1.784, 1.9569999999999999, 0.43399999999999994, 1.4609999999999999, 1.9609999999999999, 1.92, -0.02499999999999991, 0.472, 1.944, 1.9329999999999998, 0.4610000000000001, 0.4780000000000002, 1.9409999999999998, 1.9609999999999999, 1.444, 1.427, 1.948, 1.951, 0.45799999999999996, 1.458, 1.9529999999999998, 1.436, 0.45899999999999996, -0.030999999999999917, 0.579, 1.959, -0.03299999999999992, 1.96, 1.8860000000000001, 1.317, 1.4529999999999998, 1.956, 1.9489999999999998, 0.476, 1.95, 1.9609999999999999, 1.9449999999999998], "episode_lengths": [300, 41, 20, 13, 29, 15, 27, 15, 15, 15, 30, 13, 16, 86, 16, 18, 14, 18, 15, 21, 13, 17, 13, 15, 16, 15, 22, 300, 26, 15, 16, 40, 17, 16, 9, 19, 9, 17, 300, 15, 28, 16, 14, 20, 18, 18, 21, 24, 16, 23, 13, 16, 15, 15, 300, 18, 14, 15, 19, 19, 14, 13, 15, 19, 29, 31, 300, 9, 16, 18, 20, 35, 13, 16, 16, 17, 14, 14, 8, 14, 40, 21, 17, 12, 14, 20, 29, 13, 13, 15, 300, 17, 66, 14, 300, 13, 13, 25, 8, 9, 18, 21, 12, 7, 19, 13, 18, 23, 17, 16, 14, 14, 15, 21, 13, 10, 284, 13, 10, 13, 36, 55, 15, 14, 17, 8, 16, 13, 18], "policy_red_0_reward": [0.488, 1.375, 1.4369999999999998, -1.001, 1.411, 1.455, 1.415, 0.5, 1.455, 0.5, 1.4100000000000001, 0.5, 1.452, 0.739, 1.451, 1.444, 1.458, 1.4449999999999998, 1.455, 0.498, -0.001, 1.448, 0.499, 1.455, 1.451, 1.455, 1.434, 0.489, 1.421, 1.455, 1.451, 1.375, -0.5, 1.45, 0.973, 0.499, 0.972, 1.4489999999999998, 0.48, 1.455, 0.498, 1.45, 1.458, 1.44, 1.4449999999999998, 1.446, 1.436, 1.427, 1.452, 0.499, 1.4609999999999999, 1.452, 1.455, 1.455, 0.46599999999999997, 1.446, 1.4569999999999999, 1.455, 1.44, 1.443, 1.458, 1.4609999999999999, 1.455, 1.443, 0.498, 1.407, -0.023000000000000013, -0.5, -1.0, 1.446, 1.439, 1.393, 1.4609999999999999, 1.452, 1.451, 0.0, 0.5, 1.458, -1.0, 1.458, 1.3780000000000001, 0.5, 1.4489999999999998, -0.5, 1.458, 1.44, 1.4100000000000001, 0.0, 1.4609999999999999, -0.5, 0.45699999999999996, 1.4489999999999998, 1.294, 1.458, -0.028000000000000018, 1.4609999999999999, 1.4609999999999999, 1.423, -1.001, 1.4729999999999999, 1.4449999999999998, 1.434, -0.5019999999999999, 0.979, 1.443, 1.4609999999999999, -0.001, 1.431, 0.499, 1.452, -0.5, 1.458, 1.455, 1.4369999999999998, -1.001, -1.0, 0.603, 1.4609999999999999, -1.001, 1.4609999999999999, 1.391, -0.011000000000000003, 1.455, 1.458, 1.4489999999999998, -0.5, 1.451, 0.5, 0.5], "policy_blue_0_reward": [0.46799999999999997, 0.494, 0.497, 1.46, 0.498, 0.499, -0.002, 1.455, -0.002, 1.454, 0.496, 1.4609999999999999, -0.004, -1.013, 0.499, 0.498, 0.5, 0.5, -0.001, 1.435, 1.4609999999999999, 0.499, 1.4609999999999999, -0.001, 0.498, -0.003, 0.0, 0.46799999999999997, 0.497, 0.5, 0.498, -0.002, 0.949, -0.501, -1.001, 1.4409999999999998, -0.502, -0.5019999999999999, 0.46599999999999997, 0.498, 1.413, 0.5, 0.499, 0.498, 0.496, -0.001, 0.498, 0.496, 0.5, 1.4300000000000002, 0.5, 0.499, 0.499, 0.5, 0.46699999999999997, 0.5, 0.498, 0.497, 0.497, -0.002, 0.499, 0.499, 0.499, 0.497, 1.409, -0.002, 0.45499999999999996, 1.472, 0.951, -0.002, -0.003, -0.011000000000000003, 0.5, 0.498, -0.001, 1.4489999999999998, 1.458, 0.499, 0.974, 0.499, 0.495, 1.435, -0.001, 1.463, 0.498, 0.498, 0.5, 1.4609999999999999, 0.499, 1.455, 0.46699999999999997, 0.5, 0.49, 0.499, 0.46199999999999997, 0.0, 0.5, 0.497, 0.976, -1.001, 0.499, 0.499, 0.963, -0.5009999999999999, 0.498, 0.5, 1.4449999999999998, -0.004, 1.4489999999999998, 0.499, 0.958, 0.0, 0.498, -0.001, 1.46, 0.969, -0.024000000000000014, 0.498, 0.968, 0.499, 0.495, 1.3279999999999998, -0.002, 0.498, 0.5, 0.976, 0.499, 1.4609999999999999, 1.4449999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4239683706811945, "mean_inference_ms": 7.468423546964171, "mean_action_processing_ms": 0.3907621980096644, "mean_env_wait_ms": 0.5221617045734166, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1375029253405194, "StateBufferConnector_ms": 0.009312278540559518, "ViewRequirementAgentConnector_ms": 0.17951856287874918}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.274, "episode_reward_mean": 1.5161937984496123, "episode_len_mean": 35.98449612403101, "episodes_this_iter": 129, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.472}, "policy_reward_mean": {"red_0": 0.9626744186046512, "blue_0": 0.5535193798449612}, "hist_stats": {"episode_reward": [0.956, 1.869, 1.934, 0.45899999999999996, 1.909, 1.954, 1.413, 1.955, 1.4529999999999998, 1.954, 1.9060000000000001, 1.9609999999999999, 1.448, -0.274, 1.95, 1.942, 1.958, 1.9449999999999998, 1.454, 1.9329999999999998, 1.46, 1.947, 1.96, 1.454, 1.949, 1.452, 1.434, 0.957, 1.9180000000000001, 1.955, 1.9489999999999998, 1.373, 0.44899999999999995, 0.9489999999999998, -0.028000000000000025, 1.94, 0.47, 0.9470000000000001, 0.946, 1.9529999999999998, 1.911, 1.95, 1.9569999999999999, 1.938, 1.9409999999999998, 1.4449999999999998, 1.934, 1.923, 1.952, 1.929, 1.9609999999999999, 1.951, 1.954, 1.955, 0.9329999999999999, 1.946, 1.955, 1.952, 1.9369999999999998, 1.4409999999999998, 1.9569999999999999, 1.96, 1.954, 1.94, 1.907, 1.405, 0.43199999999999994, 0.972, -0.04899999999999993, 1.444, 1.436, 1.3820000000000001, 1.9609999999999999, 1.95, 1.4500000000000002, 1.4489999999999998, 1.958, 1.9569999999999999, -0.026000000000000023, 1.9569999999999999, 1.873, 1.935, 1.448, 0.963, 1.956, 1.9380000000000002, 1.9100000000000001, 1.4609999999999999, 1.96, 0.955, 0.9239999999999999, 1.9489999999999998, 1.784, 1.9569999999999999, 0.43399999999999994, 1.4609999999999999, 1.9609999999999999, 1.92, -0.02499999999999991, 0.472, 1.944, 1.9329999999999998, 0.4610000000000001, 0.4780000000000002, 1.9409999999999998, 1.9609999999999999, 1.444, 1.427, 1.948, 1.951, 0.45799999999999996, 1.458, 1.9529999999999998, 1.436, 0.45899999999999996, -0.030999999999999917, 0.579, 1.959, -0.03299999999999992, 1.96, 1.8860000000000001, 1.317, 1.4529999999999998, 1.956, 1.9489999999999998, 0.476, 1.95, 1.9609999999999999, 1.9449999999999998], "episode_lengths": [300, 41, 20, 13, 29, 15, 27, 15, 15, 15, 30, 13, 16, 86, 16, 18, 14, 18, 15, 21, 13, 17, 13, 15, 16, 15, 22, 300, 26, 15, 16, 40, 17, 16, 9, 19, 9, 17, 300, 15, 28, 16, 14, 20, 18, 18, 21, 24, 16, 23, 13, 16, 15, 15, 300, 18, 14, 15, 19, 19, 14, 13, 15, 19, 29, 31, 300, 9, 16, 18, 20, 35, 13, 16, 16, 17, 14, 14, 8, 14, 40, 21, 17, 12, 14, 20, 29, 13, 13, 15, 300, 17, 66, 14, 300, 13, 13, 25, 8, 9, 18, 21, 12, 7, 19, 13, 18, 23, 17, 16, 14, 14, 15, 21, 13, 10, 284, 13, 10, 13, 36, 55, 15, 14, 17, 8, 16, 13, 18], "policy_red_0_reward": [0.488, 1.375, 1.4369999999999998, -1.001, 1.411, 1.455, 1.415, 0.5, 1.455, 0.5, 1.4100000000000001, 0.5, 1.452, 0.739, 1.451, 1.444, 1.458, 1.4449999999999998, 1.455, 0.498, -0.001, 1.448, 0.499, 1.455, 1.451, 1.455, 1.434, 0.489, 1.421, 1.455, 1.451, 1.375, -0.5, 1.45, 0.973, 0.499, 0.972, 1.4489999999999998, 0.48, 1.455, 0.498, 1.45, 1.458, 1.44, 1.4449999999999998, 1.446, 1.436, 1.427, 1.452, 0.499, 1.4609999999999999, 1.452, 1.455, 1.455, 0.46599999999999997, 1.446, 1.4569999999999999, 1.455, 1.44, 1.443, 1.458, 1.4609999999999999, 1.455, 1.443, 0.498, 1.407, -0.023000000000000013, -0.5, -1.0, 1.446, 1.439, 1.393, 1.4609999999999999, 1.452, 1.451, 0.0, 0.5, 1.458, -1.0, 1.458, 1.3780000000000001, 0.5, 1.4489999999999998, -0.5, 1.458, 1.44, 1.4100000000000001, 0.0, 1.4609999999999999, -0.5, 0.45699999999999996, 1.4489999999999998, 1.294, 1.458, -0.028000000000000018, 1.4609999999999999, 1.4609999999999999, 1.423, -1.001, 1.4729999999999999, 1.4449999999999998, 1.434, -0.5019999999999999, 0.979, 1.443, 1.4609999999999999, -0.001, 1.431, 0.499, 1.452, -0.5, 1.458, 1.455, 1.4369999999999998, -1.001, -1.0, 0.603, 1.4609999999999999, -1.001, 1.4609999999999999, 1.391, -0.011000000000000003, 1.455, 1.458, 1.4489999999999998, -0.5, 1.451, 0.5, 0.5], "policy_blue_0_reward": [0.46799999999999997, 0.494, 0.497, 1.46, 0.498, 0.499, -0.002, 1.455, -0.002, 1.454, 0.496, 1.4609999999999999, -0.004, -1.013, 0.499, 0.498, 0.5, 0.5, -0.001, 1.435, 1.4609999999999999, 0.499, 1.4609999999999999, -0.001, 0.498, -0.003, 0.0, 0.46799999999999997, 0.497, 0.5, 0.498, -0.002, 0.949, -0.501, -1.001, 1.4409999999999998, -0.502, -0.5019999999999999, 0.46599999999999997, 0.498, 1.413, 0.5, 0.499, 0.498, 0.496, -0.001, 0.498, 0.496, 0.5, 1.4300000000000002, 0.5, 0.499, 0.499, 0.5, 0.46699999999999997, 0.5, 0.498, 0.497, 0.497, -0.002, 0.499, 0.499, 0.499, 0.497, 1.409, -0.002, 0.45499999999999996, 1.472, 0.951, -0.002, -0.003, -0.011000000000000003, 0.5, 0.498, -0.001, 1.4489999999999998, 1.458, 0.499, 0.974, 0.499, 0.495, 1.435, -0.001, 1.463, 0.498, 0.498, 0.5, 1.4609999999999999, 0.499, 1.455, 0.46699999999999997, 0.5, 0.49, 0.499, 0.46199999999999997, 0.0, 0.5, 0.497, 0.976, -1.001, 0.499, 0.499, 0.963, -0.5009999999999999, 0.498, 0.5, 1.4449999999999998, -0.004, 1.4489999999999998, 0.499, 0.958, 0.0, 0.498, -0.001, 1.46, 0.969, -0.024000000000000014, 0.498, 0.968, 0.499, 0.495, 1.3279999999999998, -0.002, 0.498, 0.5, 0.976, 0.499, 1.4609999999999999, 1.4449999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4239683706811945, "mean_inference_ms": 7.468423546964171, "mean_action_processing_ms": 0.3907621980096644, "mean_env_wait_ms": 0.5221617045734166, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1375029253405194, "StateBufferConnector_ms": 0.009312278540559518, "ViewRequirementAgentConnector_ms": 0.17951856287874918}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 952000, "num_agent_steps_trained": 952000, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 133.17266985595376, "num_env_steps_trained_throughput_per_sec": 133.17266985595376, "timesteps_total": 476000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 952000, "timers": {"training_iteration_time_ms": 32093.104, "sample_time_ms": 4142.217, "learn_time_ms": 27920.593, "learn_throughput": 143.263, "synch_weights_time_ms": 28.625}, "counters": {"num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 952000, "num_agent_steps_trained": 952000}, "done": false, "episodes_total": 9401, "training_iteration": 119, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-00-29", "timestamp": 1694840429, "time_this_iter_s": 30.057215929031372, "time_total_s": 3720.266655445099, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219b5900>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3720.266655445099, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 24.18409090909091, "ram_util_percent": 57.050000000000004}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6778523489932886, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.10738255033557047, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08053691275167785, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.10738255033557047, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.10067114093959731, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08053691275167785, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.10738255033557047, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08053691275167785, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47245935862883925, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03710010270103036, "policy_loss": -0.07317276977216049, "vf_loss": 0.028695437086571473, "vf_explained_var": 0.7832039014125863, "kl": 0.009967774339857864, "entropy": 0.9828877931460738, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 114720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5015365341367821, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.05414548275390795, "policy_loss": -0.09240169715922093, "vf_loss": 0.028915597768112398, "vf_explained_var": 0.6097210733840863, "kl": 0.01105887410059016, "entropy": 1.395082515478134, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 114720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06400000000000006, "episode_reward_mean": 1.5504496644295302, "episode_len_mean": 28.57718120805369, "episode_media": {}, "episodes_this_iter": 149, "policy_reward_min": {"red_0": -1.006, "blue_0": -1.0039999999999998}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 1.1140604026845637, "blue_0": 0.4363892617449664}, "custom_metrics": {"red_0/door_open_done_mean": 0.6778523489932886, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.10738255033557047, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08053691275167785, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.10738255033557047, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.10067114093959731, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08053691275167785, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.10738255033557047, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08053691275167785, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.41800000000000015, 1.912, 1.451, 1.9409999999999998, 1.9609999999999999, 1.931, 1.9369999999999998, 1.95, 1.9609999999999999, 1.952, 1.948, 1.939, 0.964, 1.943, 1.4609999999999999, 1.956, 1.95, 1.911, 1.952, 1.448, 0.964, 1.9569999999999999, 0.44399999999999995, 1.95, 1.436, 0.45799999999999996, 1.934, 0.962, 1.4609999999999999, 1.431, 1.46, 1.96, 1.454, 0.952, 0.967, 1.427, 1.951, 0.43299999999999983, 1.932, 1.947, 1.012, 1.9489999999999998, 0.41400000000000003, 1.946, 0.956, 1.447, 1.4449999999999998, 1.952, -0.052999999999999936, 1.9500000000000002, 1.447, 1.958, 1.448, 1.948, 1.9609999999999999, 0.969, 1.871, 0.9609999999999999, 1.9489999999999998, 1.947, 1.897, 1.955, 1.9180000000000001, 0.3859999999999999, 1.9569999999999999, 0.46399999999999997, 1.417, 1.954, 0.401, 1.451, 1.93, 1.943, 1.455, 1.951, 0.44799999999999995, 1.959, 1.454, 0.43199999999999994, 1.9609999999999999, 1.927, 1.96, 1.9529999999999998, 0.46799999999999997, 1.9609999999999999, 1.9569999999999999, 0.9229999999999999, 0.44799999999999995, 1.958, 1.941, 1.952, 1.951, 1.9289999999999998, 1.9489999999999998, 1.954, 1.946, 0.9319999999999999, 1.943, 1.96, 1.456, 1.909, 1.94, 1.798, 1.958, 1.923, 1.458, 1.9210000000000003, 1.92, 1.438, 1.946, 1.442, 1.956, 0.46399999999999997, 0.9239999999999999, 1.9569999999999999, 1.948, 0.476, 1.952, 1.904, 1.954, 1.44, 0.883, -0.06400000000000006, 0.945, 1.955, 1.936, 1.4609999999999999, 1.4569999999999999, 0.45199999999999996, 1.4180000000000001, 0.45099999999999996, 1.948, 0.9369999999999998, 1.454, 1.95, 1.952, 1.9489999999999998, 1.944, 1.954, 1.923, 1.4609999999999999, 1.9329999999999998, 0.44699999999999995, 1.9540000000000002, 1.9609999999999999, 1.819, 1.954, 1.9489999999999998, 1.9460000000000002, 1.416], "episode_lengths": [26, 28, 15, 18, 13, 23, 20, 16, 13, 16, 17, 20, 12, 18, 13, 14, 16, 27, 16, 17, 12, 14, 17, 16, 20, 13, 21, 12, 13, 22, 13, 13, 15, 15, 300, 22, 15, 21, 22, 17, 154, 17, 28, 17, 14, 17, 17, 15, 16, 16, 17, 14, 17, 16, 13, 10, 40, 13, 17, 17, 32, 15, 26, 300, 14, 12, 27, 15, 31, 16, 22, 18, 15, 16, 17, 13, 15, 300, 13, 23, 13, 15, 10, 13, 14, 300, 17, 14, 18, 15, 16, 22, 16, 15, 17, 21, 19, 13, 14, 29, 18, 62, 14, 25, 14, 25, 25, 18, 17, 19, 13, 12, 24, 14, 17, 8, 14, 29, 15, 19, 36, 21, 300, 15, 21, 13, 14, 16, 27, 16, 17, 20, 15, 16, 15, 17, 18, 15, 24, 13, 21, 17, 15, 13, 58, 15, 17, 17, 27], "policy_red_0_reward": [0.922, 0.498, 1.455, 1.443, 1.4609999999999999, 1.431, 1.439, 1.452, 1.4609999999999999, 1.452, 1.4489999999999998, 1.44, 1.464, 1.4449999999999998, 1.4609999999999999, 1.458, 1.452, 1.417, 1.452, 1.448, 1.464, 1.4569999999999999, 1.448, 1.452, 1.438, 1.46, 1.4369999999999998, -0.5, 1.4609999999999999, 1.434, 1.4609999999999999, 1.4609999999999999, 1.455, 1.455, 0.489, 1.434, 1.455, 1.436, 1.432, 1.448, 1.03, 1.4489999999999998, -1.0, 1.4489999999999998, -0.5, 1.4489999999999998, 1.4489999999999998, 1.455, -1.001, 1.451, 1.448, 1.458, 1.4489999999999998, 1.45, 0.5, -0.5, 0.497, 1.4609999999999999, 1.4489999999999998, 1.4489999999999998, 1.4020000000000001, 1.455, 1.42, -0.04000000000000003, 1.458, 1.464, 1.419, 1.455, -1.006, 1.452, 1.4329999999999998, 1.446, 1.455, 1.451, -0.501, 1.4609999999999999, 0.0, -0.03800000000000003, 1.4609999999999999, 0.499, 1.4609999999999999, 1.454, -1.002, 1.4609999999999999, 0.499, 0.46299999999999997, -1.0, 0.5, 1.444, 1.455, 0.5, 1.4329999999999998, 1.452, 0.499, 1.4489999999999998, -0.5, 1.443, 1.4609999999999999, 1.458, 1.411, 1.444, 1.312, 1.458, 1.425, 1.458, 1.425, 1.421, 1.443, 1.4489999999999998, 1.443, 1.4609999999999999, 0.964, 1.428, 1.458, 1.4489999999999998, 1.476, 1.458, 1.412, 0.499, 1.443, 1.387, 0.9369999999999999, 0.484, 0.5, 1.4369999999999998, 1.4609999999999999, 1.458, 0.952, 0.0, -0.501, 1.4489999999999998, 1.438, 1.454, 1.452, 1.454, 1.4489999999999998, 1.446, 1.455, 0.497, 1.4609999999999999, 1.436, -0.5, 1.455, 1.4609999999999999, 1.323, 0.5, 0.5, 1.4489999999999998, 1.419], "policy_blue_0_reward": [-0.504, 1.4140000000000001, -0.004, 0.498, 0.5, 0.5, 0.498, 0.498, 0.5, 0.5, 0.499, 0.499, -0.5, 0.498, 0.0, 0.498, 0.498, 0.494, 0.5, 0.0, -0.5, 0.5, -1.0039999999999998, 0.498, -0.002, -1.002, 0.497, 1.462, 0.0, -0.003, -0.001, 0.499, -0.001, -0.5029999999999999, 0.478, -0.007, 0.496, -1.003, 0.5, 0.499, -0.01800000000000001, 0.5, 1.4140000000000001, 0.497, 1.456, -0.002, -0.004, 0.497, 0.948, 0.499, -0.001, 0.5, -0.001, 0.498, 1.4609999999999999, 1.4689999999999999, 1.374, -0.5, 0.5, 0.498, 0.495, 0.5, 0.498, 0.42599999999999993, 0.499, -1.0, -0.002, 0.499, 1.407, -0.001, 0.497, 0.497, 0.0, 0.5, 0.949, 0.498, 1.454, 0.47, 0.5, 1.428, 0.499, 0.499, 1.47, 0.5, 1.458, 0.45999999999999996, 1.448, 1.458, 0.497, 0.497, 1.451, 0.496, 0.497, 1.455, 0.497, 1.432, 0.5, 0.499, -0.002, 0.498, 0.496, 0.486, 0.5, 0.498, 0.0, 0.496, 0.499, -0.005, 0.497, -0.001, 0.495, -0.5, -0.504, 0.499, 0.499, -1.0, 0.494, 0.492, 1.455, -0.003, -0.5039999999999999, -1.001, 0.46099999999999997, 1.455, 0.499, 0.0, -0.001, -0.5, 1.4180000000000001, 0.952, 0.499, -0.501, 0.0, 0.498, 0.498, 0.5, 0.498, 0.499, 1.426, 0.0, 0.497, 0.947, 0.499, 0.5, 0.496, 1.454, 1.4489999999999998, 0.497, -0.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.426632780323193, "mean_inference_ms": 7.4663841548230705, "mean_action_processing_ms": 0.3907829335304994, "mean_env_wait_ms": 0.5225113091546207, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1518401523564486, "StateBufferConnector_ms": 0.009836206500162214, "ViewRequirementAgentConnector_ms": 0.19945146253445004}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06400000000000006, "episode_reward_mean": 1.5504496644295302, "episode_len_mean": 28.57718120805369, "episodes_this_iter": 149, "policy_reward_min": {"red_0": -1.006, "blue_0": -1.0039999999999998}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 1.1140604026845637, "blue_0": 0.4363892617449664}, "hist_stats": {"episode_reward": [0.41800000000000015, 1.912, 1.451, 1.9409999999999998, 1.9609999999999999, 1.931, 1.9369999999999998, 1.95, 1.9609999999999999, 1.952, 1.948, 1.939, 0.964, 1.943, 1.4609999999999999, 1.956, 1.95, 1.911, 1.952, 1.448, 0.964, 1.9569999999999999, 0.44399999999999995, 1.95, 1.436, 0.45799999999999996, 1.934, 0.962, 1.4609999999999999, 1.431, 1.46, 1.96, 1.454, 0.952, 0.967, 1.427, 1.951, 0.43299999999999983, 1.932, 1.947, 1.012, 1.9489999999999998, 0.41400000000000003, 1.946, 0.956, 1.447, 1.4449999999999998, 1.952, -0.052999999999999936, 1.9500000000000002, 1.447, 1.958, 1.448, 1.948, 1.9609999999999999, 0.969, 1.871, 0.9609999999999999, 1.9489999999999998, 1.947, 1.897, 1.955, 1.9180000000000001, 0.3859999999999999, 1.9569999999999999, 0.46399999999999997, 1.417, 1.954, 0.401, 1.451, 1.93, 1.943, 1.455, 1.951, 0.44799999999999995, 1.959, 1.454, 0.43199999999999994, 1.9609999999999999, 1.927, 1.96, 1.9529999999999998, 0.46799999999999997, 1.9609999999999999, 1.9569999999999999, 0.9229999999999999, 0.44799999999999995, 1.958, 1.941, 1.952, 1.951, 1.9289999999999998, 1.9489999999999998, 1.954, 1.946, 0.9319999999999999, 1.943, 1.96, 1.456, 1.909, 1.94, 1.798, 1.958, 1.923, 1.458, 1.9210000000000003, 1.92, 1.438, 1.946, 1.442, 1.956, 0.46399999999999997, 0.9239999999999999, 1.9569999999999999, 1.948, 0.476, 1.952, 1.904, 1.954, 1.44, 0.883, -0.06400000000000006, 0.945, 1.955, 1.936, 1.4609999999999999, 1.4569999999999999, 0.45199999999999996, 1.4180000000000001, 0.45099999999999996, 1.948, 0.9369999999999998, 1.454, 1.95, 1.952, 1.9489999999999998, 1.944, 1.954, 1.923, 1.4609999999999999, 1.9329999999999998, 0.44699999999999995, 1.9540000000000002, 1.9609999999999999, 1.819, 1.954, 1.9489999999999998, 1.9460000000000002, 1.416], "episode_lengths": [26, 28, 15, 18, 13, 23, 20, 16, 13, 16, 17, 20, 12, 18, 13, 14, 16, 27, 16, 17, 12, 14, 17, 16, 20, 13, 21, 12, 13, 22, 13, 13, 15, 15, 300, 22, 15, 21, 22, 17, 154, 17, 28, 17, 14, 17, 17, 15, 16, 16, 17, 14, 17, 16, 13, 10, 40, 13, 17, 17, 32, 15, 26, 300, 14, 12, 27, 15, 31, 16, 22, 18, 15, 16, 17, 13, 15, 300, 13, 23, 13, 15, 10, 13, 14, 300, 17, 14, 18, 15, 16, 22, 16, 15, 17, 21, 19, 13, 14, 29, 18, 62, 14, 25, 14, 25, 25, 18, 17, 19, 13, 12, 24, 14, 17, 8, 14, 29, 15, 19, 36, 21, 300, 15, 21, 13, 14, 16, 27, 16, 17, 20, 15, 16, 15, 17, 18, 15, 24, 13, 21, 17, 15, 13, 58, 15, 17, 17, 27], "policy_red_0_reward": [0.922, 0.498, 1.455, 1.443, 1.4609999999999999, 1.431, 1.439, 1.452, 1.4609999999999999, 1.452, 1.4489999999999998, 1.44, 1.464, 1.4449999999999998, 1.4609999999999999, 1.458, 1.452, 1.417, 1.452, 1.448, 1.464, 1.4569999999999999, 1.448, 1.452, 1.438, 1.46, 1.4369999999999998, -0.5, 1.4609999999999999, 1.434, 1.4609999999999999, 1.4609999999999999, 1.455, 1.455, 0.489, 1.434, 1.455, 1.436, 1.432, 1.448, 1.03, 1.4489999999999998, -1.0, 1.4489999999999998, -0.5, 1.4489999999999998, 1.4489999999999998, 1.455, -1.001, 1.451, 1.448, 1.458, 1.4489999999999998, 1.45, 0.5, -0.5, 0.497, 1.4609999999999999, 1.4489999999999998, 1.4489999999999998, 1.4020000000000001, 1.455, 1.42, -0.04000000000000003, 1.458, 1.464, 1.419, 1.455, -1.006, 1.452, 1.4329999999999998, 1.446, 1.455, 1.451, -0.501, 1.4609999999999999, 0.0, -0.03800000000000003, 1.4609999999999999, 0.499, 1.4609999999999999, 1.454, -1.002, 1.4609999999999999, 0.499, 0.46299999999999997, -1.0, 0.5, 1.444, 1.455, 0.5, 1.4329999999999998, 1.452, 0.499, 1.4489999999999998, -0.5, 1.443, 1.4609999999999999, 1.458, 1.411, 1.444, 1.312, 1.458, 1.425, 1.458, 1.425, 1.421, 1.443, 1.4489999999999998, 1.443, 1.4609999999999999, 0.964, 1.428, 1.458, 1.4489999999999998, 1.476, 1.458, 1.412, 0.499, 1.443, 1.387, 0.9369999999999999, 0.484, 0.5, 1.4369999999999998, 1.4609999999999999, 1.458, 0.952, 0.0, -0.501, 1.4489999999999998, 1.438, 1.454, 1.452, 1.454, 1.4489999999999998, 1.446, 1.455, 0.497, 1.4609999999999999, 1.436, -0.5, 1.455, 1.4609999999999999, 1.323, 0.5, 0.5, 1.4489999999999998, 1.419], "policy_blue_0_reward": [-0.504, 1.4140000000000001, -0.004, 0.498, 0.5, 0.5, 0.498, 0.498, 0.5, 0.5, 0.499, 0.499, -0.5, 0.498, 0.0, 0.498, 0.498, 0.494, 0.5, 0.0, -0.5, 0.5, -1.0039999999999998, 0.498, -0.002, -1.002, 0.497, 1.462, 0.0, -0.003, -0.001, 0.499, -0.001, -0.5029999999999999, 0.478, -0.007, 0.496, -1.003, 0.5, 0.499, -0.01800000000000001, 0.5, 1.4140000000000001, 0.497, 1.456, -0.002, -0.004, 0.497, 0.948, 0.499, -0.001, 0.5, -0.001, 0.498, 1.4609999999999999, 1.4689999999999999, 1.374, -0.5, 0.5, 0.498, 0.495, 0.5, 0.498, 0.42599999999999993, 0.499, -1.0, -0.002, 0.499, 1.407, -0.001, 0.497, 0.497, 0.0, 0.5, 0.949, 0.498, 1.454, 0.47, 0.5, 1.428, 0.499, 0.499, 1.47, 0.5, 1.458, 0.45999999999999996, 1.448, 1.458, 0.497, 0.497, 1.451, 0.496, 0.497, 1.455, 0.497, 1.432, 0.5, 0.499, -0.002, 0.498, 0.496, 0.486, 0.5, 0.498, 0.0, 0.496, 0.499, -0.005, 0.497, -0.001, 0.495, -0.5, -0.504, 0.499, 0.499, -1.0, 0.494, 0.492, 1.455, -0.003, -0.5039999999999999, -1.001, 0.46099999999999997, 1.455, 0.499, 0.0, -0.001, -0.5, 1.4180000000000001, 0.952, 0.499, -0.501, 0.0, 0.498, 0.498, 0.5, 0.498, 0.499, 1.426, 0.0, 0.497, 0.947, 0.499, 0.5, 0.496, 1.454, 1.4489999999999998, 0.497, -0.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.426632780323193, "mean_inference_ms": 7.4663841548230705, "mean_action_processing_ms": 0.3907829335304994, "mean_env_wait_ms": 0.5225113091546207, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1518401523564486, "StateBufferConnector_ms": 0.009836206500162214, "ViewRequirementAgentConnector_ms": 0.19945146253445004}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.82143221343722, "num_env_steps_trained_throughput_per_sec": 128.82143221343722, "timesteps_total": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 31972.812, "sample_time_ms": 4177.805, "learn_time_ms": 27764.851, "learn_throughput": 144.067, "synch_weights_time_ms": 28.511}, "counters": {"num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "episodes_total": 9550, "training_iteration": 120, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-01-02", "timestamp": 1694840462, "time_this_iter_s": 31.069961071014404, "time_total_s": 3751.3366165161133, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a2e8430>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3751.3366165161133, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 25.39565217391304, "ram_util_percent": 57.16521739130434}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6428571428571429, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.07142857142857142, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08441558441558442, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.07142857142857142, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.18181818181818182, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08441558441558442, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.07142857142857142, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08441558441558442, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4470654736428211, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.032595701710670257, "policy_loss": -0.06817703709433166, "vf_loss": 0.03552876332735953, "vf_explained_var": 0.7301245493193468, "kl": 0.008224312795344494, "entropy": 0.9190591609105467, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 115680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4824865981936455, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04093133976663618, "policy_loss": -0.0764628102100687, "vf_loss": 0.033169677237553215, "vf_explained_var": 0.5946303655082981, "kl": 0.008902072058697214, "entropy": 1.333401291569074, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 115680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 968000, "num_agent_steps_trained": 968000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.05399999999999994, "episode_reward_mean": 1.6052597402597404, "episode_len_mean": 22.850649350649352, "episode_media": {}, "episodes_this_iter": 154, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.001}, "policy_reward_max": {"red_0": 1.482, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.0200714285714285, "blue_0": 0.5851883116883116}, "custom_metrics": {"red_0/door_open_done_mean": 0.6428571428571429, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.07142857142857142, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08441558441558442, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.07142857142857142, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.18181818181818182, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.08441558441558442, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.07142857142857142, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08441558441558442, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.96, 1.952, -0.05399999999999994, 0.964, 0.482, 1.9609999999999999, 1.412, 0.43199999999999994, 1.934, 1.4569999999999999, 1.452, 0.942, 1.935, 1.417, 1.9569999999999999, 1.9609999999999999, 1.917, 1.9569999999999999, 1.9529999999999998, 1.903, 1.9609999999999999, 1.9409999999999998, -0.030000000000000027, 1.9609999999999999, 1.452, 1.9569999999999999, 1.924, 1.9449999999999998, 1.4409999999999998, 1.947, 1.455, 1.954, 1.938, 0.96, 1.942, 0.9510000000000001, 1.9609999999999999, 0.43599999999999994, 1.96, 1.909, 1.927, 1.9249999999999998, -0.018000000000000016, 1.9609999999999999, 1.943, 1.363, 1.948, 0.43399999999999994, 1.436, 1.9569999999999999, 1.9569999999999999, 1.96, 1.951, 1.9609999999999999, 1.46, 1.956, 1.954, 1.9609999999999999, 0.45999999999999996, 1.9609999999999999, 1.9489999999999998, 1.9289999999999998, 0.97, 1.946, 1.93, 1.952, 1.9020000000000001, 1.948, 1.958, 1.9409999999999998, 1.8599999999999999, 1.427, 1.96, 1.9449999999999998, 0.4630000000000001, 0.46899999999999986, 1.955, 0.479, 1.9060000000000001, 1.442, 1.948, 1.946, 1.4609999999999999, 1.956, 1.946, 1.459, 1.9449999999999998, 1.943, 0.966, 1.951, 0.907, 1.948, 1.417, 1.444, 1.942, 1.9489999999999998, 1.958, 1.94, 1.952, 1.946, -0.03400000000000003, 1.9449999999999998, 1.448, 1.939, 1.958, 1.903, 1.447, 1.4569999999999999, 1.9329999999999998, 1.95, 1.9609999999999999, 1.4569999999999999, 1.958, 0.957, 1.946, 1.8940000000000001, 0.964, 0.44599999999999995, 1.958, 1.444, 1.952, 1.9609999999999999, 1.431, 1.951, 0.45399999999999996, 0.46599999999999997, 1.958, 1.936, 1.428, 1.454, 1.9329999999999998, 1.958, 1.9449999999999998, 1.938, 1.96, 1.935, 1.952, 1.9609999999999999, 1.959, 0.45199999999999996, 1.927, -0.029000000000000026, 1.96, 1.954, 1.9449999999999998, 1.9609999999999999, 1.951, 1.33, -0.027999999999999914, 1.424, 1.9609999999999999, 1.448, 1.96, 1.96], "episode_lengths": [13, 15, 17, 300, 6, 13, 29, 300, 20, 14, 16, 18, 21, 25, 14, 13, 27, 14, 15, 30, 13, 19, 10, 13, 15, 14, 24, 18, 19, 17, 15, 15, 19, 13, 18, 16, 13, 20, 13, 29, 24, 24, 6, 13, 18, 45, 16, 20, 20, 14, 14, 13, 16, 13, 13, 14, 15, 13, 13, 13, 17, 22, 10, 18, 22, 16, 32, 17, 14, 19, 44, 23, 13, 17, 11, 10, 15, 7, 30, 18, 17, 18, 13, 14, 17, 13, 18, 18, 11, 16, 28, 17, 25, 18, 18, 16, 14, 20, 16, 18, 11, 18, 17, 19, 14, 31, 17, 14, 21, 16, 13, 14, 14, 14, 17, 34, 12, 17, 14, 18, 15, 13, 22, 16, 15, 10, 14, 21, 23, 15, 21, 14, 18, 20, 13, 21, 16, 13, 13, 300, 24, 9, 13, 15, 18, 13, 16, 53, 9, 25, 13, 17, 13, 13], "policy_red_0_reward": [1.4609999999999999, 1.455, -1.002, 0.487, 1.482, 0.5, 1.412, -0.028000000000000018, 0.496, 1.458, 1.452, 1.446, 1.4369999999999998, 1.424, 0.499, 1.4609999999999999, 0.499, 1.458, 1.455, 1.408, 0.5, 1.442, 0.97, 0.5, 1.455, 1.458, 1.427, 1.4449999999999998, 1.443, 1.4489999999999998, 0.0, 1.455, 1.442, -0.5, 0.497, 1.452, 0.5, -1.002, 1.4609999999999999, 1.411, 0.499, 0.499, -1.0, 1.4609999999999999, 1.4449999999999998, 0.0, 1.451, -0.502, -0.002, 0.5, 1.458, 1.4609999999999999, 1.452, 1.4609999999999999, 1.4609999999999999, 1.458, 1.455, 1.4609999999999999, -1.0, 1.4609999999999999, 1.4489999999999998, 1.43, 1.47, 0.5, 1.431, 1.452, 1.403, 1.4489999999999998, 0.5, 1.443, 1.363, 1.4300000000000002, 1.4609999999999999, 1.4489999999999998, 0.965, 0.969, 1.455, -1.0, 1.409, 1.446, 1.4489999999999998, 1.446, 1.4609999999999999, 1.4569999999999999, 0.498, 1.4609999999999999, 1.446, 1.4449999999999998, -0.5, 0.499, 1.412, 1.448, 1.421, 1.4449999999999998, 1.443, 1.452, 0.5, 1.44, 1.452, 1.446, 0.966, 1.446, 1.4489999999999998, 1.442, 0.5, 1.407, 1.4489999999999998, -0.001, 1.435, 1.452, 0.5, -0.001, 1.458, -0.5, 1.448, 1.396, 1.464, -1.0, 1.458, 1.4449999999999998, 1.455, 1.4609999999999999, 1.434, 1.452, -1.001, -0.5, 1.458, 1.4369999999999998, -0.002, -0.001, 1.4369999999999998, 1.458, 1.446, 1.44, 1.4609999999999999, 1.4369999999999998, 0.5, 0.5, 1.4609999999999999, 0.482, 1.427, 0.972, 1.4609999999999999, 1.455, 1.446, 1.4609999999999999, 1.452, -0.006, -1.001, 1.425, 1.4609999999999999, 1.4489999999999998, 1.4609999999999999, 1.4609999999999999], "policy_blue_0_reward": [0.499, 0.497, 0.948, 0.477, -1.0, 1.4609999999999999, 0.0, 0.45999999999999996, 1.438, -0.001, 0.0, -0.504, 0.498, -0.007, 1.458, 0.5, 1.4180000000000001, 0.499, 0.498, 0.495, 1.4609999999999999, 0.499, -1.0, 1.4609999999999999, -0.003, 0.499, 0.497, 0.5, -0.002, 0.498, 1.455, 0.499, 0.496, 1.46, 1.4449999999999998, -0.501, 1.4609999999999999, 1.438, 0.499, 0.498, 1.428, 1.426, 0.982, 0.5, 0.498, 1.363, 0.497, 0.9359999999999999, 1.438, 1.4569999999999999, 0.499, 0.499, 0.499, 0.5, -0.001, 0.498, 0.499, 0.5, 1.46, 0.5, 0.5, 0.499, -0.5, 1.446, 0.499, 0.5, 0.499, 0.499, 1.458, 0.498, 0.497, -0.003, 0.499, 0.496, -0.502, -0.5, 0.5, 1.479, 0.497, -0.004, 0.499, 0.5, 0.0, 0.499, 1.448, -0.002, 0.499, 0.498, 1.466, 1.452, -0.5049999999999999, 0.5, -0.004, -0.001, 0.499, 0.497, 1.458, 0.5, 0.5, 0.5, -1.0, 0.499, -0.001, 0.497, 1.458, 0.496, -0.002, 1.458, 0.498, 0.498, 1.4609999999999999, 1.458, 0.5, 1.4569999999999999, 0.498, 0.498, -0.5, 1.446, 0.5, -0.001, 0.497, 0.5, -0.003, 0.499, 1.455, 0.966, 0.5, 0.499, 1.4300000000000002, 1.455, 0.496, 0.5, 0.499, 0.498, 0.499, 0.498, 1.452, 1.4609999999999999, 0.498, -0.03000000000000002, 0.5, -1.001, 0.499, 0.499, 0.499, 0.5, 0.499, 1.3359999999999999, 0.973, -0.001, 0.5, -0.001, 0.499, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4243626044588897, "mean_inference_ms": 7.462623798247808, "mean_action_processing_ms": 0.39066032599050854, "mean_env_wait_ms": 0.5220690288903591, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14698698923185274, "StateBufferConnector_ms": 0.010005529824789468, "ViewRequirementAgentConnector_ms": 0.18690298129985858}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.05399999999999994, "episode_reward_mean": 1.6052597402597404, "episode_len_mean": 22.850649350649352, "episodes_this_iter": 154, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.001}, "policy_reward_max": {"red_0": 1.482, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.0200714285714285, "blue_0": 0.5851883116883116}, "hist_stats": {"episode_reward": [1.96, 1.952, -0.05399999999999994, 0.964, 0.482, 1.9609999999999999, 1.412, 0.43199999999999994, 1.934, 1.4569999999999999, 1.452, 0.942, 1.935, 1.417, 1.9569999999999999, 1.9609999999999999, 1.917, 1.9569999999999999, 1.9529999999999998, 1.903, 1.9609999999999999, 1.9409999999999998, -0.030000000000000027, 1.9609999999999999, 1.452, 1.9569999999999999, 1.924, 1.9449999999999998, 1.4409999999999998, 1.947, 1.455, 1.954, 1.938, 0.96, 1.942, 0.9510000000000001, 1.9609999999999999, 0.43599999999999994, 1.96, 1.909, 1.927, 1.9249999999999998, -0.018000000000000016, 1.9609999999999999, 1.943, 1.363, 1.948, 0.43399999999999994, 1.436, 1.9569999999999999, 1.9569999999999999, 1.96, 1.951, 1.9609999999999999, 1.46, 1.956, 1.954, 1.9609999999999999, 0.45999999999999996, 1.9609999999999999, 1.9489999999999998, 1.9289999999999998, 0.97, 1.946, 1.93, 1.952, 1.9020000000000001, 1.948, 1.958, 1.9409999999999998, 1.8599999999999999, 1.427, 1.96, 1.9449999999999998, 0.4630000000000001, 0.46899999999999986, 1.955, 0.479, 1.9060000000000001, 1.442, 1.948, 1.946, 1.4609999999999999, 1.956, 1.946, 1.459, 1.9449999999999998, 1.943, 0.966, 1.951, 0.907, 1.948, 1.417, 1.444, 1.942, 1.9489999999999998, 1.958, 1.94, 1.952, 1.946, -0.03400000000000003, 1.9449999999999998, 1.448, 1.939, 1.958, 1.903, 1.447, 1.4569999999999999, 1.9329999999999998, 1.95, 1.9609999999999999, 1.4569999999999999, 1.958, 0.957, 1.946, 1.8940000000000001, 0.964, 0.44599999999999995, 1.958, 1.444, 1.952, 1.9609999999999999, 1.431, 1.951, 0.45399999999999996, 0.46599999999999997, 1.958, 1.936, 1.428, 1.454, 1.9329999999999998, 1.958, 1.9449999999999998, 1.938, 1.96, 1.935, 1.952, 1.9609999999999999, 1.959, 0.45199999999999996, 1.927, -0.029000000000000026, 1.96, 1.954, 1.9449999999999998, 1.9609999999999999, 1.951, 1.33, -0.027999999999999914, 1.424, 1.9609999999999999, 1.448, 1.96, 1.96], "episode_lengths": [13, 15, 17, 300, 6, 13, 29, 300, 20, 14, 16, 18, 21, 25, 14, 13, 27, 14, 15, 30, 13, 19, 10, 13, 15, 14, 24, 18, 19, 17, 15, 15, 19, 13, 18, 16, 13, 20, 13, 29, 24, 24, 6, 13, 18, 45, 16, 20, 20, 14, 14, 13, 16, 13, 13, 14, 15, 13, 13, 13, 17, 22, 10, 18, 22, 16, 32, 17, 14, 19, 44, 23, 13, 17, 11, 10, 15, 7, 30, 18, 17, 18, 13, 14, 17, 13, 18, 18, 11, 16, 28, 17, 25, 18, 18, 16, 14, 20, 16, 18, 11, 18, 17, 19, 14, 31, 17, 14, 21, 16, 13, 14, 14, 14, 17, 34, 12, 17, 14, 18, 15, 13, 22, 16, 15, 10, 14, 21, 23, 15, 21, 14, 18, 20, 13, 21, 16, 13, 13, 300, 24, 9, 13, 15, 18, 13, 16, 53, 9, 25, 13, 17, 13, 13], "policy_red_0_reward": [1.4609999999999999, 1.455, -1.002, 0.487, 1.482, 0.5, 1.412, -0.028000000000000018, 0.496, 1.458, 1.452, 1.446, 1.4369999999999998, 1.424, 0.499, 1.4609999999999999, 0.499, 1.458, 1.455, 1.408, 0.5, 1.442, 0.97, 0.5, 1.455, 1.458, 1.427, 1.4449999999999998, 1.443, 1.4489999999999998, 0.0, 1.455, 1.442, -0.5, 0.497, 1.452, 0.5, -1.002, 1.4609999999999999, 1.411, 0.499, 0.499, -1.0, 1.4609999999999999, 1.4449999999999998, 0.0, 1.451, -0.502, -0.002, 0.5, 1.458, 1.4609999999999999, 1.452, 1.4609999999999999, 1.4609999999999999, 1.458, 1.455, 1.4609999999999999, -1.0, 1.4609999999999999, 1.4489999999999998, 1.43, 1.47, 0.5, 1.431, 1.452, 1.403, 1.4489999999999998, 0.5, 1.443, 1.363, 1.4300000000000002, 1.4609999999999999, 1.4489999999999998, 0.965, 0.969, 1.455, -1.0, 1.409, 1.446, 1.4489999999999998, 1.446, 1.4609999999999999, 1.4569999999999999, 0.498, 1.4609999999999999, 1.446, 1.4449999999999998, -0.5, 0.499, 1.412, 1.448, 1.421, 1.4449999999999998, 1.443, 1.452, 0.5, 1.44, 1.452, 1.446, 0.966, 1.446, 1.4489999999999998, 1.442, 0.5, 1.407, 1.4489999999999998, -0.001, 1.435, 1.452, 0.5, -0.001, 1.458, -0.5, 1.448, 1.396, 1.464, -1.0, 1.458, 1.4449999999999998, 1.455, 1.4609999999999999, 1.434, 1.452, -1.001, -0.5, 1.458, 1.4369999999999998, -0.002, -0.001, 1.4369999999999998, 1.458, 1.446, 1.44, 1.4609999999999999, 1.4369999999999998, 0.5, 0.5, 1.4609999999999999, 0.482, 1.427, 0.972, 1.4609999999999999, 1.455, 1.446, 1.4609999999999999, 1.452, -0.006, -1.001, 1.425, 1.4609999999999999, 1.4489999999999998, 1.4609999999999999, 1.4609999999999999], "policy_blue_0_reward": [0.499, 0.497, 0.948, 0.477, -1.0, 1.4609999999999999, 0.0, 0.45999999999999996, 1.438, -0.001, 0.0, -0.504, 0.498, -0.007, 1.458, 0.5, 1.4180000000000001, 0.499, 0.498, 0.495, 1.4609999999999999, 0.499, -1.0, 1.4609999999999999, -0.003, 0.499, 0.497, 0.5, -0.002, 0.498, 1.455, 0.499, 0.496, 1.46, 1.4449999999999998, -0.501, 1.4609999999999999, 1.438, 0.499, 0.498, 1.428, 1.426, 0.982, 0.5, 0.498, 1.363, 0.497, 0.9359999999999999, 1.438, 1.4569999999999999, 0.499, 0.499, 0.499, 0.5, -0.001, 0.498, 0.499, 0.5, 1.46, 0.5, 0.5, 0.499, -0.5, 1.446, 0.499, 0.5, 0.499, 0.499, 1.458, 0.498, 0.497, -0.003, 0.499, 0.496, -0.502, -0.5, 0.5, 1.479, 0.497, -0.004, 0.499, 0.5, 0.0, 0.499, 1.448, -0.002, 0.499, 0.498, 1.466, 1.452, -0.5049999999999999, 0.5, -0.004, -0.001, 0.499, 0.497, 1.458, 0.5, 0.5, 0.5, -1.0, 0.499, -0.001, 0.497, 1.458, 0.496, -0.002, 1.458, 0.498, 0.498, 1.4609999999999999, 1.458, 0.5, 1.4569999999999999, 0.498, 0.498, -0.5, 1.446, 0.5, -0.001, 0.497, 0.5, -0.003, 0.499, 1.455, 0.966, 0.5, 0.499, 1.4300000000000002, 1.455, 0.496, 0.5, 0.499, 0.498, 0.499, 0.498, 1.452, 1.4609999999999999, 0.498, -0.03000000000000002, 0.5, -1.001, 0.499, 0.499, 0.499, 0.5, 0.499, 1.3359999999999999, 0.973, -0.001, 0.5, -0.001, 0.499, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4243626044588897, "mean_inference_ms": 7.462623798247808, "mean_action_processing_ms": 0.39066032599050854, "mean_env_wait_ms": 0.5220690288903591, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14698698923185274, "StateBufferConnector_ms": 0.010005529824789468, "ViewRequirementAgentConnector_ms": 0.18690298129985858}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 968000, "num_agent_steps_trained": 968000, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 117.15007458942856, "num_env_steps_trained_throughput_per_sec": 117.15007458942856, "timesteps_total": 484000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 968000, "timers": {"training_iteration_time_ms": 31744.608, "sample_time_ms": 4119.589, "learn_time_ms": 27594.945, "learn_throughput": 144.954, "synch_weights_time_ms": 28.47}, "counters": {"num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 968000, "num_agent_steps_trained": 968000}, "done": false, "episodes_total": 9704, "training_iteration": 121, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-01-37", "timestamp": 1694840497, "time_this_iter_s": 34.165820837020874, "time_total_s": 3785.502437353134, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21981120>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3785.502437353134, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 32.98571428571429, "ram_util_percent": 57.18571428571429}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6666666666666666, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.09027777777777778, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.041666666666666664, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.09027777777777778, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1736111111111111, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.041666666666666664, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.09027777777777778, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.041666666666666664, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.46889404927690825, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.035079208824511925, "policy_loss": -0.0694029657888071, "vf_loss": 0.02638351177010918, "vf_explained_var": 0.7706502444421252, "kl": 0.009713714806061565, "entropy": 0.9970565687865018, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 116640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48733803289942446, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04527386830789813, "policy_loss": -0.07965514796378556, "vf_loss": 0.02859540033969097, "vf_explained_var": 0.5826020390416186, "kl": 0.009421735659094736, "entropy": 1.3803119659423828, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 116640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.051000000000000045, "episode_reward_mean": 1.621048611111111, "episode_len_mean": 25.84722222222222, "episode_media": {}, "episodes_this_iter": 144, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 1.1259513888888888, "blue_0": 0.4950972222222222}, "custom_metrics": {"red_0/door_open_done_mean": 0.6666666666666666, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.09027777777777778, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.041666666666666664, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.09027777777777778, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1736111111111111, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.041666666666666664, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.09027777777777778, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.041666666666666664, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.45799999999999996, 1.952, 1.956, 1.9489999999999998, 1.439, 1.451, 1.923, 1.456, 0.46299999999999997, 1.932, 0.947, 1.4580000000000002, 1.936, 1.934, 1.9569999999999999, 1.9569999999999999, 0.46799999999999997, 1.949, 1.9609999999999999, 1.94, 1.939, 1.9569999999999999, 1.9569999999999999, 0.46399999999999997, 1.941, 1.444, 1.948, 0.9390000000000001, 1.087, 1.948, 1.932, 1.931, 1.452, 1.951, 1.954, 1.452, 1.9569999999999999, 1.943, 1.954, 1.426, 1.4609999999999999, 1.95, 1.456, 1.452, 1.447, 1.943, 1.955, 1.896, 1.4569999999999999, 1.9409999999999998, 0.97, 0.472, 1.447, 0.969, 1.958, 1.94, 1.942, 0.954, 1.855, 1.439, 1.959, 1.9449999999999998, 0.9489999999999998, 1.9609999999999999, 1.9569999999999999, 1.946, 1.9609999999999999, 1.4569999999999999, 1.955, 1.948, 1.943, 1.454, 1.4529999999999998, 0.96, 1.454, 1.956, 1.419, 1.9300000000000002, 1.942, 0.473, 1.9569999999999999, 1.913, 1.888, 1.948, 1.9609999999999999, 1.938, 1.919, 1.96, 1.428, 1.954, 1.737, 1.952, -0.03500000000000003, 1.458, 1.928, 1.9540000000000002, 0.476, 1.956, 1.955, 1.96, 1.9609999999999999, 1.952, 0.471, 1.952, 0.9349999999999999, 1.431, 1.939, 1.96, 1.955, 1.909, 0.949, 1.454, 1.958, 1.9489999999999998, 0.45599999999999996, 1.95, 1.4489999999999998, 1.9569999999999999, -0.051000000000000045, 1.923, 0.9670000000000001, 1.454, 1.942, 1.96, 1.949, 1.924, 1.458, 1.459, 0.45100000000000007, 1.9529999999999998, 1.928, 1.9449999999999998, 1.46, 1.953, 1.9500000000000002, 1.952, 0.9359999999999999, 1.931, 1.9489999999999998, 1.4529999999999998, 1.9609999999999999, 1.442, 1.9409999999999998, 1.459], "episode_lengths": [14, 15, 14, 17, 19, 15, 24, 14, 12, 22, 300, 13, 20, 21, 14, 14, 10, 16, 13, 19, 20, 14, 14, 12, 19, 18, 17, 20, 132, 17, 21, 22, 16, 16, 15, 16, 14, 18, 15, 24, 13, 16, 14, 16, 17, 19, 15, 32, 14, 19, 10, 9, 17, 10, 14, 19, 19, 15, 45, 19, 13, 17, 16, 13, 14, 17, 13, 14, 15, 17, 19, 15, 15, 300, 15, 14, 26, 21, 19, 9, 14, 28, 35, 17, 13, 20, 24, 13, 24, 15, 83, 16, 11, 14, 22, 15, 8, 14, 15, 13, 13, 16, 9, 16, 300, 22, 20, 13, 15, 29, 17, 15, 14, 17, 14, 16, 17, 14, 15, 24, 11, 15, 19, 13, 16, 23, 14, 13, 16, 15, 22, 18, 13, 15, 16, 16, 300, 22, 16, 15, 13, 19, 19, 13], "policy_red_0_reward": [1.458, 1.455, 1.4569999999999999, 1.4489999999999998, -0.003, 1.4529999999999998, 1.428, 1.458, -0.5, 1.434, 0.475, 1.4609999999999999, 1.439, 1.4369999999999998, 1.458, 1.458, 0.97, 1.452, 1.4609999999999999, 1.442, 0.5, 1.458, 1.458, 0.964, 1.442, 1.446, 0.499, 1.44, -0.007, 1.4489999999999998, 1.436, 1.4329999999999998, 1.452, 1.452, 1.454, 1.452, 1.458, 1.446, 0.5, 1.427, 1.4609999999999999, 1.452, 1.458, 1.452, 1.4489999999999998, 1.443, 1.455, 1.4020000000000001, 1.4569999999999999, 1.443, 1.47, 0.972, 1.4489999999999998, -0.5, 0.5, 0.499, 1.443, -0.5, 1.361, 1.44, 1.4609999999999999, 1.448, 1.452, 0.5, 0.499, 1.4489999999999998, 1.4609999999999999, 1.458, 1.455, 1.4489999999999998, 1.443, 1.455, 1.455, 0.487, 1.455, 1.4569999999999999, -0.001, 1.436, 1.443, -1.0, 0.499, 1.415, 1.3940000000000001, 0.5, 1.4609999999999999, 0.5, 1.427, 1.4609999999999999, 0.0, 0.5, 1.244, 1.452, 0.967, 1.458, 1.4329999999999998, 1.455, 1.476, 1.458, 1.455, 1.4609999999999999, 1.4609999999999999, 0.5, 0.972, 1.452, 0.46499999999999997, 1.432, 1.44, 1.4609999999999999, 0.5, 1.412, -0.5, 1.455, 1.458, 1.4489999999999998, 1.458, 1.452, 1.4489999999999998, 1.458, -1.003, 0.499, 1.467, 1.454, 0.5, 1.4609999999999999, 1.452, 0.495, 0.0, -0.002, 1.451, 1.455, 1.434, 1.4449999999999998, 1.4609999999999999, 1.455, 1.452, 0.5, 0.469, 1.434, 0.5, 1.454, 1.4609999999999999, 1.443, 1.443, -0.002], "policy_blue_0_reward": [-1.0, 0.497, 0.499, 0.5, 1.442, -0.002, 0.495, -0.002, 0.963, 0.498, 0.472, -0.003, 0.497, 0.497, 0.499, 0.499, -0.502, 0.497, 0.5, 0.498, 1.439, 0.499, 0.499, -0.5, 0.499, -0.002, 1.4489999999999998, -0.501, 1.0939999999999999, 0.499, 0.496, 0.498, 0.0, 0.499, 0.5, 0.0, 0.499, 0.497, 1.454, -0.001, 0.0, 0.498, -0.002, 0.0, -0.002, 0.5, 0.5, 0.494, 0.0, 0.498, -0.5, -0.5, -0.002, 1.4689999999999999, 1.458, 1.4409999999999998, 0.499, 1.454, 0.494, -0.001, 0.498, 0.497, -0.503, 1.4609999999999999, 1.458, 0.497, 0.5, -0.001, 0.5, 0.499, 0.5, -0.001, -0.002, 0.473, -0.001, 0.499, 1.42, 0.494, 0.499, 1.4729999999999999, 1.458, 0.498, 0.494, 1.448, 0.5, 1.438, 0.492, 0.499, 1.428, 1.454, 0.493, 0.5, -1.002, 0.0, 0.495, 0.499, -1.0, 0.498, 0.5, 0.499, 0.5, 1.452, -0.501, 0.5, 0.47, -0.001, 0.499, 0.499, 1.455, 0.497, 1.4489999999999998, -0.001, 0.5, 0.5, -1.002, 0.498, 0.0, 0.499, 0.952, 1.424, -0.5, 0.0, 1.442, 0.499, 0.497, 1.429, 1.458, 1.4609999999999999, -1.0, 0.498, 0.494, 0.5, -0.001, 0.498, 0.498, 1.452, 0.46699999999999997, 0.497, 1.4489999999999998, -0.001, 0.5, -0.001, 0.498, 1.4609999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4247566962600995, "mean_inference_ms": 7.4723166369115965, "mean_action_processing_ms": 0.3920423708128926, "mean_env_wait_ms": 0.5221252274657802, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1524047719107734, "StateBufferConnector_ms": 0.009885016414854262, "ViewRequirementAgentConnector_ms": 0.19465933243433634}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.051000000000000045, "episode_reward_mean": 1.621048611111111, "episode_len_mean": 25.84722222222222, "episodes_this_iter": 144, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 1.1259513888888888, "blue_0": 0.4950972222222222}, "hist_stats": {"episode_reward": [0.45799999999999996, 1.952, 1.956, 1.9489999999999998, 1.439, 1.451, 1.923, 1.456, 0.46299999999999997, 1.932, 0.947, 1.4580000000000002, 1.936, 1.934, 1.9569999999999999, 1.9569999999999999, 0.46799999999999997, 1.949, 1.9609999999999999, 1.94, 1.939, 1.9569999999999999, 1.9569999999999999, 0.46399999999999997, 1.941, 1.444, 1.948, 0.9390000000000001, 1.087, 1.948, 1.932, 1.931, 1.452, 1.951, 1.954, 1.452, 1.9569999999999999, 1.943, 1.954, 1.426, 1.4609999999999999, 1.95, 1.456, 1.452, 1.447, 1.943, 1.955, 1.896, 1.4569999999999999, 1.9409999999999998, 0.97, 0.472, 1.447, 0.969, 1.958, 1.94, 1.942, 0.954, 1.855, 1.439, 1.959, 1.9449999999999998, 0.9489999999999998, 1.9609999999999999, 1.9569999999999999, 1.946, 1.9609999999999999, 1.4569999999999999, 1.955, 1.948, 1.943, 1.454, 1.4529999999999998, 0.96, 1.454, 1.956, 1.419, 1.9300000000000002, 1.942, 0.473, 1.9569999999999999, 1.913, 1.888, 1.948, 1.9609999999999999, 1.938, 1.919, 1.96, 1.428, 1.954, 1.737, 1.952, -0.03500000000000003, 1.458, 1.928, 1.9540000000000002, 0.476, 1.956, 1.955, 1.96, 1.9609999999999999, 1.952, 0.471, 1.952, 0.9349999999999999, 1.431, 1.939, 1.96, 1.955, 1.909, 0.949, 1.454, 1.958, 1.9489999999999998, 0.45599999999999996, 1.95, 1.4489999999999998, 1.9569999999999999, -0.051000000000000045, 1.923, 0.9670000000000001, 1.454, 1.942, 1.96, 1.949, 1.924, 1.458, 1.459, 0.45100000000000007, 1.9529999999999998, 1.928, 1.9449999999999998, 1.46, 1.953, 1.9500000000000002, 1.952, 0.9359999999999999, 1.931, 1.9489999999999998, 1.4529999999999998, 1.9609999999999999, 1.442, 1.9409999999999998, 1.459], "episode_lengths": [14, 15, 14, 17, 19, 15, 24, 14, 12, 22, 300, 13, 20, 21, 14, 14, 10, 16, 13, 19, 20, 14, 14, 12, 19, 18, 17, 20, 132, 17, 21, 22, 16, 16, 15, 16, 14, 18, 15, 24, 13, 16, 14, 16, 17, 19, 15, 32, 14, 19, 10, 9, 17, 10, 14, 19, 19, 15, 45, 19, 13, 17, 16, 13, 14, 17, 13, 14, 15, 17, 19, 15, 15, 300, 15, 14, 26, 21, 19, 9, 14, 28, 35, 17, 13, 20, 24, 13, 24, 15, 83, 16, 11, 14, 22, 15, 8, 14, 15, 13, 13, 16, 9, 16, 300, 22, 20, 13, 15, 29, 17, 15, 14, 17, 14, 16, 17, 14, 15, 24, 11, 15, 19, 13, 16, 23, 14, 13, 16, 15, 22, 18, 13, 15, 16, 16, 300, 22, 16, 15, 13, 19, 19, 13], "policy_red_0_reward": [1.458, 1.455, 1.4569999999999999, 1.4489999999999998, -0.003, 1.4529999999999998, 1.428, 1.458, -0.5, 1.434, 0.475, 1.4609999999999999, 1.439, 1.4369999999999998, 1.458, 1.458, 0.97, 1.452, 1.4609999999999999, 1.442, 0.5, 1.458, 1.458, 0.964, 1.442, 1.446, 0.499, 1.44, -0.007, 1.4489999999999998, 1.436, 1.4329999999999998, 1.452, 1.452, 1.454, 1.452, 1.458, 1.446, 0.5, 1.427, 1.4609999999999999, 1.452, 1.458, 1.452, 1.4489999999999998, 1.443, 1.455, 1.4020000000000001, 1.4569999999999999, 1.443, 1.47, 0.972, 1.4489999999999998, -0.5, 0.5, 0.499, 1.443, -0.5, 1.361, 1.44, 1.4609999999999999, 1.448, 1.452, 0.5, 0.499, 1.4489999999999998, 1.4609999999999999, 1.458, 1.455, 1.4489999999999998, 1.443, 1.455, 1.455, 0.487, 1.455, 1.4569999999999999, -0.001, 1.436, 1.443, -1.0, 0.499, 1.415, 1.3940000000000001, 0.5, 1.4609999999999999, 0.5, 1.427, 1.4609999999999999, 0.0, 0.5, 1.244, 1.452, 0.967, 1.458, 1.4329999999999998, 1.455, 1.476, 1.458, 1.455, 1.4609999999999999, 1.4609999999999999, 0.5, 0.972, 1.452, 0.46499999999999997, 1.432, 1.44, 1.4609999999999999, 0.5, 1.412, -0.5, 1.455, 1.458, 1.4489999999999998, 1.458, 1.452, 1.4489999999999998, 1.458, -1.003, 0.499, 1.467, 1.454, 0.5, 1.4609999999999999, 1.452, 0.495, 0.0, -0.002, 1.451, 1.455, 1.434, 1.4449999999999998, 1.4609999999999999, 1.455, 1.452, 0.5, 0.469, 1.434, 0.5, 1.454, 1.4609999999999999, 1.443, 1.443, -0.002], "policy_blue_0_reward": [-1.0, 0.497, 0.499, 0.5, 1.442, -0.002, 0.495, -0.002, 0.963, 0.498, 0.472, -0.003, 0.497, 0.497, 0.499, 0.499, -0.502, 0.497, 0.5, 0.498, 1.439, 0.499, 0.499, -0.5, 0.499, -0.002, 1.4489999999999998, -0.501, 1.0939999999999999, 0.499, 0.496, 0.498, 0.0, 0.499, 0.5, 0.0, 0.499, 0.497, 1.454, -0.001, 0.0, 0.498, -0.002, 0.0, -0.002, 0.5, 0.5, 0.494, 0.0, 0.498, -0.5, -0.5, -0.002, 1.4689999999999999, 1.458, 1.4409999999999998, 0.499, 1.454, 0.494, -0.001, 0.498, 0.497, -0.503, 1.4609999999999999, 1.458, 0.497, 0.5, -0.001, 0.5, 0.499, 0.5, -0.001, -0.002, 0.473, -0.001, 0.499, 1.42, 0.494, 0.499, 1.4729999999999999, 1.458, 0.498, 0.494, 1.448, 0.5, 1.438, 0.492, 0.499, 1.428, 1.454, 0.493, 0.5, -1.002, 0.0, 0.495, 0.499, -1.0, 0.498, 0.5, 0.499, 0.5, 1.452, -0.501, 0.5, 0.47, -0.001, 0.499, 0.499, 1.455, 0.497, 1.4489999999999998, -0.001, 0.5, 0.5, -1.002, 0.498, 0.0, 0.499, 0.952, 1.424, -0.5, 0.0, 1.442, 0.499, 0.497, 1.429, 1.458, 1.4609999999999999, -1.0, 0.498, 0.494, 0.5, -0.001, 0.498, 0.498, 1.452, 0.46699999999999997, 0.497, 1.4489999999999998, -0.001, 0.5, -0.001, 0.498, 1.4609999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4247566962600995, "mean_inference_ms": 7.4723166369115965, "mean_action_processing_ms": 0.3920423708128926, "mean_env_wait_ms": 0.5221252274657802, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1524047719107734, "StateBufferConnector_ms": 0.009885016414854262, "ViewRequirementAgentConnector_ms": 0.19465933243433634}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.39054540431053, "num_env_steps_trained_throughput_per_sec": 128.39054540431053, "timesteps_total": 488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 31518.782, "sample_time_ms": 4091.675, "learn_time_ms": 27397.057, "learn_throughput": 146.001, "synch_weights_time_ms": 28.539}, "counters": {"num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "episodes_total": 9848, "training_iteration": 122, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-02-09", "timestamp": 1694840529, "time_this_iter_s": 31.174296855926514, "time_total_s": 3816.6767342090607, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a2ea290>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3816.6767342090607, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 21.930434782608693, "ram_util_percent": 57.23913043478259}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6666666666666666, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.08148148148148149, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.05185185185185185, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.08148148148148149, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14074074074074075, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.05185185185185185, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.08148148148148149, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.05185185185185185, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.41447807469715675, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03784421470093851, "policy_loss": -0.06668926610727795, "vf_loss": 0.023275582592759747, "vf_explained_var": 0.8010559435312946, "kl": 0.007988607711176317, "entropy": 0.9917874631161491, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 117600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4785914399195462, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04630337913501232, "policy_loss": -0.07752886149731543, "vf_loss": 0.023853050069495414, "vf_explained_var": 0.6366694239278634, "kl": 0.009091867873110216, "entropy": 1.4134552932033937, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 117600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 984000, "num_agent_steps_trained": 984000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.03700000000000003, "episode_reward_mean": 1.5939703703703703, "episode_len_mean": 34.17777777777778, "episode_media": {}, "episodes_this_iter": 135, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 1.0954666666666666, "blue_0": 0.4985037037037037}, "custom_metrics": {"red_0/door_open_done_mean": 0.6666666666666666, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.08148148148148149, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.05185185185185185, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.08148148148148149, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.14074074074074075, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.05185185185185185, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.08148148148148149, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.05185185185185185, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.968, 1.939, 0.962, 1.943, 1.94, 1.952, 1.9609999999999999, 0.9470000000000001, 1.958, 0.953, 1.96, 1.96, 1.458, 1.928, 1.408, 1.934, 1.9449999999999998, 1.9180000000000001, 0.44599999999999995, 0.954, 1.404, 1.94, 1.952, 0.47, 1.9569999999999999, 1.951, 1.9449999999999998, 1.96, 1.45, 1.452, 1.95, 1.944, 0.46099999999999997, 1.951, 1.916, 0.9359999999999999, 1.9569999999999999, 1.9609999999999999, 1.9409999999999998, 1.9449999999999998, 1.948, 1.438, 1.4609999999999999, 1.9609999999999999, 1.946, 1.936, 1.952, 0.47, 1.448, 1.954, 0.9269999999999999, 1.907, 1.456, 1.4609999999999999, 0.45999999999999996, 1.4609999999999999, 1.9369999999999998, 1.932, 1.956, 1.96, 1.9449999999999998, 1.4569999999999999, 1.954, 0.9339999999999999, 1.958, -0.02199999999999991, 1.936, 1.4489999999999998, 1.4529999999999998, 0.954, 1.854, 1.958, 1.454, 1.9329999999999998, 1.9449999999999998, 1.9529999999999998, 1.4529999999999998, 1.95, 1.948, 1.947, 0.43799999999999994, 1.45, 0.9670000000000001, 1.459, 1.955, 1.958, 0.45199999999999996, 1.4529999999999998, 1.943, 1.9300000000000002, 0.44399999999999995, 1.947, 1.954, 1.93, 1.934, -0.031000000000000028, 1.905, 0.44999999999999996, 1.93, 1.9329999999999998, 1.96, 1.455, 1.455, 1.454, 1.945, 0.938, 1.939, 1.4140000000000001, 1.8980000000000001, 1.935, 1.916, 1.448, 1.9529999999999998, 0.962, 0.9550000000000001, 1.932, 1.944, -0.03700000000000003, 1.955, 1.9489999999999998, 1.944, 1.924, 1.96, 1.4100000000000001, 1.951, 1.93, 1.9500000000000002, 1.447, 1.952, 1.9609999999999999, 1.9529999999999998, 0.9359999999999999, 1.446, 1.4409999999999998, 1.9489999999999998], "episode_lengths": [300, 20, 300, 18, 19, 15, 13, 16, 14, 300, 13, 13, 14, 23, 29, 20, 18, 26, 16, 15, 31, 19, 16, 10, 14, 16, 18, 13, 16, 16, 16, 18, 12, 16, 27, 21, 14, 13, 19, 18, 17, 19, 13, 13, 18, 20, 15, 10, 16, 15, 300, 29, 14, 13, 13, 13, 20, 21, 14, 13, 18, 14, 15, 300, 14, 7, 21, 16, 15, 15, 46, 14, 15, 22, 17, 15, 15, 16, 17, 17, 19, 16, 11, 13, 15, 14, 16, 15, 18, 23, 300, 17, 15, 22, 21, 10, 29, 16, 22, 21, 13, 15, 14, 15, 17, 300, 20, 27, 31, 21, 26, 17, 15, 300, 15, 22, 18, 11, 15, 16, 18, 24, 13, 29, 16, 22, 16, 17, 16, 13, 15, 20, 18, 19, 17], "policy_red_0_reward": [0.487, 1.44, 0.491, 1.444, 1.442, 1.454, 0.5, 1.451, 0.5, 0.491, 1.4609999999999999, 1.4609999999999999, 0.0, 1.431, 0.0, 1.438, 1.446, 1.421, 1.448, 1.454, 0.0, 1.443, 1.452, 1.47, 1.458, 1.452, 1.446, 1.4609999999999999, 1.452, 1.452, 0.5, 1.446, -0.501, 1.452, 1.4180000000000001, -0.5, 1.458, 1.4609999999999999, 1.443, 1.446, 1.4489999999999998, 1.442, 0.0, 1.4609999999999999, 1.446, 1.44, 1.455, 0.97, 1.452, 1.455, 0.45799999999999996, 1.411, 1.458, 1.4609999999999999, -1.001, 1.4609999999999999, 1.439, 1.435, 1.4569999999999999, 0.499, 0.5, 0.0, 1.455, 0.46299999999999997, 0.5, -1.001, 1.436, -0.002, -0.001, -0.5, 1.359, 0.5, 1.455, 1.4329999999999998, 1.448, 1.455, 1.455, 1.452, 1.4489999999999998, 1.448, 1.443, 1.452, 1.467, -0.002, 1.455, 0.5, 1.452, 1.455, 1.4449999999999998, 1.431, -0.024000000000000014, 1.448, 1.455, 1.434, 0.5, 0.969, 1.409, 1.451, 1.4329999999999998, 1.435, 1.4609999999999999, 1.455, 1.458, 1.455, 1.4489999999999998, 0.46599999999999997, 1.44, 1.4180000000000001, 1.403, 1.4369999999999998, 1.419, 1.4489999999999998, 1.455, 0.484, 1.455, 1.434, 1.4449999999999998, -1.001, 1.455, 1.451, 1.446, 1.427, 1.4609999999999999, -0.001, 1.451, 1.4329999999999998, 1.452, -0.001, 1.452, 1.4609999999999999, 1.454, -0.502, 1.446, 1.443, 1.4489999999999998], "policy_blue_0_reward": [0.481, 0.499, 0.471, 0.499, 0.498, 0.498, 1.4609999999999999, -0.5039999999999999, 1.458, 0.46199999999999997, 0.499, 0.499, 1.458, 0.497, 1.408, 0.496, 0.499, 0.497, -1.002, -0.5, 1.404, 0.497, 0.5, -1.0, 0.499, 0.499, 0.499, 0.499, -0.002, 0.0, 1.45, 0.498, 0.962, 0.499, 0.498, 1.436, 0.499, 0.5, 0.498, 0.499, 0.499, -0.004, 1.4609999999999999, 0.5, 0.5, 0.496, 0.497, -0.5, -0.004, 0.499, 0.469, 0.496, -0.002, 0.0, 1.4609999999999999, 0.0, 0.498, 0.497, 0.499, 1.4609999999999999, 1.4449999999999998, 1.4569999999999999, 0.499, 0.471, 1.458, 0.979, 0.5, 1.451, 1.454, 1.454, 0.495, 1.458, -0.001, 0.5, 0.497, 0.498, -0.002, 0.498, 0.499, 0.499, -1.005, -0.002, -0.5, 1.4609999999999999, 0.5, 1.458, -1.0, -0.002, 0.498, 0.499, 0.46799999999999997, 0.499, 0.499, 0.496, 1.434, -1.0, 0.496, -1.001, 0.497, 0.498, 0.499, 0.0, -0.003, -0.001, 0.496, 0.472, 0.499, -0.004, 0.495, 0.498, 0.497, -0.001, 0.498, 0.478, -0.5, 0.498, 0.499, 0.964, 0.5, 0.498, 0.498, 0.497, 0.499, 1.411, 0.5, 0.497, 0.498, 1.448, 0.5, 0.5, 0.499, 1.438, 0.0, -0.002, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4261379663148128, "mean_inference_ms": 7.472953085725704, "mean_action_processing_ms": 0.3899429579304267, "mean_env_wait_ms": 0.522159453477518, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13936457810578523, "StateBufferConnector_ms": 0.008932131308096426, "ViewRequirementAgentConnector_ms": 0.17617269798561377}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.03700000000000003, "episode_reward_mean": 1.5939703703703703, "episode_len_mean": 34.17777777777778, "episodes_this_iter": 135, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 1.0954666666666666, "blue_0": 0.4985037037037037}, "hist_stats": {"episode_reward": [0.968, 1.939, 0.962, 1.943, 1.94, 1.952, 1.9609999999999999, 0.9470000000000001, 1.958, 0.953, 1.96, 1.96, 1.458, 1.928, 1.408, 1.934, 1.9449999999999998, 1.9180000000000001, 0.44599999999999995, 0.954, 1.404, 1.94, 1.952, 0.47, 1.9569999999999999, 1.951, 1.9449999999999998, 1.96, 1.45, 1.452, 1.95, 1.944, 0.46099999999999997, 1.951, 1.916, 0.9359999999999999, 1.9569999999999999, 1.9609999999999999, 1.9409999999999998, 1.9449999999999998, 1.948, 1.438, 1.4609999999999999, 1.9609999999999999, 1.946, 1.936, 1.952, 0.47, 1.448, 1.954, 0.9269999999999999, 1.907, 1.456, 1.4609999999999999, 0.45999999999999996, 1.4609999999999999, 1.9369999999999998, 1.932, 1.956, 1.96, 1.9449999999999998, 1.4569999999999999, 1.954, 0.9339999999999999, 1.958, -0.02199999999999991, 1.936, 1.4489999999999998, 1.4529999999999998, 0.954, 1.854, 1.958, 1.454, 1.9329999999999998, 1.9449999999999998, 1.9529999999999998, 1.4529999999999998, 1.95, 1.948, 1.947, 0.43799999999999994, 1.45, 0.9670000000000001, 1.459, 1.955, 1.958, 0.45199999999999996, 1.4529999999999998, 1.943, 1.9300000000000002, 0.44399999999999995, 1.947, 1.954, 1.93, 1.934, -0.031000000000000028, 1.905, 0.44999999999999996, 1.93, 1.9329999999999998, 1.96, 1.455, 1.455, 1.454, 1.945, 0.938, 1.939, 1.4140000000000001, 1.8980000000000001, 1.935, 1.916, 1.448, 1.9529999999999998, 0.962, 0.9550000000000001, 1.932, 1.944, -0.03700000000000003, 1.955, 1.9489999999999998, 1.944, 1.924, 1.96, 1.4100000000000001, 1.951, 1.93, 1.9500000000000002, 1.447, 1.952, 1.9609999999999999, 1.9529999999999998, 0.9359999999999999, 1.446, 1.4409999999999998, 1.9489999999999998], "episode_lengths": [300, 20, 300, 18, 19, 15, 13, 16, 14, 300, 13, 13, 14, 23, 29, 20, 18, 26, 16, 15, 31, 19, 16, 10, 14, 16, 18, 13, 16, 16, 16, 18, 12, 16, 27, 21, 14, 13, 19, 18, 17, 19, 13, 13, 18, 20, 15, 10, 16, 15, 300, 29, 14, 13, 13, 13, 20, 21, 14, 13, 18, 14, 15, 300, 14, 7, 21, 16, 15, 15, 46, 14, 15, 22, 17, 15, 15, 16, 17, 17, 19, 16, 11, 13, 15, 14, 16, 15, 18, 23, 300, 17, 15, 22, 21, 10, 29, 16, 22, 21, 13, 15, 14, 15, 17, 300, 20, 27, 31, 21, 26, 17, 15, 300, 15, 22, 18, 11, 15, 16, 18, 24, 13, 29, 16, 22, 16, 17, 16, 13, 15, 20, 18, 19, 17], "policy_red_0_reward": [0.487, 1.44, 0.491, 1.444, 1.442, 1.454, 0.5, 1.451, 0.5, 0.491, 1.4609999999999999, 1.4609999999999999, 0.0, 1.431, 0.0, 1.438, 1.446, 1.421, 1.448, 1.454, 0.0, 1.443, 1.452, 1.47, 1.458, 1.452, 1.446, 1.4609999999999999, 1.452, 1.452, 0.5, 1.446, -0.501, 1.452, 1.4180000000000001, -0.5, 1.458, 1.4609999999999999, 1.443, 1.446, 1.4489999999999998, 1.442, 0.0, 1.4609999999999999, 1.446, 1.44, 1.455, 0.97, 1.452, 1.455, 0.45799999999999996, 1.411, 1.458, 1.4609999999999999, -1.001, 1.4609999999999999, 1.439, 1.435, 1.4569999999999999, 0.499, 0.5, 0.0, 1.455, 0.46299999999999997, 0.5, -1.001, 1.436, -0.002, -0.001, -0.5, 1.359, 0.5, 1.455, 1.4329999999999998, 1.448, 1.455, 1.455, 1.452, 1.4489999999999998, 1.448, 1.443, 1.452, 1.467, -0.002, 1.455, 0.5, 1.452, 1.455, 1.4449999999999998, 1.431, -0.024000000000000014, 1.448, 1.455, 1.434, 0.5, 0.969, 1.409, 1.451, 1.4329999999999998, 1.435, 1.4609999999999999, 1.455, 1.458, 1.455, 1.4489999999999998, 0.46599999999999997, 1.44, 1.4180000000000001, 1.403, 1.4369999999999998, 1.419, 1.4489999999999998, 1.455, 0.484, 1.455, 1.434, 1.4449999999999998, -1.001, 1.455, 1.451, 1.446, 1.427, 1.4609999999999999, -0.001, 1.451, 1.4329999999999998, 1.452, -0.001, 1.452, 1.4609999999999999, 1.454, -0.502, 1.446, 1.443, 1.4489999999999998], "policy_blue_0_reward": [0.481, 0.499, 0.471, 0.499, 0.498, 0.498, 1.4609999999999999, -0.5039999999999999, 1.458, 0.46199999999999997, 0.499, 0.499, 1.458, 0.497, 1.408, 0.496, 0.499, 0.497, -1.002, -0.5, 1.404, 0.497, 0.5, -1.0, 0.499, 0.499, 0.499, 0.499, -0.002, 0.0, 1.45, 0.498, 0.962, 0.499, 0.498, 1.436, 0.499, 0.5, 0.498, 0.499, 0.499, -0.004, 1.4609999999999999, 0.5, 0.5, 0.496, 0.497, -0.5, -0.004, 0.499, 0.469, 0.496, -0.002, 0.0, 1.4609999999999999, 0.0, 0.498, 0.497, 0.499, 1.4609999999999999, 1.4449999999999998, 1.4569999999999999, 0.499, 0.471, 1.458, 0.979, 0.5, 1.451, 1.454, 1.454, 0.495, 1.458, -0.001, 0.5, 0.497, 0.498, -0.002, 0.498, 0.499, 0.499, -1.005, -0.002, -0.5, 1.4609999999999999, 0.5, 1.458, -1.0, -0.002, 0.498, 0.499, 0.46799999999999997, 0.499, 0.499, 0.496, 1.434, -1.0, 0.496, -1.001, 0.497, 0.498, 0.499, 0.0, -0.003, -0.001, 0.496, 0.472, 0.499, -0.004, 0.495, 0.498, 0.497, -0.001, 0.498, 0.478, -0.5, 0.498, 0.499, 0.964, 0.5, 0.498, 0.498, 0.497, 0.499, 1.411, 0.5, 0.497, 0.498, 1.448, 0.5, 0.5, 0.499, 1.438, 0.0, -0.002, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4261379663148128, "mean_inference_ms": 7.472953085725704, "mean_action_processing_ms": 0.3899429579304267, "mean_env_wait_ms": 0.522159453477518, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13936457810578523, "StateBufferConnector_ms": 0.008932131308096426, "ViewRequirementAgentConnector_ms": 0.17617269798561377}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 984000, "num_agent_steps_trained": 984000, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.5642406867161, "num_env_steps_trained_throughput_per_sec": 129.5642406867161, "timesteps_total": 492000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 984000, "timers": {"training_iteration_time_ms": 31471.406, "sample_time_ms": 4051.791, "learn_time_ms": 27389.506, "learn_throughput": 146.041, "synch_weights_time_ms": 28.559}, "counters": {"num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 984000, "num_agent_steps_trained": 984000}, "done": false, "episodes_total": 9983, "training_iteration": 123, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-02-41", "timestamp": 1694840561, "time_this_iter_s": 30.89203405380249, "time_total_s": 3847.568768262863, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21981480>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3847.568768262863, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 25.217777777777776, "ram_util_percent": 57.21333333333336}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6530612244897959, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.08843537414965986, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10884353741496598, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.08843537414965986, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11564625850340136, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10884353741496598, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.08843537414965986, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10884353741496598, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4011010341501484, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.026124205809416403, "policy_loss": -0.05932415620530567, "vf_loss": 0.03412937529792544, "vf_explained_var": 0.7589296892285347, "kl": 0.0075011068815949026, "entropy": 0.9531966390709082, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 118560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.46484877038747074, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04939933628823686, "policy_loss": -0.08262187151412945, "vf_loss": 0.02837689793717194, "vf_explained_var": 0.6006046302616597, "kl": 0.008964958826454822, "entropy": 1.389211198190848, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 118560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.07299999999999995, "episode_reward_mean": 1.5213197278911565, "episode_len_mean": 26.755102040816325, "episode_media": {}, "episodes_this_iter": 147, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.004}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 1.027272108843537, "blue_0": 0.49404761904761907}, "custom_metrics": {"red_0/door_open_done_mean": 0.6530612244897959, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.08843537414965986, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.10884353741496598, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.08843537414965986, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.11564625850340136, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.10884353741496598, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.08843537414965986, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.10884353741496598, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.955, 1.899, 0.46799999999999997, 1.458, 1.947, -0.03399999999999992, 0.45299999999999985, 1.954, -0.07299999999999995, 1.9609999999999999, 1.95, 1.954, 1.954, 1.9609999999999999, 1.913, 1.951, 1.9609999999999999, 1.948, 1.9300000000000002, 1.943, 1.958, 1.954, 1.9609999999999999, 1.455, 1.46, 1.9529999999999998, 1.936, 1.438, 1.947, 1.439, 1.935, 1.4569999999999999, 0.3640000000000001, 1.956, 0.964, 0.961, 1.951, 0.9790000000000001, 1.938, 0.4630000000000001, 0.967, 0.469, 1.454, 1.955, 1.429, 1.951, 1.4529999999999998, 1.951, 1.947, 1.9609999999999999, 1.95, 1.959, 1.9329999999999998, 0.953, 1.948, 0.9660000000000002, -0.03300000000000003, 1.451, 1.907, 1.951, 1.9540000000000002, 1.9609999999999999, 0.46399999999999997, 1.9609999999999999, 1.959, 0.46199999999999997, 1.942, 1.954, 0.45899999999999996, 1.905, 1.951, 0.943, 1.448, -0.039999999999999925, 1.952, 1.96, 0.47, 1.951, 1.9609999999999999, 0.46499999999999997, 1.4609999999999999, 1.9580000000000002, 1.438, 0.45299999999999996, 1.9569999999999999, 1.951, 1.9569999999999999, 1.947, -0.04600000000000004, -0.027999999999999914, 0.44799999999999995, 1.463, 0.96, 1.95, 1.454, 1.899, -0.05499999999999994, 1.9609999999999999, 1.935, 1.423, 1.456, 1.9609999999999999, 1.956, 1.958, 1.943, 1.958, 0.41999999999999993, 1.448, 1.9609999999999999, 1.853, 1.458, 1.958, 1.9409999999999998, 1.942, 1.948, 0.43599999999999994, 0.9530000000000001, 1.952, 1.4609999999999999, 1.454, 1.958, 1.9449999999999998, 1.958, 1.96, 1.447, 1.46, 1.956, 0.45999999999999996, 1.458, 1.94, 1.932, 1.95, 1.9489999999999998, 1.955, 1.947, 0.97, 1.9569999999999999, 1.944, 1.9489999999999998, 1.9529999999999998, -0.051000000000000045, 1.943, 1.452, 1.454, 0.9790000000000001, 1.4529999999999998, 1.927], "episode_lengths": [15, 32, 10, 14, 17, 11, 15, 15, 23, 13, 16, 14, 15, 13, 28, 16, 13, 17, 23, 18, 14, 15, 13, 15, 13, 15, 20, 19, 17, 19, 20, 14, 43, 14, 12, 300, 16, 7, 20, 11, 11, 10, 15, 15, 23, 16, 15, 15, 17, 13, 16, 13, 21, 300, 17, 11, 11, 16, 29, 16, 15, 13, 12, 13, 13, 11, 19, 15, 13, 30, 16, 300, 17, 13, 15, 13, 10, 16, 13, 11, 13, 13, 19, 14, 14, 16, 13, 17, 14, 9, 17, 166, 13, 16, 15, 33, 18, 13, 21, 24, 14, 13, 14, 14, 18, 14, 300, 17, 13, 45, 14, 14, 19, 19, 17, 300, 15, 16, 13, 15, 14, 18, 14, 13, 17, 13, 14, 13, 13, 19, 22, 16, 16, 15, 16, 10, 14, 18, 17, 15, 16, 18, 16, 15, 7, 15, 24], "policy_red_0_reward": [0.5, 1.401, -0.5, 1.458, 1.448, -1.0, 1.455, 1.455, -1.002, 1.4609999999999999, 1.451, 1.458, 1.455, 1.4609999999999999, 1.415, 1.452, 1.4609999999999999, 1.4489999999999998, 1.431, 1.4449999999999998, 0.5, 1.455, 1.4609999999999999, 1.455, 1.4609999999999999, 1.455, 1.439, 1.443, 1.4489999999999998, 1.443, 1.44, -0.001, -1.001, 1.4569999999999999, 1.464, 0.489, 1.452, 1.479, 1.44, 1.467, -0.5, -1.0, 1.454, 1.455, -0.001, 0.5, 1.454, 1.454, 1.4489999999999998, 1.4609999999999999, 1.451, 1.4609999999999999, 1.436, 0.484, 1.4489999999999998, 1.467, -1.0, 1.452, 1.411, 1.452, 1.455, 1.4609999999999999, 1.464, 1.4609999999999999, 1.4609999999999999, -0.501, 1.443, 1.455, -0.5, 1.409, 1.452, 0.471, 1.4489999999999998, -1.0, 1.455, 1.4609999999999999, 0.97, 1.451, 0.5, -1.0, 1.4609999999999999, 1.4609999999999999, 1.4409999999999998, -0.502, 1.458, 1.452, 1.4609999999999999, 1.4489999999999998, -1.0, -1.001, 1.4489999999999998, 0.985, 1.46, 0.499, 1.454, 1.399, -1.001, 0.5, 0.499, 1.428, 1.4569999999999999, 1.4609999999999999, 1.4569999999999999, 0.5, 1.4449999999999998, 0.5, 0.45199999999999996, 1.4489999999999998, 1.4609999999999999, 1.358, 0.0, 1.458, 1.443, 0.5, 1.4489999999999998, -0.024000000000000014, 1.454, 1.452, 1.4609999999999999, 1.455, 1.458, 1.446, 1.458, 1.4609999999999999, -0.001, -0.001, 1.458, -1.001, 1.4609999999999999, 1.442, 1.4329999999999998, 1.451, 1.452, 1.455, 1.452, 1.47, 0.5, 0.499, 1.4489999999999998, 1.455, 0.95, 1.446, 1.452, 1.455, 1.479, 1.455, 1.428], "policy_blue_0_reward": [1.455, 0.498, 0.968, 0.0, 0.499, 0.966, -1.002, 0.499, 0.929, 0.5, 0.499, 0.496, 0.499, 0.5, 0.498, 0.499, 0.5, 0.499, 0.499, 0.498, 1.458, 0.499, 0.5, 0.0, -0.001, 0.498, 0.497, -0.005, 0.498, -0.004, 0.495, 1.458, 1.365, 0.499, -0.5, 0.472, 0.499, -0.5, 0.498, -1.004, 1.467, 1.4689999999999999, 0.0, 0.5, 1.4300000000000002, 1.451, -0.001, 0.497, 0.498, 0.5, 0.499, 0.498, 0.497, 0.469, 0.499, -0.5009999999999999, 0.967, -0.001, 0.496, 0.499, 0.499, 0.5, -1.0, 0.5, 0.498, 0.963, 0.499, 0.499, 0.959, 0.496, 0.499, 0.472, -0.001, 0.96, 0.497, 0.499, -0.5, 0.5, 1.4609999999999999, 1.4649999999999999, 0.0, 0.497, -0.003, 0.955, 0.499, 0.499, 0.496, 0.498, 0.954, 0.973, -1.001, 0.478, -0.5, 1.451, 0.0, 0.5, 0.946, 1.4609999999999999, 1.436, -0.005, -0.001, 0.5, 0.499, 1.458, 0.498, 1.458, -0.03200000000000002, -0.001, 0.5, 0.495, 1.458, 0.5, 0.498, 1.442, 0.499, 0.45999999999999996, -0.5009999999999999, 0.5, 0.0, -0.001, 0.5, 0.499, 0.5, 0.499, 1.448, 1.4609999999999999, 0.498, 1.4609999999999999, -0.003, 0.498, 0.499, 0.499, 0.497, 0.5, 0.495, -0.5, 1.4569999999999999, 1.4449999999999998, 0.5, 0.498, -1.001, 0.497, 0.0, -0.001, -0.5, -0.002, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4272221182915674, "mean_inference_ms": 7.4741801815849875, "mean_action_processing_ms": 0.3917171619812462, "mean_env_wait_ms": 0.5232225190252899, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.146890740816285, "StateBufferConnector_ms": 0.009712556592461204, "ViewRequirementAgentConnector_ms": 0.196248738944125}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.07299999999999995, "episode_reward_mean": 1.5213197278911565, "episode_len_mean": 26.755102040816325, "episodes_this_iter": 147, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.004}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 1.027272108843537, "blue_0": 0.49404761904761907}, "hist_stats": {"episode_reward": [1.955, 1.899, 0.46799999999999997, 1.458, 1.947, -0.03399999999999992, 0.45299999999999985, 1.954, -0.07299999999999995, 1.9609999999999999, 1.95, 1.954, 1.954, 1.9609999999999999, 1.913, 1.951, 1.9609999999999999, 1.948, 1.9300000000000002, 1.943, 1.958, 1.954, 1.9609999999999999, 1.455, 1.46, 1.9529999999999998, 1.936, 1.438, 1.947, 1.439, 1.935, 1.4569999999999999, 0.3640000000000001, 1.956, 0.964, 0.961, 1.951, 0.9790000000000001, 1.938, 0.4630000000000001, 0.967, 0.469, 1.454, 1.955, 1.429, 1.951, 1.4529999999999998, 1.951, 1.947, 1.9609999999999999, 1.95, 1.959, 1.9329999999999998, 0.953, 1.948, 0.9660000000000002, -0.03300000000000003, 1.451, 1.907, 1.951, 1.9540000000000002, 1.9609999999999999, 0.46399999999999997, 1.9609999999999999, 1.959, 0.46199999999999997, 1.942, 1.954, 0.45899999999999996, 1.905, 1.951, 0.943, 1.448, -0.039999999999999925, 1.952, 1.96, 0.47, 1.951, 1.9609999999999999, 0.46499999999999997, 1.4609999999999999, 1.9580000000000002, 1.438, 0.45299999999999996, 1.9569999999999999, 1.951, 1.9569999999999999, 1.947, -0.04600000000000004, -0.027999999999999914, 0.44799999999999995, 1.463, 0.96, 1.95, 1.454, 1.899, -0.05499999999999994, 1.9609999999999999, 1.935, 1.423, 1.456, 1.9609999999999999, 1.956, 1.958, 1.943, 1.958, 0.41999999999999993, 1.448, 1.9609999999999999, 1.853, 1.458, 1.958, 1.9409999999999998, 1.942, 1.948, 0.43599999999999994, 0.9530000000000001, 1.952, 1.4609999999999999, 1.454, 1.958, 1.9449999999999998, 1.958, 1.96, 1.447, 1.46, 1.956, 0.45999999999999996, 1.458, 1.94, 1.932, 1.95, 1.9489999999999998, 1.955, 1.947, 0.97, 1.9569999999999999, 1.944, 1.9489999999999998, 1.9529999999999998, -0.051000000000000045, 1.943, 1.452, 1.454, 0.9790000000000001, 1.4529999999999998, 1.927], "episode_lengths": [15, 32, 10, 14, 17, 11, 15, 15, 23, 13, 16, 14, 15, 13, 28, 16, 13, 17, 23, 18, 14, 15, 13, 15, 13, 15, 20, 19, 17, 19, 20, 14, 43, 14, 12, 300, 16, 7, 20, 11, 11, 10, 15, 15, 23, 16, 15, 15, 17, 13, 16, 13, 21, 300, 17, 11, 11, 16, 29, 16, 15, 13, 12, 13, 13, 11, 19, 15, 13, 30, 16, 300, 17, 13, 15, 13, 10, 16, 13, 11, 13, 13, 19, 14, 14, 16, 13, 17, 14, 9, 17, 166, 13, 16, 15, 33, 18, 13, 21, 24, 14, 13, 14, 14, 18, 14, 300, 17, 13, 45, 14, 14, 19, 19, 17, 300, 15, 16, 13, 15, 14, 18, 14, 13, 17, 13, 14, 13, 13, 19, 22, 16, 16, 15, 16, 10, 14, 18, 17, 15, 16, 18, 16, 15, 7, 15, 24], "policy_red_0_reward": [0.5, 1.401, -0.5, 1.458, 1.448, -1.0, 1.455, 1.455, -1.002, 1.4609999999999999, 1.451, 1.458, 1.455, 1.4609999999999999, 1.415, 1.452, 1.4609999999999999, 1.4489999999999998, 1.431, 1.4449999999999998, 0.5, 1.455, 1.4609999999999999, 1.455, 1.4609999999999999, 1.455, 1.439, 1.443, 1.4489999999999998, 1.443, 1.44, -0.001, -1.001, 1.4569999999999999, 1.464, 0.489, 1.452, 1.479, 1.44, 1.467, -0.5, -1.0, 1.454, 1.455, -0.001, 0.5, 1.454, 1.454, 1.4489999999999998, 1.4609999999999999, 1.451, 1.4609999999999999, 1.436, 0.484, 1.4489999999999998, 1.467, -1.0, 1.452, 1.411, 1.452, 1.455, 1.4609999999999999, 1.464, 1.4609999999999999, 1.4609999999999999, -0.501, 1.443, 1.455, -0.5, 1.409, 1.452, 0.471, 1.4489999999999998, -1.0, 1.455, 1.4609999999999999, 0.97, 1.451, 0.5, -1.0, 1.4609999999999999, 1.4609999999999999, 1.4409999999999998, -0.502, 1.458, 1.452, 1.4609999999999999, 1.4489999999999998, -1.0, -1.001, 1.4489999999999998, 0.985, 1.46, 0.499, 1.454, 1.399, -1.001, 0.5, 0.499, 1.428, 1.4569999999999999, 1.4609999999999999, 1.4569999999999999, 0.5, 1.4449999999999998, 0.5, 0.45199999999999996, 1.4489999999999998, 1.4609999999999999, 1.358, 0.0, 1.458, 1.443, 0.5, 1.4489999999999998, -0.024000000000000014, 1.454, 1.452, 1.4609999999999999, 1.455, 1.458, 1.446, 1.458, 1.4609999999999999, -0.001, -0.001, 1.458, -1.001, 1.4609999999999999, 1.442, 1.4329999999999998, 1.451, 1.452, 1.455, 1.452, 1.47, 0.5, 0.499, 1.4489999999999998, 1.455, 0.95, 1.446, 1.452, 1.455, 1.479, 1.455, 1.428], "policy_blue_0_reward": [1.455, 0.498, 0.968, 0.0, 0.499, 0.966, -1.002, 0.499, 0.929, 0.5, 0.499, 0.496, 0.499, 0.5, 0.498, 0.499, 0.5, 0.499, 0.499, 0.498, 1.458, 0.499, 0.5, 0.0, -0.001, 0.498, 0.497, -0.005, 0.498, -0.004, 0.495, 1.458, 1.365, 0.499, -0.5, 0.472, 0.499, -0.5, 0.498, -1.004, 1.467, 1.4689999999999999, 0.0, 0.5, 1.4300000000000002, 1.451, -0.001, 0.497, 0.498, 0.5, 0.499, 0.498, 0.497, 0.469, 0.499, -0.5009999999999999, 0.967, -0.001, 0.496, 0.499, 0.499, 0.5, -1.0, 0.5, 0.498, 0.963, 0.499, 0.499, 0.959, 0.496, 0.499, 0.472, -0.001, 0.96, 0.497, 0.499, -0.5, 0.5, 1.4609999999999999, 1.4649999999999999, 0.0, 0.497, -0.003, 0.955, 0.499, 0.499, 0.496, 0.498, 0.954, 0.973, -1.001, 0.478, -0.5, 1.451, 0.0, 0.5, 0.946, 1.4609999999999999, 1.436, -0.005, -0.001, 0.5, 0.499, 1.458, 0.498, 1.458, -0.03200000000000002, -0.001, 0.5, 0.495, 1.458, 0.5, 0.498, 1.442, 0.499, 0.45999999999999996, -0.5009999999999999, 0.5, 0.0, -0.001, 0.5, 0.499, 0.5, 0.499, 1.448, 1.4609999999999999, 0.498, 1.4609999999999999, -0.003, 0.498, 0.499, 0.499, 0.497, 0.5, 0.495, -0.5, 1.4569999999999999, 1.4449999999999998, 0.5, 0.498, -1.001, 0.497, 0.0, -0.001, -0.5, -0.002, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4272221182915674, "mean_inference_ms": 7.4741801815849875, "mean_action_processing_ms": 0.3917171619812462, "mean_env_wait_ms": 0.5232225190252899, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.146890740816285, "StateBufferConnector_ms": 0.009712556592461204, "ViewRequirementAgentConnector_ms": 0.196248738944125}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.70337624492754, "num_env_steps_trained_throughput_per_sec": 128.70337624492754, "timesteps_total": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 31329.145, "sample_time_ms": 4068.529, "learn_time_ms": 27230.634, "learn_throughput": 146.893, "synch_weights_time_ms": 28.42}, "counters": {"num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "episodes_total": 10130, "training_iteration": 124, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-03-13", "timestamp": 1694840593, "time_this_iter_s": 31.099355220794678, "time_total_s": 3878.668123483658, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a2eba30>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3878.668123483658, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 25.65111111111111, "ram_util_percent": 57.18666666666666}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6211180124223602, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.11180124223602485, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07453416149068323, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.11180124223602485, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.17391304347826086, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.07453416149068323, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.11180124223602485, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07453416149068323, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4646506367406497, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.02968321539325795, "policy_loss": -0.06611964439750105, "vf_loss": 0.03535588294131837, "vf_explained_var": 0.7285576793675621, "kl": 0.00865063672278006, "entropy": 0.9487452790761988, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 119520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4912932960471759, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.039888266297445324, "policy_loss": -0.08072415123848865, "vf_loss": 0.03613374406607666, "vf_explained_var": 0.5886093095565835, "kl": 0.010561257804566064, "entropy": 1.290853003785014, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 119520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 1000000, "num_agent_steps_trained": 1000000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.039000000000000035, "episode_reward_mean": 1.598378881987578, "episode_len_mean": 23.627329192546583, "episode_media": {}, "episodes_this_iter": 161, "policy_reward_min": {"red_0": -1.006, "blue_0": -1.004}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.052142857142857, "blue_0": 0.5462360248447206}, "custom_metrics": {"red_0/door_open_done_mean": 0.6211180124223602, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.11180124223602485, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07453416149068323, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.11180124223602485, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.17391304347826086, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.07453416149068323, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.11180124223602485, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07453416149068323, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.949, 1.9489999999999998, 0.97, 1.892, 1.42, 1.837, 1.94, 1.956, 1.9609999999999999, 1.94, 0.47, 1.95, 1.9609999999999999, 0.479, 1.955, 1.9609999999999999, 1.946, 0.45999999999999996, 0.46799999999999997, 1.952, -0.03199999999999992, 1.95, 1.935, 1.9609999999999999, 0.97, 1.955, 1.929, 0.43399999999999994, 1.9409999999999998, 1.96, 1.9609999999999999, 1.952, 1.9609999999999999, 1.9449999999999998, 1.95, 1.954, 1.9180000000000001, 1.44, 1.9369999999999998, 0.46499999999999986, -0.03300000000000003, 1.9609999999999999, 1.94, 1.446, 1.96, 0.479, 1.9329999999999998, 0.47, 1.94, 1.939, 1.9529999999999998, 1.96, 1.955, 1.954, 1.16, -0.039000000000000035, 1.907, 0.956, 1.951, 1.958, 1.951, 1.9489999999999998, 1.9529999999999998, 1.9489999999999998, 1.951, 1.958, 1.9409999999999998, 1.954, 1.947, 0.2650000000000001, 1.948, 0.97, 1.9569999999999999, 1.935, 1.95, 1.948, 1.942, 1.9449999999999998, 1.9609999999999999, 1.951, 1.96, 1.946, 1.451, -0.030000000000000027, 1.942, 0.939, 0.45299999999999996, 0.46499999999999986, 0.476, 1.9409999999999998, 1.959, 1.8050000000000002, 1.45, 0.956, 1.9260000000000002, 1.952, 1.951, 0.9710000000000001, 1.9409999999999998, 1.458, 1.934, 1.9569999999999999, 1.9409999999999998, 1.9609999999999999, 1.948, 1.903, 1.956, 1.946, -0.03300000000000003, 1.443, 1.958, 1.9529999999999998, 1.4609999999999999, 1.46, 1.96, 1.413, 1.954, 1.955, 1.949, 1.943, 1.936, 1.955, 1.4569999999999999, 1.959, 1.95, 1.96, 1.9609999999999999, 1.94, 0.46799999999999997, 1.4449999999999998, 1.958, 1.958, 0.46399999999999997, 1.448, -0.038000000000000034, 1.958, 0.46699999999999997, 0.879, 1.96, 1.946, 0.968, 1.946, 1.952, 1.924, 1.9569999999999999, 1.956, 1.95, 1.934, 1.951, 1.96, 1.4329999999999998, -0.027000000000000024, 1.948, 1.9529999999999998, 1.9489999999999998, 1.46, 1.947, 1.9609999999999999, 1.4449999999999998, 1.9289999999999998, 0.9609999999999999], "episode_lengths": [300, 17, 9, 34, 26, 52, 19, 14, 13, 19, 10, 16, 13, 7, 15, 13, 18, 12, 10, 16, 10, 16, 21, 13, 9, 15, 23, 19, 18, 13, 13, 16, 13, 17, 16, 15, 26, 20, 20, 11, 11, 13, 19, 17, 13, 7, 21, 10, 19, 19, 15, 13, 15, 15, 104, 12, 30, 14, 16, 14, 16, 17, 15, 17, 16, 14, 19, 15, 17, 75, 17, 300, 14, 20, 16, 17, 19, 18, 13, 16, 13, 17, 16, 9, 18, 20, 15, 10, 8, 19, 13, 62, 16, 14, 23, 16, 16, 9, 19, 14, 21, 14, 19, 13, 17, 31, 14, 17, 11, 18, 14, 15, 13, 169, 13, 27, 15, 15, 16, 19, 21, 15, 14, 13, 16, 13, 13, 19, 10, 18, 14, 14, 12, 17, 12, 14, 11, 39, 13, 17, 300, 17, 15, 25, 14, 14, 16, 22, 16, 13, 21, 9, 17, 15, 17, 13, 17, 13, 17, 22, 13], "policy_red_0_reward": [0.481, 1.4489999999999998, 1.4729999999999999, 1.396, 1.4220000000000002, 1.341, 1.442, 1.458, 1.4609999999999999, 1.442, -1.0, 1.452, 1.4609999999999999, -1.0, 1.455, 0.5, 1.446, 1.464, 0.969, 1.452, 0.969, 1.451, 1.436, 1.4609999999999999, -0.501, 1.455, 1.431, -1.006, 1.444, 1.4609999999999999, 1.4609999999999999, 0.5, 1.4609999999999999, 1.446, 1.452, 1.454, 1.42, 1.44, 0.498, 0.966, -1.0, 0.5, 1.443, -0.001, 1.4609999999999999, -1.0, 1.436, 1.47, 1.442, 1.443, 1.455, 1.4609999999999999, 1.455, 1.454, 1.17, 0.963, 1.408, 1.4569999999999999, 1.451, 0.5, 1.452, 1.4489999999999998, 0.498, 0.5, 1.452, 0.5, 1.443, 1.455, 1.4489999999999998, 0.773, 1.4489999999999998, 0.489, 1.4569999999999999, 1.439, 1.452, 1.4489999999999998, 0.5, 1.446, 0.5, 1.452, 1.4609999999999999, 0.499, 1.452, 0.971, 1.4449999999999998, -0.501, -0.501, 0.969, -0.5, 1.442, 0.498, 1.312, 1.452, 1.4569999999999999, 1.4300000000000002, 1.452, 1.452, 1.4729999999999999, 1.443, 0.0, 1.436, 0.5, 1.443, 1.4609999999999999, 0.5, 1.405, 1.4569999999999999, 1.4489999999999998, -1.0, 1.4449999999999998, 0.5, 1.455, 1.4609999999999999, 0.977, 1.4609999999999999, 1.416, 1.455, 1.455, 1.452, 0.5, 1.4369999999999998, 1.455, 1.458, 1.4609999999999999, 1.452, 1.4609999999999999, 0.5, 1.4409999999999998, -1.002, 1.446, 0.5, 0.5, 1.464, 1.4489999999999998, 0.964, 0.5, -0.5, 1.379, 1.4609999999999999, 1.448, 0.489, 0.499, 1.454, 0.499, 1.4569999999999999, 1.458, 1.451, 1.434, 1.452, 1.4609999999999999, -0.003, 0.973, 1.4489999999999998, 1.455, 1.4489999999999998, 1.4609999999999999, 0.5, 1.4609999999999999, -0.004, 0.496, 1.4609999999999999], "policy_blue_0_reward": [0.46799999999999997, 0.5, -0.503, 0.496, -0.002, 0.496, 0.498, 0.498, 0.5, 0.498, 1.47, 0.498, 0.5, 1.479, 0.5, 1.4609999999999999, 0.5, -1.004, -0.501, 0.5, -1.001, 0.499, 0.499, 0.5, 1.471, 0.5, 0.498, 1.44, 0.497, 0.499, 0.5, 1.452, 0.5, 0.499, 0.498, 0.5, 0.498, 0.0, 1.439, -0.501, 0.967, 1.4609999999999999, 0.497, 1.447, 0.499, 1.479, 0.497, -1.0, 0.498, 0.496, 0.498, 0.499, 0.5, 0.5, -0.010000000000000002, -1.002, 0.499, -0.501, 0.5, 1.458, 0.499, 0.5, 1.455, 1.4489999999999998, 0.499, 1.458, 0.498, 0.499, 0.498, -0.508, 0.499, 0.481, 0.5, 0.496, 0.498, 0.499, 1.442, 0.499, 1.4609999999999999, 0.499, 0.499, 1.447, -0.001, -1.001, 0.497, 1.44, 0.954, -0.504, 0.976, 0.499, 1.4609999999999999, 0.493, -0.002, -0.501, 0.496, 0.5, 0.499, -0.502, 0.498, 1.458, 0.498, 1.4569999999999999, 0.498, 0.5, 1.448, 0.498, 0.499, 0.497, 0.967, -0.002, 1.458, 0.498, 0.0, 0.483, 0.499, -0.003, 0.499, 0.5, 0.497, 1.443, 0.499, 0.5, -0.001, 0.498, 0.498, 0.499, 1.4609999999999999, 0.499, 1.47, -0.001, 1.458, 1.458, -1.0, -0.001, -1.002, 1.458, 0.967, -0.5, 0.499, 0.498, 0.479, 1.447, 0.498, 1.425, 0.5, 0.498, 0.499, 0.5, 0.499, 0.499, 1.436, -1.0, 0.499, 0.498, 0.5, -0.001, 1.447, 0.5, 1.4489999999999998, 1.4329999999999998, -0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4256341717867942, "mean_inference_ms": 7.454871499565865, "mean_action_processing_ms": 0.3915156487992108, "mean_env_wait_ms": 0.5226667995934112, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13862033808453483, "StateBufferConnector_ms": 0.009159419847571331, "ViewRequirementAgentConnector_ms": 0.17786936730331515}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.039000000000000035, "episode_reward_mean": 1.598378881987578, "episode_len_mean": 23.627329192546583, "episodes_this_iter": 161, "policy_reward_min": {"red_0": -1.006, "blue_0": -1.004}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.052142857142857, "blue_0": 0.5462360248447206}, "hist_stats": {"episode_reward": [0.949, 1.9489999999999998, 0.97, 1.892, 1.42, 1.837, 1.94, 1.956, 1.9609999999999999, 1.94, 0.47, 1.95, 1.9609999999999999, 0.479, 1.955, 1.9609999999999999, 1.946, 0.45999999999999996, 0.46799999999999997, 1.952, -0.03199999999999992, 1.95, 1.935, 1.9609999999999999, 0.97, 1.955, 1.929, 0.43399999999999994, 1.9409999999999998, 1.96, 1.9609999999999999, 1.952, 1.9609999999999999, 1.9449999999999998, 1.95, 1.954, 1.9180000000000001, 1.44, 1.9369999999999998, 0.46499999999999986, -0.03300000000000003, 1.9609999999999999, 1.94, 1.446, 1.96, 0.479, 1.9329999999999998, 0.47, 1.94, 1.939, 1.9529999999999998, 1.96, 1.955, 1.954, 1.16, -0.039000000000000035, 1.907, 0.956, 1.951, 1.958, 1.951, 1.9489999999999998, 1.9529999999999998, 1.9489999999999998, 1.951, 1.958, 1.9409999999999998, 1.954, 1.947, 0.2650000000000001, 1.948, 0.97, 1.9569999999999999, 1.935, 1.95, 1.948, 1.942, 1.9449999999999998, 1.9609999999999999, 1.951, 1.96, 1.946, 1.451, -0.030000000000000027, 1.942, 0.939, 0.45299999999999996, 0.46499999999999986, 0.476, 1.9409999999999998, 1.959, 1.8050000000000002, 1.45, 0.956, 1.9260000000000002, 1.952, 1.951, 0.9710000000000001, 1.9409999999999998, 1.458, 1.934, 1.9569999999999999, 1.9409999999999998, 1.9609999999999999, 1.948, 1.903, 1.956, 1.946, -0.03300000000000003, 1.443, 1.958, 1.9529999999999998, 1.4609999999999999, 1.46, 1.96, 1.413, 1.954, 1.955, 1.949, 1.943, 1.936, 1.955, 1.4569999999999999, 1.959, 1.95, 1.96, 1.9609999999999999, 1.94, 0.46799999999999997, 1.4449999999999998, 1.958, 1.958, 0.46399999999999997, 1.448, -0.038000000000000034, 1.958, 0.46699999999999997, 0.879, 1.96, 1.946, 0.968, 1.946, 1.952, 1.924, 1.9569999999999999, 1.956, 1.95, 1.934, 1.951, 1.96, 1.4329999999999998, -0.027000000000000024, 1.948, 1.9529999999999998, 1.9489999999999998, 1.46, 1.947, 1.9609999999999999, 1.4449999999999998, 1.9289999999999998, 0.9609999999999999], "episode_lengths": [300, 17, 9, 34, 26, 52, 19, 14, 13, 19, 10, 16, 13, 7, 15, 13, 18, 12, 10, 16, 10, 16, 21, 13, 9, 15, 23, 19, 18, 13, 13, 16, 13, 17, 16, 15, 26, 20, 20, 11, 11, 13, 19, 17, 13, 7, 21, 10, 19, 19, 15, 13, 15, 15, 104, 12, 30, 14, 16, 14, 16, 17, 15, 17, 16, 14, 19, 15, 17, 75, 17, 300, 14, 20, 16, 17, 19, 18, 13, 16, 13, 17, 16, 9, 18, 20, 15, 10, 8, 19, 13, 62, 16, 14, 23, 16, 16, 9, 19, 14, 21, 14, 19, 13, 17, 31, 14, 17, 11, 18, 14, 15, 13, 169, 13, 27, 15, 15, 16, 19, 21, 15, 14, 13, 16, 13, 13, 19, 10, 18, 14, 14, 12, 17, 12, 14, 11, 39, 13, 17, 300, 17, 15, 25, 14, 14, 16, 22, 16, 13, 21, 9, 17, 15, 17, 13, 17, 13, 17, 22, 13], "policy_red_0_reward": [0.481, 1.4489999999999998, 1.4729999999999999, 1.396, 1.4220000000000002, 1.341, 1.442, 1.458, 1.4609999999999999, 1.442, -1.0, 1.452, 1.4609999999999999, -1.0, 1.455, 0.5, 1.446, 1.464, 0.969, 1.452, 0.969, 1.451, 1.436, 1.4609999999999999, -0.501, 1.455, 1.431, -1.006, 1.444, 1.4609999999999999, 1.4609999999999999, 0.5, 1.4609999999999999, 1.446, 1.452, 1.454, 1.42, 1.44, 0.498, 0.966, -1.0, 0.5, 1.443, -0.001, 1.4609999999999999, -1.0, 1.436, 1.47, 1.442, 1.443, 1.455, 1.4609999999999999, 1.455, 1.454, 1.17, 0.963, 1.408, 1.4569999999999999, 1.451, 0.5, 1.452, 1.4489999999999998, 0.498, 0.5, 1.452, 0.5, 1.443, 1.455, 1.4489999999999998, 0.773, 1.4489999999999998, 0.489, 1.4569999999999999, 1.439, 1.452, 1.4489999999999998, 0.5, 1.446, 0.5, 1.452, 1.4609999999999999, 0.499, 1.452, 0.971, 1.4449999999999998, -0.501, -0.501, 0.969, -0.5, 1.442, 0.498, 1.312, 1.452, 1.4569999999999999, 1.4300000000000002, 1.452, 1.452, 1.4729999999999999, 1.443, 0.0, 1.436, 0.5, 1.443, 1.4609999999999999, 0.5, 1.405, 1.4569999999999999, 1.4489999999999998, -1.0, 1.4449999999999998, 0.5, 1.455, 1.4609999999999999, 0.977, 1.4609999999999999, 1.416, 1.455, 1.455, 1.452, 0.5, 1.4369999999999998, 1.455, 1.458, 1.4609999999999999, 1.452, 1.4609999999999999, 0.5, 1.4409999999999998, -1.002, 1.446, 0.5, 0.5, 1.464, 1.4489999999999998, 0.964, 0.5, -0.5, 1.379, 1.4609999999999999, 1.448, 0.489, 0.499, 1.454, 0.499, 1.4569999999999999, 1.458, 1.451, 1.434, 1.452, 1.4609999999999999, -0.003, 0.973, 1.4489999999999998, 1.455, 1.4489999999999998, 1.4609999999999999, 0.5, 1.4609999999999999, -0.004, 0.496, 1.4609999999999999], "policy_blue_0_reward": [0.46799999999999997, 0.5, -0.503, 0.496, -0.002, 0.496, 0.498, 0.498, 0.5, 0.498, 1.47, 0.498, 0.5, 1.479, 0.5, 1.4609999999999999, 0.5, -1.004, -0.501, 0.5, -1.001, 0.499, 0.499, 0.5, 1.471, 0.5, 0.498, 1.44, 0.497, 0.499, 0.5, 1.452, 0.5, 0.499, 0.498, 0.5, 0.498, 0.0, 1.439, -0.501, 0.967, 1.4609999999999999, 0.497, 1.447, 0.499, 1.479, 0.497, -1.0, 0.498, 0.496, 0.498, 0.499, 0.5, 0.5, -0.010000000000000002, -1.002, 0.499, -0.501, 0.5, 1.458, 0.499, 0.5, 1.455, 1.4489999999999998, 0.499, 1.458, 0.498, 0.499, 0.498, -0.508, 0.499, 0.481, 0.5, 0.496, 0.498, 0.499, 1.442, 0.499, 1.4609999999999999, 0.499, 0.499, 1.447, -0.001, -1.001, 0.497, 1.44, 0.954, -0.504, 0.976, 0.499, 1.4609999999999999, 0.493, -0.002, -0.501, 0.496, 0.5, 0.499, -0.502, 0.498, 1.458, 0.498, 1.4569999999999999, 0.498, 0.5, 1.448, 0.498, 0.499, 0.497, 0.967, -0.002, 1.458, 0.498, 0.0, 0.483, 0.499, -0.003, 0.499, 0.5, 0.497, 1.443, 0.499, 0.5, -0.001, 0.498, 0.498, 0.499, 1.4609999999999999, 0.499, 1.47, -0.001, 1.458, 1.458, -1.0, -0.001, -1.002, 1.458, 0.967, -0.5, 0.499, 0.498, 0.479, 1.447, 0.498, 1.425, 0.5, 0.498, 0.499, 0.5, 0.499, 0.499, 1.436, -1.0, 0.499, 0.498, 0.5, -0.001, 1.447, 0.5, 1.4489999999999998, 1.4329999999999998, -0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4256341717867942, "mean_inference_ms": 7.454871499565865, "mean_action_processing_ms": 0.3915156487992108, "mean_env_wait_ms": 0.5226667995934112, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13862033808453483, "StateBufferConnector_ms": 0.009159419847571331, "ViewRequirementAgentConnector_ms": 0.17786936730331515}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1000000, "num_agent_steps_trained": 1000000, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 123.27088306194202, "num_env_steps_trained_throughput_per_sec": 123.27088306194202, "timesteps_total": 500000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1000000, "timers": {"training_iteration_time_ms": 31471.789, "sample_time_ms": 4054.471, "learn_time_ms": 27387.386, "learn_throughput": 146.053, "synch_weights_time_ms": 28.398}, "counters": {"num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 1000000, "num_agent_steps_trained": 1000000}, "done": false, "episodes_total": 10291, "training_iteration": 125, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-03-46", "timestamp": 1694840626, "time_this_iter_s": 32.469671964645386, "time_total_s": 3911.137795448303, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21982830>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3911.137795448303, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 28.73829787234042, "ram_util_percent": 57.180851063829785}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6705882352941176, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.07058823529411765, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.047058823529411764, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.07058823529411765, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.18235294117647058, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.047058823529411764, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.07058823529411765, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.047058823529411764, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.42858983351228136, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03149266577675007, "policy_loss": -0.0654284020551131, "vf_loss": 0.03130273416415245, "vf_explained_var": 0.7446920977284511, "kl": 0.008421538041199004, "entropy": 0.9009473944082856, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 120480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47528846994973717, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04004408458955974, "policy_loss": -0.07535845085088416, "vf_loss": 0.031345055930432866, "vf_explained_var": 0.5940300256634752, "kl": 0.00919189374948719, "entropy": 1.2984450299292802, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 120480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.030000000000000027, "episode_reward_mean": 1.6237470588235292, "episode_len_mean": 26.123529411764707, "episode_media": {}, "episodes_this_iter": 170, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.1028470588235295, "blue_0": 0.5209}, "custom_metrics": {"red_0/door_open_done_mean": 0.6705882352941176, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.07058823529411765, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.047058823529411764, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.07058823529411765, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.18235294117647058, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.047058823529411764, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.07058823529411765, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.047058823529411764, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.454, 1.9609999999999999, 1.9529999999999998, 1.936, 1.955, 1.439, 1.943, 1.954, 1.936, 1.95, 1.458, 1.947, 1.885, 0.472, 1.448, 1.439, 1.452, 0.46899999999999986, 1.95, 0.9750000000000001, 1.948, 1.9500000000000002, 1.9609999999999999, 1.951, 1.455, 1.954, 1.947, 1.96, 1.9609999999999999, 1.947, 1.954, 1.446, 1.4569999999999999, 1.948, 1.4569999999999999, 1.9569999999999999, 1.956, 1.94, 0.9689999999999999, 1.456, 1.9529999999999998, 1.4060000000000001, 0.957, 0.96, 1.936, 1.9, 1.943, 1.9609999999999999, 1.9609999999999999, 1.948, 1.434, 1.9569999999999999, 1.454, 1.432, 1.9609999999999999, 1.4609999999999999, 1.955, 1.9609999999999999, 1.955, 1.948, 1.454, 1.4489999999999998, 1.458, 1.958, 0.14100000000000001, 1.919, 1.94, 1.96, 0.43299999999999994, 1.454, 1.942, 1.947, 1.416, 1.9449999999999998, 1.944, 1.9529999999999998, 0.929, 1.936, 1.942, 1.956, 1.9529999999999998, 1.96, 1.9449999999999998, 1.9329999999999998, 1.3780000000000001, 0.43499999999999994, 1.434, 1.95, 0.472, 1.9609999999999999, 1.958, 1.947, 1.4529999999999998, 1.9449999999999998, 0.44099999999999984, 1.946, 1.955, 0.46399999999999997, 1.454, 1.449, 1.95, 1.4569999999999999, 1.9569999999999999, 1.452, 1.95, 1.254, 1.9449999999999998, 1.951, 1.9609999999999999, 1.3399999999999999, 0.9689999999999999, -0.030000000000000027, 1.96, 1.955, 1.9329999999999998, 1.931, 0.955, 0.45799999999999996, 1.9409999999999998, 1.96, 1.95, 1.428, 1.4300000000000002, 1.427, 1.951, 1.443, 1.9609999999999999, 1.951, 1.927, 1.9569999999999999, 1.4609999999999999, 1.958, 1.954, 0.957, 1.45, 1.958, 1.767, 1.454, 1.947, 1.948, 1.451, 1.943, 1.9569999999999999, 1.958, 1.958, 1.459, 1.9569999999999999, 1.9449999999999998, 1.942, 1.427, 0.476, 1.913, 0.954, 1.955, 1.4580000000000002, 1.454, 0.44399999999999995, 1.4489999999999998, 1.96, 0.979, 1.451, 1.954, 1.9609999999999999, 0.4159999999999999, 0.45299999999999985, 1.9369999999999998, 1.9609999999999999, 1.956, 0.939, 1.94], "episode_lengths": [15, 13, 15, 20, 15, 19, 18, 15, 21, 16, 14, 17, 37, 9, 17, 19, 16, 10, 15, 8, 17, 16, 13, 16, 15, 15, 17, 13, 13, 17, 15, 18, 14, 17, 14, 14, 14, 19, 10, 14, 15, 29, 14, 13, 20, 31, 18, 13, 13, 17, 21, 14, 15, 22, 13, 13, 15, 13, 15, 17, 15, 17, 14, 14, 113, 26, 19, 13, 300, 15, 19, 17, 27, 17, 18, 15, 22, 21, 19, 14, 15, 13, 18, 22, 37, 300, 21, 16, 9, 13, 14, 17, 15, 17, 19, 17, 15, 11, 15, 16, 16, 14, 14, 16, 16, 76, 17, 16, 13, 48, 10, 10, 13, 15, 22, 23, 300, 13, 19, 13, 16, 24, 23, 23, 16, 18, 13, 16, 23, 14, 13, 13, 15, 14, 16, 14, 75, 15, 17, 17, 16, 18, 14, 14, 14, 13, 14, 18, 19, 24, 8, 27, 14, 15, 13, 15, 18, 17, 13, 7, 16, 15, 13, 300, 15, 20, 13, 14, 300, 19], "policy_red_0_reward": [1.455, 0.5, 1.455, 0.497, 1.455, 1.442, 1.446, 1.455, 1.4369999999999998, 1.452, 1.458, 1.448, 1.3860000000000001, -1.001, 1.4489999999999998, -0.004, 0.0, 0.969, 1.455, 1.476, 1.4489999999999998, 1.452, 1.4609999999999999, 1.451, 1.455, 1.455, 1.4489999999999998, 1.4609999999999999, 1.4609999999999999, 1.4489999999999998, 1.455, 1.446, 1.458, 0.5, 1.458, 1.458, 1.458, 0.5, 1.47, -0.002, 1.455, 1.411, -0.501, 1.4609999999999999, 1.44, 1.401, 1.444, 1.4609999999999999, 1.4609999999999999, 1.4489999999999998, 1.435, 1.458, 1.455, 1.4329999999999998, 0.5, 1.4609999999999999, 1.455, 1.4609999999999999, 1.455, 0.5, 0.0, 0.0, 1.458, 0.5, 0.656, 1.4220000000000002, 0.498, 1.4609999999999999, -0.03400000000000002, 1.455, 0.499, 0.498, 1.416, 0.498, 1.4449999999999998, 1.455, 1.4329999999999998, 1.4369999999999998, 1.443, 1.458, 1.455, 1.4609999999999999, 1.4449999999999998, 1.434, 1.385, 0.46599999999999997, 1.4369999999999998, 1.452, 1.4729999999999999, 1.4609999999999999, 0.5, 0.498, -0.002, 1.448, 0.942, 1.448, 1.455, -0.5, -0.001, 1.451, 1.451, 1.458, 1.458, 1.452, 0.499, -0.009000000000000001, 1.448, 0.499, 0.5, -0.006, 1.47, -1.0, 1.4609999999999999, 1.455, 1.434, 0.5, 0.488, -0.501, 1.442, 1.4609999999999999, 1.452, 1.428, 1.431, -0.001, 1.451, 1.4449999999999998, 1.4609999999999999, 1.451, 1.4300000000000002, 1.458, 1.4609999999999999, 1.4609999999999999, 1.454, -0.5, 1.452, 0.5, 1.27, 1.455, 1.4489999999999998, 1.448, 1.452, 1.4449999999999998, 0.5, 1.458, 1.458, 1.4609999999999999, 1.458, 1.446, 1.443, 1.428, 1.476, 1.415, -0.502, 1.455, 1.4609999999999999, 1.455, 1.4449999999999998, 1.4489999999999998, 0.499, -0.5, 1.451, 1.455, 1.4609999999999999, -0.037000000000000026, 1.455, 1.439, 0.5, 1.4569999999999999, 0.469, 1.4409999999999998], "policy_blue_0_reward": [-0.001, 1.4609999999999999, 0.498, 1.439, 0.5, -0.003, 0.497, 0.499, 0.499, 0.498, 0.0, 0.499, 0.499, 1.4729999999999999, -0.001, 1.443, 1.452, -0.5, 0.495, -0.501, 0.499, 0.498, 0.5, 0.5, 0.0, 0.499, 0.498, 0.499, 0.5, 0.498, 0.499, 0.0, -0.001, 1.448, -0.001, 0.499, 0.498, 1.44, -0.501, 1.458, 0.498, -0.005, 1.458, -0.501, 0.496, 0.499, 0.499, 0.5, 0.5, 0.499, -0.001, 0.499, -0.001, -0.001, 1.4609999999999999, 0.0, 0.5, 0.5, 0.5, 1.448, 1.454, 1.4489999999999998, 0.0, 1.458, -0.515, 0.497, 1.442, 0.499, 0.46699999999999997, -0.001, 1.443, 1.4489999999999998, 0.0, 1.447, 0.499, 0.498, -0.5039999999999999, 0.499, 0.499, 0.498, 0.498, 0.499, 0.5, 0.499, -0.007, -0.03100000000000002, -0.003, 0.498, -1.001, 0.5, 1.458, 1.4489999999999998, 1.455, 0.497, -0.501, 0.498, 0.5, 0.964, 1.455, -0.002, 0.499, -0.001, 0.499, 0.0, 1.451, 1.263, 0.497, 1.452, 1.4609999999999999, 1.346, -0.501, 0.97, 0.499, 0.5, 0.499, 1.431, 0.46699999999999997, 0.959, 0.499, 0.499, 0.498, 0.0, -0.001, 1.428, 0.5, -0.002, 0.5, 0.5, 0.497, 0.499, 0.0, 0.497, 0.5, 1.4569999999999999, -0.002, 1.458, 0.497, -0.001, 0.498, 0.5, -0.001, 0.498, 1.4569999999999999, 0.5, 0.5, -0.002, 0.499, 0.499, 0.499, -0.001, -1.0, 0.498, 1.456, 0.5, -0.003, -0.001, -1.001, 0.0, 1.4609999999999999, 1.479, 0.0, 0.499, 0.5, 0.45299999999999996, -1.002, 0.498, 1.4609999999999999, 0.499, 0.47, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4270425714486412, "mean_inference_ms": 7.454427035509581, "mean_action_processing_ms": 0.3916795908526355, "mean_env_wait_ms": 0.5223332522697814, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1463166405172909, "StateBufferConnector_ms": 0.009348743102129768, "ViewRequirementAgentConnector_ms": 0.1857269511503332}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.030000000000000027, "episode_reward_mean": 1.6237470588235292, "episode_len_mean": 26.123529411764707, "episodes_this_iter": 170, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.1028470588235295, "blue_0": 0.5209}, "hist_stats": {"episode_reward": [1.454, 1.9609999999999999, 1.9529999999999998, 1.936, 1.955, 1.439, 1.943, 1.954, 1.936, 1.95, 1.458, 1.947, 1.885, 0.472, 1.448, 1.439, 1.452, 0.46899999999999986, 1.95, 0.9750000000000001, 1.948, 1.9500000000000002, 1.9609999999999999, 1.951, 1.455, 1.954, 1.947, 1.96, 1.9609999999999999, 1.947, 1.954, 1.446, 1.4569999999999999, 1.948, 1.4569999999999999, 1.9569999999999999, 1.956, 1.94, 0.9689999999999999, 1.456, 1.9529999999999998, 1.4060000000000001, 0.957, 0.96, 1.936, 1.9, 1.943, 1.9609999999999999, 1.9609999999999999, 1.948, 1.434, 1.9569999999999999, 1.454, 1.432, 1.9609999999999999, 1.4609999999999999, 1.955, 1.9609999999999999, 1.955, 1.948, 1.454, 1.4489999999999998, 1.458, 1.958, 0.14100000000000001, 1.919, 1.94, 1.96, 0.43299999999999994, 1.454, 1.942, 1.947, 1.416, 1.9449999999999998, 1.944, 1.9529999999999998, 0.929, 1.936, 1.942, 1.956, 1.9529999999999998, 1.96, 1.9449999999999998, 1.9329999999999998, 1.3780000000000001, 0.43499999999999994, 1.434, 1.95, 0.472, 1.9609999999999999, 1.958, 1.947, 1.4529999999999998, 1.9449999999999998, 0.44099999999999984, 1.946, 1.955, 0.46399999999999997, 1.454, 1.449, 1.95, 1.4569999999999999, 1.9569999999999999, 1.452, 1.95, 1.254, 1.9449999999999998, 1.951, 1.9609999999999999, 1.3399999999999999, 0.9689999999999999, -0.030000000000000027, 1.96, 1.955, 1.9329999999999998, 1.931, 0.955, 0.45799999999999996, 1.9409999999999998, 1.96, 1.95, 1.428, 1.4300000000000002, 1.427, 1.951, 1.443, 1.9609999999999999, 1.951, 1.927, 1.9569999999999999, 1.4609999999999999, 1.958, 1.954, 0.957, 1.45, 1.958, 1.767, 1.454, 1.947, 1.948, 1.451, 1.943, 1.9569999999999999, 1.958, 1.958, 1.459, 1.9569999999999999, 1.9449999999999998, 1.942, 1.427, 0.476, 1.913, 0.954, 1.955, 1.4580000000000002, 1.454, 0.44399999999999995, 1.4489999999999998, 1.96, 0.979, 1.451, 1.954, 1.9609999999999999, 0.4159999999999999, 0.45299999999999985, 1.9369999999999998, 1.9609999999999999, 1.956, 0.939, 1.94], "episode_lengths": [15, 13, 15, 20, 15, 19, 18, 15, 21, 16, 14, 17, 37, 9, 17, 19, 16, 10, 15, 8, 17, 16, 13, 16, 15, 15, 17, 13, 13, 17, 15, 18, 14, 17, 14, 14, 14, 19, 10, 14, 15, 29, 14, 13, 20, 31, 18, 13, 13, 17, 21, 14, 15, 22, 13, 13, 15, 13, 15, 17, 15, 17, 14, 14, 113, 26, 19, 13, 300, 15, 19, 17, 27, 17, 18, 15, 22, 21, 19, 14, 15, 13, 18, 22, 37, 300, 21, 16, 9, 13, 14, 17, 15, 17, 19, 17, 15, 11, 15, 16, 16, 14, 14, 16, 16, 76, 17, 16, 13, 48, 10, 10, 13, 15, 22, 23, 300, 13, 19, 13, 16, 24, 23, 23, 16, 18, 13, 16, 23, 14, 13, 13, 15, 14, 16, 14, 75, 15, 17, 17, 16, 18, 14, 14, 14, 13, 14, 18, 19, 24, 8, 27, 14, 15, 13, 15, 18, 17, 13, 7, 16, 15, 13, 300, 15, 20, 13, 14, 300, 19], "policy_red_0_reward": [1.455, 0.5, 1.455, 0.497, 1.455, 1.442, 1.446, 1.455, 1.4369999999999998, 1.452, 1.458, 1.448, 1.3860000000000001, -1.001, 1.4489999999999998, -0.004, 0.0, 0.969, 1.455, 1.476, 1.4489999999999998, 1.452, 1.4609999999999999, 1.451, 1.455, 1.455, 1.4489999999999998, 1.4609999999999999, 1.4609999999999999, 1.4489999999999998, 1.455, 1.446, 1.458, 0.5, 1.458, 1.458, 1.458, 0.5, 1.47, -0.002, 1.455, 1.411, -0.501, 1.4609999999999999, 1.44, 1.401, 1.444, 1.4609999999999999, 1.4609999999999999, 1.4489999999999998, 1.435, 1.458, 1.455, 1.4329999999999998, 0.5, 1.4609999999999999, 1.455, 1.4609999999999999, 1.455, 0.5, 0.0, 0.0, 1.458, 0.5, 0.656, 1.4220000000000002, 0.498, 1.4609999999999999, -0.03400000000000002, 1.455, 0.499, 0.498, 1.416, 0.498, 1.4449999999999998, 1.455, 1.4329999999999998, 1.4369999999999998, 1.443, 1.458, 1.455, 1.4609999999999999, 1.4449999999999998, 1.434, 1.385, 0.46599999999999997, 1.4369999999999998, 1.452, 1.4729999999999999, 1.4609999999999999, 0.5, 0.498, -0.002, 1.448, 0.942, 1.448, 1.455, -0.5, -0.001, 1.451, 1.451, 1.458, 1.458, 1.452, 0.499, -0.009000000000000001, 1.448, 0.499, 0.5, -0.006, 1.47, -1.0, 1.4609999999999999, 1.455, 1.434, 0.5, 0.488, -0.501, 1.442, 1.4609999999999999, 1.452, 1.428, 1.431, -0.001, 1.451, 1.4449999999999998, 1.4609999999999999, 1.451, 1.4300000000000002, 1.458, 1.4609999999999999, 1.4609999999999999, 1.454, -0.5, 1.452, 0.5, 1.27, 1.455, 1.4489999999999998, 1.448, 1.452, 1.4449999999999998, 0.5, 1.458, 1.458, 1.4609999999999999, 1.458, 1.446, 1.443, 1.428, 1.476, 1.415, -0.502, 1.455, 1.4609999999999999, 1.455, 1.4449999999999998, 1.4489999999999998, 0.499, -0.5, 1.451, 1.455, 1.4609999999999999, -0.037000000000000026, 1.455, 1.439, 0.5, 1.4569999999999999, 0.469, 1.4409999999999998], "policy_blue_0_reward": [-0.001, 1.4609999999999999, 0.498, 1.439, 0.5, -0.003, 0.497, 0.499, 0.499, 0.498, 0.0, 0.499, 0.499, 1.4729999999999999, -0.001, 1.443, 1.452, -0.5, 0.495, -0.501, 0.499, 0.498, 0.5, 0.5, 0.0, 0.499, 0.498, 0.499, 0.5, 0.498, 0.499, 0.0, -0.001, 1.448, -0.001, 0.499, 0.498, 1.44, -0.501, 1.458, 0.498, -0.005, 1.458, -0.501, 0.496, 0.499, 0.499, 0.5, 0.5, 0.499, -0.001, 0.499, -0.001, -0.001, 1.4609999999999999, 0.0, 0.5, 0.5, 0.5, 1.448, 1.454, 1.4489999999999998, 0.0, 1.458, -0.515, 0.497, 1.442, 0.499, 0.46699999999999997, -0.001, 1.443, 1.4489999999999998, 0.0, 1.447, 0.499, 0.498, -0.5039999999999999, 0.499, 0.499, 0.498, 0.498, 0.499, 0.5, 0.499, -0.007, -0.03100000000000002, -0.003, 0.498, -1.001, 0.5, 1.458, 1.4489999999999998, 1.455, 0.497, -0.501, 0.498, 0.5, 0.964, 1.455, -0.002, 0.499, -0.001, 0.499, 0.0, 1.451, 1.263, 0.497, 1.452, 1.4609999999999999, 1.346, -0.501, 0.97, 0.499, 0.5, 0.499, 1.431, 0.46699999999999997, 0.959, 0.499, 0.499, 0.498, 0.0, -0.001, 1.428, 0.5, -0.002, 0.5, 0.5, 0.497, 0.499, 0.0, 0.497, 0.5, 1.4569999999999999, -0.002, 1.458, 0.497, -0.001, 0.498, 0.5, -0.001, 0.498, 1.4569999999999999, 0.5, 0.5, -0.002, 0.499, 0.499, 0.499, -0.001, -1.0, 0.498, 1.456, 0.5, -0.003, -0.001, -1.001, 0.0, 1.4609999999999999, 1.479, 0.0, 0.499, 0.5, 0.45299999999999996, -1.002, 0.498, 1.4609999999999999, 0.499, 0.47, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4270425714486412, "mean_inference_ms": 7.454427035509581, "mean_action_processing_ms": 0.3916795908526355, "mean_env_wait_ms": 0.5223332522697814, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1463166405172909, "StateBufferConnector_ms": 0.009348743102129768, "ViewRequirementAgentConnector_ms": 0.1857269511503332}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 132.32097979580794, "num_env_steps_trained_throughput_per_sec": 132.32097979580794, "timesteps_total": 504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 31310.153, "sample_time_ms": 4043.997, "learn_time_ms": 27235.721, "learn_throughput": 146.866, "synch_weights_time_ms": 28.91}, "counters": {"num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "episodes_total": 10461, "training_iteration": 126, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-04-17", "timestamp": 1694840657, "time_this_iter_s": 30.250648736953735, "time_total_s": 3941.388444185257, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a2e92d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3941.388444185257, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 24.459090909090904, "ram_util_percent": 56.83409090909088}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6621621621621622, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.07432432432432433, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.05405405405405406, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.07432432432432433, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1891891891891892, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.05405405405405406, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.07432432432432433, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.05405405405405406, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.436447699352478, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.030556580324324994, "policy_loss": -0.06151881222370624, "vf_loss": 0.02664998279651627, "vf_explained_var": 0.7800185334558288, "kl": 0.008176146519724781, "entropy": 0.989043659158051, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 121440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48301556557416914, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.048941433271587204, "policy_loss": -0.08292372993358489, "vf_loss": 0.026279390852626722, "vf_explained_var": 0.6491390954082211, "kl": 0.009747740398546086, "entropy": 1.3639699891209602, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 121440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 1016000, "num_agent_steps_trained": 1016000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.15300000000000002, "episode_reward_mean": 1.6273918918918917, "episode_len_mean": 23.277027027027028, "episode_media": {}, "episodes_this_iter": 148, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 1.0790067567567567, "blue_0": 0.5483851351351351}, "custom_metrics": {"red_0/door_open_done_mean": 0.6621621621621622, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.07432432432432433, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.05405405405405406, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.07432432432432433, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.1891891891891892, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.05405405405405406, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.07432432432432433, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.05405405405405406, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.9449999999999998, 1.9569999999999999, 0.44099999999999995, 1.341, 1.9500000000000002, 1.9609999999999999, 1.9569999999999999, 1.9489999999999998, 0.972, 1.455, 1.45, 1.436, 1.959, -0.03400000000000003, 1.9329999999999998, 1.948, 1.9489999999999998, 1.455, 0.46499999999999997, 1.9569999999999999, 1.958, 1.435, 1.415, -0.15300000000000002, 1.9569999999999999, 1.951, 1.9100000000000001, 1.452, 1.9220000000000002, 1.96, 1.928, 1.4449999999999998, 1.9569999999999999, 1.936, 1.955, 1.448, 0.9409999999999998, 1.9180000000000001, 1.306, 1.444, 1.9609999999999999, 1.958, 1.947, 1.947, 1.955, 1.943, 1.94, 1.4609999999999999, 1.927, 1.9449999999999998, 1.931, 1.4529999999999998, 1.454, 1.955, 1.952, 1.455, 1.438, 0.43999999999999995, 1.9489999999999998, 1.947, 1.955, 1.934, 1.9449999999999998, 1.899, 1.96, 1.942, 1.443, 1.948, 1.896, 1.946, 1.95, 1.423, 1.9609999999999999, 0.46099999999999985, 1.932, 0.958, 1.957, 1.956, 0.45799999999999996, 1.959, 1.9140000000000001, 1.455, 1.956, 1.431, 1.9449999999999998, -0.027000000000000024, 0.976, 1.9569999999999999, -0.04500000000000004, 0.97, 1.952, 1.45, 1.956, 1.9409999999999998, 1.939, 1.9609999999999999, 1.959, 1.958, 1.932, 1.932, 1.445, 1.9449999999999998, 1.4489999999999998, 1.96, 1.958, 1.9329999999999998, 1.458, 0.45699999999999996, 1.9609999999999999, 1.959, 1.956, 1.9569999999999999, 1.948, 1.9609999999999999, 1.951, 1.946, 1.942, 0.949, 1.45, 1.935, 1.9609999999999999, 1.946, 1.9449999999999998, 1.946, -0.030000000000000027, -0.09300000000000007, 1.957, 1.951, 1.3860000000000001, 1.958, 1.95, 1.907, 1.947, 1.954, 1.955, -0.03399999999999992, 1.9580000000000002, 1.455, 1.942, 0.45999999999999996, 1.9489999999999998, 1.96, 1.943, 1.876, 0.942, 1.9449999999999998, 0.966, 1.448], "episode_lengths": [18, 14, 300, 50, 16, 13, 14, 16, 9, 14, 16, 20, 13, 10, 22, 17, 17, 14, 11, 14, 14, 21, 27, 46, 14, 16, 29, 15, 25, 13, 23, 17, 14, 21, 15, 17, 19, 26, 62, 18, 13, 13, 17, 17, 15, 18, 19, 13, 23, 18, 22, 15, 15, 14, 15, 14, 20, 300, 17, 17, 15, 22, 18, 32, 13, 17, 19, 17, 33, 17, 16, 24, 13, 12, 21, 13, 14, 14, 14, 13, 28, 15, 14, 22, 18, 9, 8, 14, 14, 10, 15, 16, 14, 19, 19, 13, 13, 14, 21, 21, 18, 18, 17, 13, 14, 20, 14, 13, 13, 13, 14, 14, 17, 13, 16, 17, 19, 16, 16, 21, 13, 18, 18, 17, 10, 300, 14, 16, 36, 14, 16, 29, 17, 15, 15, 11, 13, 14, 19, 13, 16, 13, 19, 40, 18, 18, 11, 17], "policy_red_0_reward": [1.4449999999999998, 1.4569999999999999, 0.46799999999999997, -0.003, 1.452, 1.4609999999999999, 1.4569999999999999, 0.5, 1.4729999999999999, 1.458, 1.452, 1.4369999999999998, 1.4609999999999999, 0.968, 1.434, 1.4489999999999998, 1.4489999999999998, 1.458, -1.001, 0.499, 1.458, -0.001, -0.003, 0.85, 1.458, 0.499, 0.497, 1.455, 0.498, 1.4609999999999999, 1.4300000000000002, 1.448, 1.458, 1.4369999999999998, 1.455, 1.4489999999999998, 1.443, 1.42, 1.311, -0.002, 1.4609999999999999, 1.4609999999999999, 0.5, 1.4489999999999998, 1.455, 0.5, 1.442, 0.0, 1.4300000000000002, 0.499, 0.498, 1.455, 1.455, 1.458, 0.499, -0.002, 1.44, 0.45499999999999996, 1.4489999999999998, 1.4489999999999998, 1.455, 1.434, 1.446, 1.4020000000000001, 1.4609999999999999, 1.447, 1.443, 1.4489999999999998, 1.3980000000000001, 1.448, 0.498, -0.002, 1.4609999999999999, 1.463, 1.436, 1.46, 1.458, 1.458, 1.458, 1.4609999999999999, 1.415, 1.455, 1.4569999999999999, 1.4329999999999998, 1.446, 0.973, 1.476, 1.458, 0.958, -0.5, 1.455, 1.451, 1.4569999999999999, 1.443, 1.443, 1.4609999999999999, 1.4609999999999999, 1.458, 1.435, 1.435, 1.446, 1.446, 1.4489999999999998, 1.4609999999999999, 1.458, 0.497, 0.0, -0.501, 1.4609999999999999, 1.4609999999999999, 1.458, 1.458, 1.4489999999999998, 1.4609999999999999, 1.452, 1.448, 1.443, -0.5, 1.452, 1.4369999999999998, 1.4609999999999999, 0.5, 0.499, 1.448, -1.0, -0.04500000000000003, 1.458, 0.499, -0.003, 1.458, 1.451, 1.4100000000000001, 1.4489999999999998, 1.455, 0.5, -1.0, 1.4609999999999999, -0.003, 1.443, -0.5, 1.452, 1.4609999999999999, 1.443, 0.498, -0.501, 1.4449999999999998, 1.467, -0.001], "policy_blue_0_reward": [0.5, 0.5, -0.027000000000000017, 1.3439999999999999, 0.498, 0.5, 0.5, 1.4489999999999998, -0.501, -0.003, -0.002, -0.001, 0.498, -1.002, 0.499, 0.499, 0.5, -0.003, 1.466, 1.458, 0.5, 1.436, 1.4180000000000001, -1.003, 0.499, 1.452, 1.413, -0.003, 1.424, 0.499, 0.498, -0.003, 0.499, 0.499, 0.5, -0.001, -0.502, 0.498, -0.005, 1.446, 0.5, 0.497, 1.447, 0.498, 0.5, 1.443, 0.498, 1.4609999999999999, 0.497, 1.446, 1.4329999999999998, -0.002, -0.001, 0.497, 1.4529999999999998, 1.4569999999999999, -0.002, -0.015000000000000006, 0.5, 0.498, 0.5, 0.5, 0.499, 0.497, 0.499, 0.495, 0.0, 0.499, 0.498, 0.498, 1.452, 1.4249999999999998, 0.5, -1.002, 0.496, -0.502, 0.499, 0.498, -1.0, 0.498, 0.499, 0.0, 0.499, -0.002, 0.499, -1.0, -0.5, 0.499, -1.003, 1.47, 0.497, -0.001, 0.499, 0.498, 0.496, 0.5, 0.498, 0.5, 0.497, 0.497, -0.001, 0.499, 0.0, 0.499, 0.5, 1.436, 1.458, 0.958, 0.5, 0.498, 0.498, 0.499, 0.499, 0.5, 0.499, 0.498, 0.499, 1.4489999999999998, -0.002, 0.498, 0.5, 1.446, 1.446, 0.498, 0.97, -0.048000000000000036, 0.499, 1.452, 1.389, 0.5, 0.499, 0.497, 0.498, 0.499, 1.455, 0.966, 0.497, 1.458, 0.499, 0.96, 0.497, 0.499, 0.5, 1.3780000000000001, 1.443, 0.5, -0.501, 1.4489999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4263889905790945, "mean_inference_ms": 7.45851535783552, "mean_action_processing_ms": 0.38979295167257216, "mean_env_wait_ms": 0.5218060755515983, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1395608122284348, "StateBufferConnector_ms": 0.009098729571780644, "ViewRequirementAgentConnector_ms": 0.19113187854354446}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.15300000000000002, "episode_reward_mean": 1.6273918918918917, "episode_len_mean": 23.277027027027028, "episodes_this_iter": 148, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 1.0790067567567567, "blue_0": 0.5483851351351351}, "hist_stats": {"episode_reward": [1.9449999999999998, 1.9569999999999999, 0.44099999999999995, 1.341, 1.9500000000000002, 1.9609999999999999, 1.9569999999999999, 1.9489999999999998, 0.972, 1.455, 1.45, 1.436, 1.959, -0.03400000000000003, 1.9329999999999998, 1.948, 1.9489999999999998, 1.455, 0.46499999999999997, 1.9569999999999999, 1.958, 1.435, 1.415, -0.15300000000000002, 1.9569999999999999, 1.951, 1.9100000000000001, 1.452, 1.9220000000000002, 1.96, 1.928, 1.4449999999999998, 1.9569999999999999, 1.936, 1.955, 1.448, 0.9409999999999998, 1.9180000000000001, 1.306, 1.444, 1.9609999999999999, 1.958, 1.947, 1.947, 1.955, 1.943, 1.94, 1.4609999999999999, 1.927, 1.9449999999999998, 1.931, 1.4529999999999998, 1.454, 1.955, 1.952, 1.455, 1.438, 0.43999999999999995, 1.9489999999999998, 1.947, 1.955, 1.934, 1.9449999999999998, 1.899, 1.96, 1.942, 1.443, 1.948, 1.896, 1.946, 1.95, 1.423, 1.9609999999999999, 0.46099999999999985, 1.932, 0.958, 1.957, 1.956, 0.45799999999999996, 1.959, 1.9140000000000001, 1.455, 1.956, 1.431, 1.9449999999999998, -0.027000000000000024, 0.976, 1.9569999999999999, -0.04500000000000004, 0.97, 1.952, 1.45, 1.956, 1.9409999999999998, 1.939, 1.9609999999999999, 1.959, 1.958, 1.932, 1.932, 1.445, 1.9449999999999998, 1.4489999999999998, 1.96, 1.958, 1.9329999999999998, 1.458, 0.45699999999999996, 1.9609999999999999, 1.959, 1.956, 1.9569999999999999, 1.948, 1.9609999999999999, 1.951, 1.946, 1.942, 0.949, 1.45, 1.935, 1.9609999999999999, 1.946, 1.9449999999999998, 1.946, -0.030000000000000027, -0.09300000000000007, 1.957, 1.951, 1.3860000000000001, 1.958, 1.95, 1.907, 1.947, 1.954, 1.955, -0.03399999999999992, 1.9580000000000002, 1.455, 1.942, 0.45999999999999996, 1.9489999999999998, 1.96, 1.943, 1.876, 0.942, 1.9449999999999998, 0.966, 1.448], "episode_lengths": [18, 14, 300, 50, 16, 13, 14, 16, 9, 14, 16, 20, 13, 10, 22, 17, 17, 14, 11, 14, 14, 21, 27, 46, 14, 16, 29, 15, 25, 13, 23, 17, 14, 21, 15, 17, 19, 26, 62, 18, 13, 13, 17, 17, 15, 18, 19, 13, 23, 18, 22, 15, 15, 14, 15, 14, 20, 300, 17, 17, 15, 22, 18, 32, 13, 17, 19, 17, 33, 17, 16, 24, 13, 12, 21, 13, 14, 14, 14, 13, 28, 15, 14, 22, 18, 9, 8, 14, 14, 10, 15, 16, 14, 19, 19, 13, 13, 14, 21, 21, 18, 18, 17, 13, 14, 20, 14, 13, 13, 13, 14, 14, 17, 13, 16, 17, 19, 16, 16, 21, 13, 18, 18, 17, 10, 300, 14, 16, 36, 14, 16, 29, 17, 15, 15, 11, 13, 14, 19, 13, 16, 13, 19, 40, 18, 18, 11, 17], "policy_red_0_reward": [1.4449999999999998, 1.4569999999999999, 0.46799999999999997, -0.003, 1.452, 1.4609999999999999, 1.4569999999999999, 0.5, 1.4729999999999999, 1.458, 1.452, 1.4369999999999998, 1.4609999999999999, 0.968, 1.434, 1.4489999999999998, 1.4489999999999998, 1.458, -1.001, 0.499, 1.458, -0.001, -0.003, 0.85, 1.458, 0.499, 0.497, 1.455, 0.498, 1.4609999999999999, 1.4300000000000002, 1.448, 1.458, 1.4369999999999998, 1.455, 1.4489999999999998, 1.443, 1.42, 1.311, -0.002, 1.4609999999999999, 1.4609999999999999, 0.5, 1.4489999999999998, 1.455, 0.5, 1.442, 0.0, 1.4300000000000002, 0.499, 0.498, 1.455, 1.455, 1.458, 0.499, -0.002, 1.44, 0.45499999999999996, 1.4489999999999998, 1.4489999999999998, 1.455, 1.434, 1.446, 1.4020000000000001, 1.4609999999999999, 1.447, 1.443, 1.4489999999999998, 1.3980000000000001, 1.448, 0.498, -0.002, 1.4609999999999999, 1.463, 1.436, 1.46, 1.458, 1.458, 1.458, 1.4609999999999999, 1.415, 1.455, 1.4569999999999999, 1.4329999999999998, 1.446, 0.973, 1.476, 1.458, 0.958, -0.5, 1.455, 1.451, 1.4569999999999999, 1.443, 1.443, 1.4609999999999999, 1.4609999999999999, 1.458, 1.435, 1.435, 1.446, 1.446, 1.4489999999999998, 1.4609999999999999, 1.458, 0.497, 0.0, -0.501, 1.4609999999999999, 1.4609999999999999, 1.458, 1.458, 1.4489999999999998, 1.4609999999999999, 1.452, 1.448, 1.443, -0.5, 1.452, 1.4369999999999998, 1.4609999999999999, 0.5, 0.499, 1.448, -1.0, -0.04500000000000003, 1.458, 0.499, -0.003, 1.458, 1.451, 1.4100000000000001, 1.4489999999999998, 1.455, 0.5, -1.0, 1.4609999999999999, -0.003, 1.443, -0.5, 1.452, 1.4609999999999999, 1.443, 0.498, -0.501, 1.4449999999999998, 1.467, -0.001], "policy_blue_0_reward": [0.5, 0.5, -0.027000000000000017, 1.3439999999999999, 0.498, 0.5, 0.5, 1.4489999999999998, -0.501, -0.003, -0.002, -0.001, 0.498, -1.002, 0.499, 0.499, 0.5, -0.003, 1.466, 1.458, 0.5, 1.436, 1.4180000000000001, -1.003, 0.499, 1.452, 1.413, -0.003, 1.424, 0.499, 0.498, -0.003, 0.499, 0.499, 0.5, -0.001, -0.502, 0.498, -0.005, 1.446, 0.5, 0.497, 1.447, 0.498, 0.5, 1.443, 0.498, 1.4609999999999999, 0.497, 1.446, 1.4329999999999998, -0.002, -0.001, 0.497, 1.4529999999999998, 1.4569999999999999, -0.002, -0.015000000000000006, 0.5, 0.498, 0.5, 0.5, 0.499, 0.497, 0.499, 0.495, 0.0, 0.499, 0.498, 0.498, 1.452, 1.4249999999999998, 0.5, -1.002, 0.496, -0.502, 0.499, 0.498, -1.0, 0.498, 0.499, 0.0, 0.499, -0.002, 0.499, -1.0, -0.5, 0.499, -1.003, 1.47, 0.497, -0.001, 0.499, 0.498, 0.496, 0.5, 0.498, 0.5, 0.497, 0.497, -0.001, 0.499, 0.0, 0.499, 0.5, 1.436, 1.458, 0.958, 0.5, 0.498, 0.498, 0.499, 0.499, 0.5, 0.499, 0.498, 0.499, 1.4489999999999998, -0.002, 0.498, 0.5, 1.446, 1.446, 0.498, 0.97, -0.048000000000000036, 0.499, 1.452, 1.389, 0.5, 0.499, 0.497, 0.498, 0.499, 1.455, 0.966, 0.497, 1.458, 0.499, 0.96, 0.497, 0.499, 0.5, 1.3780000000000001, 1.443, 0.5, -0.501, 1.4489999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4263889905790945, "mean_inference_ms": 7.45851535783552, "mean_action_processing_ms": 0.38979295167257216, "mean_env_wait_ms": 0.5218060755515983, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1395608122284348, "StateBufferConnector_ms": 0.009098729571780644, "ViewRequirementAgentConnector_ms": 0.19113187854354446}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1016000, "num_agent_steps_trained": 1016000, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.68319605153482, "num_env_steps_trained_throughput_per_sec": 130.68319605153482, "timesteps_total": 508000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1016000, "timers": {"training_iteration_time_ms": 31392.26, "sample_time_ms": 4032.774, "learn_time_ms": 27329.38, "learn_throughput": 146.363, "synch_weights_time_ms": 28.612}, "counters": {"num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 1016000, "num_agent_steps_trained": 1016000}, "done": false, "episodes_total": 10609, "training_iteration": 127, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-04-49", "timestamp": 1694840689, "time_this_iter_s": 30.626909732818604, "time_total_s": 3972.0153539180756, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb80eba170>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3972.0153539180756, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 26.838636363636365, "ram_util_percent": 56.74090909090912}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6809815950920245, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.09202453987730061, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04294478527607362, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.09202453987730061, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.147239263803681, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.04294478527607362, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.09202453987730061, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04294478527607362, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4193974641462167, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.031483392093893295, "policy_loss": -0.06633229337312514, "vf_loss": 0.028802369121694937, "vf_explained_var": 0.7747469081232945, "kl": 0.009390282198736378, "entropy": 0.9445196652164062, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 122400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.503050913165013, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.037628241693406984, "policy_loss": -0.07656509464407767, "vf_loss": 0.02970730712113436, "vf_explained_var": 0.5952129634718101, "kl": 0.011142661324481844, "entropy": 1.3011760619779429, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 122400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.08499999999999996, "episode_reward_mean": 1.6017055214723925, "episode_len_mean": 26.79754601226994, "episode_media": {}, "episodes_this_iter": 163, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.467}, "policy_reward_mean": {"red_0": 1.1343496932515338, "blue_0": 0.4673558282208589}, "custom_metrics": {"red_0/door_open_done_mean": 0.6809815950920245, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.09202453987730061, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04294478527607362, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.09202453987730061, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.147239263803681, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.04294478527607362, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.09202453987730061, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04294478527607362, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.943, 1.96, 1.954, 1.9569999999999999, 0.46499999999999997, -0.028000000000000025, 1.438, 1.954, 1.947, 1.9609999999999999, 1.451, 1.957, 1.96, 1.959, -0.03300000000000003, 0.9029999999999999, 0.976, 0.45399999999999996, 1.955, 0.944, 1.915, 1.413, 1.958, 1.951, 1.9409999999999998, -0.08499999999999996, 1.446, 1.424, 1.4409999999999998, 0.46199999999999997, 1.958, 1.9449999999999998, 1.939, 1.912, -0.08399999999999996, 1.958, 1.951, 1.4489999999999998, -0.041999999999999926, 1.4529999999999998, 1.956, 1.954, 0.9119999999999999, 1.9449999999999998, 1.9580000000000002, 1.951, 1.96, -0.027999999999999914, 1.448, 1.9609999999999999, 0.4670000000000001, 1.96, 1.934, 1.943, 0.46499999999999986, 0.9319999999999999, 1.929, 1.88, 1.448, 1.955, 1.454, 0.43999999999999995, 1.939, 1.9489999999999998, 0.42499999999999993, 1.954, 1.954, 1.451, 1.452, 1.951, 1.958, 0.46799999999999997, 1.953, 1.958, 1.956, 1.9489999999999998, 1.956, 1.4569999999999999, 1.96, 0.46199999999999997, 1.9609999999999999, 1.447, 1.455, 1.948, 1.412, 1.96, 1.956, 1.9609999999999999, 1.9609999999999999, 1.947, 1.454, 1.96, 1.439, 0.9349999999999999, 1.9609999999999999, 1.954, 1.954, 1.954, 1.439, 1.946, 1.946, 1.928, 1.953, 1.442, 1.4609999999999999, 1.45, 1.44, 1.9449999999999998, 1.454, -0.025000000000000022, 1.942, 1.9449999999999998, 1.9380000000000002, 1.959, 1.96, 0.967, 1.955, 1.954, 1.44, 1.9489999999999998, 1.9569999999999999, 1.934, 1.9529999999999998, 0.9329999999999999, 1.955, 1.937, 1.96, 1.9609999999999999, 1.9609999999999999, 1.9369999999999998, 1.955, 1.958, 1.8980000000000001, 1.9609999999999999, 1.932, 1.947, 1.446, 1.46, 0.42599999999999993, 1.459, 1.944, 1.955, 1.443, 1.916, 0.43599999999999994, 1.958, 1.95, 1.958, 1.959, 1.958, 1.943, 1.4449999999999998, 1.954, 1.923, 1.958, 1.942, 1.9569999999999999, 1.947, 1.9300000000000002, 0.9569999999999999, 1.451, 1.944, 0.9550000000000001], "episode_lengths": [19, 13, 15, 14, 11, 9, 20, 15, 17, 13, 16, 14, 13, 13, 11, 300, 8, 15, 15, 17, 26, 27, 14, 16, 19, 28, 17, 24, 18, 12, 14, 18, 20, 28, 26, 14, 16, 16, 13, 15, 14, 15, 28, 18, 13, 15, 13, 9, 16, 13, 11, 13, 21, 19, 11, 22, 23, 38, 17, 15, 15, 19, 20, 17, 300, 15, 14, 15, 15, 16, 14, 10, 15, 14, 14, 17, 14, 14, 13, 12, 13, 17, 15, 17, 29, 13, 14, 13, 13, 17, 15, 13, 19, 300, 13, 15, 15, 15, 20, 17, 18, 22, 15, 19, 13, 16, 19, 17, 15, 8, 19, 18, 19, 13, 13, 11, 14, 15, 19, 17, 14, 21, 15, 300, 15, 20, 13, 13, 13, 20, 15, 13, 32, 13, 21, 17, 17, 13, 300, 13, 18, 14, 18, 27, 300, 14, 16, 14, 13, 14, 18, 18, 15, 25, 14, 18, 14, 17, 22, 14, 16, 18, 14], "policy_red_0_reward": [1.443, 1.4609999999999999, 0.499, 1.458, -0.501, 0.972, 1.439, 1.455, 1.448, 0.5, 1.452, 1.458, 1.4609999999999999, 1.4609999999999999, -1.0, 0.44199999999999995, 1.476, -0.5, 0.5, 1.447, 1.42, 1.4180000000000001, 0.5, 1.452, 1.443, 0.916, 1.448, 1.428, 1.444, 1.464, 1.458, 1.446, 1.44, 1.415, 0.918, 1.458, 0.5, 1.451, -1.002, 1.455, 1.458, 1.455, 1.4140000000000001, 1.4449999999999998, 1.4609999999999999, 1.454, 1.4609999999999999, 0.973, 1.452, 1.4609999999999999, 1.467, 1.4609999999999999, 1.435, 1.443, 1.467, -0.502, 1.431, 1.381, 1.4489999999999998, 1.455, 1.454, 1.442, 1.44, 1.4489999999999998, -0.04000000000000003, 0.499, 1.4569999999999999, -0.004, 1.455, 1.452, 1.458, -0.5, 1.455, 1.458, 1.458, 0.5, 1.458, 0.0, 1.4609999999999999, 0.963, 1.4609999999999999, 1.448, 1.455, 1.4489999999999998, 0.0, 1.4609999999999999, 1.458, 0.5, 1.4609999999999999, 1.448, 1.454, 1.4609999999999999, 1.442, 0.471, 1.4609999999999999, 0.499, 0.499, 1.455, 0.0, 1.448, 0.5, 1.432, 1.455, 1.443, 0.0, 1.452, -0.001, 1.447, 1.455, 0.975, 1.443, 1.446, 1.442, 1.4609999999999999, 1.4609999999999999, -0.5, 1.4569999999999999, 0.499, 1.443, 1.4489999999999998, 1.458, 1.435, 1.454, 0.46699999999999997, 1.455, 1.44, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.44, 1.455, 1.4609999999999999, 1.401, 0.5, 1.436, 1.4489999999999998, 1.4489999999999998, -0.001, -0.03900000000000003, -0.002, 1.444, 1.4569999999999999, 1.4449999999999998, 1.4180000000000001, 0.45599999999999996, 0.5, 1.451, 1.458, 1.4609999999999999, 0.5, 1.4449999999999998, 1.446, 1.455, 0.499, 1.458, 1.444, 1.458, 1.448, 1.4329999999999998, 1.458, 1.452, 1.4449999999999998, 1.458], "policy_blue_0_reward": [0.5, 0.499, 1.455, 0.499, 0.966, -1.0, -0.001, 0.499, 0.499, 1.4609999999999999, -0.001, 0.499, 0.499, 0.498, 0.967, 0.46099999999999997, -0.5, 0.954, 1.455, -0.503, 0.495, -0.005, 1.458, 0.499, 0.498, -1.001, -0.002, -0.004, -0.003, -1.002, 0.5, 0.499, 0.499, 0.497, -1.002, 0.5, 1.451, -0.002, 0.96, -0.002, 0.498, 0.499, -0.502, 0.5, 0.497, 0.497, 0.499, -1.001, -0.004, 0.5, -1.0, 0.499, 0.499, 0.5, -1.002, 1.434, 0.498, 0.499, -0.001, 0.5, 0.0, -1.002, 0.499, 0.5, 0.46499999999999997, 1.455, 0.497, 1.455, -0.003, 0.499, 0.5, 0.968, 0.498, 0.5, 0.498, 1.4489999999999998, 0.498, 1.4569999999999999, 0.499, -0.501, 0.5, -0.001, 0.0, 0.499, 1.412, 0.499, 0.498, 1.4609999999999999, 0.5, 0.499, 0.0, 0.499, -0.003, 0.46399999999999997, 0.5, 1.455, 1.455, 0.499, 1.439, 0.498, 1.446, 0.496, 0.498, -0.001, 1.4609999999999999, -0.002, 1.4409999999999998, 0.498, -0.001, -1.0, 0.499, 0.499, 0.496, 0.498, 0.499, 1.467, 0.498, 1.455, -0.003, 0.5, 0.499, 0.499, 0.499, 0.46599999999999997, 0.5, 0.497, 0.499, 0.5, 0.5, 0.497, 0.5, 0.497, 0.497, 1.4609999999999999, 0.496, 0.498, -0.003, 1.4609999999999999, 0.46499999999999997, 1.4609999999999999, 0.5, 0.498, -0.002, 0.498, -0.02000000000000001, 1.458, 0.499, 0.5, 0.498, 1.458, 0.498, -0.001, 0.499, 1.424, 0.5, 0.498, 0.499, 0.499, 0.497, -0.501, -0.001, 0.499, -0.503]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4262503417316013, "mean_inference_ms": 7.469229888931144, "mean_action_processing_ms": 0.39018612037457145, "mean_env_wait_ms": 0.5226219894619691, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14507829045956852, "StateBufferConnector_ms": 0.04051404496643441, "ViewRequirementAgentConnector_ms": 0.1783759316052396}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.08499999999999996, "episode_reward_mean": 1.6017055214723925, "episode_len_mean": 26.79754601226994, "episodes_this_iter": 163, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.467}, "policy_reward_mean": {"red_0": 1.1343496932515338, "blue_0": 0.4673558282208589}, "hist_stats": {"episode_reward": [1.943, 1.96, 1.954, 1.9569999999999999, 0.46499999999999997, -0.028000000000000025, 1.438, 1.954, 1.947, 1.9609999999999999, 1.451, 1.957, 1.96, 1.959, -0.03300000000000003, 0.9029999999999999, 0.976, 0.45399999999999996, 1.955, 0.944, 1.915, 1.413, 1.958, 1.951, 1.9409999999999998, -0.08499999999999996, 1.446, 1.424, 1.4409999999999998, 0.46199999999999997, 1.958, 1.9449999999999998, 1.939, 1.912, -0.08399999999999996, 1.958, 1.951, 1.4489999999999998, -0.041999999999999926, 1.4529999999999998, 1.956, 1.954, 0.9119999999999999, 1.9449999999999998, 1.9580000000000002, 1.951, 1.96, -0.027999999999999914, 1.448, 1.9609999999999999, 0.4670000000000001, 1.96, 1.934, 1.943, 0.46499999999999986, 0.9319999999999999, 1.929, 1.88, 1.448, 1.955, 1.454, 0.43999999999999995, 1.939, 1.9489999999999998, 0.42499999999999993, 1.954, 1.954, 1.451, 1.452, 1.951, 1.958, 0.46799999999999997, 1.953, 1.958, 1.956, 1.9489999999999998, 1.956, 1.4569999999999999, 1.96, 0.46199999999999997, 1.9609999999999999, 1.447, 1.455, 1.948, 1.412, 1.96, 1.956, 1.9609999999999999, 1.9609999999999999, 1.947, 1.454, 1.96, 1.439, 0.9349999999999999, 1.9609999999999999, 1.954, 1.954, 1.954, 1.439, 1.946, 1.946, 1.928, 1.953, 1.442, 1.4609999999999999, 1.45, 1.44, 1.9449999999999998, 1.454, -0.025000000000000022, 1.942, 1.9449999999999998, 1.9380000000000002, 1.959, 1.96, 0.967, 1.955, 1.954, 1.44, 1.9489999999999998, 1.9569999999999999, 1.934, 1.9529999999999998, 0.9329999999999999, 1.955, 1.937, 1.96, 1.9609999999999999, 1.9609999999999999, 1.9369999999999998, 1.955, 1.958, 1.8980000000000001, 1.9609999999999999, 1.932, 1.947, 1.446, 1.46, 0.42599999999999993, 1.459, 1.944, 1.955, 1.443, 1.916, 0.43599999999999994, 1.958, 1.95, 1.958, 1.959, 1.958, 1.943, 1.4449999999999998, 1.954, 1.923, 1.958, 1.942, 1.9569999999999999, 1.947, 1.9300000000000002, 0.9569999999999999, 1.451, 1.944, 0.9550000000000001], "episode_lengths": [19, 13, 15, 14, 11, 9, 20, 15, 17, 13, 16, 14, 13, 13, 11, 300, 8, 15, 15, 17, 26, 27, 14, 16, 19, 28, 17, 24, 18, 12, 14, 18, 20, 28, 26, 14, 16, 16, 13, 15, 14, 15, 28, 18, 13, 15, 13, 9, 16, 13, 11, 13, 21, 19, 11, 22, 23, 38, 17, 15, 15, 19, 20, 17, 300, 15, 14, 15, 15, 16, 14, 10, 15, 14, 14, 17, 14, 14, 13, 12, 13, 17, 15, 17, 29, 13, 14, 13, 13, 17, 15, 13, 19, 300, 13, 15, 15, 15, 20, 17, 18, 22, 15, 19, 13, 16, 19, 17, 15, 8, 19, 18, 19, 13, 13, 11, 14, 15, 19, 17, 14, 21, 15, 300, 15, 20, 13, 13, 13, 20, 15, 13, 32, 13, 21, 17, 17, 13, 300, 13, 18, 14, 18, 27, 300, 14, 16, 14, 13, 14, 18, 18, 15, 25, 14, 18, 14, 17, 22, 14, 16, 18, 14], "policy_red_0_reward": [1.443, 1.4609999999999999, 0.499, 1.458, -0.501, 0.972, 1.439, 1.455, 1.448, 0.5, 1.452, 1.458, 1.4609999999999999, 1.4609999999999999, -1.0, 0.44199999999999995, 1.476, -0.5, 0.5, 1.447, 1.42, 1.4180000000000001, 0.5, 1.452, 1.443, 0.916, 1.448, 1.428, 1.444, 1.464, 1.458, 1.446, 1.44, 1.415, 0.918, 1.458, 0.5, 1.451, -1.002, 1.455, 1.458, 1.455, 1.4140000000000001, 1.4449999999999998, 1.4609999999999999, 1.454, 1.4609999999999999, 0.973, 1.452, 1.4609999999999999, 1.467, 1.4609999999999999, 1.435, 1.443, 1.467, -0.502, 1.431, 1.381, 1.4489999999999998, 1.455, 1.454, 1.442, 1.44, 1.4489999999999998, -0.04000000000000003, 0.499, 1.4569999999999999, -0.004, 1.455, 1.452, 1.458, -0.5, 1.455, 1.458, 1.458, 0.5, 1.458, 0.0, 1.4609999999999999, 0.963, 1.4609999999999999, 1.448, 1.455, 1.4489999999999998, 0.0, 1.4609999999999999, 1.458, 0.5, 1.4609999999999999, 1.448, 1.454, 1.4609999999999999, 1.442, 0.471, 1.4609999999999999, 0.499, 0.499, 1.455, 0.0, 1.448, 0.5, 1.432, 1.455, 1.443, 0.0, 1.452, -0.001, 1.447, 1.455, 0.975, 1.443, 1.446, 1.442, 1.4609999999999999, 1.4609999999999999, -0.5, 1.4569999999999999, 0.499, 1.443, 1.4489999999999998, 1.458, 1.435, 1.454, 0.46699999999999997, 1.455, 1.44, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.44, 1.455, 1.4609999999999999, 1.401, 0.5, 1.436, 1.4489999999999998, 1.4489999999999998, -0.001, -0.03900000000000003, -0.002, 1.444, 1.4569999999999999, 1.4449999999999998, 1.4180000000000001, 0.45599999999999996, 0.5, 1.451, 1.458, 1.4609999999999999, 0.5, 1.4449999999999998, 1.446, 1.455, 0.499, 1.458, 1.444, 1.458, 1.448, 1.4329999999999998, 1.458, 1.452, 1.4449999999999998, 1.458], "policy_blue_0_reward": [0.5, 0.499, 1.455, 0.499, 0.966, -1.0, -0.001, 0.499, 0.499, 1.4609999999999999, -0.001, 0.499, 0.499, 0.498, 0.967, 0.46099999999999997, -0.5, 0.954, 1.455, -0.503, 0.495, -0.005, 1.458, 0.499, 0.498, -1.001, -0.002, -0.004, -0.003, -1.002, 0.5, 0.499, 0.499, 0.497, -1.002, 0.5, 1.451, -0.002, 0.96, -0.002, 0.498, 0.499, -0.502, 0.5, 0.497, 0.497, 0.499, -1.001, -0.004, 0.5, -1.0, 0.499, 0.499, 0.5, -1.002, 1.434, 0.498, 0.499, -0.001, 0.5, 0.0, -1.002, 0.499, 0.5, 0.46499999999999997, 1.455, 0.497, 1.455, -0.003, 0.499, 0.5, 0.968, 0.498, 0.5, 0.498, 1.4489999999999998, 0.498, 1.4569999999999999, 0.499, -0.501, 0.5, -0.001, 0.0, 0.499, 1.412, 0.499, 0.498, 1.4609999999999999, 0.5, 0.499, 0.0, 0.499, -0.003, 0.46399999999999997, 0.5, 1.455, 1.455, 0.499, 1.439, 0.498, 1.446, 0.496, 0.498, -0.001, 1.4609999999999999, -0.002, 1.4409999999999998, 0.498, -0.001, -1.0, 0.499, 0.499, 0.496, 0.498, 0.499, 1.467, 0.498, 1.455, -0.003, 0.5, 0.499, 0.499, 0.499, 0.46599999999999997, 0.5, 0.497, 0.499, 0.5, 0.5, 0.497, 0.5, 0.497, 0.497, 1.4609999999999999, 0.496, 0.498, -0.003, 1.4609999999999999, 0.46499999999999997, 1.4609999999999999, 0.5, 0.498, -0.002, 0.498, -0.02000000000000001, 1.458, 0.499, 0.5, 0.498, 1.458, 0.498, -0.001, 0.499, 1.424, 0.5, 0.498, 0.499, 0.499, 0.497, -0.501, -0.001, 0.499, -0.503]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4262503417316013, "mean_inference_ms": 7.469229888931144, "mean_action_processing_ms": 0.39018612037457145, "mean_env_wait_ms": 0.5226219894619691, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14507829045956852, "StateBufferConnector_ms": 0.04051404496643441, "ViewRequirementAgentConnector_ms": 0.1783759316052396}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 134.99374765803708, "num_env_steps_trained_throughput_per_sec": 134.99374765803708, "timesteps_total": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 31125.549, "sample_time_ms": 3979.973, "learn_time_ms": 27115.558, "learn_throughput": 147.517, "synch_weights_time_ms": 28.522}, "counters": {"num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "episodes_total": 10772, "training_iteration": 128, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-05-19", "timestamp": 1694840719, "time_this_iter_s": 29.649379014968872, "time_total_s": 4001.6647329330444, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a2e8280>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4001.6647329330444, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 23.897674418604648, "ram_util_percent": 56.73488372093022}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6573033707865169, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.06741573033707865, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.056179775280898875, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.06741573033707865, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.21348314606741572, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.056179775280898875, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.06741573033707865, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.056179775280898875, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45560345947742464, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.031048546701398057, "policy_loss": -0.06886594270423908, "vf_loss": 0.03524064551165793, "vf_explained_var": 0.7266053502758344, "kl": 0.009235267978323646, "entropy": 0.8420220989113053, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 123360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4688123416621238, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.041889332487092666, "policy_loss": -0.0792108198608427, "vf_loss": 0.03400757303849484, "vf_explained_var": 0.613590278228124, "kl": 0.00946701094756813, "entropy": 1.2493344642221929, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 123360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 1032000, "num_agent_steps_trained": 1032000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.05600000000000005, "episode_reward_mean": 1.6620842696629214, "episode_len_mean": 21.640449438202246, "episode_media": {}, "episodes_this_iter": 178, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.464}, "policy_reward_mean": {"red_0": 1.077567415730337, "blue_0": 0.5845168539325841}, "custom_metrics": {"red_0/door_open_done_mean": 0.6573033707865169, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.06741573033707865, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.056179775280898875, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.06741573033707865, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.21348314606741572, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.056179775280898875, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.06741573033707865, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.056179775280898875, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.943, 1.948, 1.9289999999999998, 1.955, 1.45, 1.96, 1.45, 1.939, 1.9569999999999999, 1.955, 1.433, 0.45799999999999996, 1.4489999999999998, 1.9409999999999998, 1.4569999999999999, 1.4569999999999999, 1.9569999999999999, 1.9609999999999999, 1.9529999999999998, 1.947, 0.942, 1.952, 1.954, 1.948, 1.416, 1.451, 0.45899999999999996, 1.954, 1.4489999999999998, 1.405, 1.866, 1.9609999999999999, 1.9609999999999999, 1.9609999999999999, 1.454, 0.9550000000000001, 1.959, -0.026000000000000023, 1.954, 0.369, 0.9590000000000001, 1.9489999999999998, 1.9489999999999998, 1.452, 1.9609999999999999, 1.957, 1.948, 1.9569999999999999, 1.4609999999999999, 1.9449999999999998, 1.9609999999999999, 1.958, 1.905, 1.9609999999999999, 1.921, 0.472, 1.939, 1.9449999999999998, 1.454, 1.9449999999999998, -0.02499999999999991, 1.9529999999999998, 1.9449999999999998, 1.915, 1.938, 1.9529999999999998, 1.954, 1.9569999999999999, 1.93, 1.944, 0.946, 1.9609999999999999, 1.448, 1.951, 1.451, 0.9750000000000001, 1.4489999999999998, 1.9609999999999999, 1.9609999999999999, 1.931, 1.96, 0.951, 1.9249999999999998, -0.05600000000000005, 1.946, 1.96, 0.9689999999999999, 1.2079999999999997, 1.948, 1.9609999999999999, 1.393, 0.9570000000000001, 1.948, 1.9609999999999999, 1.951, 1.955, 1.9300000000000002, 1.9449999999999998, 1.931, 1.952, 1.947, 1.9249999999999998, 1.9609999999999999, 1.958, 1.948, 1.96, 0.922, 1.3940000000000001, 1.96, 1.947, 0.96, 1.43, 1.947, 1.9609999999999999, 1.935, 1.951, 1.944, 1.8239999999999998, 1.9529999999999998, 1.954, 1.438, 1.958, 1.95, 1.955, 1.96, 0.46799999999999997, 1.96, 1.9529999999999998, 1.9449999999999998, 1.9609999999999999, 1.939, 1.8559999999999999, 1.956, 1.458, 1.452, -0.02400000000000002, 1.9609999999999999, 1.9489999999999998, 1.95, 1.948, 1.431, 1.9609999999999999, 1.958, 1.946, 1.43, 1.366, 1.946, 1.916, 1.959, 0.406, 1.955, 1.96, 1.427, 1.426, 1.9529999999999998, 1.9249999999999998, 1.96, 1.454, 1.957, 1.444, 1.458, 1.455, 1.9609999999999999, 1.915, 1.96, 1.946, 0.5389999999999999, 1.9609999999999999, 1.952, 1.4569999999999999, 1.958, 0.46199999999999997, 1.96, 1.955, 1.458, 1.943, 1.459, 0.46299999999999997], "episode_lengths": [300, 17, 22, 15, 16, 13, 16, 20, 14, 15, 20, 13, 17, 19, 14, 14, 14, 13, 15, 17, 19, 16, 15, 17, 26, 16, 13, 15, 16, 30, 43, 13, 13, 13, 15, 14, 13, 8, 15, 42, 13, 17, 17, 16, 13, 13, 16, 14, 13, 18, 13, 14, 30, 13, 25, 9, 20, 18, 15, 18, 8, 15, 18, 26, 20, 15, 15, 14, 22, 18, 17, 13, 17, 16, 16, 8, 16, 13, 13, 22, 13, 16, 24, 18, 17, 13, 10, 243, 17, 13, 34, 14, 17, 13, 16, 15, 23, 18, 21, 15, 17, 24, 13, 14, 17, 13, 25, 33, 13, 17, 13, 22, 17, 13, 21, 16, 18, 56, 15, 15, 20, 14, 16, 15, 13, 10, 13, 15, 18, 13, 20, 47, 14, 14, 16, 8, 13, 17, 16, 17, 22, 13, 14, 18, 21, 44, 17, 26, 13, 29, 15, 13, 23, 24, 15, 24, 13, 15, 14, 18, 14, 15, 13, 27, 13, 18, 294, 13, 16, 14, 14, 12, 13, 14, 14, 18, 13, 12], "policy_red_0_reward": [0.469, 1.4489999999999998, 1.432, 0.5, -0.001, 1.4609999999999999, 1.451, 1.44, 1.4569999999999999, 1.455, 1.44, 0.959, 1.4489999999999998, 1.4409999999999998, 1.458, 1.458, 0.5, 1.4609999999999999, 1.455, 0.498, -0.501, 0.5, 1.454, 1.4489999999999998, 1.4180000000000001, 1.452, -1.0, 0.499, 1.452, 1.4060000000000001, 1.3679999999999999, 0.5, 1.4609999999999999, 1.4609999999999999, 0.0, 1.455, 1.4609999999999999, -1.0, 0.499, -0.501, 1.4609999999999999, 1.4489999999999998, 1.4489999999999998, 1.452, 1.4609999999999999, 1.4609999999999999, 1.452, 1.4569999999999999, 1.4609999999999999, 0.5, 1.4609999999999999, 0.5, 0.498, 0.5, 0.498, 1.4729999999999999, 1.44, 1.446, -0.001, 1.446, -1.0, 1.455, 1.446, 1.42, 1.44, 0.498, 0.499, 1.458, 1.432, 1.446, 1.447, 0.5, 1.4489999999999998, 1.451, 1.451, 1.476, 1.451, 1.4609999999999999, 1.4609999999999999, 1.4329999999999998, 1.4609999999999999, -0.501, 1.428, 0.946, 0.498, 1.4609999999999999, 1.47, 0.7349999999999999, 1.448, 1.4609999999999999, -0.001, 1.458, 1.4489999999999998, 1.4609999999999999, 1.452, 1.455, 1.431, 1.446, 1.435, 0.498, 1.4489999999999998, 0.499, 0.5, 0.5, 1.448, 1.4609999999999999, -0.502, 1.396, 1.4609999999999999, 1.4489999999999998, 1.4609999999999999, 1.434, 1.4489999999999998, 1.4609999999999999, 1.436, 1.451, 1.446, 1.329, 0.499, 0.5, 1.439, 1.458, 1.452, 1.455, 1.4609999999999999, 1.47, 1.4609999999999999, 1.455, 1.446, 0.5, 1.44, 0.499, 1.4569999999999999, 1.458, 1.452, 0.976, 1.4609999999999999, 1.4489999999999998, 1.451, 1.448, -0.001, 1.4609999999999999, 0.5, 1.446, -0.005, -0.001, 0.5, 0.496, 1.4609999999999999, -1.003, 1.455, 1.4609999999999999, 1.429, 0.0, 0.498, 1.428, 1.4609999999999999, 1.455, 1.458, 1.4449999999999998, 1.458, 1.455, 1.4609999999999999, 1.4180000000000001, 0.499, 1.446, 0.568, 0.5, 1.452, 1.458, 1.458, -0.5, 1.4609999999999999, 1.4569999999999999, 1.458, 1.4449999999999998, 1.4609999999999999, -1.001], "policy_blue_0_reward": [0.474, 0.499, 0.497, 1.455, 1.451, 0.499, -0.001, 0.499, 0.5, 0.5, -0.007, -0.501, 0.0, 0.5, -0.001, -0.001, 1.4569999999999999, 0.5, 0.498, 1.4489999999999998, 1.443, 1.452, 0.5, 0.499, -0.002, -0.001, 1.459, 1.455, -0.003, -0.001, 0.498, 1.4609999999999999, 0.5, 0.5, 1.454, -0.5, 0.498, 0.974, 1.455, 0.87, -0.5019999999999999, 0.5, 0.5, 0.0, 0.5, 0.496, 0.496, 0.5, 0.0, 1.4449999999999998, 0.5, 1.458, 1.407, 1.4609999999999999, 1.423, -1.001, 0.499, 0.499, 1.455, 0.499, 0.975, 0.498, 0.499, 0.495, 0.498, 1.455, 1.455, 0.499, 0.498, 0.498, -0.501, 1.4609999999999999, -0.001, 0.5, 0.0, -0.501, -0.002, 0.5, 0.5, 0.498, 0.499, 1.452, 0.497, -1.002, 1.448, 0.499, -0.501, 0.473, 0.5, 0.5, 1.3940000000000001, -0.5009999999999999, 0.499, 0.5, 0.499, 0.5, 0.499, 0.499, 0.496, 1.454, 0.498, 1.426, 1.4609999999999999, 1.458, 0.5, 0.499, 1.424, -0.002, 0.499, 0.498, -0.501, -0.004, 0.498, 0.5, 0.499, 0.5, 0.498, 0.495, 1.454, 1.454, -0.001, 0.5, 0.498, 0.5, 0.499, -1.002, 0.499, 0.498, 0.499, 1.4609999999999999, 0.499, 1.357, 0.499, 0.0, 0.0, -1.0, 0.5, 0.5, 0.499, 0.5, 1.432, 0.5, 1.458, 0.5, 1.435, 1.367, 1.446, 1.42, 0.498, 1.409, 0.5, 0.499, -0.002, 1.426, 1.455, 0.497, 0.499, -0.001, 0.499, -0.001, 0.0, 0.0, 0.5, 0.497, 1.4609999999999999, 0.5, -0.02900000000000002, 1.4609999999999999, 0.5, -0.001, 0.5, 0.962, 0.499, 0.498, 0.0, 0.498, -0.002, 1.464]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4276073902024875, "mean_inference_ms": 7.451780267550865, "mean_action_processing_ms": 0.3901958699504684, "mean_env_wait_ms": 0.5224894532070066, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13204498237438417, "StateBufferConnector_ms": 0.008748823337340624, "ViewRequirementAgentConnector_ms": 0.1706336991170819}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.05600000000000005, "episode_reward_mean": 1.6620842696629214, "episode_len_mean": 21.640449438202246, "episodes_this_iter": 178, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.464}, "policy_reward_mean": {"red_0": 1.077567415730337, "blue_0": 0.5845168539325841}, "hist_stats": {"episode_reward": [0.943, 1.948, 1.9289999999999998, 1.955, 1.45, 1.96, 1.45, 1.939, 1.9569999999999999, 1.955, 1.433, 0.45799999999999996, 1.4489999999999998, 1.9409999999999998, 1.4569999999999999, 1.4569999999999999, 1.9569999999999999, 1.9609999999999999, 1.9529999999999998, 1.947, 0.942, 1.952, 1.954, 1.948, 1.416, 1.451, 0.45899999999999996, 1.954, 1.4489999999999998, 1.405, 1.866, 1.9609999999999999, 1.9609999999999999, 1.9609999999999999, 1.454, 0.9550000000000001, 1.959, -0.026000000000000023, 1.954, 0.369, 0.9590000000000001, 1.9489999999999998, 1.9489999999999998, 1.452, 1.9609999999999999, 1.957, 1.948, 1.9569999999999999, 1.4609999999999999, 1.9449999999999998, 1.9609999999999999, 1.958, 1.905, 1.9609999999999999, 1.921, 0.472, 1.939, 1.9449999999999998, 1.454, 1.9449999999999998, -0.02499999999999991, 1.9529999999999998, 1.9449999999999998, 1.915, 1.938, 1.9529999999999998, 1.954, 1.9569999999999999, 1.93, 1.944, 0.946, 1.9609999999999999, 1.448, 1.951, 1.451, 0.9750000000000001, 1.4489999999999998, 1.9609999999999999, 1.9609999999999999, 1.931, 1.96, 0.951, 1.9249999999999998, -0.05600000000000005, 1.946, 1.96, 0.9689999999999999, 1.2079999999999997, 1.948, 1.9609999999999999, 1.393, 0.9570000000000001, 1.948, 1.9609999999999999, 1.951, 1.955, 1.9300000000000002, 1.9449999999999998, 1.931, 1.952, 1.947, 1.9249999999999998, 1.9609999999999999, 1.958, 1.948, 1.96, 0.922, 1.3940000000000001, 1.96, 1.947, 0.96, 1.43, 1.947, 1.9609999999999999, 1.935, 1.951, 1.944, 1.8239999999999998, 1.9529999999999998, 1.954, 1.438, 1.958, 1.95, 1.955, 1.96, 0.46799999999999997, 1.96, 1.9529999999999998, 1.9449999999999998, 1.9609999999999999, 1.939, 1.8559999999999999, 1.956, 1.458, 1.452, -0.02400000000000002, 1.9609999999999999, 1.9489999999999998, 1.95, 1.948, 1.431, 1.9609999999999999, 1.958, 1.946, 1.43, 1.366, 1.946, 1.916, 1.959, 0.406, 1.955, 1.96, 1.427, 1.426, 1.9529999999999998, 1.9249999999999998, 1.96, 1.454, 1.957, 1.444, 1.458, 1.455, 1.9609999999999999, 1.915, 1.96, 1.946, 0.5389999999999999, 1.9609999999999999, 1.952, 1.4569999999999999, 1.958, 0.46199999999999997, 1.96, 1.955, 1.458, 1.943, 1.459, 0.46299999999999997], "episode_lengths": [300, 17, 22, 15, 16, 13, 16, 20, 14, 15, 20, 13, 17, 19, 14, 14, 14, 13, 15, 17, 19, 16, 15, 17, 26, 16, 13, 15, 16, 30, 43, 13, 13, 13, 15, 14, 13, 8, 15, 42, 13, 17, 17, 16, 13, 13, 16, 14, 13, 18, 13, 14, 30, 13, 25, 9, 20, 18, 15, 18, 8, 15, 18, 26, 20, 15, 15, 14, 22, 18, 17, 13, 17, 16, 16, 8, 16, 13, 13, 22, 13, 16, 24, 18, 17, 13, 10, 243, 17, 13, 34, 14, 17, 13, 16, 15, 23, 18, 21, 15, 17, 24, 13, 14, 17, 13, 25, 33, 13, 17, 13, 22, 17, 13, 21, 16, 18, 56, 15, 15, 20, 14, 16, 15, 13, 10, 13, 15, 18, 13, 20, 47, 14, 14, 16, 8, 13, 17, 16, 17, 22, 13, 14, 18, 21, 44, 17, 26, 13, 29, 15, 13, 23, 24, 15, 24, 13, 15, 14, 18, 14, 15, 13, 27, 13, 18, 294, 13, 16, 14, 14, 12, 13, 14, 14, 18, 13, 12], "policy_red_0_reward": [0.469, 1.4489999999999998, 1.432, 0.5, -0.001, 1.4609999999999999, 1.451, 1.44, 1.4569999999999999, 1.455, 1.44, 0.959, 1.4489999999999998, 1.4409999999999998, 1.458, 1.458, 0.5, 1.4609999999999999, 1.455, 0.498, -0.501, 0.5, 1.454, 1.4489999999999998, 1.4180000000000001, 1.452, -1.0, 0.499, 1.452, 1.4060000000000001, 1.3679999999999999, 0.5, 1.4609999999999999, 1.4609999999999999, 0.0, 1.455, 1.4609999999999999, -1.0, 0.499, -0.501, 1.4609999999999999, 1.4489999999999998, 1.4489999999999998, 1.452, 1.4609999999999999, 1.4609999999999999, 1.452, 1.4569999999999999, 1.4609999999999999, 0.5, 1.4609999999999999, 0.5, 0.498, 0.5, 0.498, 1.4729999999999999, 1.44, 1.446, -0.001, 1.446, -1.0, 1.455, 1.446, 1.42, 1.44, 0.498, 0.499, 1.458, 1.432, 1.446, 1.447, 0.5, 1.4489999999999998, 1.451, 1.451, 1.476, 1.451, 1.4609999999999999, 1.4609999999999999, 1.4329999999999998, 1.4609999999999999, -0.501, 1.428, 0.946, 0.498, 1.4609999999999999, 1.47, 0.7349999999999999, 1.448, 1.4609999999999999, -0.001, 1.458, 1.4489999999999998, 1.4609999999999999, 1.452, 1.455, 1.431, 1.446, 1.435, 0.498, 1.4489999999999998, 0.499, 0.5, 0.5, 1.448, 1.4609999999999999, -0.502, 1.396, 1.4609999999999999, 1.4489999999999998, 1.4609999999999999, 1.434, 1.4489999999999998, 1.4609999999999999, 1.436, 1.451, 1.446, 1.329, 0.499, 0.5, 1.439, 1.458, 1.452, 1.455, 1.4609999999999999, 1.47, 1.4609999999999999, 1.455, 1.446, 0.5, 1.44, 0.499, 1.4569999999999999, 1.458, 1.452, 0.976, 1.4609999999999999, 1.4489999999999998, 1.451, 1.448, -0.001, 1.4609999999999999, 0.5, 1.446, -0.005, -0.001, 0.5, 0.496, 1.4609999999999999, -1.003, 1.455, 1.4609999999999999, 1.429, 0.0, 0.498, 1.428, 1.4609999999999999, 1.455, 1.458, 1.4449999999999998, 1.458, 1.455, 1.4609999999999999, 1.4180000000000001, 0.499, 1.446, 0.568, 0.5, 1.452, 1.458, 1.458, -0.5, 1.4609999999999999, 1.4569999999999999, 1.458, 1.4449999999999998, 1.4609999999999999, -1.001], "policy_blue_0_reward": [0.474, 0.499, 0.497, 1.455, 1.451, 0.499, -0.001, 0.499, 0.5, 0.5, -0.007, -0.501, 0.0, 0.5, -0.001, -0.001, 1.4569999999999999, 0.5, 0.498, 1.4489999999999998, 1.443, 1.452, 0.5, 0.499, -0.002, -0.001, 1.459, 1.455, -0.003, -0.001, 0.498, 1.4609999999999999, 0.5, 0.5, 1.454, -0.5, 0.498, 0.974, 1.455, 0.87, -0.5019999999999999, 0.5, 0.5, 0.0, 0.5, 0.496, 0.496, 0.5, 0.0, 1.4449999999999998, 0.5, 1.458, 1.407, 1.4609999999999999, 1.423, -1.001, 0.499, 0.499, 1.455, 0.499, 0.975, 0.498, 0.499, 0.495, 0.498, 1.455, 1.455, 0.499, 0.498, 0.498, -0.501, 1.4609999999999999, -0.001, 0.5, 0.0, -0.501, -0.002, 0.5, 0.5, 0.498, 0.499, 1.452, 0.497, -1.002, 1.448, 0.499, -0.501, 0.473, 0.5, 0.5, 1.3940000000000001, -0.5009999999999999, 0.499, 0.5, 0.499, 0.5, 0.499, 0.499, 0.496, 1.454, 0.498, 1.426, 1.4609999999999999, 1.458, 0.5, 0.499, 1.424, -0.002, 0.499, 0.498, -0.501, -0.004, 0.498, 0.5, 0.499, 0.5, 0.498, 0.495, 1.454, 1.454, -0.001, 0.5, 0.498, 0.5, 0.499, -1.002, 0.499, 0.498, 0.499, 1.4609999999999999, 0.499, 1.357, 0.499, 0.0, 0.0, -1.0, 0.5, 0.5, 0.499, 0.5, 1.432, 0.5, 1.458, 0.5, 1.435, 1.367, 1.446, 1.42, 0.498, 1.409, 0.5, 0.499, -0.002, 1.426, 1.455, 0.497, 0.499, -0.001, 0.499, -0.001, 0.0, 0.0, 0.5, 0.497, 1.4609999999999999, 0.5, -0.02900000000000002, 1.4609999999999999, 0.5, -0.001, 0.5, 0.962, 0.499, 0.498, 0.0, 0.498, -0.002, 1.464]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4276073902024875, "mean_inference_ms": 7.451780267550865, "mean_action_processing_ms": 0.3901958699504684, "mean_env_wait_ms": 0.5224894532070066, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13204498237438417, "StateBufferConnector_ms": 0.008748823337340624, "ViewRequirementAgentConnector_ms": 0.1706336991170819}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1032000, "num_agent_steps_trained": 1032000, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.30528573475678, "num_env_steps_trained_throughput_per_sec": 130.30528573475678, "timesteps_total": 516000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1032000, "timers": {"training_iteration_time_ms": 31191.645, "sample_time_ms": 3966.385, "learn_time_ms": 27196.49, "learn_throughput": 147.078, "synch_weights_time_ms": 27.311}, "counters": {"num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 1032000, "num_agent_steps_trained": 1032000}, "done": false, "episodes_total": 10950, "training_iteration": 129, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-05-51", "timestamp": 1694840751, "time_this_iter_s": 30.719955921173096, "time_total_s": 4032.3846888542175, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb7234a440>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4032.3846888542175, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 26.022222222222226, "ram_util_percent": 56.7977777777778}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.676056338028169, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.11267605633802817, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04225352112676056, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.11267605633802817, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13380281690140844, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.04225352112676056, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.11267605633802817, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04225352112676056, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4269611028799166, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03535196526402918, "policy_loss": -0.06534165234188549, "vf_loss": 0.025019875393384912, "vf_explained_var": 0.7952511144181093, "kl": 0.008096670133069367, "entropy": 0.9654775279263655, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 124320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.46763376772093274, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0462757661647629, "policy_loss": -0.07950566927684122, "vf_loss": 0.027619294771769394, "vf_explained_var": 0.5857280507062872, "kl": 0.009133720674359002, "entropy": 1.3875023336460193, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 124320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.594, "episode_reward_mean": 1.5880281690140845, "episode_len_mean": 30.154929577464788, "episode_media": {}, "episodes_this_iter": 142, "policy_reward_min": {"red_0": -0.502, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 1.1550140845070422, "blue_0": 0.43301408450704226}, "custom_metrics": {"red_0/door_open_done_mean": 0.676056338028169, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.11267605633802817, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04225352112676056, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.11267605633802817, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.13380281690140844, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.04225352112676056, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.11267605633802817, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04225352112676056, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.939, 1.946, 1.936, 1.959, 1.95, 1.947, 1.431, 1.9409999999999998, 1.674, 1.956, 1.9609999999999999, 1.4609999999999999, 1.955, 1.9569999999999999, 1.4489999999999998, 1.942, 1.952, 1.9489999999999998, 1.922, 1.896, 1.46, 1.419, 1.948, 1.9300000000000002, 1.9489999999999998, 1.959, 0.46499999999999997, 1.929, 1.96, 0.41899999999999993, 0.9569999999999999, 1.96, 1.958, 1.955, 1.442, 1.927, 1.909, 1.454, 1.9609999999999999, 1.955, 1.417, 0.9159999999999999, 1.9449999999999998, -0.03500000000000003, -0.594, 1.9609999999999999, 1.9609999999999999, 0.476, 1.9580000000000002, 0.913, 0.959, 1.599, 1.4569999999999999, 1.9609999999999999, 0.962, 1.955, 1.936, 0.957, 1.9569999999999999, 1.4409999999999998, 1.415, 1.948, 1.4300000000000002, 0.961, 1.4609999999999999, 1.94, 0.945, 1.442, 1.935, 1.9609999999999999, 1.952, 1.9609999999999999, 1.951, 1.952, 1.96, 1.952, 1.939, 1.942, 1.9529999999999998, 1.452, 1.7790000000000001, 0.47299999999999986, 1.9609999999999999, 1.4569999999999999, 1.9489999999999998, 0.95, 1.949, 1.9609999999999999, 1.3519999999999999, 0.46799999999999997, 1.9409999999999998, 1.955, 1.958, 1.9580000000000002, 1.954, 1.4449999999999998, 0.955, 0.46799999999999997, -0.03400000000000003, 1.944, 1.954, 1.954, 1.423, 1.956, 1.379, 1.4449999999999998, 0.45599999999999996, 1.955, 1.958, 1.96, 1.959, 1.446, 1.931, 1.9529999999999998, 1.903, 1.93, 1.905, 1.9609999999999999, 1.948, 1.363, -0.049000000000000044, 1.9609999999999999, 1.934, -0.04700000000000004, 1.9529999999999998, 0.942, 1.956, 1.96, 0.4790000000000001, 1.956, 0.954, 1.958, 1.9569999999999999, 1.4529999999999998, 1.4489999999999998, 1.442, 1.942, 1.363, 0.9590000000000001, 1.889, 1.954, 1.96], "episode_lengths": [300, 18, 20, 13, 16, 17, 22, 19, 102, 14, 13, 13, 15, 14, 17, 19, 16, 17, 24, 34, 13, 26, 17, 23, 16, 13, 11, 23, 13, 300, 14, 13, 14, 15, 19, 23, 29, 15, 13, 15, 25, 300, 18, 11, 185, 13, 13, 8, 13, 27, 300, 123, 14, 13, 12, 15, 21, 14, 14, 19, 27, 17, 23, 13, 13, 20, 18, 18, 21, 13, 16, 13, 16, 16, 13, 16, 19, 19, 15, 16, 70, 9, 13, 14, 17, 16, 16, 13, 47, 10, 19, 15, 14, 13, 15, 18, 14, 10, 10, 18, 15, 15, 25, 14, 39, 17, 14, 15, 14, 13, 13, 17, 22, 15, 30, 22, 30, 13, 17, 44, 16, 13, 21, 15, 15, 300, 14, 13, 7, 14, 15, 14, 14, 15, 17, 18, 19, 44, 13, 34, 15, 13], "policy_red_0_reward": [0.469, 1.446, 1.439, 1.4609999999999999, 1.452, 1.448, 1.434, 1.443, 1.182, 1.458, 0.5, 1.4609999999999999, 0.5, 1.458, 0.0, 1.443, 0.5, 1.4489999999999998, 1.423, 1.397, 1.4609999999999999, 1.4220000000000002, 0.499, 1.4300000000000002, 1.45, 1.4609999999999999, -0.502, 1.431, 1.4609999999999999, -0.03000000000000002, 1.458, 1.4609999999999999, 0.5, 1.455, 1.442, 1.429, 1.411, -0.001, 1.4609999999999999, 1.455, 1.4220000000000002, 0.45699999999999996, 1.4449999999999998, 0.965, 0.42299999999999993, 1.4609999999999999, 1.4609999999999999, 1.476, 1.4609999999999999, 1.419, 0.486, 0.486, 1.458, 1.4609999999999999, 1.463, 1.455, 1.4369999999999998, -0.501, 1.4569999999999999, 1.443, 1.417, 1.4489999999999998, 1.431, -0.5, 1.4609999999999999, 1.44, -0.5, 1.444, 1.436, 1.4609999999999999, 1.452, 0.5, 1.452, 0.5, 1.4609999999999999, 1.452, 1.44, 1.443, 1.455, 1.452, 1.287, 0.973, 1.4609999999999999, 1.458, 1.4489999999999998, -0.501, 1.452, 1.4609999999999999, -0.005, 1.4689999999999999, 1.4409999999999998, 1.455, 1.458, 1.4609999999999999, 0.499, 1.446, -0.502, 1.47, 0.968, 1.446, 1.455, 1.455, 1.424, 1.458, 1.381, 1.446, 1.458, 1.455, 1.458, 1.4609999999999999, 1.4609999999999999, 1.4489999999999998, 1.434, 1.455, 1.408, 1.4329999999999998, 1.407, 1.4609999999999999, 1.4489999999999998, 1.367, 0.952, 1.4609999999999999, 1.4369999999999998, 0.954, 0.498, 0.48, 0.499, 1.4609999999999999, 1.479, 0.499, 1.454, 0.5, 1.458, -0.002, 1.4489999999999998, 1.4449999999999998, 0.5, -0.002, 1.46, 1.395, 1.455, 1.4609999999999999], "policy_blue_0_reward": [0.47, 0.5, 0.497, 0.498, 0.498, 0.499, -0.003, 0.498, 0.492, 0.498, 1.4609999999999999, 0.0, 1.455, 0.499, 1.4489999999999998, 0.499, 1.452, 0.5, 0.499, 0.499, -0.001, -0.003, 1.4489999999999998, 0.5, 0.499, 0.498, 0.967, 0.498, 0.499, 0.44899999999999995, -0.501, 0.499, 1.458, 0.5, 0.0, 0.498, 0.498, 1.455, 0.5, 0.5, -0.005, 0.45899999999999996, 0.5, -1.0, -1.017, 0.5, 0.5, -1.0, 0.497, -0.506, 0.473, 1.113, -0.001, 0.5, -0.501, 0.5, 0.499, 1.458, 0.5, -0.002, -0.002, 0.499, -0.001, 1.4609999999999999, 0.0, 0.5, 1.4449999999999998, -0.002, 0.499, 0.5, 0.5, 1.4609999999999999, 0.499, 1.452, 0.499, 0.5, 0.499, 0.499, 0.498, 0.0, 0.492, -0.5, 0.5, -0.001, 0.5, 1.451, 0.497, 0.5, 1.357, -1.001, 0.5, 0.5, 0.5, 0.497, 1.455, -0.001, 1.4569999999999999, -1.002, -1.002, 0.498, 0.499, 0.499, -0.001, 0.498, -0.002, -0.001, -1.002, 0.5, 0.5, 0.499, 0.498, -0.003, 0.497, 0.498, 0.495, 0.497, 0.498, 0.5, 0.499, -0.004, -1.001, 0.5, 0.497, -1.001, 1.455, 0.46199999999999997, 1.4569999999999999, 0.499, -1.0, 1.4569999999999999, -0.5, 1.458, 0.499, 1.455, 0.0, -0.003, 1.442, 1.365, -0.501, 0.494, 0.499, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.428539336683043, "mean_inference_ms": 7.446452948292543, "mean_action_processing_ms": 0.39014889362072613, "mean_env_wait_ms": 0.522959591762666, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14125738345401387, "StateBufferConnector_ms": 0.009538841919160225, "ViewRequirementAgentConnector_ms": 0.192673105589101}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.594, "episode_reward_mean": 1.5880281690140845, "episode_len_mean": 30.154929577464788, "episodes_this_iter": 142, "policy_reward_min": {"red_0": -0.502, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 1.1550140845070422, "blue_0": 0.43301408450704226}, "hist_stats": {"episode_reward": [0.939, 1.946, 1.936, 1.959, 1.95, 1.947, 1.431, 1.9409999999999998, 1.674, 1.956, 1.9609999999999999, 1.4609999999999999, 1.955, 1.9569999999999999, 1.4489999999999998, 1.942, 1.952, 1.9489999999999998, 1.922, 1.896, 1.46, 1.419, 1.948, 1.9300000000000002, 1.9489999999999998, 1.959, 0.46499999999999997, 1.929, 1.96, 0.41899999999999993, 0.9569999999999999, 1.96, 1.958, 1.955, 1.442, 1.927, 1.909, 1.454, 1.9609999999999999, 1.955, 1.417, 0.9159999999999999, 1.9449999999999998, -0.03500000000000003, -0.594, 1.9609999999999999, 1.9609999999999999, 0.476, 1.9580000000000002, 0.913, 0.959, 1.599, 1.4569999999999999, 1.9609999999999999, 0.962, 1.955, 1.936, 0.957, 1.9569999999999999, 1.4409999999999998, 1.415, 1.948, 1.4300000000000002, 0.961, 1.4609999999999999, 1.94, 0.945, 1.442, 1.935, 1.9609999999999999, 1.952, 1.9609999999999999, 1.951, 1.952, 1.96, 1.952, 1.939, 1.942, 1.9529999999999998, 1.452, 1.7790000000000001, 0.47299999999999986, 1.9609999999999999, 1.4569999999999999, 1.9489999999999998, 0.95, 1.949, 1.9609999999999999, 1.3519999999999999, 0.46799999999999997, 1.9409999999999998, 1.955, 1.958, 1.9580000000000002, 1.954, 1.4449999999999998, 0.955, 0.46799999999999997, -0.03400000000000003, 1.944, 1.954, 1.954, 1.423, 1.956, 1.379, 1.4449999999999998, 0.45599999999999996, 1.955, 1.958, 1.96, 1.959, 1.446, 1.931, 1.9529999999999998, 1.903, 1.93, 1.905, 1.9609999999999999, 1.948, 1.363, -0.049000000000000044, 1.9609999999999999, 1.934, -0.04700000000000004, 1.9529999999999998, 0.942, 1.956, 1.96, 0.4790000000000001, 1.956, 0.954, 1.958, 1.9569999999999999, 1.4529999999999998, 1.4489999999999998, 1.442, 1.942, 1.363, 0.9590000000000001, 1.889, 1.954, 1.96], "episode_lengths": [300, 18, 20, 13, 16, 17, 22, 19, 102, 14, 13, 13, 15, 14, 17, 19, 16, 17, 24, 34, 13, 26, 17, 23, 16, 13, 11, 23, 13, 300, 14, 13, 14, 15, 19, 23, 29, 15, 13, 15, 25, 300, 18, 11, 185, 13, 13, 8, 13, 27, 300, 123, 14, 13, 12, 15, 21, 14, 14, 19, 27, 17, 23, 13, 13, 20, 18, 18, 21, 13, 16, 13, 16, 16, 13, 16, 19, 19, 15, 16, 70, 9, 13, 14, 17, 16, 16, 13, 47, 10, 19, 15, 14, 13, 15, 18, 14, 10, 10, 18, 15, 15, 25, 14, 39, 17, 14, 15, 14, 13, 13, 17, 22, 15, 30, 22, 30, 13, 17, 44, 16, 13, 21, 15, 15, 300, 14, 13, 7, 14, 15, 14, 14, 15, 17, 18, 19, 44, 13, 34, 15, 13], "policy_red_0_reward": [0.469, 1.446, 1.439, 1.4609999999999999, 1.452, 1.448, 1.434, 1.443, 1.182, 1.458, 0.5, 1.4609999999999999, 0.5, 1.458, 0.0, 1.443, 0.5, 1.4489999999999998, 1.423, 1.397, 1.4609999999999999, 1.4220000000000002, 0.499, 1.4300000000000002, 1.45, 1.4609999999999999, -0.502, 1.431, 1.4609999999999999, -0.03000000000000002, 1.458, 1.4609999999999999, 0.5, 1.455, 1.442, 1.429, 1.411, -0.001, 1.4609999999999999, 1.455, 1.4220000000000002, 0.45699999999999996, 1.4449999999999998, 0.965, 0.42299999999999993, 1.4609999999999999, 1.4609999999999999, 1.476, 1.4609999999999999, 1.419, 0.486, 0.486, 1.458, 1.4609999999999999, 1.463, 1.455, 1.4369999999999998, -0.501, 1.4569999999999999, 1.443, 1.417, 1.4489999999999998, 1.431, -0.5, 1.4609999999999999, 1.44, -0.5, 1.444, 1.436, 1.4609999999999999, 1.452, 0.5, 1.452, 0.5, 1.4609999999999999, 1.452, 1.44, 1.443, 1.455, 1.452, 1.287, 0.973, 1.4609999999999999, 1.458, 1.4489999999999998, -0.501, 1.452, 1.4609999999999999, -0.005, 1.4689999999999999, 1.4409999999999998, 1.455, 1.458, 1.4609999999999999, 0.499, 1.446, -0.502, 1.47, 0.968, 1.446, 1.455, 1.455, 1.424, 1.458, 1.381, 1.446, 1.458, 1.455, 1.458, 1.4609999999999999, 1.4609999999999999, 1.4489999999999998, 1.434, 1.455, 1.408, 1.4329999999999998, 1.407, 1.4609999999999999, 1.4489999999999998, 1.367, 0.952, 1.4609999999999999, 1.4369999999999998, 0.954, 0.498, 0.48, 0.499, 1.4609999999999999, 1.479, 0.499, 1.454, 0.5, 1.458, -0.002, 1.4489999999999998, 1.4449999999999998, 0.5, -0.002, 1.46, 1.395, 1.455, 1.4609999999999999], "policy_blue_0_reward": [0.47, 0.5, 0.497, 0.498, 0.498, 0.499, -0.003, 0.498, 0.492, 0.498, 1.4609999999999999, 0.0, 1.455, 0.499, 1.4489999999999998, 0.499, 1.452, 0.5, 0.499, 0.499, -0.001, -0.003, 1.4489999999999998, 0.5, 0.499, 0.498, 0.967, 0.498, 0.499, 0.44899999999999995, -0.501, 0.499, 1.458, 0.5, 0.0, 0.498, 0.498, 1.455, 0.5, 0.5, -0.005, 0.45899999999999996, 0.5, -1.0, -1.017, 0.5, 0.5, -1.0, 0.497, -0.506, 0.473, 1.113, -0.001, 0.5, -0.501, 0.5, 0.499, 1.458, 0.5, -0.002, -0.002, 0.499, -0.001, 1.4609999999999999, 0.0, 0.5, 1.4449999999999998, -0.002, 0.499, 0.5, 0.5, 1.4609999999999999, 0.499, 1.452, 0.499, 0.5, 0.499, 0.499, 0.498, 0.0, 0.492, -0.5, 0.5, -0.001, 0.5, 1.451, 0.497, 0.5, 1.357, -1.001, 0.5, 0.5, 0.5, 0.497, 1.455, -0.001, 1.4569999999999999, -1.002, -1.002, 0.498, 0.499, 0.499, -0.001, 0.498, -0.002, -0.001, -1.002, 0.5, 0.5, 0.499, 0.498, -0.003, 0.497, 0.498, 0.495, 0.497, 0.498, 0.5, 0.499, -0.004, -1.001, 0.5, 0.497, -1.001, 1.455, 0.46199999999999997, 1.4569999999999999, 0.499, -1.0, 1.4569999999999999, -0.5, 1.458, 0.499, 1.455, 0.0, -0.003, 1.442, 1.365, -0.501, 0.494, 0.499, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.428539336683043, "mean_inference_ms": 7.446452948292543, "mean_action_processing_ms": 0.39014889362072613, "mean_env_wait_ms": 0.522959591762666, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.14125738345401387, "StateBufferConnector_ms": 0.009538841919160225, "ViewRequirementAgentConnector_ms": 0.192673105589101}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.84173738344177, "num_env_steps_trained_throughput_per_sec": 131.84173738344177, "timesteps_total": 520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 31120.513, "sample_time_ms": 3928.384, "learn_time_ms": 27163.258, "learn_throughput": 147.258, "synch_weights_time_ms": 27.346}, "counters": {"num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "episodes_total": 11092, "training_iteration": 130, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-06-22", "timestamp": 1694840782, "time_this_iter_s": 30.357604026794434, "time_total_s": 4062.742292881012, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a2ea7a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4062.742292881012, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 25.1, "ram_util_percent": 56.790909090909075}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5833333333333334, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.06818181818181818, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07575757575757576, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.06818181818181818, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.22727272727272727, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.07575757575757576, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.06818181818181818, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07575757575757576, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.42075327003064256, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03357459379088444, "policy_loss": -0.06468755029588162, "vf_loss": 0.025217206909534676, "vf_explained_var": 0.784921818288664, "kl": 0.008583371982036238, "entropy": 1.0496409171571335, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 125280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47229504347778856, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.043309949519850004, "policy_loss": -0.07510989829073272, "vf_loss": 0.026072786291479133, "vf_explained_var": 0.6556780685360233, "kl": 0.008812563161448324, "entropy": 1.3125648835053048, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 125280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 1048000, "num_agent_steps_trained": 1048000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.05400000000000004, "episode_reward_mean": 1.5767499999999999, "episode_len_mean": 29.568181818181817, "episode_media": {}, "episodes_this_iter": 132, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.0039999999999998}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.472}, "policy_reward_mean": {"red_0": 0.9803787878787876, "blue_0": 0.5963712121212121}, "custom_metrics": {"red_0/door_open_done_mean": 0.5833333333333334, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.06818181818181818, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07575757575757576, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.06818181818181818, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.22727272727272727, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.07575757575757576, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.06818181818181818, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07575757575757576, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.455, 1.44, 1.9489999999999998, 1.932, 0.44700000000000006, 1.948, 1.9609999999999999, 0.43499999999999994, 1.946, 1.955, 1.94, 1.948, -0.027999999999999914, 1.942, 1.448, 1.444, 1.454, 1.459, 1.424, 1.9609999999999999, 1.935, 1.4609999999999999, 1.443, 1.447, 1.947, 1.955, 1.946, 1.952, 1.96, 0.45599999999999996, 1.9609999999999999, 1.455, 1.951, 1.907, 0.961, 0.45999999999999996, 1.944, 0.469, 1.948, 1.9449999999999998, 1.928, 1.943, 0.45299999999999985, 1.946, 1.956, 1.924, 1.958, 1.938, 1.943, 1.951, 1.947, 1.956, 1.96, 1.451, 1.427, 1.9529999999999998, 1.9609999999999999, 1.9609999999999999, 1.955, 1.9489999999999998, 1.952, 1.9609999999999999, 1.4100000000000001, 1.395, 1.9609999999999999, 1.951, 1.9609999999999999, 1.939, 1.9609999999999999, -0.05400000000000004, 1.4329999999999998, 1.932, 1.438, 0.41999999999999993, 1.932, 1.9609999999999999, 1.4369999999999998, 1.9409999999999998, 1.947, 1.9609999999999999, 1.94, 1.934, 1.953, 0.9570000000000001, 1.451, 0.43899999999999995, 1.4240000000000002, 1.96, 1.451, 1.401, 1.455, 1.449, 1.9489999999999998, 1.955, 0.41400000000000015, 1.954, 1.43, 1.954, 1.9329999999999998, 0.43699999999999994, 1.951, 1.959, 1.958, 1.9609999999999999, 1.9609999999999999, 0.972, 1.958, 0.951, 1.954, 0.47299999999999986, 1.9489999999999998, 0.46399999999999997, 0.951, 0.9319999999999999, 1.451, 0.95, 1.959, 0.97, 1.9609999999999999, 0.919, 1.958, 0.44099999999999984, -0.03300000000000003, 1.954, 1.924, 1.447, 1.4609999999999999, 1.948, 1.96, 1.455, 1.955, 1.955], "episode_lengths": [15, 20, 16, 21, 16, 16, 13, 20, 18, 15, 19, 17, 9, 18, 17, 18, 15, 13, 25, 13, 21, 13, 18, 17, 17, 15, 18, 16, 13, 14, 13, 15, 16, 30, 12, 13, 18, 10, 17, 18, 23, 18, 15, 17, 14, 25, 14, 20, 18, 16, 17, 14, 13, 16, 23, 15, 13, 13, 15, 17, 16, 13, 29, 33, 13, 16, 13, 19, 13, 300, 22, 21, 20, 300, 22, 13, 20, 18, 17, 13, 20, 22, 15, 13, 16, 20, 25, 13, 16, 31, 15, 16, 16, 15, 27, 15, 22, 15, 22, 300, 16, 13, 14, 13, 13, 9, 14, 15, 15, 9, 17, 11, 300, 300, 16, 300, 13, 10, 13, 26, 14, 19, 10, 15, 24, 17, 13, 17, 13, 15, 15, 15], "policy_red_0_reward": [1.455, 1.44, 0.498, 0.497, 0.952, 1.451, 0.5, -1.003, 1.446, 1.455, 1.442, 1.448, -1.001, 0.499, 1.4489999999999998, 1.4449999999999998, 1.454, 1.4609999999999999, 1.424, 0.5, 1.4369999999999998, 1.4609999999999999, 1.446, 1.4489999999999998, 1.4489999999999998, 0.5, 0.5, 0.5, 1.4609999999999999, 1.458, 1.4609999999999999, 1.455, 1.451, 1.409, -0.5, -1.001, 1.4449999999999998, -1.001, 1.4489999999999998, 1.446, 1.431, 1.4449999999999998, 1.454, 1.447, 1.458, 1.424, 0.5, 1.439, 0.499, 1.452, 1.4489999999999998, 0.498, 1.4609999999999999, -0.001, 1.4300000000000002, 1.454, 1.4609999999999999, 0.5, 1.455, 1.4489999999999998, 1.452, 1.4609999999999999, 1.412, -0.003, 1.4609999999999999, 1.451, 0.5, 0.499, 1.4609999999999999, -0.03000000000000002, 0.0, 1.436, 1.438, 0.45299999999999996, 1.434, 0.5, 1.439, 1.444, 1.448, 1.4609999999999999, 1.44, 1.434, 1.455, 1.4609999999999999, 0.0, -0.501, 1.425, 1.4609999999999999, 1.452, 0.0, 1.455, 1.452, 1.451, 1.455, 1.4180000000000001, 1.455, 1.4329999999999998, 0.499, 0.5, -0.028000000000000018, 0.499, 1.4609999999999999, 1.458, 0.5, 0.5, -0.5, 0.5, -0.502, 1.455, 0.973, 1.4489999999999998, 0.966, 0.48, 0.487, 1.452, 0.47, 1.4609999999999999, -0.5, 1.4609999999999999, -0.503, 0.5, 1.443, 0.968, 1.455, 1.426, -0.001, 1.4609999999999999, 1.4489999999999998, 1.4609999999999999, 1.455, 0.5, 0.5], "policy_blue_0_reward": [0.0, 0.0, 1.451, 1.435, -0.505, 0.497, 1.4609999999999999, 1.438, 0.5, 0.5, 0.498, 0.5, 0.973, 1.443, -0.001, -0.001, 0.0, -0.002, 0.0, 1.4609999999999999, 0.498, 0.0, -0.003, -0.002, 0.498, 1.455, 1.446, 1.452, 0.499, -1.002, 0.5, 0.0, 0.5, 0.498, 1.4609999999999999, 1.4609999999999999, 0.499, 1.47, 0.499, 0.499, 0.497, 0.498, -1.001, 0.499, 0.498, 0.5, 1.458, 0.499, 1.444, 0.499, 0.498, 1.458, 0.499, 1.452, -0.003, 0.499, 0.5, 1.4609999999999999, 0.5, 0.5, 0.5, 0.5, -0.002, 1.3980000000000001, 0.5, 0.5, 1.4609999999999999, 1.44, 0.5, -0.024000000000000014, 1.4329999999999998, 0.496, 0.0, -0.03300000000000002, 0.498, 1.4609999999999999, -0.002, 0.497, 0.499, 0.5, 0.5, 0.5, 0.498, -0.5039999999999999, 1.451, 0.94, -0.001, 0.499, -0.001, 1.401, 0.0, -0.003, 0.498, 0.5, -1.0039999999999998, 0.499, -0.003, 1.455, 1.4329999999999998, 0.46499999999999997, 1.452, 0.498, 0.5, 1.4609999999999999, 1.4609999999999999, 1.472, 1.458, 1.4529999999999998, 0.499, -0.5, 0.5, -0.502, 0.471, 0.44499999999999995, -0.001, 0.48, 0.498, 1.47, 0.5, 1.4220000000000002, 1.458, -1.002, -1.001, 0.499, 0.498, 1.448, 0.0, 0.499, 0.499, 0.0, 1.455, 1.455]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4315777015252225, "mean_inference_ms": 7.458495911120332, "mean_action_processing_ms": 0.39257711045317173, "mean_env_wait_ms": 0.5233748614432234, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.16749302546183267, "StateBufferConnector_ms": 0.010575579874443285, "ViewRequirementAgentConnector_ms": 0.21766198403907544}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.05400000000000004, "episode_reward_mean": 1.5767499999999999, "episode_len_mean": 29.568181818181817, "episodes_this_iter": 132, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.0039999999999998}, "policy_reward_max": {"red_0": 1.4609999999999999, "blue_0": 1.472}, "policy_reward_mean": {"red_0": 0.9803787878787876, "blue_0": 0.5963712121212121}, "hist_stats": {"episode_reward": [1.455, 1.44, 1.9489999999999998, 1.932, 0.44700000000000006, 1.948, 1.9609999999999999, 0.43499999999999994, 1.946, 1.955, 1.94, 1.948, -0.027999999999999914, 1.942, 1.448, 1.444, 1.454, 1.459, 1.424, 1.9609999999999999, 1.935, 1.4609999999999999, 1.443, 1.447, 1.947, 1.955, 1.946, 1.952, 1.96, 0.45599999999999996, 1.9609999999999999, 1.455, 1.951, 1.907, 0.961, 0.45999999999999996, 1.944, 0.469, 1.948, 1.9449999999999998, 1.928, 1.943, 0.45299999999999985, 1.946, 1.956, 1.924, 1.958, 1.938, 1.943, 1.951, 1.947, 1.956, 1.96, 1.451, 1.427, 1.9529999999999998, 1.9609999999999999, 1.9609999999999999, 1.955, 1.9489999999999998, 1.952, 1.9609999999999999, 1.4100000000000001, 1.395, 1.9609999999999999, 1.951, 1.9609999999999999, 1.939, 1.9609999999999999, -0.05400000000000004, 1.4329999999999998, 1.932, 1.438, 0.41999999999999993, 1.932, 1.9609999999999999, 1.4369999999999998, 1.9409999999999998, 1.947, 1.9609999999999999, 1.94, 1.934, 1.953, 0.9570000000000001, 1.451, 0.43899999999999995, 1.4240000000000002, 1.96, 1.451, 1.401, 1.455, 1.449, 1.9489999999999998, 1.955, 0.41400000000000015, 1.954, 1.43, 1.954, 1.9329999999999998, 0.43699999999999994, 1.951, 1.959, 1.958, 1.9609999999999999, 1.9609999999999999, 0.972, 1.958, 0.951, 1.954, 0.47299999999999986, 1.9489999999999998, 0.46399999999999997, 0.951, 0.9319999999999999, 1.451, 0.95, 1.959, 0.97, 1.9609999999999999, 0.919, 1.958, 0.44099999999999984, -0.03300000000000003, 1.954, 1.924, 1.447, 1.4609999999999999, 1.948, 1.96, 1.455, 1.955, 1.955], "episode_lengths": [15, 20, 16, 21, 16, 16, 13, 20, 18, 15, 19, 17, 9, 18, 17, 18, 15, 13, 25, 13, 21, 13, 18, 17, 17, 15, 18, 16, 13, 14, 13, 15, 16, 30, 12, 13, 18, 10, 17, 18, 23, 18, 15, 17, 14, 25, 14, 20, 18, 16, 17, 14, 13, 16, 23, 15, 13, 13, 15, 17, 16, 13, 29, 33, 13, 16, 13, 19, 13, 300, 22, 21, 20, 300, 22, 13, 20, 18, 17, 13, 20, 22, 15, 13, 16, 20, 25, 13, 16, 31, 15, 16, 16, 15, 27, 15, 22, 15, 22, 300, 16, 13, 14, 13, 13, 9, 14, 15, 15, 9, 17, 11, 300, 300, 16, 300, 13, 10, 13, 26, 14, 19, 10, 15, 24, 17, 13, 17, 13, 15, 15, 15], "policy_red_0_reward": [1.455, 1.44, 0.498, 0.497, 0.952, 1.451, 0.5, -1.003, 1.446, 1.455, 1.442, 1.448, -1.001, 0.499, 1.4489999999999998, 1.4449999999999998, 1.454, 1.4609999999999999, 1.424, 0.5, 1.4369999999999998, 1.4609999999999999, 1.446, 1.4489999999999998, 1.4489999999999998, 0.5, 0.5, 0.5, 1.4609999999999999, 1.458, 1.4609999999999999, 1.455, 1.451, 1.409, -0.5, -1.001, 1.4449999999999998, -1.001, 1.4489999999999998, 1.446, 1.431, 1.4449999999999998, 1.454, 1.447, 1.458, 1.424, 0.5, 1.439, 0.499, 1.452, 1.4489999999999998, 0.498, 1.4609999999999999, -0.001, 1.4300000000000002, 1.454, 1.4609999999999999, 0.5, 1.455, 1.4489999999999998, 1.452, 1.4609999999999999, 1.412, -0.003, 1.4609999999999999, 1.451, 0.5, 0.499, 1.4609999999999999, -0.03000000000000002, 0.0, 1.436, 1.438, 0.45299999999999996, 1.434, 0.5, 1.439, 1.444, 1.448, 1.4609999999999999, 1.44, 1.434, 1.455, 1.4609999999999999, 0.0, -0.501, 1.425, 1.4609999999999999, 1.452, 0.0, 1.455, 1.452, 1.451, 1.455, 1.4180000000000001, 1.455, 1.4329999999999998, 0.499, 0.5, -0.028000000000000018, 0.499, 1.4609999999999999, 1.458, 0.5, 0.5, -0.5, 0.5, -0.502, 1.455, 0.973, 1.4489999999999998, 0.966, 0.48, 0.487, 1.452, 0.47, 1.4609999999999999, -0.5, 1.4609999999999999, -0.503, 0.5, 1.443, 0.968, 1.455, 1.426, -0.001, 1.4609999999999999, 1.4489999999999998, 1.4609999999999999, 1.455, 0.5, 0.5], "policy_blue_0_reward": [0.0, 0.0, 1.451, 1.435, -0.505, 0.497, 1.4609999999999999, 1.438, 0.5, 0.5, 0.498, 0.5, 0.973, 1.443, -0.001, -0.001, 0.0, -0.002, 0.0, 1.4609999999999999, 0.498, 0.0, -0.003, -0.002, 0.498, 1.455, 1.446, 1.452, 0.499, -1.002, 0.5, 0.0, 0.5, 0.498, 1.4609999999999999, 1.4609999999999999, 0.499, 1.47, 0.499, 0.499, 0.497, 0.498, -1.001, 0.499, 0.498, 0.5, 1.458, 0.499, 1.444, 0.499, 0.498, 1.458, 0.499, 1.452, -0.003, 0.499, 0.5, 1.4609999999999999, 0.5, 0.5, 0.5, 0.5, -0.002, 1.3980000000000001, 0.5, 0.5, 1.4609999999999999, 1.44, 0.5, -0.024000000000000014, 1.4329999999999998, 0.496, 0.0, -0.03300000000000002, 0.498, 1.4609999999999999, -0.002, 0.497, 0.499, 0.5, 0.5, 0.5, 0.498, -0.5039999999999999, 1.451, 0.94, -0.001, 0.499, -0.001, 1.401, 0.0, -0.003, 0.498, 0.5, -1.0039999999999998, 0.499, -0.003, 1.455, 1.4329999999999998, 0.46499999999999997, 1.452, 0.498, 0.5, 1.4609999999999999, 1.4609999999999999, 1.472, 1.458, 1.4529999999999998, 0.499, -0.5, 0.5, -0.502, 0.471, 0.44499999999999995, -0.001, 0.48, 0.498, 1.47, 0.5, 1.4220000000000002, 1.458, -1.002, -1.001, 0.499, 0.498, 1.448, 0.0, 0.499, 0.499, 0.0, 1.455, 1.455]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4315777015252225, "mean_inference_ms": 7.458495911120332, "mean_action_processing_ms": 0.39257711045317173, "mean_env_wait_ms": 0.5233748614432234, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.16749302546183267, "StateBufferConnector_ms": 0.010575579874443285, "ViewRequirementAgentConnector_ms": 0.21766198403907544}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1048000, "num_agent_steps_trained": 1048000, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 111.02853987709047, "num_env_steps_trained_throughput_per_sec": 111.02853987709047, "timesteps_total": 524000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1048000, "timers": {"training_iteration_time_ms": 31308.764, "sample_time_ms": 4005.597, "learn_time_ms": 27274.356, "learn_throughput": 146.658, "synch_weights_time_ms": 27.243}, "counters": {"num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 1048000, "num_agent_steps_trained": 1048000}, "done": false, "episodes_total": 11224, "training_iteration": 131, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-06-59", "timestamp": 1694840819, "time_this_iter_s": 36.04728579521179, "time_total_s": 4098.789578676224, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a254af0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4098.789578676224, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 33.065384615384616, "ram_util_percent": 56.88653846153846}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6090225563909775, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.06766917293233082, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03759398496240601, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.06766917293233082, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.24060150375939848, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.03759398496240601, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.06766917293233082, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03759398496240601, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.39869723771698773, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03349540923663881, "policy_loss": -0.06252631899139184, "vf_loss": 0.023500144113980544, "vf_explained_var": 0.7900625115881363, "kl": 0.00802578342474202, "entropy": 1.0029000759745637, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 126240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4670198855611185, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04128726537940868, "policy_loss": -0.07236917731449163, "vf_loss": 0.0247035205582506, "vf_explained_var": 0.670070224131147, "kl": 0.00881519226767696, "entropy": 1.3519582877556482, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 126240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.09699999999999998, "episode_reward_mean": 1.6779172932330828, "episode_len_mean": 29.32330827067669, "episode_media": {}, "episodes_this_iter": 133, "policy_reward_min": {"red_0": -1.0039999999999998, "blue_0": -1.004}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 1.0594285714285714, "blue_0": 0.6184887218045113}, "custom_metrics": {"red_0/door_open_done_mean": 0.6090225563909775, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.06766917293233082, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03759398496240601, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.06766917293233082, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.24060150375939848, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.03759398496240601, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.06766917293233082, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03759398496240601, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.945, 1.96, 1.44, 0.379, 1.9609999999999999, 1.96, 1.9609999999999999, 1.9409999999999998, 0.94, 1.456, 0.46099999999999985, 1.959, 0.94, 1.955, 1.94, 0.46599999999999997, 1.9609999999999999, 1.9529999999999998, 1.4609999999999999, -0.04599999999999982, 1.9529999999999998, 1.959, 1.424, 1.9329999999999998, 1.454, 1.9489999999999998, 0.381, 0.938, 1.95, 1.944, 1.426, 1.955, 1.955, 1.958, 1.956, 1.448, 1.931, 1.448, 1.9369999999999998, 1.957, 1.936, 1.9569999999999999, 1.9569999999999999, 1.955, 1.951, 1.955, 1.9569999999999999, 1.9449999999999998, -0.040000000000000036, 1.958, 1.956, 1.4569999999999999, 1.948, 1.954, 1.951, 1.96, 1.94, 0.944, 1.944, 1.9329999999999998, 0.4630000000000001, 1.9609999999999999, 1.422, 1.946, 1.946, 1.901, 1.9569999999999999, 1.958, 1.94, 1.9609999999999999, 1.94, 1.931, 1.9609999999999999, 1.943, 1.948, 1.955, 1.921, 0.97, 1.452, 1.9609999999999999, 1.9489999999999998, 1.96, 1.943, -0.09699999999999998, 1.959, 1.958, 0.96, 1.9489999999999998, 1.9569999999999999, 1.955, 1.9609999999999999, 1.4449999999999998, 1.947, 1.9529999999999998, 1.948, 0.964, 1.9609999999999999, 1.9609999999999999, 1.9449999999999998, 1.954, 0.94, 0.959, 1.456, 1.9569999999999999, 1.948, 1.9609999999999999, 0.45100000000000007, 1.958, 1.931, 1.446, 1.955, 1.95, 1.9569999999999999, 1.46, 1.455, 1.853, 0.9369999999999999, 1.954, 1.958, 1.458, 1.95, 1.9449999999999998, 1.4529999999999998, 1.954, 1.9569999999999999, 1.955, 1.95, 1.9609999999999999, 1.959, 1.9489999999999998, 1.936, 1.455, 1.459], "episode_lengths": [300, 13, 20, 39, 13, 13, 13, 19, 300, 14, 13, 13, 300, 15, 19, 10, 13, 15, 13, 14, 15, 13, 23, 21, 15, 17, 39, 300, 16, 18, 24, 15, 15, 14, 14, 17, 22, 16, 20, 13, 21, 14, 14, 15, 16, 14, 14, 18, 13, 13, 14, 14, 16, 15, 16, 13, 20, 300, 18, 21, 12, 13, 24, 16, 18, 32, 14, 14, 19, 13, 19, 22, 13, 19, 17, 15, 26, 10, 15, 13, 16, 13, 18, 31, 13, 14, 12, 17, 14, 15, 13, 18, 17, 15, 17, 300, 13, 13, 18, 15, 19, 12, 14, 14, 17, 13, 15, 14, 22, 17, 15, 16, 14, 13, 15, 46, 21, 15, 14, 14, 16, 18, 15, 15, 14, 15, 16, 13, 13, 16, 21, 14, 13], "policy_red_0_reward": [0.474, 0.499, 1.44, -1.003, 1.4609999999999999, 0.499, 0.5, 1.443, 0.484, 1.458, 1.4609999999999999, 1.4609999999999999, 0.472, 1.455, 1.443, 0.97, 1.4609999999999999, 0.498, 1.4609999999999999, -1.0039999999999998, 1.454, 1.4609999999999999, -0.004, 0.499, 1.455, 0.5, 0.883, 0.478, 1.452, 1.4449999999999998, 1.428, 1.455, 1.455, 1.458, 1.458, -0.001, 1.434, 1.452, 1.439, 1.4609999999999999, 1.4369999999999998, 0.5, 1.458, 0.5, 1.451, 1.4569999999999999, 1.4569999999999999, 1.446, 0.96, 1.4609999999999999, 1.458, 1.458, 0.497, 1.454, 1.452, 1.4609999999999999, 0.5, 0.472, 1.446, 0.5, 1.464, 1.4609999999999999, -0.004, 1.452, 1.446, 1.403, 0.5, 1.458, 1.443, 1.4609999999999999, 1.443, 0.5, 0.5, 1.443, 1.4489999999999998, 0.5, 1.421, 1.47, 1.455, 1.4609999999999999, 1.451, 1.4609999999999999, 1.4449999999999998, 0.906, 1.4609999999999999, 1.458, 1.464, 1.4489999999999998, 1.4569999999999999, 0.5, 0.5, 1.446, 1.4489999999999998, 0.498, 0.499, 0.488, 1.4609999999999999, 1.4609999999999999, 0.5, 1.454, -0.502, -0.5, 1.458, 0.5, 1.4489999999999998, 1.4609999999999999, 1.455, 0.5, 0.499, -0.002, 0.5, 1.452, 1.458, 1.4609999999999999, 1.455, 1.358, -0.5, 0.499, 1.458, 0.0, 1.451, 1.4449999999999998, -0.001, 1.455, 1.4569999999999999, 1.455, 1.452, 1.4609999999999999, 1.4609999999999999, 0.499, 1.4369999999999998, 1.458, 1.4609999999999999], "policy_blue_0_reward": [0.471, 1.4609999999999999, 0.0, 1.3820000000000001, 0.5, 1.4609999999999999, 1.4609999999999999, 0.498, 0.45599999999999996, -0.002, -1.0, 0.498, 0.46799999999999997, 0.5, 0.497, -0.504, 0.5, 1.455, 0.0, 0.958, 0.499, 0.498, 1.428, 1.434, -0.001, 1.4489999999999998, -0.502, 0.45999999999999996, 0.498, 0.499, -0.002, 0.5, 0.5, 0.5, 0.498, 1.4489999999999998, 0.497, -0.004, 0.498, 0.496, 0.499, 1.4569999999999999, 0.499, 1.455, 0.5, 0.498, 0.5, 0.499, -1.0, 0.497, 0.498, -0.001, 1.451, 0.5, 0.499, 0.499, 1.44, 0.472, 0.498, 1.4329999999999998, -1.001, 0.5, 1.426, 0.494, 0.5, 0.498, 1.4569999999999999, 0.5, 0.497, 0.5, 0.497, 1.431, 1.4609999999999999, 0.5, 0.499, 1.455, 0.5, -0.5, -0.003, 0.5, 0.498, 0.499, 0.498, -1.003, 0.498, 0.5, -0.504, 0.5, 0.5, 1.455, 1.4609999999999999, -0.001, 0.498, 1.455, 1.4489999999999998, 0.476, 0.5, 0.5, 1.4449999999999998, 0.5, 1.442, 1.459, -0.002, 1.4569999999999999, 0.499, 0.5, -1.004, 1.458, 1.432, 1.448, 1.455, 0.498, 0.499, -0.001, 0.0, 0.495, 1.4369999999999998, 1.455, 0.5, 1.458, 0.499, 0.5, 1.454, 0.499, 0.5, 0.5, 0.498, 0.5, 0.498, 1.45, 0.499, -0.003, -0.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.431761572189421, "mean_inference_ms": 7.479360610405796, "mean_action_processing_ms": 0.38872640499022615, "mean_env_wait_ms": 0.5238438162768999, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.16135300012459433, "StateBufferConnector_ms": 0.009851437762267608, "ViewRequirementAgentConnector_ms": 0.2026257658363285}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.09699999999999998, "episode_reward_mean": 1.6779172932330828, "episode_len_mean": 29.32330827067669, "episodes_this_iter": 133, "policy_reward_min": {"red_0": -1.0039999999999998, "blue_0": -1.004}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 1.0594285714285714, "blue_0": 0.6184887218045113}, "hist_stats": {"episode_reward": [0.945, 1.96, 1.44, 0.379, 1.9609999999999999, 1.96, 1.9609999999999999, 1.9409999999999998, 0.94, 1.456, 0.46099999999999985, 1.959, 0.94, 1.955, 1.94, 0.46599999999999997, 1.9609999999999999, 1.9529999999999998, 1.4609999999999999, -0.04599999999999982, 1.9529999999999998, 1.959, 1.424, 1.9329999999999998, 1.454, 1.9489999999999998, 0.381, 0.938, 1.95, 1.944, 1.426, 1.955, 1.955, 1.958, 1.956, 1.448, 1.931, 1.448, 1.9369999999999998, 1.957, 1.936, 1.9569999999999999, 1.9569999999999999, 1.955, 1.951, 1.955, 1.9569999999999999, 1.9449999999999998, -0.040000000000000036, 1.958, 1.956, 1.4569999999999999, 1.948, 1.954, 1.951, 1.96, 1.94, 0.944, 1.944, 1.9329999999999998, 0.4630000000000001, 1.9609999999999999, 1.422, 1.946, 1.946, 1.901, 1.9569999999999999, 1.958, 1.94, 1.9609999999999999, 1.94, 1.931, 1.9609999999999999, 1.943, 1.948, 1.955, 1.921, 0.97, 1.452, 1.9609999999999999, 1.9489999999999998, 1.96, 1.943, -0.09699999999999998, 1.959, 1.958, 0.96, 1.9489999999999998, 1.9569999999999999, 1.955, 1.9609999999999999, 1.4449999999999998, 1.947, 1.9529999999999998, 1.948, 0.964, 1.9609999999999999, 1.9609999999999999, 1.9449999999999998, 1.954, 0.94, 0.959, 1.456, 1.9569999999999999, 1.948, 1.9609999999999999, 0.45100000000000007, 1.958, 1.931, 1.446, 1.955, 1.95, 1.9569999999999999, 1.46, 1.455, 1.853, 0.9369999999999999, 1.954, 1.958, 1.458, 1.95, 1.9449999999999998, 1.4529999999999998, 1.954, 1.9569999999999999, 1.955, 1.95, 1.9609999999999999, 1.959, 1.9489999999999998, 1.936, 1.455, 1.459], "episode_lengths": [300, 13, 20, 39, 13, 13, 13, 19, 300, 14, 13, 13, 300, 15, 19, 10, 13, 15, 13, 14, 15, 13, 23, 21, 15, 17, 39, 300, 16, 18, 24, 15, 15, 14, 14, 17, 22, 16, 20, 13, 21, 14, 14, 15, 16, 14, 14, 18, 13, 13, 14, 14, 16, 15, 16, 13, 20, 300, 18, 21, 12, 13, 24, 16, 18, 32, 14, 14, 19, 13, 19, 22, 13, 19, 17, 15, 26, 10, 15, 13, 16, 13, 18, 31, 13, 14, 12, 17, 14, 15, 13, 18, 17, 15, 17, 300, 13, 13, 18, 15, 19, 12, 14, 14, 17, 13, 15, 14, 22, 17, 15, 16, 14, 13, 15, 46, 21, 15, 14, 14, 16, 18, 15, 15, 14, 15, 16, 13, 13, 16, 21, 14, 13], "policy_red_0_reward": [0.474, 0.499, 1.44, -1.003, 1.4609999999999999, 0.499, 0.5, 1.443, 0.484, 1.458, 1.4609999999999999, 1.4609999999999999, 0.472, 1.455, 1.443, 0.97, 1.4609999999999999, 0.498, 1.4609999999999999, -1.0039999999999998, 1.454, 1.4609999999999999, -0.004, 0.499, 1.455, 0.5, 0.883, 0.478, 1.452, 1.4449999999999998, 1.428, 1.455, 1.455, 1.458, 1.458, -0.001, 1.434, 1.452, 1.439, 1.4609999999999999, 1.4369999999999998, 0.5, 1.458, 0.5, 1.451, 1.4569999999999999, 1.4569999999999999, 1.446, 0.96, 1.4609999999999999, 1.458, 1.458, 0.497, 1.454, 1.452, 1.4609999999999999, 0.5, 0.472, 1.446, 0.5, 1.464, 1.4609999999999999, -0.004, 1.452, 1.446, 1.403, 0.5, 1.458, 1.443, 1.4609999999999999, 1.443, 0.5, 0.5, 1.443, 1.4489999999999998, 0.5, 1.421, 1.47, 1.455, 1.4609999999999999, 1.451, 1.4609999999999999, 1.4449999999999998, 0.906, 1.4609999999999999, 1.458, 1.464, 1.4489999999999998, 1.4569999999999999, 0.5, 0.5, 1.446, 1.4489999999999998, 0.498, 0.499, 0.488, 1.4609999999999999, 1.4609999999999999, 0.5, 1.454, -0.502, -0.5, 1.458, 0.5, 1.4489999999999998, 1.4609999999999999, 1.455, 0.5, 0.499, -0.002, 0.5, 1.452, 1.458, 1.4609999999999999, 1.455, 1.358, -0.5, 0.499, 1.458, 0.0, 1.451, 1.4449999999999998, -0.001, 1.455, 1.4569999999999999, 1.455, 1.452, 1.4609999999999999, 1.4609999999999999, 0.499, 1.4369999999999998, 1.458, 1.4609999999999999], "policy_blue_0_reward": [0.471, 1.4609999999999999, 0.0, 1.3820000000000001, 0.5, 1.4609999999999999, 1.4609999999999999, 0.498, 0.45599999999999996, -0.002, -1.0, 0.498, 0.46799999999999997, 0.5, 0.497, -0.504, 0.5, 1.455, 0.0, 0.958, 0.499, 0.498, 1.428, 1.434, -0.001, 1.4489999999999998, -0.502, 0.45999999999999996, 0.498, 0.499, -0.002, 0.5, 0.5, 0.5, 0.498, 1.4489999999999998, 0.497, -0.004, 0.498, 0.496, 0.499, 1.4569999999999999, 0.499, 1.455, 0.5, 0.498, 0.5, 0.499, -1.0, 0.497, 0.498, -0.001, 1.451, 0.5, 0.499, 0.499, 1.44, 0.472, 0.498, 1.4329999999999998, -1.001, 0.5, 1.426, 0.494, 0.5, 0.498, 1.4569999999999999, 0.5, 0.497, 0.5, 0.497, 1.431, 1.4609999999999999, 0.5, 0.499, 1.455, 0.5, -0.5, -0.003, 0.5, 0.498, 0.499, 0.498, -1.003, 0.498, 0.5, -0.504, 0.5, 0.5, 1.455, 1.4609999999999999, -0.001, 0.498, 1.455, 1.4489999999999998, 0.476, 0.5, 0.5, 1.4449999999999998, 0.5, 1.442, 1.459, -0.002, 1.4569999999999999, 0.499, 0.5, -1.004, 1.458, 1.432, 1.448, 1.455, 0.498, 0.499, -0.001, 0.0, 0.495, 1.4369999999999998, 1.455, 0.5, 1.458, 0.499, 0.5, 1.454, 0.499, 0.5, 0.5, 0.498, 0.5, 0.498, 1.45, 0.499, -0.003, -0.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.431761572189421, "mean_inference_ms": 7.479360610405796, "mean_action_processing_ms": 0.38872640499022615, "mean_env_wait_ms": 0.5238438162768999, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.16135300012459433, "StateBufferConnector_ms": 0.009851437762267608, "ViewRequirementAgentConnector_ms": 0.2026257658363285}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 116.55957200559834, "num_env_steps_trained_throughput_per_sec": 116.55957200559834, "timesteps_total": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 31624.991, "sample_time_ms": 4021.643, "learn_time_ms": 27574.721, "learn_throughput": 145.06, "synch_weights_time_ms": 27.04}, "counters": {"num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "episodes_total": 11357, "training_iteration": 132, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-07-35", "timestamp": 1694840855, "time_this_iter_s": 34.33442282676697, "time_total_s": 4133.124001502991, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb21983d00>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4133.124001502991, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 33.272, "ram_util_percent": 59.57}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5255474452554745, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.08029197080291971, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.043795620437956206, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.08029197080291971, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.30656934306569344, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.043795620437956206, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.08029197080291971, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.043795620437956206, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4216332556369404, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.028763554995627296, "policy_loss": -0.06156834877256188, "vf_loss": 0.029540691964211874, "vf_explained_var": 0.7342613836750388, "kl": 0.008385125620744283, "entropy": 1.0679168321813146, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 127200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47987231337465347, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04195932846293241, "policy_loss": -0.07749662486457964, "vf_loss": 0.02778013272230358, "vf_explained_var": 0.671363152253131, "kl": 0.010083440184636383, "entropy": 1.3241073861718178, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 127200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_agent_steps_sampled": 1064000, "num_agent_steps_trained": 1064000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06099999999999994, "episode_reward_mean": 1.656715328467153, "episode_len_mean": 30.875912408759124, "episode_media": {}, "episodes_this_iter": 137, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.9679343065693429, "blue_0": 0.6887810218978102}, "custom_metrics": {"red_0/door_open_done_mean": 0.5255474452554745, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.08029197080291971, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.043795620437956206, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.08029197080291971, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.30656934306569344, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.043795620437956206, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.08029197080291971, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.043795620437956206, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.4159999999999999, 1.392, 0.9269999999999999, 1.9409999999999998, 1.94, 1.954, 1.95, 1.447, 1.947, 1.955, 1.362, 1.9529999999999998, 0.45999999999999996, 1.9529999999999998, 1.954, 1.909, 1.46, 1.9569999999999999, 1.928, 1.9369999999999998, 1.417, 1.959, 1.4569999999999999, 1.955, 1.424, 1.951, 1.935, 1.948, 1.954, 1.948, 1.9609999999999999, 1.9329999999999998, 1.9060000000000001, 1.454, 0.9580000000000002, 0.4630000000000001, 1.9529999999999998, 1.9289999999999998, 1.96, 1.95, 1.9489999999999998, 1.954, -0.06099999999999994, 1.9369999999999998, 1.9569999999999999, 1.948, 1.95, 1.427, 1.9449999999999998, 1.9489999999999998, 1.956, 1.931, 1.4489999999999998, 1.9329999999999998, 1.948, 1.956, 1.447, 1.956, 1.946, 0.4950000000000001, 0.959, 1.956, 1.958, 1.46, 1.955, 0.4179999999999999, 1.96, 1.45, 0.9729999999999999, 1.9569999999999999, 0.9609999999999999, 0.4149999999999999, 1.952, 0.966, 1.4449999999999998, 1.9569999999999999, 1.956, 1.959, 0.966, 1.9569999999999999, 0.953, 1.948, 0.966, 1.95, 0.748, 1.943, 1.913, 1.957, 1.958, 1.943, 1.4369999999999998, 1.917, 1.454, 1.9529999999999998, 1.9449999999999998, 0.9089999999999999, 0.46299999999999997, 1.442, 0.9729999999999999, 1.9609999999999999, 1.9529999999999998, 0.949, 1.959, 1.952, 1.9529999999999998, 1.951, 1.904, 0.47, 0.964, 1.9449999999999998, 1.932, 1.926, 1.9609999999999999, 1.958, 1.9409999999999998, 1.444, 1.446, 1.428, 1.387, 1.951, 1.9100000000000001, 1.9609999999999999, 1.9609999999999999, 1.4489999999999998, 1.951, 1.459, 1.9529999999999998, 1.947, 1.954, 1.951, 1.956, 1.9569999999999999, 1.9489999999999998, 1.944, 1.9529999999999998, 1.9449999999999998, 1.954], "episode_lengths": [300, 35, 300, 19, 20, 15, 16, 17, 17, 15, 45, 15, 13, 15, 15, 29, 13, 14, 23, 21, 27, 13, 14, 15, 24, 16, 21, 17, 15, 17, 13, 21, 30, 15, 13, 12, 15, 22, 13, 16, 16, 15, 20, 21, 14, 17, 16, 23, 18, 17, 14, 22, 16, 22, 17, 14, 17, 14, 17, 158, 13, 14, 14, 13, 15, 300, 13, 16, 9, 14, 12, 300, 15, 11, 18, 14, 14, 13, 10, 14, 300, 17, 11, 16, 77, 18, 28, 14, 14, 18, 21, 27, 15, 15, 17, 300, 12, 19, 9, 13, 15, 16, 13, 16, 15, 16, 31, 9, 11, 18, 21, 24, 13, 14, 19, 18, 17, 23, 36, 16, 29, 13, 13, 16, 16, 13, 15, 16, 15, 16, 14, 14, 17, 18, 15, 18, 14], "policy_red_0_reward": [-0.03100000000000002, 1.3940000000000001, 0.46299999999999997, 0.5, 1.44, 0.499, 1.452, -0.002, 1.4489999999999998, 1.455, -0.001, 1.455, -0.5, 1.455, 0.5, 1.411, 1.4609999999999999, 0.5, 0.498, 1.4369999999999998, -0.002, 1.4609999999999999, -0.001, 0.5, -0.001, 1.452, 1.4369999999999998, 1.448, 1.454, 1.4489999999999998, 0.5, 1.436, 1.4100000000000001, 1.455, 1.46, 1.464, 0.5, 1.4329999999999998, 1.4609999999999999, 1.452, 0.499, 1.455, -1.0, 0.5, 1.458, 1.4489999999999998, 1.451, 1.429, 1.446, 0.5, 0.498, 1.4329999999999998, 1.45, 1.434, 0.499, 1.458, 1.4489999999999998, 0.498, 1.448, 1.016, -0.502, 1.458, 1.458, 1.4609999999999999, 1.455, -0.03900000000000003, 1.4609999999999999, -0.002, 1.4729999999999999, 0.499, 1.4609999999999999, -0.03900000000000003, 1.455, 1.467, -0.001, 0.5, 1.458, 1.4609999999999999, 1.47, 1.458, 0.484, 0.499, 1.467, 1.452, -0.514, 0.498, 0.499, 1.458, 1.458, 1.4449999999999998, 1.4369999999999998, 1.4180000000000001, 0.0, 1.455, 1.447, 0.43499999999999994, -0.5, 1.443, 1.4729999999999999, 1.4609999999999999, 1.455, -0.501, 1.4609999999999999, 1.452, 1.4529999999999998, 0.499, 1.4060000000000001, 1.472, 1.466, 0.5, 1.434, 1.428, 0.5, 0.5, 0.499, -0.002, 1.448, -0.001, -0.001, 1.452, 1.412, 1.4609999999999999, 1.4609999999999999, 1.45, 1.452, -0.002, 0.499, 1.452, 0.499, 0.499, 0.498, 0.499, 1.4489999999999998, 0.5, 1.455, 1.446, 1.4569999999999999], "policy_blue_0_reward": [0.44699999999999995, -0.002, 0.46399999999999997, 1.4409999999999998, 0.5, 1.455, 0.498, 1.4489999999999998, 0.498, 0.5, 1.363, 0.498, 0.96, 0.498, 1.454, 0.498, -0.001, 1.4569999999999999, 1.4300000000000002, 0.5, 1.419, 0.498, 1.458, 1.455, 1.4249999999999998, 0.499, 0.498, 0.5, 0.5, 0.499, 1.4609999999999999, 0.497, 0.496, -0.001, -0.5019999999999999, -1.001, 1.4529999999999998, 0.496, 0.499, 0.498, 1.45, 0.499, 0.939, 1.4369999999999998, 0.499, 0.499, 0.499, -0.002, 0.499, 1.4489999999999998, 1.458, 0.498, -0.001, 0.499, 1.4489999999999998, 0.498, -0.002, 1.458, 0.498, -0.521, 1.4609999999999999, 0.498, 0.5, -0.001, 0.5, 0.45699999999999996, 0.499, 1.452, -0.5, 1.458, -0.5, 0.45399999999999996, 0.497, -0.501, 1.446, 1.4569999999999999, 0.498, 0.498, -0.504, 0.499, 0.469, 1.4489999999999998, -0.501, 0.498, 1.262, 1.4449999999999998, 1.4140000000000001, 0.499, 0.5, 0.498, 0.0, 0.499, 1.454, 0.498, 0.498, 0.474, 0.963, -0.001, -0.5, 0.5, 0.498, 1.45, 0.498, 0.5, 0.5, 1.452, 0.498, -1.002, -0.502, 1.4449999999999998, 0.498, 0.498, 1.4609999999999999, 1.458, 1.442, 1.446, -0.002, 1.429, 1.388, 0.499, 0.498, 0.5, 0.5, -0.001, 0.499, 1.4609999999999999, 1.454, 0.495, 1.455, 1.452, 1.458, 1.458, 0.5, 1.444, 0.498, 0.499, 0.497]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4309810910431515, "mean_inference_ms": 7.468891903666075, "mean_action_processing_ms": 0.39016502049538526, "mean_env_wait_ms": 0.5226003845161237, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15886352010016894, "StateBufferConnector_ms": 0.010149409301089544, "ViewRequirementAgentConnector_ms": 0.20089488830009516}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06099999999999994, "episode_reward_mean": 1.656715328467153, "episode_len_mean": 30.875912408759124, "episodes_this_iter": 137, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 0.9679343065693429, "blue_0": 0.6887810218978102}, "hist_stats": {"episode_reward": [0.4159999999999999, 1.392, 0.9269999999999999, 1.9409999999999998, 1.94, 1.954, 1.95, 1.447, 1.947, 1.955, 1.362, 1.9529999999999998, 0.45999999999999996, 1.9529999999999998, 1.954, 1.909, 1.46, 1.9569999999999999, 1.928, 1.9369999999999998, 1.417, 1.959, 1.4569999999999999, 1.955, 1.424, 1.951, 1.935, 1.948, 1.954, 1.948, 1.9609999999999999, 1.9329999999999998, 1.9060000000000001, 1.454, 0.9580000000000002, 0.4630000000000001, 1.9529999999999998, 1.9289999999999998, 1.96, 1.95, 1.9489999999999998, 1.954, -0.06099999999999994, 1.9369999999999998, 1.9569999999999999, 1.948, 1.95, 1.427, 1.9449999999999998, 1.9489999999999998, 1.956, 1.931, 1.4489999999999998, 1.9329999999999998, 1.948, 1.956, 1.447, 1.956, 1.946, 0.4950000000000001, 0.959, 1.956, 1.958, 1.46, 1.955, 0.4179999999999999, 1.96, 1.45, 0.9729999999999999, 1.9569999999999999, 0.9609999999999999, 0.4149999999999999, 1.952, 0.966, 1.4449999999999998, 1.9569999999999999, 1.956, 1.959, 0.966, 1.9569999999999999, 0.953, 1.948, 0.966, 1.95, 0.748, 1.943, 1.913, 1.957, 1.958, 1.943, 1.4369999999999998, 1.917, 1.454, 1.9529999999999998, 1.9449999999999998, 0.9089999999999999, 0.46299999999999997, 1.442, 0.9729999999999999, 1.9609999999999999, 1.9529999999999998, 0.949, 1.959, 1.952, 1.9529999999999998, 1.951, 1.904, 0.47, 0.964, 1.9449999999999998, 1.932, 1.926, 1.9609999999999999, 1.958, 1.9409999999999998, 1.444, 1.446, 1.428, 1.387, 1.951, 1.9100000000000001, 1.9609999999999999, 1.9609999999999999, 1.4489999999999998, 1.951, 1.459, 1.9529999999999998, 1.947, 1.954, 1.951, 1.956, 1.9569999999999999, 1.9489999999999998, 1.944, 1.9529999999999998, 1.9449999999999998, 1.954], "episode_lengths": [300, 35, 300, 19, 20, 15, 16, 17, 17, 15, 45, 15, 13, 15, 15, 29, 13, 14, 23, 21, 27, 13, 14, 15, 24, 16, 21, 17, 15, 17, 13, 21, 30, 15, 13, 12, 15, 22, 13, 16, 16, 15, 20, 21, 14, 17, 16, 23, 18, 17, 14, 22, 16, 22, 17, 14, 17, 14, 17, 158, 13, 14, 14, 13, 15, 300, 13, 16, 9, 14, 12, 300, 15, 11, 18, 14, 14, 13, 10, 14, 300, 17, 11, 16, 77, 18, 28, 14, 14, 18, 21, 27, 15, 15, 17, 300, 12, 19, 9, 13, 15, 16, 13, 16, 15, 16, 31, 9, 11, 18, 21, 24, 13, 14, 19, 18, 17, 23, 36, 16, 29, 13, 13, 16, 16, 13, 15, 16, 15, 16, 14, 14, 17, 18, 15, 18, 14], "policy_red_0_reward": [-0.03100000000000002, 1.3940000000000001, 0.46299999999999997, 0.5, 1.44, 0.499, 1.452, -0.002, 1.4489999999999998, 1.455, -0.001, 1.455, -0.5, 1.455, 0.5, 1.411, 1.4609999999999999, 0.5, 0.498, 1.4369999999999998, -0.002, 1.4609999999999999, -0.001, 0.5, -0.001, 1.452, 1.4369999999999998, 1.448, 1.454, 1.4489999999999998, 0.5, 1.436, 1.4100000000000001, 1.455, 1.46, 1.464, 0.5, 1.4329999999999998, 1.4609999999999999, 1.452, 0.499, 1.455, -1.0, 0.5, 1.458, 1.4489999999999998, 1.451, 1.429, 1.446, 0.5, 0.498, 1.4329999999999998, 1.45, 1.434, 0.499, 1.458, 1.4489999999999998, 0.498, 1.448, 1.016, -0.502, 1.458, 1.458, 1.4609999999999999, 1.455, -0.03900000000000003, 1.4609999999999999, -0.002, 1.4729999999999999, 0.499, 1.4609999999999999, -0.03900000000000003, 1.455, 1.467, -0.001, 0.5, 1.458, 1.4609999999999999, 1.47, 1.458, 0.484, 0.499, 1.467, 1.452, -0.514, 0.498, 0.499, 1.458, 1.458, 1.4449999999999998, 1.4369999999999998, 1.4180000000000001, 0.0, 1.455, 1.447, 0.43499999999999994, -0.5, 1.443, 1.4729999999999999, 1.4609999999999999, 1.455, -0.501, 1.4609999999999999, 1.452, 1.4529999999999998, 0.499, 1.4060000000000001, 1.472, 1.466, 0.5, 1.434, 1.428, 0.5, 0.5, 0.499, -0.002, 1.448, -0.001, -0.001, 1.452, 1.412, 1.4609999999999999, 1.4609999999999999, 1.45, 1.452, -0.002, 0.499, 1.452, 0.499, 0.499, 0.498, 0.499, 1.4489999999999998, 0.5, 1.455, 1.446, 1.4569999999999999], "policy_blue_0_reward": [0.44699999999999995, -0.002, 0.46399999999999997, 1.4409999999999998, 0.5, 1.455, 0.498, 1.4489999999999998, 0.498, 0.5, 1.363, 0.498, 0.96, 0.498, 1.454, 0.498, -0.001, 1.4569999999999999, 1.4300000000000002, 0.5, 1.419, 0.498, 1.458, 1.455, 1.4249999999999998, 0.499, 0.498, 0.5, 0.5, 0.499, 1.4609999999999999, 0.497, 0.496, -0.001, -0.5019999999999999, -1.001, 1.4529999999999998, 0.496, 0.499, 0.498, 1.45, 0.499, 0.939, 1.4369999999999998, 0.499, 0.499, 0.499, -0.002, 0.499, 1.4489999999999998, 1.458, 0.498, -0.001, 0.499, 1.4489999999999998, 0.498, -0.002, 1.458, 0.498, -0.521, 1.4609999999999999, 0.498, 0.5, -0.001, 0.5, 0.45699999999999996, 0.499, 1.452, -0.5, 1.458, -0.5, 0.45399999999999996, 0.497, -0.501, 1.446, 1.4569999999999999, 0.498, 0.498, -0.504, 0.499, 0.469, 1.4489999999999998, -0.501, 0.498, 1.262, 1.4449999999999998, 1.4140000000000001, 0.499, 0.5, 0.498, 0.0, 0.499, 1.454, 0.498, 0.498, 0.474, 0.963, -0.001, -0.5, 0.5, 0.498, 1.45, 0.498, 0.5, 0.5, 1.452, 0.498, -1.002, -0.502, 1.4449999999999998, 0.498, 0.498, 1.4609999999999999, 1.458, 1.442, 1.446, -0.002, 1.429, 1.388, 0.499, 0.498, 0.5, 0.5, -0.001, 0.499, 1.4609999999999999, 1.454, 0.495, 1.455, 1.452, 1.458, 1.458, 0.5, 1.444, 0.498, 0.499, 0.497]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4309810910431515, "mean_inference_ms": 7.468891903666075, "mean_action_processing_ms": 0.39016502049538526, "mean_env_wait_ms": 0.5226003845161237, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15886352010016894, "StateBufferConnector_ms": 0.010149409301089544, "ViewRequirementAgentConnector_ms": 0.20089488830009516}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1064000, "num_agent_steps_trained": 1064000, "num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 141.62780344647248, "num_env_steps_trained_throughput_per_sec": 141.62780344647248, "timesteps_total": 532000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1064000, "timers": {"training_iteration_time_ms": 31362.022, "sample_time_ms": 4066.968, "learn_time_ms": 27266.678, "learn_throughput": 146.699, "synch_weights_time_ms": 26.828}, "counters": {"num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_agent_steps_sampled": 1064000, "num_agent_steps_trained": 1064000}, "done": false, "episodes_total": 11494, "training_iteration": 133, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-08-04", "timestamp": 1694840884, "time_this_iter_s": 28.26013970375061, "time_total_s": 4161.384141206741, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a349360>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4161.384141206741, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 25.942857142857147, "ram_util_percent": 58.00238095238096}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6166666666666667, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.09444444444444444, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.044444444444444446, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.09444444444444444, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.22777777777777777, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.044444444444444446, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.09444444444444444, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.044444444444444446, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4340960326138884, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.031221222692208055, "policy_loss": -0.06839855610232917, "vf_loss": 0.036788487071559454, "vf_explained_var": 0.7006386067097385, "kl": 0.008626454286081886, "entropy": 0.8690508513400952, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 128160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4837040695051352, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.043150109729322136, "policy_loss": -0.08356085921356377, "vf_loss": 0.03598399516389084, "vf_explained_var": 0.6162627616897225, "kl": 0.01038233748120471, "entropy": 1.2335108559578658, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 128160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06899999999999995, "episode_reward_mean": 1.6512055555555554, "episode_len_mean": 22.25, "episode_media": {}, "episodes_this_iter": 180, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.001}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 1.078588888888889, "blue_0": 0.5726166666666667}, "custom_metrics": {"red_0/door_open_done_mean": 0.6166666666666667, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.09444444444444444, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.044444444444444446, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.09444444444444444, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.22777777777777777, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.044444444444444446, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.09444444444444444, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.044444444444444446, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.44199999999999995, 1.938, 1.956, 1.9489999999999998, 1.4609999999999999, 1.946, 1.938, -0.06899999999999995, 1.454, 1.9609999999999999, 0.46899999999999986, 1.438, 1.4609999999999999, 1.955, 1.919, 1.9609999999999999, 1.958, 1.9609999999999999, 1.9409999999999998, 1.951, 1.958, 1.958, 1.454, 1.954, 1.96, 1.9569999999999999, 1.9609999999999999, 1.935, 1.95, 1.266, 1.919, 1.9569999999999999, 1.946, 1.938, 1.942, 1.443, 1.452, 1.451, 1.885, 1.958, 0.951, -0.05500000000000005, 0.4660000000000002, 1.936, 1.951, 1.9489999999999998, 1.9180000000000001, 1.899, 1.96, 1.951, 1.399, 0.9630000000000001, 0.476, 1.427, 1.947, 1.9609999999999999, 1.95, 1.9569999999999999, 1.938, 1.9529999999999998, 0.967, 1.4569999999999999, 0.9729999999999999, 1.911, 1.815, 1.92, 1.95, 0.9729999999999999, 1.952, 0.952, 0.9689999999999999, 1.952, 1.9609999999999999, 1.952, 1.955, 1.446, 1.948, 1.9529999999999998, 1.9569999999999999, 1.959, 1.9529999999999998, 1.436, 1.443, 0.961, 1.9569999999999999, 1.958, 1.4300000000000002, 1.959, 1.947, 1.9609999999999999, 1.917, 1.955, 1.924, 1.947, 1.9609999999999999, 1.447, 1.939, 1.9529999999999998, 1.9449999999999998, 1.935, 0.476, 1.958, 1.919, 1.952, 1.4369999999999998, 1.4489999999999998, 1.444, 0.45100000000000007, 1.939, 1.9609999999999999, 1.939, 1.417, 1.958, 1.444, 0.97, 1.438, 1.943, 1.9489999999999998, 1.958, 1.9569999999999999, 1.951, 1.4609999999999999, 0.976, 1.9449999999999998, 0.97, 1.405, 1.456, 1.955, 1.94, 1.9449999999999998, 1.943, 0.956, 0.947, 1.46, 0.935, 1.444, 0.45399999999999996, 1.946, 1.455, 1.96, 1.952, 1.958, 0.954, 1.456, 1.454, 1.959, 1.951, 1.4609999999999999, 1.897, 1.95, 1.915, 1.9489999999999998, 1.251, 1.952, 1.924, 1.958, 1.959, 1.9260000000000002, 1.4369999999999998, 1.955, 1.955, 1.439, 1.954, 1.95, 1.955, 1.4260000000000002, 1.46, 1.9489999999999998, 1.96, 0.96, 0.482, 1.93, 0.966, 1.9569999999999999, 1.935, 0.46499999999999986, 1.958, 1.9609999999999999, 1.96, 1.9329999999999998], "episode_lengths": [300, 20, 14, 17, 13, 18, 20, 23, 15, 13, 10, 19, 13, 15, 26, 13, 14, 13, 19, 16, 14, 14, 15, 15, 13, 14, 13, 19, 16, 73, 26, 14, 18, 20, 19, 18, 16, 16, 37, 14, 16, 17, 10, 21, 16, 15, 26, 30, 13, 16, 33, 12, 8, 24, 17, 13, 16, 14, 20, 15, 11, 14, 9, 28, 59, 25, 16, 9, 16, 300, 10, 16, 13, 16, 15, 17, 17, 15, 14, 13, 15, 21, 18, 300, 14, 14, 23, 13, 16, 13, 27, 15, 24, 17, 13, 17, 19, 15, 18, 21, 8, 14, 26, 15, 19, 16, 18, 16, 20, 13, 19, 26, 14, 18, 10, 20, 18, 17, 14, 14, 16, 13, 8, 18, 10, 30, 14, 15, 19, 18, 19, 13, 17, 13, 21, 18, 15, 17, 15, 13, 16, 14, 14, 14, 15, 13, 16, 13, 33, 16, 27, 17, 79, 16, 24, 14, 13, 23, 20, 15, 15, 19, 15, 16, 14, 23, 13, 16, 13, 12, 6, 22, 11, 14, 21, 11, 14, 13, 13, 22], "policy_red_0_reward": [-0.03000000000000002, 0.498, 1.458, 1.4489999999999998, 1.4609999999999999, 0.5, 1.438, 0.931, 1.455, 1.4609999999999999, 1.47, 1.442, 0.0, 1.455, 1.42, 1.4609999999999999, 0.5, 1.4609999999999999, 1.443, 1.452, 1.458, 0.5, 1.455, 0.499, 1.4609999999999999, 0.5, 1.4609999999999999, 1.442, 1.452, -0.007, 1.421, 1.458, 0.5, 1.438, 1.442, 1.446, 1.452, -0.001, 1.388, 0.5, -0.501, -1.002, 0.969, 1.4369999999999998, 1.451, 1.4529999999999998, 1.42, 1.408, 1.4609999999999999, 1.451, -0.001, 1.464, -0.5, 1.428, 0.499, 0.5, 1.452, 0.499, 0.499, 1.454, -0.5, 1.458, 1.4729999999999999, 1.413, 1.322, 1.424, 1.452, 1.4729999999999999, 0.5, 0.48, 1.4689999999999999, 1.452, 1.4609999999999999, 0.5, 1.455, -0.001, 1.448, 1.454, 1.458, 1.4609999999999999, 1.455, 1.4369999999999998, 1.4449999999999998, 0.49, 0.5, 1.458, 1.431, 1.4609999999999999, 1.45, 0.5, 1.4180000000000001, 0.5, 0.499, 1.448, 1.4609999999999999, 1.448, 1.442, 1.454, 0.5, 1.4369999999999998, 0.976, 1.458, 0.5, 1.455, 1.443, -0.002, 1.4449999999999998, 1.452, 1.44, 0.5, 1.442, 1.419, 1.458, 1.446, 1.47, 1.439, 1.446, 1.4489999999999998, 0.5, 1.458, 1.451, 1.4609999999999999, -0.5, 1.446, 1.47, -0.002, -0.002, 0.5, 1.4409999999999998, 0.499, 1.443, 1.46, -0.501, 1.4609999999999999, 1.436, 1.4449999999999998, 0.954, 1.4489999999999998, 1.455, 1.4609999999999999, 1.452, 0.5, -0.501, 1.458, 1.454, 1.4609999999999999, 1.452, 1.4609999999999999, 0.498, 1.451, 1.419, 1.4489999999999998, 1.259, 1.452, 0.498, 0.5, 1.4609999999999999, 1.428, -0.002, 1.455, 1.455, -0.001, 1.455, 0.499, 1.458, 1.4300000000000002, 1.4609999999999999, 1.452, 1.4609999999999999, 1.464, 0.982, 1.432, -0.5, 0.499, 1.436, 0.967, 1.458, 0.5, 1.4609999999999999, 1.434], "policy_blue_0_reward": [0.472, 1.44, 0.498, 0.5, 0.0, 1.446, 0.5, -1.0, -0.001, 0.5, -1.001, -0.004, 1.4609999999999999, 0.5, 0.499, 0.5, 1.458, 0.5, 0.498, 0.499, 0.5, 1.458, -0.001, 1.455, 0.499, 1.4569999999999999, 0.5, 0.493, 0.498, 1.273, 0.498, 0.499, 1.446, 0.5, 0.5, -0.003, 0.0, 1.452, 0.497, 1.458, 1.452, 0.947, -0.5029999999999999, 0.499, 0.5, 0.496, 0.498, 0.491, 0.499, 0.5, 1.4, -0.501, 0.976, -0.001, 1.448, 1.4609999999999999, 0.498, 1.458, 1.439, 0.499, 1.467, -0.001, -0.5, 0.498, 0.493, 0.496, 0.498, -0.5, 1.452, 0.472, -0.5, 0.5, 0.5, 1.452, 0.5, 1.447, 0.5, 0.499, 0.499, 0.498, 0.498, -0.001, -0.002, 0.471, 1.4569999999999999, 0.5, -0.001, 0.498, 0.497, 1.4609999999999999, 0.499, 1.455, 1.4249999999999998, 0.499, 0.5, -0.001, 0.497, 0.499, 1.4449999999999998, 0.498, -0.5, 0.5, 1.419, 0.497, -0.006, 1.451, -0.001, -1.001, 0.499, 1.4609999999999999, 0.497, -0.002, 0.5, -0.002, -0.5, -0.001, 0.497, 0.5, 1.458, 0.499, 0.5, 0.0, 1.476, 0.499, -0.5, 1.407, 1.458, 1.455, 0.499, 1.446, 0.5, -0.5039999999999999, 1.448, -0.001, -0.501, -0.001, -0.5, 0.497, 0.0, 0.499, 0.5, 1.458, 1.455, -0.002, 0.0, 0.498, 0.499, 0.0, 1.399, 0.499, 0.496, 0.5, -0.008, 0.5, 1.426, 1.458, 0.498, 0.498, 1.439, 0.5, 0.5, 1.44, 0.499, 1.451, 0.497, -0.004, -0.001, 0.497, 0.499, -0.504, -0.5, 0.498, 1.466, 1.458, 0.499, -0.502, 0.5, 1.4609999999999999, 0.499, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.431181607457601, "mean_inference_ms": 7.464704178830991, "mean_action_processing_ms": 0.38965832744302403, "mean_env_wait_ms": 0.5228104562536544, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1374534765879313, "StateBufferConnector_ms": 0.008411407470703125, "ViewRequirementAgentConnector_ms": 0.17309142483605278}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06899999999999995, "episode_reward_mean": 1.6512055555555554, "episode_len_mean": 22.25, "episodes_this_iter": 180, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.001}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 1.078588888888889, "blue_0": 0.5726166666666667}, "hist_stats": {"episode_reward": [0.44199999999999995, 1.938, 1.956, 1.9489999999999998, 1.4609999999999999, 1.946, 1.938, -0.06899999999999995, 1.454, 1.9609999999999999, 0.46899999999999986, 1.438, 1.4609999999999999, 1.955, 1.919, 1.9609999999999999, 1.958, 1.9609999999999999, 1.9409999999999998, 1.951, 1.958, 1.958, 1.454, 1.954, 1.96, 1.9569999999999999, 1.9609999999999999, 1.935, 1.95, 1.266, 1.919, 1.9569999999999999, 1.946, 1.938, 1.942, 1.443, 1.452, 1.451, 1.885, 1.958, 0.951, -0.05500000000000005, 0.4660000000000002, 1.936, 1.951, 1.9489999999999998, 1.9180000000000001, 1.899, 1.96, 1.951, 1.399, 0.9630000000000001, 0.476, 1.427, 1.947, 1.9609999999999999, 1.95, 1.9569999999999999, 1.938, 1.9529999999999998, 0.967, 1.4569999999999999, 0.9729999999999999, 1.911, 1.815, 1.92, 1.95, 0.9729999999999999, 1.952, 0.952, 0.9689999999999999, 1.952, 1.9609999999999999, 1.952, 1.955, 1.446, 1.948, 1.9529999999999998, 1.9569999999999999, 1.959, 1.9529999999999998, 1.436, 1.443, 0.961, 1.9569999999999999, 1.958, 1.4300000000000002, 1.959, 1.947, 1.9609999999999999, 1.917, 1.955, 1.924, 1.947, 1.9609999999999999, 1.447, 1.939, 1.9529999999999998, 1.9449999999999998, 1.935, 0.476, 1.958, 1.919, 1.952, 1.4369999999999998, 1.4489999999999998, 1.444, 0.45100000000000007, 1.939, 1.9609999999999999, 1.939, 1.417, 1.958, 1.444, 0.97, 1.438, 1.943, 1.9489999999999998, 1.958, 1.9569999999999999, 1.951, 1.4609999999999999, 0.976, 1.9449999999999998, 0.97, 1.405, 1.456, 1.955, 1.94, 1.9449999999999998, 1.943, 0.956, 0.947, 1.46, 0.935, 1.444, 0.45399999999999996, 1.946, 1.455, 1.96, 1.952, 1.958, 0.954, 1.456, 1.454, 1.959, 1.951, 1.4609999999999999, 1.897, 1.95, 1.915, 1.9489999999999998, 1.251, 1.952, 1.924, 1.958, 1.959, 1.9260000000000002, 1.4369999999999998, 1.955, 1.955, 1.439, 1.954, 1.95, 1.955, 1.4260000000000002, 1.46, 1.9489999999999998, 1.96, 0.96, 0.482, 1.93, 0.966, 1.9569999999999999, 1.935, 0.46499999999999986, 1.958, 1.9609999999999999, 1.96, 1.9329999999999998], "episode_lengths": [300, 20, 14, 17, 13, 18, 20, 23, 15, 13, 10, 19, 13, 15, 26, 13, 14, 13, 19, 16, 14, 14, 15, 15, 13, 14, 13, 19, 16, 73, 26, 14, 18, 20, 19, 18, 16, 16, 37, 14, 16, 17, 10, 21, 16, 15, 26, 30, 13, 16, 33, 12, 8, 24, 17, 13, 16, 14, 20, 15, 11, 14, 9, 28, 59, 25, 16, 9, 16, 300, 10, 16, 13, 16, 15, 17, 17, 15, 14, 13, 15, 21, 18, 300, 14, 14, 23, 13, 16, 13, 27, 15, 24, 17, 13, 17, 19, 15, 18, 21, 8, 14, 26, 15, 19, 16, 18, 16, 20, 13, 19, 26, 14, 18, 10, 20, 18, 17, 14, 14, 16, 13, 8, 18, 10, 30, 14, 15, 19, 18, 19, 13, 17, 13, 21, 18, 15, 17, 15, 13, 16, 14, 14, 14, 15, 13, 16, 13, 33, 16, 27, 17, 79, 16, 24, 14, 13, 23, 20, 15, 15, 19, 15, 16, 14, 23, 13, 16, 13, 12, 6, 22, 11, 14, 21, 11, 14, 13, 13, 22], "policy_red_0_reward": [-0.03000000000000002, 0.498, 1.458, 1.4489999999999998, 1.4609999999999999, 0.5, 1.438, 0.931, 1.455, 1.4609999999999999, 1.47, 1.442, 0.0, 1.455, 1.42, 1.4609999999999999, 0.5, 1.4609999999999999, 1.443, 1.452, 1.458, 0.5, 1.455, 0.499, 1.4609999999999999, 0.5, 1.4609999999999999, 1.442, 1.452, -0.007, 1.421, 1.458, 0.5, 1.438, 1.442, 1.446, 1.452, -0.001, 1.388, 0.5, -0.501, -1.002, 0.969, 1.4369999999999998, 1.451, 1.4529999999999998, 1.42, 1.408, 1.4609999999999999, 1.451, -0.001, 1.464, -0.5, 1.428, 0.499, 0.5, 1.452, 0.499, 0.499, 1.454, -0.5, 1.458, 1.4729999999999999, 1.413, 1.322, 1.424, 1.452, 1.4729999999999999, 0.5, 0.48, 1.4689999999999999, 1.452, 1.4609999999999999, 0.5, 1.455, -0.001, 1.448, 1.454, 1.458, 1.4609999999999999, 1.455, 1.4369999999999998, 1.4449999999999998, 0.49, 0.5, 1.458, 1.431, 1.4609999999999999, 1.45, 0.5, 1.4180000000000001, 0.5, 0.499, 1.448, 1.4609999999999999, 1.448, 1.442, 1.454, 0.5, 1.4369999999999998, 0.976, 1.458, 0.5, 1.455, 1.443, -0.002, 1.4449999999999998, 1.452, 1.44, 0.5, 1.442, 1.419, 1.458, 1.446, 1.47, 1.439, 1.446, 1.4489999999999998, 0.5, 1.458, 1.451, 1.4609999999999999, -0.5, 1.446, 1.47, -0.002, -0.002, 0.5, 1.4409999999999998, 0.499, 1.443, 1.46, -0.501, 1.4609999999999999, 1.436, 1.4449999999999998, 0.954, 1.4489999999999998, 1.455, 1.4609999999999999, 1.452, 0.5, -0.501, 1.458, 1.454, 1.4609999999999999, 1.452, 1.4609999999999999, 0.498, 1.451, 1.419, 1.4489999999999998, 1.259, 1.452, 0.498, 0.5, 1.4609999999999999, 1.428, -0.002, 1.455, 1.455, -0.001, 1.455, 0.499, 1.458, 1.4300000000000002, 1.4609999999999999, 1.452, 1.4609999999999999, 1.464, 0.982, 1.432, -0.5, 0.499, 1.436, 0.967, 1.458, 0.5, 1.4609999999999999, 1.434], "policy_blue_0_reward": [0.472, 1.44, 0.498, 0.5, 0.0, 1.446, 0.5, -1.0, -0.001, 0.5, -1.001, -0.004, 1.4609999999999999, 0.5, 0.499, 0.5, 1.458, 0.5, 0.498, 0.499, 0.5, 1.458, -0.001, 1.455, 0.499, 1.4569999999999999, 0.5, 0.493, 0.498, 1.273, 0.498, 0.499, 1.446, 0.5, 0.5, -0.003, 0.0, 1.452, 0.497, 1.458, 1.452, 0.947, -0.5029999999999999, 0.499, 0.5, 0.496, 0.498, 0.491, 0.499, 0.5, 1.4, -0.501, 0.976, -0.001, 1.448, 1.4609999999999999, 0.498, 1.458, 1.439, 0.499, 1.467, -0.001, -0.5, 0.498, 0.493, 0.496, 0.498, -0.5, 1.452, 0.472, -0.5, 0.5, 0.5, 1.452, 0.5, 1.447, 0.5, 0.499, 0.499, 0.498, 0.498, -0.001, -0.002, 0.471, 1.4569999999999999, 0.5, -0.001, 0.498, 0.497, 1.4609999999999999, 0.499, 1.455, 1.4249999999999998, 0.499, 0.5, -0.001, 0.497, 0.499, 1.4449999999999998, 0.498, -0.5, 0.5, 1.419, 0.497, -0.006, 1.451, -0.001, -1.001, 0.499, 1.4609999999999999, 0.497, -0.002, 0.5, -0.002, -0.5, -0.001, 0.497, 0.5, 1.458, 0.499, 0.5, 0.0, 1.476, 0.499, -0.5, 1.407, 1.458, 1.455, 0.499, 1.446, 0.5, -0.5039999999999999, 1.448, -0.001, -0.501, -0.001, -0.5, 0.497, 0.0, 0.499, 0.5, 1.458, 1.455, -0.002, 0.0, 0.498, 0.499, 0.0, 1.399, 0.499, 0.496, 0.5, -0.008, 0.5, 1.426, 1.458, 0.498, 0.498, 1.439, 0.5, 0.5, 1.44, 0.499, 1.451, 0.497, -0.004, -0.001, 0.497, 0.499, -0.504, -0.5, 0.498, 1.466, 1.458, 0.499, -0.502, 0.5, 1.4609999999999999, 0.499, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.431181607457601, "mean_inference_ms": 7.464704178830991, "mean_action_processing_ms": 0.38965832744302403, "mean_env_wait_ms": 0.5228104562536544, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1374534765879313, "StateBufferConnector_ms": 0.008411407470703125, "ViewRequirementAgentConnector_ms": 0.17309142483605278}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 154.34730747730444, "num_env_steps_trained_throughput_per_sec": 154.34730747730444, "timesteps_total": 536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 30845.659, "sample_time_ms": 4019.287, "learn_time_ms": 26798.114, "learn_throughput": 149.264, "synch_weights_time_ms": 26.735}, "counters": {"num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "episodes_total": 11674, "training_iteration": 134, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-08-31", "timestamp": 1694840911, "time_this_iter_s": 25.93674087524414, "time_total_s": 4187.3208820819855, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a2eb250>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4187.3208820819855, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 22.326315789473682, "ram_util_percent": 56.39210526315789}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6859504132231405, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.03305785123966942, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04132231404958678, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.03305785123966942, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.2066115702479339, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.04132231404958678, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.03305785123966942, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04132231404958678, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3950361900186787, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03258680617145728, "policy_loss": -0.06155631667425041, "vf_loss": 0.02084648191278878, "vf_explained_var": 0.8120293956249952, "kl": 0.008599785357267754, "entropy": 1.0451169742271305, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 129120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.44825534797273575, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04340729418036062, "policy_loss": -0.07230538116855315, "vf_loss": 0.020813342105733077, "vf_explained_var": 0.6490142701814572, "kl": 0.008721775454527384, "entropy": 1.3778785345455011, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 129120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_agent_steps_sampled": 1080000, "num_agent_steps_trained": 1080000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06300000000000004, "episode_reward_mean": 1.683099173553719, "episode_len_mean": 28.760330578512395, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 1.0807685950413224, "blue_0": 0.6023305785123967}, "custom_metrics": {"red_0/door_open_done_mean": 0.6859504132231405, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.03305785123966942, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04132231404958678, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.03305785123966942, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.2066115702479339, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.04132231404958678, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.03305785123966942, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04132231404958678, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.42499999999999993, 1.951, 1.954, 1.952, 1.443, 1.942, 1.947, 1.955, 1.452, 1.233, 1.9609999999999999, 1.948, 1.942, 0.476, 1.33, 0.762, 1.948, 1.952, 1.931, 1.947, 1.951, 1.959, 1.959, 1.458, 1.956, 1.958, 1.936, 1.938, 1.9569999999999999, 1.946, 1.954, 1.954, 1.4409999999999998, 1.451, 1.4260000000000002, 0.469, 1.951, 1.439, 1.9489999999999998, 1.903, 0.402, 1.943, 1.9609999999999999, 1.448, 1.9569999999999999, 1.427, 1.9489999999999998, 1.954, 1.948, 1.958, 1.9609999999999999, 1.4369999999999998, 1.9489999999999998, 1.442, 1.947, 1.434, 1.947, 1.9569999999999999, 1.92, 1.9300000000000002, 1.459, 0.963, 1.96, 1.951, 1.9529999999999998, 1.95, 1.954, -0.06300000000000004, 1.95, 1.9329999999999998, 1.96, 1.96, 1.442, 1.443, 1.9449999999999998, 1.901, 1.934, 1.946, 1.954, 1.931, 1.45, 1.9609999999999999, 1.9609999999999999, 1.4529999999999998, 1.4489999999999998, 1.935, 1.9569999999999999, 1.954, 0.478, 1.9609999999999999, 1.9569999999999999, 1.954, 1.954, 1.915, 1.9609999999999999, 1.9569999999999999, 0.42900000000000005, 1.451, 1.458, 1.9249999999999998, 1.956, 1.9040000000000001, 1.9569999999999999, 1.9609999999999999, 1.434, 0.45699999999999996, 1.9609999999999999, 1.942, 0.47, 1.454, 1.952, 1.458, 1.9449999999999998, 1.935, 1.447, 1.9609999999999999, 0.45299999999999985, 1.952, 0.9299999999999999, 1.948, 1.955], "episode_lengths": [300, 16, 15, 15, 19, 19, 17, 14, 16, 241, 13, 17, 18, 8, 53, 70, 17, 16, 23, 17, 16, 13, 13, 14, 14, 14, 20, 20, 14, 17, 15, 15, 19, 16, 23, 10, 16, 20, 16, 30, 31, 19, 13, 17, 14, 24, 17, 15, 17, 14, 13, 20, 17, 19, 17, 21, 17, 14, 25, 22, 13, 300, 13, 16, 15, 16, 15, 300, 16, 22, 13, 13, 18, 18, 17, 32, 21, 18, 15, 23, 16, 13, 13, 15, 16, 21, 14, 15, 7, 13, 14, 15, 15, 28, 13, 14, 23, 16, 13, 24, 14, 30, 14, 13, 21, 14, 13, 19, 10, 15, 16, 14, 18, 20, 17, 13, 15, 15, 300, 17, 15], "policy_red_0_reward": [-0.037000000000000026, 1.452, 1.455, 1.454, 1.443, 1.443, 1.448, 1.4569999999999999, 1.452, 0.753, 1.4609999999999999, 1.4489999999999998, 0.497, 0.976, -0.007, -0.504, 1.4489999999999998, 0.5, 1.431, 1.4489999999999998, 0.499, 1.4609999999999999, 1.4609999999999999, 0.0, 1.458, 1.458, 0.497, 0.498, 1.458, 0.499, 1.455, 0.5, 1.442, -0.001, 1.429, -1.0, 1.452, 0.0, 0.5, 1.408, -1.001, 1.443, 1.4609999999999999, 1.4489999999999998, 1.458, 1.427, 1.4489999999999998, 1.455, 0.499, 0.5, 1.4609999999999999, 1.44, 1.4489999999999998, 1.442, 1.448, -0.003, 1.448, 1.4569999999999999, 1.423, 1.4329999999999998, 1.4609999999999999, 0.491, 1.4609999999999999, 1.451, 1.455, 1.452, 1.455, -0.035000000000000024, 1.452, 1.434, 1.4609999999999999, 1.4609999999999999, 1.4449999999999998, 1.446, 1.447, 1.403, 1.434, 0.5, 0.499, 1.431, 1.451, 1.4609999999999999, 0.5, 1.455, 1.452, 1.4369999999999998, 1.458, 0.499, 1.479, 1.4609999999999999, 1.458, 1.455, 0.499, 0.499, 1.4609999999999999, 0.5, -1.0, 1.452, 1.4609999999999999, 1.4249999999999998, 1.458, 1.4060000000000001, 1.458, 1.4609999999999999, 1.435, -1.001, 1.4609999999999999, 1.443, 0.97, 1.455, 1.452, 1.458, 1.4449999999999998, 0.497, 1.4489999999999998, 0.5, 1.455, 1.454, 0.46299999999999997, 0.499, 1.455], "policy_blue_0_reward": [0.46199999999999997, 0.499, 0.499, 0.498, 0.0, 0.499, 0.499, 0.498, 0.0, 0.48, 0.5, 0.499, 1.4449999999999998, -0.5, 1.337, 1.266, 0.499, 1.452, 0.5, 0.498, 1.452, 0.498, 0.498, 1.458, 0.498, 0.5, 1.439, 1.44, 0.499, 1.447, 0.499, 1.454, -0.001, 1.452, -0.003, 1.4689999999999999, 0.499, 1.439, 1.4489999999999998, 0.495, 1.403, 0.5, 0.5, -0.001, 0.499, 0.0, 0.5, 0.499, 1.4489999999999998, 1.458, 0.5, -0.003, 0.5, 0.0, 0.499, 1.4369999999999998, 0.499, 0.5, 0.497, 0.497, -0.002, 0.472, 0.499, 0.5, 0.498, 0.498, 0.499, -0.028000000000000018, 0.498, 0.499, 0.499, 0.499, -0.003, -0.003, 0.498, 0.498, 0.5, 1.446, 1.455, 0.5, -0.001, 0.5, 1.4609999999999999, -0.002, -0.003, 0.498, 0.499, 1.455, -1.001, 0.5, 0.499, 0.499, 1.455, 1.416, 0.5, 1.4569999999999999, 1.429, -0.001, -0.003, 0.5, 0.498, 0.498, 0.499, 0.5, -0.001, 1.458, 0.5, 0.499, -0.5, -0.001, 0.5, 0.0, 0.5, 1.438, -0.002, 1.4609999999999999, -1.002, 0.498, 0.46699999999999997, 1.4489999999999998, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.430593760517821, "mean_inference_ms": 7.47936096783444, "mean_action_processing_ms": 0.3898955683112126, "mean_env_wait_ms": 0.5235248994735254, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1833121638652707, "StateBufferConnector_ms": 0.010224511800718702, "ViewRequirementAgentConnector_ms": 0.20439220854073517}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06300000000000004, "episode_reward_mean": 1.683099173553719, "episode_len_mean": 28.760330578512395, "episodes_this_iter": 121, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.4689999999999999}, "policy_reward_mean": {"red_0": 1.0807685950413224, "blue_0": 0.6023305785123967}, "hist_stats": {"episode_reward": [0.42499999999999993, 1.951, 1.954, 1.952, 1.443, 1.942, 1.947, 1.955, 1.452, 1.233, 1.9609999999999999, 1.948, 1.942, 0.476, 1.33, 0.762, 1.948, 1.952, 1.931, 1.947, 1.951, 1.959, 1.959, 1.458, 1.956, 1.958, 1.936, 1.938, 1.9569999999999999, 1.946, 1.954, 1.954, 1.4409999999999998, 1.451, 1.4260000000000002, 0.469, 1.951, 1.439, 1.9489999999999998, 1.903, 0.402, 1.943, 1.9609999999999999, 1.448, 1.9569999999999999, 1.427, 1.9489999999999998, 1.954, 1.948, 1.958, 1.9609999999999999, 1.4369999999999998, 1.9489999999999998, 1.442, 1.947, 1.434, 1.947, 1.9569999999999999, 1.92, 1.9300000000000002, 1.459, 0.963, 1.96, 1.951, 1.9529999999999998, 1.95, 1.954, -0.06300000000000004, 1.95, 1.9329999999999998, 1.96, 1.96, 1.442, 1.443, 1.9449999999999998, 1.901, 1.934, 1.946, 1.954, 1.931, 1.45, 1.9609999999999999, 1.9609999999999999, 1.4529999999999998, 1.4489999999999998, 1.935, 1.9569999999999999, 1.954, 0.478, 1.9609999999999999, 1.9569999999999999, 1.954, 1.954, 1.915, 1.9609999999999999, 1.9569999999999999, 0.42900000000000005, 1.451, 1.458, 1.9249999999999998, 1.956, 1.9040000000000001, 1.9569999999999999, 1.9609999999999999, 1.434, 0.45699999999999996, 1.9609999999999999, 1.942, 0.47, 1.454, 1.952, 1.458, 1.9449999999999998, 1.935, 1.447, 1.9609999999999999, 0.45299999999999985, 1.952, 0.9299999999999999, 1.948, 1.955], "episode_lengths": [300, 16, 15, 15, 19, 19, 17, 14, 16, 241, 13, 17, 18, 8, 53, 70, 17, 16, 23, 17, 16, 13, 13, 14, 14, 14, 20, 20, 14, 17, 15, 15, 19, 16, 23, 10, 16, 20, 16, 30, 31, 19, 13, 17, 14, 24, 17, 15, 17, 14, 13, 20, 17, 19, 17, 21, 17, 14, 25, 22, 13, 300, 13, 16, 15, 16, 15, 300, 16, 22, 13, 13, 18, 18, 17, 32, 21, 18, 15, 23, 16, 13, 13, 15, 16, 21, 14, 15, 7, 13, 14, 15, 15, 28, 13, 14, 23, 16, 13, 24, 14, 30, 14, 13, 21, 14, 13, 19, 10, 15, 16, 14, 18, 20, 17, 13, 15, 15, 300, 17, 15], "policy_red_0_reward": [-0.037000000000000026, 1.452, 1.455, 1.454, 1.443, 1.443, 1.448, 1.4569999999999999, 1.452, 0.753, 1.4609999999999999, 1.4489999999999998, 0.497, 0.976, -0.007, -0.504, 1.4489999999999998, 0.5, 1.431, 1.4489999999999998, 0.499, 1.4609999999999999, 1.4609999999999999, 0.0, 1.458, 1.458, 0.497, 0.498, 1.458, 0.499, 1.455, 0.5, 1.442, -0.001, 1.429, -1.0, 1.452, 0.0, 0.5, 1.408, -1.001, 1.443, 1.4609999999999999, 1.4489999999999998, 1.458, 1.427, 1.4489999999999998, 1.455, 0.499, 0.5, 1.4609999999999999, 1.44, 1.4489999999999998, 1.442, 1.448, -0.003, 1.448, 1.4569999999999999, 1.423, 1.4329999999999998, 1.4609999999999999, 0.491, 1.4609999999999999, 1.451, 1.455, 1.452, 1.455, -0.035000000000000024, 1.452, 1.434, 1.4609999999999999, 1.4609999999999999, 1.4449999999999998, 1.446, 1.447, 1.403, 1.434, 0.5, 0.499, 1.431, 1.451, 1.4609999999999999, 0.5, 1.455, 1.452, 1.4369999999999998, 1.458, 0.499, 1.479, 1.4609999999999999, 1.458, 1.455, 0.499, 0.499, 1.4609999999999999, 0.5, -1.0, 1.452, 1.4609999999999999, 1.4249999999999998, 1.458, 1.4060000000000001, 1.458, 1.4609999999999999, 1.435, -1.001, 1.4609999999999999, 1.443, 0.97, 1.455, 1.452, 1.458, 1.4449999999999998, 0.497, 1.4489999999999998, 0.5, 1.455, 1.454, 0.46299999999999997, 0.499, 1.455], "policy_blue_0_reward": [0.46199999999999997, 0.499, 0.499, 0.498, 0.0, 0.499, 0.499, 0.498, 0.0, 0.48, 0.5, 0.499, 1.4449999999999998, -0.5, 1.337, 1.266, 0.499, 1.452, 0.5, 0.498, 1.452, 0.498, 0.498, 1.458, 0.498, 0.5, 1.439, 1.44, 0.499, 1.447, 0.499, 1.454, -0.001, 1.452, -0.003, 1.4689999999999999, 0.499, 1.439, 1.4489999999999998, 0.495, 1.403, 0.5, 0.5, -0.001, 0.499, 0.0, 0.5, 0.499, 1.4489999999999998, 1.458, 0.5, -0.003, 0.5, 0.0, 0.499, 1.4369999999999998, 0.499, 0.5, 0.497, 0.497, -0.002, 0.472, 0.499, 0.5, 0.498, 0.498, 0.499, -0.028000000000000018, 0.498, 0.499, 0.499, 0.499, -0.003, -0.003, 0.498, 0.498, 0.5, 1.446, 1.455, 0.5, -0.001, 0.5, 1.4609999999999999, -0.002, -0.003, 0.498, 0.499, 1.455, -1.001, 0.5, 0.499, 0.499, 1.455, 1.416, 0.5, 1.4569999999999999, 1.429, -0.001, -0.003, 0.5, 0.498, 0.498, 0.499, 0.5, -0.001, 1.458, 0.5, 0.499, -0.5, -0.001, 0.5, 0.0, 0.5, 1.438, -0.002, 1.4609999999999999, -1.002, 0.498, 0.46699999999999997, 1.4489999999999998, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.430593760517821, "mean_inference_ms": 7.47936096783444, "mean_action_processing_ms": 0.3898955683112126, "mean_env_wait_ms": 0.5235248994735254, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1833121638652707, "StateBufferConnector_ms": 0.010224511800718702, "ViewRequirementAgentConnector_ms": 0.20439220854073517}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1080000, "num_agent_steps_trained": 1080000, "num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 147.84187870920096, "num_env_steps_trained_throughput_per_sec": 147.84187870920096, "timesteps_total": 540000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1080000, "timers": {"training_iteration_time_ms": 30306.366, "sample_time_ms": 4125.82, "learn_time_ms": 26152.984, "learn_throughput": 152.946, "synch_weights_time_ms": 26.038}, "counters": {"num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_agent_steps_sampled": 1080000, "num_agent_steps_trained": 1080000}, "done": false, "episodes_total": 11795, "training_iteration": 135, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-08-59", "timestamp": 1694840939, "time_this_iter_s": 27.072120904922485, "time_total_s": 4214.393002986908, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a3497e0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4214.393002986908, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 28.985000000000003, "ram_util_percent": 56.585}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.584, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.088, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.072, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.088, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.208, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.072, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.088, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.072, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.40164981967148683, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03028174528250626, "policy_loss": -0.05877880586194806, "vf_loss": 0.025216139863672046, "vf_explained_var": 0.7743292563905319, "kl": 0.0074412485792438405, "entropy": 1.0631045899664362, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 130080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4166496792497734, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04785834905924276, "policy_loss": -0.07837541154585778, "vf_loss": 0.025362102724708773, "vf_explained_var": 0.651490168645978, "kl": 0.008442101602283755, "entropy": 1.3961526160438855, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 130080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.040000000000000036, "episode_reward_mean": 1.5790799999999998, "episode_len_mean": 30.56, "episode_media": {}, "episodes_this_iter": 125, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.475}, "policy_reward_mean": {"red_0": 1.0206720000000002, "blue_0": 0.558408}, "custom_metrics": {"red_0/door_open_done_mean": 0.584, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.088, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.072, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.088, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.208, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.072, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.088, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.072, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.959, 1.9609999999999999, 1.96, 1.958, 1.455, 0.475, 0.43899999999999995, 0.45599999999999996, 1.9569999999999999, 1.4609999999999999, 1.929, 1.9529999999999998, 1.9569999999999999, 1.903, 0.4750000000000001, 1.9609999999999999, 1.908, 1.9609999999999999, 1.459, 0.9319999999999999, 1.951, 1.46, 1.4489999999999998, 1.956, 0.953, 1.957, 1.954, 1.954, 1.941, 1.948, -0.027999999999999914, 1.956, 0.46499999999999986, 1.956, 1.958, 0.973, 0.45399999999999996, 1.9569999999999999, 1.409, 0.954, 1.455, 1.955, 0.954, 1.958, 1.935, 1.456, 1.9609999999999999, 1.452, 1.952, 1.9489999999999998, 1.9609999999999999, 1.951, 1.4529999999999998, 0.958, 1.9369999999999998, 1.96, 1.9449999999999998, 1.955, -0.040000000000000036, 1.96, 0.44999999999999996, 1.9529999999999998, 1.942, 1.452, 1.9609999999999999, 1.6680000000000001, -0.03700000000000003, 0.44499999999999995, 1.9569999999999999, 1.958, 1.439, 1.365, 1.96, 1.956, 1.96, 1.948, 1.952, 1.451, 0.909, 1.951, 1.44, 1.956, 0.45899999999999996, 1.955, 1.436, 1.9609999999999999, 0.4119999999999999, 0.41999999999999993, 1.924, 1.438, 1.9569999999999999, 1.958, 1.9569999999999999, 1.959, 1.4580000000000002, 1.9529999999999998, 1.958, 1.9609999999999999, 1.946, 1.9489999999999998, 1.9529999999999998, 1.412, 1.946, 1.9489999999999998, 1.9529999999999998, 1.9609999999999999, 1.9449999999999998, 0.923, 0.916, 1.9100000000000001, -0.02100000000000002, 1.9569999999999999, 1.9609999999999999, 1.95, 1.9609999999999999, 1.9249999999999998, 1.4409999999999998, 1.9609999999999999, 0.96, 1.46, 1.943, 1.946, 1.944, 1.952, 1.917], "episode_lengths": [300, 13, 13, 14, 14, 8, 300, 14, 14, 13, 23, 15, 14, 32, 8, 13, 28, 13, 13, 300, 16, 13, 17, 14, 300, 14, 15, 15, 19, 17, 9, 14, 11, 14, 14, 9, 13, 14, 28, 15, 14, 15, 15, 13, 21, 14, 13, 15, 15, 17, 13, 16, 15, 300, 20, 13, 18, 14, 13, 13, 16, 15, 18, 16, 13, 105, 11, 18, 14, 14, 20, 42, 13, 14, 13, 17, 16, 14, 28, 16, 20, 14, 13, 15, 21, 13, 27, 300, 24, 20, 14, 14, 14, 13, 13, 15, 14, 13, 17, 17, 15, 29, 18, 16, 15, 13, 18, 24, 27, 29, 7, 14, 13, 16, 13, 24, 19, 13, 13, 13, 18, 18, 18, 16, 27], "policy_red_0_reward": [0.483, 0.5, 1.4609999999999999, 1.458, 1.4569999999999999, -1.0, 0.46699999999999997, 1.4569999999999999, 0.5, 1.4609999999999999, 1.431, 1.4529999999999998, 1.458, 1.403, 1.476, 0.5, 1.415, 1.4609999999999999, 1.4609999999999999, 0.47, 1.452, -0.001, 1.4489999999999998, 1.458, 0.483, 1.458, 0.5, 0.5, 1.442, 1.448, 0.973, 0.499, 1.467, 1.458, 1.458, -0.5, 1.459, 0.5, 1.4140000000000001, -0.5, 1.458, 0.5, 1.454, 1.4609999999999999, 0.498, 1.458, 1.4609999999999999, 1.455, 1.454, 0.5, 1.4609999999999999, 1.452, 1.455, 0.486, 0.499, 1.4609999999999999, 1.446, 1.4569999999999999, 0.96, 1.4609999999999999, -1.0, 1.454, 0.498, 1.452, 1.4609999999999999, 0.489, -1.001, -0.5, 0.499, 1.458, 1.44, 1.371, 1.4609999999999999, 1.4569999999999999, 0.499, 1.4489999999999998, 1.452, 1.4569999999999999, 1.416, 0.5, 1.44, 0.498, -1.0, 1.455, 1.4369999999999998, 1.4609999999999999, 0.917, -0.04200000000000003, 1.427, 1.439, 0.499, 1.458, 0.499, 1.4609999999999999, 1.4609999999999999, 1.454, 1.458, 1.4609999999999999, 1.447, 1.4489999999999998, 1.455, -0.001, 1.446, 1.451, 0.499, 1.4609999999999999, 1.446, 1.4249999999999998, -0.501, 1.412, 0.979, 0.499, 0.5, 0.499, 0.5, 1.427, 1.443, 1.4609999999999999, -0.501, 1.4609999999999999, 1.446, 1.446, 1.444, 1.452, 1.4180000000000001], "policy_blue_0_reward": [0.476, 1.4609999999999999, 0.499, 0.5, -0.002, 1.475, -0.028000000000000018, -1.001, 1.4569999999999999, 0.0, 0.498, 0.5, 0.499, 0.5, -1.001, 1.4609999999999999, 0.493, 0.5, -0.002, 0.46199999999999997, 0.499, 1.4609999999999999, 0.0, 0.498, 0.47, 0.499, 1.454, 1.454, 0.499, 0.5, -1.001, 1.4569999999999999, -1.002, 0.498, 0.5, 1.4729999999999999, -1.005, 1.4569999999999999, -0.005, 1.454, -0.003, 1.455, -0.5, 0.497, 1.4369999999999998, -0.002, 0.5, -0.003, 0.498, 1.4489999999999998, 0.5, 0.499, -0.002, 0.472, 1.438, 0.499, 0.499, 0.498, -1.0, 0.499, 1.45, 0.499, 1.444, 0.0, 0.5, 1.179, 0.964, 0.945, 1.458, 0.5, -0.001, -0.006, 0.499, 0.499, 1.4609999999999999, 0.499, 0.5, -0.006, -0.507, 1.451, 0.0, 1.458, 1.459, 0.5, -0.001, 0.5, -0.505, 0.46199999999999997, 0.497, -0.001, 1.458, 0.5, 1.458, 0.498, -0.003, 0.499, 0.5, 0.5, 0.499, 0.5, 0.498, 1.413, 0.5, 0.498, 1.454, 0.5, 0.499, -0.502, 1.417, 0.498, -1.0, 1.458, 1.4609999999999999, 1.451, 1.4609999999999999, 0.498, -0.002, 0.5, 1.4609999999999999, -0.001, 0.497, 0.5, 0.5, 0.5, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4329017431178825, "mean_inference_ms": 7.4824498882473565, "mean_action_processing_ms": 0.3884073049780513, "mean_env_wait_ms": 0.5235457826442124, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.12428779602050781, "StateBufferConnector_ms": 0.008445072174072265, "ViewRequirementAgentConnector_ms": 0.18040180206298828}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.040000000000000036, "episode_reward_mean": 1.5790799999999998, "episode_len_mean": 30.56, "episodes_this_iter": 125, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.005}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.475}, "policy_reward_mean": {"red_0": 1.0206720000000002, "blue_0": 0.558408}, "hist_stats": {"episode_reward": [0.959, 1.9609999999999999, 1.96, 1.958, 1.455, 0.475, 0.43899999999999995, 0.45599999999999996, 1.9569999999999999, 1.4609999999999999, 1.929, 1.9529999999999998, 1.9569999999999999, 1.903, 0.4750000000000001, 1.9609999999999999, 1.908, 1.9609999999999999, 1.459, 0.9319999999999999, 1.951, 1.46, 1.4489999999999998, 1.956, 0.953, 1.957, 1.954, 1.954, 1.941, 1.948, -0.027999999999999914, 1.956, 0.46499999999999986, 1.956, 1.958, 0.973, 0.45399999999999996, 1.9569999999999999, 1.409, 0.954, 1.455, 1.955, 0.954, 1.958, 1.935, 1.456, 1.9609999999999999, 1.452, 1.952, 1.9489999999999998, 1.9609999999999999, 1.951, 1.4529999999999998, 0.958, 1.9369999999999998, 1.96, 1.9449999999999998, 1.955, -0.040000000000000036, 1.96, 0.44999999999999996, 1.9529999999999998, 1.942, 1.452, 1.9609999999999999, 1.6680000000000001, -0.03700000000000003, 0.44499999999999995, 1.9569999999999999, 1.958, 1.439, 1.365, 1.96, 1.956, 1.96, 1.948, 1.952, 1.451, 0.909, 1.951, 1.44, 1.956, 0.45899999999999996, 1.955, 1.436, 1.9609999999999999, 0.4119999999999999, 0.41999999999999993, 1.924, 1.438, 1.9569999999999999, 1.958, 1.9569999999999999, 1.959, 1.4580000000000002, 1.9529999999999998, 1.958, 1.9609999999999999, 1.946, 1.9489999999999998, 1.9529999999999998, 1.412, 1.946, 1.9489999999999998, 1.9529999999999998, 1.9609999999999999, 1.9449999999999998, 0.923, 0.916, 1.9100000000000001, -0.02100000000000002, 1.9569999999999999, 1.9609999999999999, 1.95, 1.9609999999999999, 1.9249999999999998, 1.4409999999999998, 1.9609999999999999, 0.96, 1.46, 1.943, 1.946, 1.944, 1.952, 1.917], "episode_lengths": [300, 13, 13, 14, 14, 8, 300, 14, 14, 13, 23, 15, 14, 32, 8, 13, 28, 13, 13, 300, 16, 13, 17, 14, 300, 14, 15, 15, 19, 17, 9, 14, 11, 14, 14, 9, 13, 14, 28, 15, 14, 15, 15, 13, 21, 14, 13, 15, 15, 17, 13, 16, 15, 300, 20, 13, 18, 14, 13, 13, 16, 15, 18, 16, 13, 105, 11, 18, 14, 14, 20, 42, 13, 14, 13, 17, 16, 14, 28, 16, 20, 14, 13, 15, 21, 13, 27, 300, 24, 20, 14, 14, 14, 13, 13, 15, 14, 13, 17, 17, 15, 29, 18, 16, 15, 13, 18, 24, 27, 29, 7, 14, 13, 16, 13, 24, 19, 13, 13, 13, 18, 18, 18, 16, 27], "policy_red_0_reward": [0.483, 0.5, 1.4609999999999999, 1.458, 1.4569999999999999, -1.0, 0.46699999999999997, 1.4569999999999999, 0.5, 1.4609999999999999, 1.431, 1.4529999999999998, 1.458, 1.403, 1.476, 0.5, 1.415, 1.4609999999999999, 1.4609999999999999, 0.47, 1.452, -0.001, 1.4489999999999998, 1.458, 0.483, 1.458, 0.5, 0.5, 1.442, 1.448, 0.973, 0.499, 1.467, 1.458, 1.458, -0.5, 1.459, 0.5, 1.4140000000000001, -0.5, 1.458, 0.5, 1.454, 1.4609999999999999, 0.498, 1.458, 1.4609999999999999, 1.455, 1.454, 0.5, 1.4609999999999999, 1.452, 1.455, 0.486, 0.499, 1.4609999999999999, 1.446, 1.4569999999999999, 0.96, 1.4609999999999999, -1.0, 1.454, 0.498, 1.452, 1.4609999999999999, 0.489, -1.001, -0.5, 0.499, 1.458, 1.44, 1.371, 1.4609999999999999, 1.4569999999999999, 0.499, 1.4489999999999998, 1.452, 1.4569999999999999, 1.416, 0.5, 1.44, 0.498, -1.0, 1.455, 1.4369999999999998, 1.4609999999999999, 0.917, -0.04200000000000003, 1.427, 1.439, 0.499, 1.458, 0.499, 1.4609999999999999, 1.4609999999999999, 1.454, 1.458, 1.4609999999999999, 1.447, 1.4489999999999998, 1.455, -0.001, 1.446, 1.451, 0.499, 1.4609999999999999, 1.446, 1.4249999999999998, -0.501, 1.412, 0.979, 0.499, 0.5, 0.499, 0.5, 1.427, 1.443, 1.4609999999999999, -0.501, 1.4609999999999999, 1.446, 1.446, 1.444, 1.452, 1.4180000000000001], "policy_blue_0_reward": [0.476, 1.4609999999999999, 0.499, 0.5, -0.002, 1.475, -0.028000000000000018, -1.001, 1.4569999999999999, 0.0, 0.498, 0.5, 0.499, 0.5, -1.001, 1.4609999999999999, 0.493, 0.5, -0.002, 0.46199999999999997, 0.499, 1.4609999999999999, 0.0, 0.498, 0.47, 0.499, 1.454, 1.454, 0.499, 0.5, -1.001, 1.4569999999999999, -1.002, 0.498, 0.5, 1.4729999999999999, -1.005, 1.4569999999999999, -0.005, 1.454, -0.003, 1.455, -0.5, 0.497, 1.4369999999999998, -0.002, 0.5, -0.003, 0.498, 1.4489999999999998, 0.5, 0.499, -0.002, 0.472, 1.438, 0.499, 0.499, 0.498, -1.0, 0.499, 1.45, 0.499, 1.444, 0.0, 0.5, 1.179, 0.964, 0.945, 1.458, 0.5, -0.001, -0.006, 0.499, 0.499, 1.4609999999999999, 0.499, 0.5, -0.006, -0.507, 1.451, 0.0, 1.458, 1.459, 0.5, -0.001, 0.5, -0.505, 0.46199999999999997, 0.497, -0.001, 1.458, 0.5, 1.458, 0.498, -0.003, 0.499, 0.5, 0.5, 0.499, 0.5, 0.498, 1.413, 0.5, 0.498, 1.454, 0.5, 0.499, -0.502, 1.417, 0.498, -1.0, 1.458, 1.4609999999999999, 1.451, 1.4609999999999999, 0.498, -0.002, 0.5, 1.4609999999999999, -0.001, 0.497, 0.5, 0.5, 0.5, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4329017431178825, "mean_inference_ms": 7.4824498882473565, "mean_action_processing_ms": 0.3884073049780513, "mean_env_wait_ms": 0.5235457826442124, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.12428779602050781, "StateBufferConnector_ms": 0.008445072174072265, "ViewRequirementAgentConnector_ms": 0.18040180206298828}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 158.29561119580995, "num_env_steps_trained_throughput_per_sec": 158.29561119580995, "timesteps_total": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 29810.331, "sample_time_ms": 4075.831, "learn_time_ms": 25707.294, "learn_throughput": 155.598, "synch_weights_time_ms": 25.64}, "counters": {"num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "episodes_total": 11920, "training_iteration": 136, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-09-25", "timestamp": 1694840965, "time_this_iter_s": 25.28787398338318, "time_total_s": 4239.680876970291, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a2ea0e0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4239.680876970291, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 22.683783783783785, "ram_util_percent": 56.92972972972972}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.625, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.07608695652173914, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02717391304347826, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.07608695652173914, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.24456521739130435, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.02717391304347826, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.07608695652173914, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02717391304347826, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.40455745096939305, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.032165482994363025, "policy_loss": -0.06878025295785241, "vf_loss": 0.035549614755048725, "vf_explained_var": 0.7008579998587569, "kl": 0.008645638196195885, "entropy": 0.8558831203728914, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 131040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4715899871351818, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.04006839231975998, "policy_loss": -0.07993360118562123, "vf_loss": 0.03768592611692535, "vf_explained_var": 0.5904083613306284, "kl": 0.009750771574872122, "entropy": 1.1912306954463323, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 131040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_agent_steps_sampled": 1096000, "num_agent_steps_trained": 1096000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.13, "episode_reward_mean": 1.6410108695652175, "episode_len_mean": 25.206521739130434, "episode_media": {}, "episodes_this_iter": 184, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.475}, "policy_reward_mean": {"red_0": 1.0826521739130435, "blue_0": 0.5583586956521739}, "custom_metrics": {"red_0/door_open_done_mean": 0.625, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.07608695652173914, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02717391304347826, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.07608695652173914, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.24456521739130435, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.02717391304347826, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.07608695652173914, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02717391304347826, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.4149999999999999, 1.9609999999999999, 1.934, 1.46, 1.951, 0.9690000000000001, -0.02400000000000002, 1.448, 1.96, 1.93, 1.929, 0.9590000000000001, 0.45500000000000007, 0.954, 0.472, 1.951, 1.951, 1.4609999999999999, 1.9489999999999998, 1.452, 1.456, 0.45199999999999996, 1.9140000000000001, 1.44, -0.13, 1.947, 0.46499999999999986, 1.954, 1.954, 1.9289999999999998, 1.444, 1.4369999999999998, 0.43899999999999995, 1.449, 1.908, 1.9609999999999999, 1.954, 1.9369999999999998, 1.9529999999999998, 1.952, 1.956, 1.948, 1.911, 1.946, 1.9529999999999998, 1.9609999999999999, 1.948, 1.451, 1.9409999999999998, 1.46, 1.923, 1.9569999999999999, 1.95, 1.942, 1.938, 1.954, 1.9529999999999998, 0.471, 1.958, 1.9529999999999998, 1.942, 1.446, 1.915, 1.4529999999999998, 1.94, 1.442, 1.9180000000000001, 1.958, 1.948, 0.975, 1.272, 1.9540000000000002, 1.4569999999999999, 1.9489999999999998, 1.444, 1.9609999999999999, 1.946, 1.35, 1.951, 1.455, 1.45, 0.96, 1.456, 1.958, 1.955, 1.946, 1.4529999999999998, 1.9449999999999998, 1.913, 1.923, 1.9569999999999999, 1.455, 1.9290000000000003, 0.43499999999999994, 1.9569999999999999, 1.442, 1.953, 1.919, 1.9329999999999998, 1.9569999999999999, 0.478, 1.9529999999999998, 1.9289999999999998, 1.948, 1.946, 1.942, 1.447, 1.955, 1.9609999999999999, 1.9569999999999999, 1.96, 1.951, 1.427, 1.9609999999999999, 1.943, 1.955, -0.05500000000000005, 1.9609999999999999, 1.944, 1.954, 0.9470000000000001, -0.04400000000000004, 1.436, 0.46099999999999985, 0.9299999999999999, 1.9609999999999999, 1.9489999999999998, 1.95, 1.388, 1.96, 1.9500000000000002, 1.3199999999999998, 1.942, 1.92, 1.428, 0.945, 1.4609999999999999, 1.955, 1.9060000000000001, 1.455, 1.954, 1.959, 1.9569999999999999, 1.928, 0.4670000000000001, 1.4609999999999999, 1.46, 1.942, 1.4100000000000001, 1.935, 1.947, 1.958, 1.438, 1.46, 1.943, 1.9569999999999999, 1.4569999999999999, 1.934, 1.454, 1.4609999999999999, 1.955, 1.9300000000000002, 1.94, 1.451, 1.9609999999999999, 1.451, 1.929, 1.957, 1.952, 1.939, 1.9529999999999998, 1.9500000000000002, 1.9569999999999999, 1.956, 1.955, 1.458, 1.454, 1.9609999999999999, 1.9529999999999998, 1.959, 0.45299999999999985, 1.943, 1.955, 1.9569999999999999], "episode_lengths": [300, 13, 22, 13, 16, 10, 8, 17, 13, 22, 23, 13, 15, 300, 9, 16, 16, 13, 16, 16, 14, 16, 28, 20, 42, 17, 11, 15, 15, 22, 18, 20, 300, 16, 29, 13, 15, 19, 15, 16, 14, 16, 29, 18, 15, 13, 17, 16, 19, 13, 25, 14, 16, 19, 20, 15, 15, 9, 14, 15, 19, 18, 28, 15, 20, 19, 26, 14, 16, 8, 70, 15, 14, 17, 18, 13, 18, 48, 16, 14, 16, 13, 14, 14, 15, 18, 15, 18, 28, 25, 14, 14, 23, 300, 14, 19, 15, 26, 20, 14, 7, 15, 22, 16, 17, 18, 17, 15, 13, 14, 13, 16, 23, 13, 19, 15, 18, 13, 18, 15, 17, 14, 21, 12, 300, 13, 16, 16, 34, 13, 16, 56, 19, 26, 23, 18, 13, 15, 30, 15, 15, 13, 14, 23, 10, 13, 13, 19, 29, 21, 17, 14, 20, 13, 18, 14, 14, 22, 15, 13, 15, 22, 19, 16, 13, 16, 23, 14, 16, 20, 15, 16, 14, 14, 15, 13, 15, 13, 15, 13, 15, 18, 15, 14], "policy_red_0_reward": [-0.047000000000000035, 1.4609999999999999, 1.434, -0.001, 1.452, 1.47, -1.0, 1.4489999999999998, 1.4609999999999999, 0.499, 1.4300000000000002, 1.4609999999999999, 1.455, 0.479, 0.972, 0.5, 1.451, 0.0, 1.452, 1.452, 1.4569999999999999, 1.452, 1.4140000000000001, 0.0, 0.872, 1.448, 0.966, 1.455, 0.499, 1.431, 1.4449999999999998, 1.44, -0.03100000000000002, 1.452, 1.412, 0.5, 0.5, 1.442, 1.455, 1.452, 0.498, 1.451, 1.412, 0.5, 1.455, 1.4609999999999999, 1.448, 1.452, 1.443, 1.4609999999999999, 1.424, 1.458, 0.499, 0.5, 0.5, 1.455, 1.455, -0.5, 1.458, 1.455, 0.5, 1.446, 1.416, 1.454, 1.44, 1.443, 1.421, 0.5, 0.497, -0.5, -0.005, 1.455, -0.001, 1.4489999999999998, 1.446, 1.4609999999999999, 0.5, -0.004, 1.451, 1.4569999999999999, 1.452, -0.501, 1.4569999999999999, 0.5, 1.455, 0.5, 1.454, 1.446, 0.5, 0.5, 0.499, 1.458, 1.431, -0.03900000000000003, 0.5, 1.442, 1.455, 0.499, 1.4369999999999998, 1.458, 1.479, 0.499, 1.431, 1.451, 1.447, 1.4449999999999998, -0.001, 1.455, 1.4609999999999999, 1.458, 1.4609999999999999, 1.452, 1.429, 0.5, 1.443, 1.455, 0.945, 0.5, 0.498, 0.5, 1.448, 0.957, 1.4369999999999998, 0.963, 0.469, 0.5, 1.451, 0.5, 1.3940000000000001, 1.4609999999999999, 1.452, -0.005, 1.443, 0.5, 1.431, -0.5, 0.0, 1.455, 0.499, 1.455, 1.455, 1.4609999999999999, 1.4569999999999999, 0.497, 1.47, 1.4609999999999999, 1.4609999999999999, 1.443, 1.412, 0.499, 1.448, 1.458, 1.44, 1.4609999999999999, 1.4449999999999998, 0.5, 1.458, 1.434, 1.455, 1.4609999999999999, 1.455, 1.4329999999999998, 1.4409999999999998, 1.452, 1.4609999999999999, 1.452, 0.499, 1.458, 1.452, 1.44, 1.455, 1.452, 1.4569999999999999, 0.498, 1.455, 1.4609999999999999, 1.455, 1.4609999999999999, 0.499, 1.4609999999999999, 0.955, 1.4449999999999998, 1.455, 1.4569999999999999], "policy_blue_0_reward": [0.46199999999999997, 0.5, 0.5, 1.4609999999999999, 0.499, -0.5009999999999999, 0.976, -0.001, 0.499, 1.431, 0.499, -0.502, -1.0, 0.475, -0.5, 1.451, 0.5, 1.4609999999999999, 0.497, 0.0, -0.001, -1.0, 0.5, 1.44, -1.002, 0.499, -0.501, 0.499, 1.455, 0.498, -0.001, -0.003, 0.47, -0.003, 0.496, 1.4609999999999999, 1.454, 0.495, 0.498, 0.5, 1.458, 0.497, 0.499, 1.446, 0.498, 0.5, 0.5, -0.001, 0.498, -0.001, 0.499, 0.499, 1.451, 1.442, 1.438, 0.499, 0.498, 0.971, 0.5, 0.498, 1.442, 0.0, 0.499, -0.001, 0.5, -0.001, 0.497, 1.458, 1.451, 1.475, 1.2770000000000001, 0.499, 1.458, 0.5, -0.002, 0.5, 1.446, 1.354, 0.5, -0.002, -0.002, 1.4609999999999999, -0.001, 1.458, 0.5, 1.446, -0.001, 0.499, 1.413, 1.423, 1.458, -0.003, 0.498, 0.474, 1.4569999999999999, 0.0, 0.498, 1.42, 0.496, 0.499, -1.001, 1.454, 0.498, 0.497, 0.499, 0.497, 1.448, 0.5, 0.5, 0.499, 0.499, 0.499, -0.002, 1.4609999999999999, 0.5, 0.5, -1.0, 1.4609999999999999, 1.446, 1.454, -0.501, -1.001, -0.001, -0.502, 0.46099999999999997, 1.4609999999999999, 0.498, 1.45, -0.006, 0.499, 0.498, 1.325, 0.499, 1.42, -0.003, 1.4449999999999998, 1.4609999999999999, 0.5, 1.407, 0.0, 0.499, 0.498, 0.5, 1.431, -1.003, 0.0, -0.001, 0.499, -0.002, 1.436, 0.499, 0.5, -0.002, -0.001, 0.498, 1.4569999999999999, -0.001, 0.5, -0.001, 0.0, 0.5, 0.497, 0.499, -0.001, 0.5, -0.001, 1.4300000000000002, 0.499, 0.5, 0.499, 0.498, 0.498, 0.5, 1.458, 0.5, -0.003, -0.001, 0.5, 1.454, 0.498, -0.502, 0.498, 0.5, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4325274631621485, "mean_inference_ms": 7.467950890847224, "mean_action_processing_ms": 0.3896728820580709, "mean_env_wait_ms": 0.5226530839886944, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13390915549319723, "StateBufferConnector_ms": 0.008602181206578794, "ViewRequirementAgentConnector_ms": 0.17509013414382935}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.13, "episode_reward_mean": 1.6410108695652175, "episode_len_mean": 25.206521739130434, "episodes_this_iter": 184, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.475}, "policy_reward_mean": {"red_0": 1.0826521739130435, "blue_0": 0.5583586956521739}, "hist_stats": {"episode_reward": [0.4149999999999999, 1.9609999999999999, 1.934, 1.46, 1.951, 0.9690000000000001, -0.02400000000000002, 1.448, 1.96, 1.93, 1.929, 0.9590000000000001, 0.45500000000000007, 0.954, 0.472, 1.951, 1.951, 1.4609999999999999, 1.9489999999999998, 1.452, 1.456, 0.45199999999999996, 1.9140000000000001, 1.44, -0.13, 1.947, 0.46499999999999986, 1.954, 1.954, 1.9289999999999998, 1.444, 1.4369999999999998, 0.43899999999999995, 1.449, 1.908, 1.9609999999999999, 1.954, 1.9369999999999998, 1.9529999999999998, 1.952, 1.956, 1.948, 1.911, 1.946, 1.9529999999999998, 1.9609999999999999, 1.948, 1.451, 1.9409999999999998, 1.46, 1.923, 1.9569999999999999, 1.95, 1.942, 1.938, 1.954, 1.9529999999999998, 0.471, 1.958, 1.9529999999999998, 1.942, 1.446, 1.915, 1.4529999999999998, 1.94, 1.442, 1.9180000000000001, 1.958, 1.948, 0.975, 1.272, 1.9540000000000002, 1.4569999999999999, 1.9489999999999998, 1.444, 1.9609999999999999, 1.946, 1.35, 1.951, 1.455, 1.45, 0.96, 1.456, 1.958, 1.955, 1.946, 1.4529999999999998, 1.9449999999999998, 1.913, 1.923, 1.9569999999999999, 1.455, 1.9290000000000003, 0.43499999999999994, 1.9569999999999999, 1.442, 1.953, 1.919, 1.9329999999999998, 1.9569999999999999, 0.478, 1.9529999999999998, 1.9289999999999998, 1.948, 1.946, 1.942, 1.447, 1.955, 1.9609999999999999, 1.9569999999999999, 1.96, 1.951, 1.427, 1.9609999999999999, 1.943, 1.955, -0.05500000000000005, 1.9609999999999999, 1.944, 1.954, 0.9470000000000001, -0.04400000000000004, 1.436, 0.46099999999999985, 0.9299999999999999, 1.9609999999999999, 1.9489999999999998, 1.95, 1.388, 1.96, 1.9500000000000002, 1.3199999999999998, 1.942, 1.92, 1.428, 0.945, 1.4609999999999999, 1.955, 1.9060000000000001, 1.455, 1.954, 1.959, 1.9569999999999999, 1.928, 0.4670000000000001, 1.4609999999999999, 1.46, 1.942, 1.4100000000000001, 1.935, 1.947, 1.958, 1.438, 1.46, 1.943, 1.9569999999999999, 1.4569999999999999, 1.934, 1.454, 1.4609999999999999, 1.955, 1.9300000000000002, 1.94, 1.451, 1.9609999999999999, 1.451, 1.929, 1.957, 1.952, 1.939, 1.9529999999999998, 1.9500000000000002, 1.9569999999999999, 1.956, 1.955, 1.458, 1.454, 1.9609999999999999, 1.9529999999999998, 1.959, 0.45299999999999985, 1.943, 1.955, 1.9569999999999999], "episode_lengths": [300, 13, 22, 13, 16, 10, 8, 17, 13, 22, 23, 13, 15, 300, 9, 16, 16, 13, 16, 16, 14, 16, 28, 20, 42, 17, 11, 15, 15, 22, 18, 20, 300, 16, 29, 13, 15, 19, 15, 16, 14, 16, 29, 18, 15, 13, 17, 16, 19, 13, 25, 14, 16, 19, 20, 15, 15, 9, 14, 15, 19, 18, 28, 15, 20, 19, 26, 14, 16, 8, 70, 15, 14, 17, 18, 13, 18, 48, 16, 14, 16, 13, 14, 14, 15, 18, 15, 18, 28, 25, 14, 14, 23, 300, 14, 19, 15, 26, 20, 14, 7, 15, 22, 16, 17, 18, 17, 15, 13, 14, 13, 16, 23, 13, 19, 15, 18, 13, 18, 15, 17, 14, 21, 12, 300, 13, 16, 16, 34, 13, 16, 56, 19, 26, 23, 18, 13, 15, 30, 15, 15, 13, 14, 23, 10, 13, 13, 19, 29, 21, 17, 14, 20, 13, 18, 14, 14, 22, 15, 13, 15, 22, 19, 16, 13, 16, 23, 14, 16, 20, 15, 16, 14, 14, 15, 13, 15, 13, 15, 13, 15, 18, 15, 14], "policy_red_0_reward": [-0.047000000000000035, 1.4609999999999999, 1.434, -0.001, 1.452, 1.47, -1.0, 1.4489999999999998, 1.4609999999999999, 0.499, 1.4300000000000002, 1.4609999999999999, 1.455, 0.479, 0.972, 0.5, 1.451, 0.0, 1.452, 1.452, 1.4569999999999999, 1.452, 1.4140000000000001, 0.0, 0.872, 1.448, 0.966, 1.455, 0.499, 1.431, 1.4449999999999998, 1.44, -0.03100000000000002, 1.452, 1.412, 0.5, 0.5, 1.442, 1.455, 1.452, 0.498, 1.451, 1.412, 0.5, 1.455, 1.4609999999999999, 1.448, 1.452, 1.443, 1.4609999999999999, 1.424, 1.458, 0.499, 0.5, 0.5, 1.455, 1.455, -0.5, 1.458, 1.455, 0.5, 1.446, 1.416, 1.454, 1.44, 1.443, 1.421, 0.5, 0.497, -0.5, -0.005, 1.455, -0.001, 1.4489999999999998, 1.446, 1.4609999999999999, 0.5, -0.004, 1.451, 1.4569999999999999, 1.452, -0.501, 1.4569999999999999, 0.5, 1.455, 0.5, 1.454, 1.446, 0.5, 0.5, 0.499, 1.458, 1.431, -0.03900000000000003, 0.5, 1.442, 1.455, 0.499, 1.4369999999999998, 1.458, 1.479, 0.499, 1.431, 1.451, 1.447, 1.4449999999999998, -0.001, 1.455, 1.4609999999999999, 1.458, 1.4609999999999999, 1.452, 1.429, 0.5, 1.443, 1.455, 0.945, 0.5, 0.498, 0.5, 1.448, 0.957, 1.4369999999999998, 0.963, 0.469, 0.5, 1.451, 0.5, 1.3940000000000001, 1.4609999999999999, 1.452, -0.005, 1.443, 0.5, 1.431, -0.5, 0.0, 1.455, 0.499, 1.455, 1.455, 1.4609999999999999, 1.4569999999999999, 0.497, 1.47, 1.4609999999999999, 1.4609999999999999, 1.443, 1.412, 0.499, 1.448, 1.458, 1.44, 1.4609999999999999, 1.4449999999999998, 0.5, 1.458, 1.434, 1.455, 1.4609999999999999, 1.455, 1.4329999999999998, 1.4409999999999998, 1.452, 1.4609999999999999, 1.452, 0.499, 1.458, 1.452, 1.44, 1.455, 1.452, 1.4569999999999999, 0.498, 1.455, 1.4609999999999999, 1.455, 1.4609999999999999, 0.499, 1.4609999999999999, 0.955, 1.4449999999999998, 1.455, 1.4569999999999999], "policy_blue_0_reward": [0.46199999999999997, 0.5, 0.5, 1.4609999999999999, 0.499, -0.5009999999999999, 0.976, -0.001, 0.499, 1.431, 0.499, -0.502, -1.0, 0.475, -0.5, 1.451, 0.5, 1.4609999999999999, 0.497, 0.0, -0.001, -1.0, 0.5, 1.44, -1.002, 0.499, -0.501, 0.499, 1.455, 0.498, -0.001, -0.003, 0.47, -0.003, 0.496, 1.4609999999999999, 1.454, 0.495, 0.498, 0.5, 1.458, 0.497, 0.499, 1.446, 0.498, 0.5, 0.5, -0.001, 0.498, -0.001, 0.499, 0.499, 1.451, 1.442, 1.438, 0.499, 0.498, 0.971, 0.5, 0.498, 1.442, 0.0, 0.499, -0.001, 0.5, -0.001, 0.497, 1.458, 1.451, 1.475, 1.2770000000000001, 0.499, 1.458, 0.5, -0.002, 0.5, 1.446, 1.354, 0.5, -0.002, -0.002, 1.4609999999999999, -0.001, 1.458, 0.5, 1.446, -0.001, 0.499, 1.413, 1.423, 1.458, -0.003, 0.498, 0.474, 1.4569999999999999, 0.0, 0.498, 1.42, 0.496, 0.499, -1.001, 1.454, 0.498, 0.497, 0.499, 0.497, 1.448, 0.5, 0.5, 0.499, 0.499, 0.499, -0.002, 1.4609999999999999, 0.5, 0.5, -1.0, 1.4609999999999999, 1.446, 1.454, -0.501, -1.001, -0.001, -0.502, 0.46099999999999997, 1.4609999999999999, 0.498, 1.45, -0.006, 0.499, 0.498, 1.325, 0.499, 1.42, -0.003, 1.4449999999999998, 1.4609999999999999, 0.5, 1.407, 0.0, 0.499, 0.498, 0.5, 1.431, -1.003, 0.0, -0.001, 0.499, -0.002, 1.436, 0.499, 0.5, -0.002, -0.001, 0.498, 1.4569999999999999, -0.001, 0.5, -0.001, 0.0, 0.5, 0.497, 0.499, -0.001, 0.5, -0.001, 1.4300000000000002, 0.499, 0.5, 0.499, 0.498, 0.498, 0.5, 1.458, 0.5, -0.003, -0.001, 0.5, 1.454, 0.498, -0.502, 0.498, 0.5, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4325274631621485, "mean_inference_ms": 7.467950890847224, "mean_action_processing_ms": 0.3896728820580709, "mean_env_wait_ms": 0.5226530839886944, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13390915549319723, "StateBufferConnector_ms": 0.008602181206578794, "ViewRequirementAgentConnector_ms": 0.17509013414382935}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1096000, "num_agent_steps_trained": 1096000, "num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 154.05605491130981, "num_env_steps_trained_throughput_per_sec": 154.05605491130981, "timesteps_total": 548000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1096000, "timers": {"training_iteration_time_ms": 29345.952, "sample_time_ms": 4077.382, "learn_time_ms": 25241.593, "learn_throughput": 158.469, "synch_weights_time_ms": 25.416}, "counters": {"num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_agent_steps_sampled": 1096000, "num_agent_steps_trained": 1096000}, "done": false, "episodes_total": 12104, "training_iteration": 137, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-09-52", "timestamp": 1694840992, "time_this_iter_s": 25.986281871795654, "time_total_s": 4265.667158842087, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a34a170>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4265.667158842087, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 25.05263157894737, "ram_util_percent": 56.76578947368421}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6273291925465838, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.062111801242236024, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.062111801242236024, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.062111801242236024, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.22981366459627328, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.062111801242236024, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.062111801242236024, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.062111801242236024, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.41202880383158724, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.029312152292550308, "policy_loss": -0.06284579726440521, "vf_loss": 0.031391406989617586, "vf_explained_var": 0.7539905180533727, "kl": 0.008235537437504022, "entropy": 0.9236423312996824, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 132000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.438147266736875, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.036306384026344556, "policy_loss": -0.07118730110450996, "vf_loss": 0.034423815266927706, "vf_explained_var": 0.5776111784701546, "kl": 0.008301055904956911, "entropy": 1.2418342236429454, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 132000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.04999999999999993, "episode_reward_mean": 1.6245217391304347, "episode_len_mean": 22.236024844720497, "episode_media": {}, "episodes_this_iter": 161, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.001}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 1.0243416149068323, "blue_0": 0.6001801242236026}, "custom_metrics": {"red_0/door_open_done_mean": 0.6273291925465838, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.062111801242236024, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.062111801242236024, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.062111801242236024, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.22981366459627328, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.062111801242236024, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.062111801242236024, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.062111801242236024, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.951, 1.938, -0.02400000000000002, 1.919, -0.040000000000000036, 1.4449999999999998, 1.956, 1.946, 1.956, 1.952, 1.958, 1.9609999999999999, 1.4489999999999998, 1.9609999999999999, 1.459, 1.9609999999999999, 1.9449999999999998, 1.456, 1.9569999999999999, 1.9609999999999999, 1.439, 1.947, 1.955, 1.9609999999999999, 0.475, 1.9609999999999999, 1.954, 1.905, 1.951, 1.947, 1.9449999999999998, 1.455, 1.9609999999999999, 1.95, 1.9329999999999998, -0.03399999999999992, -0.04800000000000004, 1.936, 1.958, 1.959, 1.451, 1.9569999999999999, -0.04999999999999993, 1.917, 1.947, 1.4609999999999999, 1.9529999999999998, 1.9569999999999999, 1.935, 1.456, 1.943, 1.9609999999999999, 1.9500000000000002, 1.4260000000000002, 1.9569999999999999, 1.958, 1.095, 1.958, 1.9609999999999999, 1.96, 0.47, 1.9489999999999998, 0.9239999999999999, -0.04400000000000004, 1.9529999999999998, 1.458, 1.44, 1.947, 1.435, 1.96, 1.9529999999999998, 0.43599999999999994, 1.426, 1.447, 1.9609999999999999, 1.96, 1.9529999999999998, 1.96, 1.955, 1.4420000000000002, 1.9609999999999999, 1.958, 1.9609999999999999, 1.404, 1.951, 1.958, 1.951, 1.9489999999999998, 1.9609999999999999, 1.9609999999999999, 1.955, 1.9529999999999998, 0.813, 0.966, 1.9529999999999998, 1.955, 0.45499999999999996, 1.451, 1.911, 1.451, 0.9670000000000001, 1.9569999999999999, 1.939, 1.955, 1.9609999999999999, 1.455, 0.476, 1.447, 1.951, 1.944, 1.95, 1.956, 1.9609999999999999, 1.958, 1.9609999999999999, 1.9449999999999998, 1.424, 1.953, 1.9449999999999998, 1.458, 1.306, 1.455, 1.9609999999999999, 0.41800000000000015, 0.476, 1.952, 1.46, 1.929, 0.972, 1.952, 1.9409999999999998, 0.4750000000000001, 1.4460000000000002, 1.456, 1.951, 1.457, 0.47299999999999986, 1.9609999999999999, 1.432, 1.9569999999999999, 1.955, 1.958, 1.9569999999999999, 1.944, 1.9609999999999999, 1.912, 1.458, 1.9609999999999999, 1.431, 1.958, 1.951, 0.46299999999999997, 1.9180000000000001, 1.431, 1.958, 1.9569999999999999, 1.9500000000000002, 1.9609999999999999, 0.46199999999999997, 1.958, 1.458], "episode_lengths": [300, 20, 8, 25, 13, 18, 14, 17, 14, 16, 14, 13, 16, 13, 13, 13, 18, 14, 14, 13, 20, 17, 15, 13, 8, 13, 15, 29, 16, 17, 18, 15, 13, 16, 22, 11, 16, 21, 14, 13, 16, 14, 15, 27, 17, 13, 15, 14, 20, 14, 19, 13, 16, 23, 14, 14, 126, 14, 13, 13, 10, 17, 24, 14, 15, 14, 19, 17, 21, 13, 15, 300, 24, 17, 13, 13, 15, 13, 15, 19, 13, 14, 13, 30, 16, 14, 16, 17, 13, 13, 15, 15, 60, 11, 15, 15, 15, 16, 28, 16, 10, 14, 20, 15, 13, 15, 8, 17, 16, 17, 16, 14, 13, 14, 13, 18, 23, 15, 17, 14, 60, 15, 13, 25, 8, 16, 13, 23, 9, 15, 19, 8, 17, 14, 16, 14, 9, 13, 22, 14, 15, 14, 14, 18, 13, 27, 14, 13, 22, 14, 16, 300, 25, 22, 14, 14, 16, 13, 12, 14, 14], "policy_red_0_reward": [0.471, 1.44, 0.976, 1.425, 0.96, 0.0, 1.4569999999999999, 1.448, 1.458, 0.5, 1.458, 0.5, 1.452, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.446, 1.458, 1.458, 1.4609999999999999, 1.44, 1.4489999999999998, 1.455, 1.4609999999999999, -0.501, 1.4609999999999999, 1.455, 1.409, 1.452, 1.4489999999999998, 0.499, 1.455, 1.4609999999999999, 1.451, 1.434, -1.001, 0.952, 1.4369999999999998, 0.5, 1.4609999999999999, -0.001, 1.458, -1.0, 1.419, 1.448, 1.4609999999999999, 1.454, 0.5, 1.438, -0.002, 1.443, 1.4609999999999999, 1.452, -0.003, 1.458, 0.5, -0.007, 0.5, 1.4609999999999999, 0.499, 1.47, 1.4489999999999998, -0.504, -1.001, 1.455, 1.458, 1.443, 1.4489999999999998, -0.001, 1.4609999999999999, 1.455, 0.478, 1.427, 1.4489999999999998, 1.4609999999999999, 1.4609999999999999, 0.499, 1.4609999999999999, 1.455, 1.443, 1.4609999999999999, 0.5, 1.4609999999999999, -0.003, 1.451, 0.5, 0.5, 1.4489999999999998, 1.4609999999999999, 0.5, 1.455, 1.455, -0.506, 1.467, 0.499, 0.5, -1.0, 1.452, 1.412, 1.451, -0.5029999999999999, 1.458, 1.44, 1.455, 0.5, 0.0, -1.0, 1.447, 1.451, 1.448, 0.5, 0.498, 0.5, 1.458, 1.4609999999999999, 0.499, -0.001, 1.455, 0.498, 1.458, 1.317, 0.0, 1.4609999999999999, 0.923, -1.0, 0.5, 1.4609999999999999, 1.4300000000000002, 1.4729999999999999, 1.455, 1.442, 0.976, 1.4489999999999998, -0.002, 1.451, 1.458, 1.4729999999999999, 1.4609999999999999, 1.432, 1.4569999999999999, 1.455, 0.5, 1.458, 0.5, 1.4609999999999999, 1.417, 1.458, 1.4609999999999999, 1.4329999999999998, 1.458, 1.452, 0.477, 1.423, 1.4329999999999998, 0.5, 0.5, 1.452, 1.4609999999999999, 1.463, 1.458, 1.458], "policy_blue_0_reward": [0.48, 0.498, -1.0, 0.494, -1.0, 1.4449999999999998, 0.499, 0.498, 0.498, 1.452, 0.5, 1.4609999999999999, -0.003, 0.5, -0.002, 0.5, 0.499, -0.002, 0.499, 0.5, -0.001, 0.498, 0.5, 0.5, 0.976, 0.5, 0.499, 0.496, 0.499, 0.498, 1.446, 0.0, 0.5, 0.499, 0.499, 0.967, -1.0, 0.499, 1.458, 0.498, 1.452, 0.499, 0.95, 0.498, 0.499, 0.0, 0.499, 1.4569999999999999, 0.497, 1.458, 0.5, 0.5, 0.498, 1.429, 0.499, 1.458, 1.1019999999999999, 1.458, 0.5, 1.4609999999999999, -1.0, 0.5, 1.428, 0.957, 0.498, 0.0, -0.003, 0.498, 1.436, 0.499, 0.498, -0.04200000000000003, -0.001, -0.002, 0.5, 0.499, 1.454, 0.499, 0.5, -0.001, 0.5, 1.458, 0.5, 1.407, 0.5, 1.458, 1.451, 0.5, 0.5, 1.4609999999999999, 0.5, 0.498, 1.319, -0.501, 1.454, 1.455, 1.455, -0.001, 0.499, 0.0, 1.47, 0.499, 0.499, 0.5, 1.4609999999999999, 1.455, 1.476, 0.0, 0.5, 0.496, 1.45, 1.458, 1.4609999999999999, 0.5, 0.5, 1.446, 1.425, 0.498, 1.447, 0.0, -0.011000000000000003, 1.455, 0.5, -0.5049999999999999, 1.476, 1.452, -0.001, 0.499, -0.501, 0.497, 0.499, -0.5009999999999999, -0.003, 1.458, 0.5, -0.001, -1.0, 0.5, 0.0, 0.5, 0.5, 1.458, 0.499, 1.444, 0.5, 0.495, 0.0, 0.5, -0.002, 0.5, 0.499, -0.014000000000000005, 0.495, -0.002, 1.458, 1.4569999999999999, 0.498, 0.5, -1.001, 0.5, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4320026472916845, "mean_inference_ms": 7.453028315425827, "mean_action_processing_ms": 0.3893773686324658, "mean_env_wait_ms": 0.5224784397507238, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.12478998729160853, "StateBufferConnector_ms": 0.008135330602989434, "ViewRequirementAgentConnector_ms": 0.16475989951850464}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.04999999999999993, "episode_reward_mean": 1.6245217391304347, "episode_len_mean": 22.236024844720497, "episodes_this_iter": 161, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.001}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 1.0243416149068323, "blue_0": 0.6001801242236026}, "hist_stats": {"episode_reward": [0.951, 1.938, -0.02400000000000002, 1.919, -0.040000000000000036, 1.4449999999999998, 1.956, 1.946, 1.956, 1.952, 1.958, 1.9609999999999999, 1.4489999999999998, 1.9609999999999999, 1.459, 1.9609999999999999, 1.9449999999999998, 1.456, 1.9569999999999999, 1.9609999999999999, 1.439, 1.947, 1.955, 1.9609999999999999, 0.475, 1.9609999999999999, 1.954, 1.905, 1.951, 1.947, 1.9449999999999998, 1.455, 1.9609999999999999, 1.95, 1.9329999999999998, -0.03399999999999992, -0.04800000000000004, 1.936, 1.958, 1.959, 1.451, 1.9569999999999999, -0.04999999999999993, 1.917, 1.947, 1.4609999999999999, 1.9529999999999998, 1.9569999999999999, 1.935, 1.456, 1.943, 1.9609999999999999, 1.9500000000000002, 1.4260000000000002, 1.9569999999999999, 1.958, 1.095, 1.958, 1.9609999999999999, 1.96, 0.47, 1.9489999999999998, 0.9239999999999999, -0.04400000000000004, 1.9529999999999998, 1.458, 1.44, 1.947, 1.435, 1.96, 1.9529999999999998, 0.43599999999999994, 1.426, 1.447, 1.9609999999999999, 1.96, 1.9529999999999998, 1.96, 1.955, 1.4420000000000002, 1.9609999999999999, 1.958, 1.9609999999999999, 1.404, 1.951, 1.958, 1.951, 1.9489999999999998, 1.9609999999999999, 1.9609999999999999, 1.955, 1.9529999999999998, 0.813, 0.966, 1.9529999999999998, 1.955, 0.45499999999999996, 1.451, 1.911, 1.451, 0.9670000000000001, 1.9569999999999999, 1.939, 1.955, 1.9609999999999999, 1.455, 0.476, 1.447, 1.951, 1.944, 1.95, 1.956, 1.9609999999999999, 1.958, 1.9609999999999999, 1.9449999999999998, 1.424, 1.953, 1.9449999999999998, 1.458, 1.306, 1.455, 1.9609999999999999, 0.41800000000000015, 0.476, 1.952, 1.46, 1.929, 0.972, 1.952, 1.9409999999999998, 0.4750000000000001, 1.4460000000000002, 1.456, 1.951, 1.457, 0.47299999999999986, 1.9609999999999999, 1.432, 1.9569999999999999, 1.955, 1.958, 1.9569999999999999, 1.944, 1.9609999999999999, 1.912, 1.458, 1.9609999999999999, 1.431, 1.958, 1.951, 0.46299999999999997, 1.9180000000000001, 1.431, 1.958, 1.9569999999999999, 1.9500000000000002, 1.9609999999999999, 0.46199999999999997, 1.958, 1.458], "episode_lengths": [300, 20, 8, 25, 13, 18, 14, 17, 14, 16, 14, 13, 16, 13, 13, 13, 18, 14, 14, 13, 20, 17, 15, 13, 8, 13, 15, 29, 16, 17, 18, 15, 13, 16, 22, 11, 16, 21, 14, 13, 16, 14, 15, 27, 17, 13, 15, 14, 20, 14, 19, 13, 16, 23, 14, 14, 126, 14, 13, 13, 10, 17, 24, 14, 15, 14, 19, 17, 21, 13, 15, 300, 24, 17, 13, 13, 15, 13, 15, 19, 13, 14, 13, 30, 16, 14, 16, 17, 13, 13, 15, 15, 60, 11, 15, 15, 15, 16, 28, 16, 10, 14, 20, 15, 13, 15, 8, 17, 16, 17, 16, 14, 13, 14, 13, 18, 23, 15, 17, 14, 60, 15, 13, 25, 8, 16, 13, 23, 9, 15, 19, 8, 17, 14, 16, 14, 9, 13, 22, 14, 15, 14, 14, 18, 13, 27, 14, 13, 22, 14, 16, 300, 25, 22, 14, 14, 16, 13, 12, 14, 14], "policy_red_0_reward": [0.471, 1.44, 0.976, 1.425, 0.96, 0.0, 1.4569999999999999, 1.448, 1.458, 0.5, 1.458, 0.5, 1.452, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.446, 1.458, 1.458, 1.4609999999999999, 1.44, 1.4489999999999998, 1.455, 1.4609999999999999, -0.501, 1.4609999999999999, 1.455, 1.409, 1.452, 1.4489999999999998, 0.499, 1.455, 1.4609999999999999, 1.451, 1.434, -1.001, 0.952, 1.4369999999999998, 0.5, 1.4609999999999999, -0.001, 1.458, -1.0, 1.419, 1.448, 1.4609999999999999, 1.454, 0.5, 1.438, -0.002, 1.443, 1.4609999999999999, 1.452, -0.003, 1.458, 0.5, -0.007, 0.5, 1.4609999999999999, 0.499, 1.47, 1.4489999999999998, -0.504, -1.001, 1.455, 1.458, 1.443, 1.4489999999999998, -0.001, 1.4609999999999999, 1.455, 0.478, 1.427, 1.4489999999999998, 1.4609999999999999, 1.4609999999999999, 0.499, 1.4609999999999999, 1.455, 1.443, 1.4609999999999999, 0.5, 1.4609999999999999, -0.003, 1.451, 0.5, 0.5, 1.4489999999999998, 1.4609999999999999, 0.5, 1.455, 1.455, -0.506, 1.467, 0.499, 0.5, -1.0, 1.452, 1.412, 1.451, -0.5029999999999999, 1.458, 1.44, 1.455, 0.5, 0.0, -1.0, 1.447, 1.451, 1.448, 0.5, 0.498, 0.5, 1.458, 1.4609999999999999, 0.499, -0.001, 1.455, 0.498, 1.458, 1.317, 0.0, 1.4609999999999999, 0.923, -1.0, 0.5, 1.4609999999999999, 1.4300000000000002, 1.4729999999999999, 1.455, 1.442, 0.976, 1.4489999999999998, -0.002, 1.451, 1.458, 1.4729999999999999, 1.4609999999999999, 1.432, 1.4569999999999999, 1.455, 0.5, 1.458, 0.5, 1.4609999999999999, 1.417, 1.458, 1.4609999999999999, 1.4329999999999998, 1.458, 1.452, 0.477, 1.423, 1.4329999999999998, 0.5, 0.5, 1.452, 1.4609999999999999, 1.463, 1.458, 1.458], "policy_blue_0_reward": [0.48, 0.498, -1.0, 0.494, -1.0, 1.4449999999999998, 0.499, 0.498, 0.498, 1.452, 0.5, 1.4609999999999999, -0.003, 0.5, -0.002, 0.5, 0.499, -0.002, 0.499, 0.5, -0.001, 0.498, 0.5, 0.5, 0.976, 0.5, 0.499, 0.496, 0.499, 0.498, 1.446, 0.0, 0.5, 0.499, 0.499, 0.967, -1.0, 0.499, 1.458, 0.498, 1.452, 0.499, 0.95, 0.498, 0.499, 0.0, 0.499, 1.4569999999999999, 0.497, 1.458, 0.5, 0.5, 0.498, 1.429, 0.499, 1.458, 1.1019999999999999, 1.458, 0.5, 1.4609999999999999, -1.0, 0.5, 1.428, 0.957, 0.498, 0.0, -0.003, 0.498, 1.436, 0.499, 0.498, -0.04200000000000003, -0.001, -0.002, 0.5, 0.499, 1.454, 0.499, 0.5, -0.001, 0.5, 1.458, 0.5, 1.407, 0.5, 1.458, 1.451, 0.5, 0.5, 1.4609999999999999, 0.5, 0.498, 1.319, -0.501, 1.454, 1.455, 1.455, -0.001, 0.499, 0.0, 1.47, 0.499, 0.499, 0.5, 1.4609999999999999, 1.455, 1.476, 0.0, 0.5, 0.496, 1.45, 1.458, 1.4609999999999999, 0.5, 0.5, 1.446, 1.425, 0.498, 1.447, 0.0, -0.011000000000000003, 1.455, 0.5, -0.5049999999999999, 1.476, 1.452, -0.001, 0.499, -0.501, 0.497, 0.499, -0.5009999999999999, -0.003, 1.458, 0.5, -0.001, -1.0, 0.5, 0.0, 0.5, 0.5, 1.458, 0.499, 1.444, 0.5, 0.495, 0.0, 0.5, -0.002, 0.5, 0.499, -0.014000000000000005, 0.495, -0.002, 1.458, 1.4569999999999999, 0.498, 0.5, -1.001, 0.5, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4320026472916845, "mean_inference_ms": 7.453028315425827, "mean_action_processing_ms": 0.3893773686324658, "mean_env_wait_ms": 0.5224784397507238, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.12478998729160853, "StateBufferConnector_ms": 0.008135330602989434, "ViewRequirementAgentConnector_ms": 0.16475989951850464}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 157.84609660858334, "num_env_steps_trained_throughput_per_sec": 157.84609660858334, "timesteps_total": 552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 28916.966, "sample_time_ms": 4031.533, "learn_time_ms": 24858.172, "learn_throughput": 160.913, "synch_weights_time_ms": 25.715}, "counters": {"num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "episodes_total": 12265, "training_iteration": 138, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-10-18", "timestamp": 1694841018, "time_this_iter_s": 25.36099910736084, "time_total_s": 4291.028157949448, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a2eb250>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4291.028157949448, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 21.92162162162162, "ram_util_percent": 56.38378378378378}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5955056179775281, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.06179775280898876, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06179775280898876, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.06179775280898876, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.25280898876404495, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.06179775280898876, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.06179775280898876, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06179775280898876, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4478698097169399, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.027152852658279394, "policy_loss": -0.06355920389711779, "vf_loss": 0.03560842066654004, "vf_explained_var": 0.7183735617746909, "kl": 0.008548850205015742, "entropy": 0.8732099100326498, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 132960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43074293692285814, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.034226761022000576, "policy_loss": -0.07178989173941469, "vf_loss": 0.039369744489279886, "vf_explained_var": 0.5977178571745754, "kl": 0.008364560963366744, "entropy": 1.1772571428989371, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 132960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_agent_steps_sampled": 1112000, "num_agent_steps_trained": 1112000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.09099999999999997, "episode_reward_mean": 1.6709269662921347, "episode_len_mean": 24.39325842696629, "episode_media": {}, "episodes_this_iter": 178, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.001}, "policy_reward_max": {"red_0": 1.482, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.0131235955056181, "blue_0": 0.6578033707865169}, "custom_metrics": {"red_0/door_open_done_mean": 0.5955056179775281, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.06179775280898876, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06179775280898876, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.06179775280898876, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.25280898876404495, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.06179775280898876, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.06179775280898876, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06179775280898876, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.944, 1.9609999999999999, 1.954, -0.02499999999999991, 1.96, 1.4449999999999998, 1.96, 0.979, 1.451, 1.96, 1.958, 1.951, 1.429, 1.958, 1.9289999999999998, 1.96, 1.9569999999999999, 1.448, 0.482, 1.954, 0.476, 1.454, 0.44299999999999995, 1.943, 1.448, 1.958, 1.96, 0.43299999999999994, 0.42900000000000005, 1.951, 1.9489999999999998, 1.9369999999999998, 1.9249999999999998, 1.458, 1.944, 1.9329999999999998, 1.9489999999999998, 0.479, 1.958, 1.9209999999999998, 1.96, -0.030999999999999917, 0.948, 1.943, 1.951, 0.45099999999999996, 1.44, 1.9569999999999999, 1.958, 1.9609999999999999, 1.4369999999999998, 1.952, 1.458, 1.44, 0.964, 1.939, 1.948, 1.96, 1.96, 1.951, -0.03300000000000003, 1.954, 0.9339999999999999, 1.4609999999999999, 1.958, 1.935, 1.951, 1.959, 1.9409999999999998, 1.955, 1.952, 1.815, 0.9510000000000001, 1.9329999999999998, 1.9489999999999998, 1.9609999999999999, 1.879, 1.935, 1.955, 1.923, 1.947, 1.9609999999999999, -0.028999999999999915, 1.958, 0.968, 1.9569999999999999, -0.03500000000000003, 1.9609999999999999, 1.9489999999999998, 1.4529999999999998, 1.951, 1.952, 0.9079999999999999, 1.942, 1.942, 1.45, 1.952, 1.954, 1.959, 1.958, 1.458, 1.956, 1.9609999999999999, 1.446, 1.954, 0.44799999999999995, 1.959, 1.95, 1.455, 1.913, 1.952, 1.944, 1.958, 1.943, 1.9489999999999998, 1.943, -0.09099999999999997, 1.958, 1.931, 0.948, 1.936, 1.958, 1.9609999999999999, 1.954, 1.9409999999999998, 1.9529999999999998, 1.956, 1.455, 1.96, 0.44699999999999995, 1.958, 1.958, 1.9609999999999999, 1.947, 1.943, 1.958, 1.456, 1.9569999999999999, 1.947, 1.9489999999999998, 1.936, 1.952, 1.451, 1.956, 0.964, 1.95, 1.959, 1.939, 1.943, 1.9609999999999999, 1.955, 1.448, 1.947, 1.951, 1.958, 1.9369999999999998, 1.9540000000000002, 1.9609999999999999, 1.958, 1.944, 1.3719999999999999, 1.443, 1.952, 1.958, 1.895, 1.944, 1.942, 1.9569999999999999, 1.444, 1.951, 1.96, 0.9420000000000001, 0.9750000000000001, 1.938, 1.9489999999999998, 1.932, 1.96, 1.9609999999999999], "episode_lengths": [300, 13, 15, 8, 13, 17, 13, 7, 16, 13, 14, 16, 23, 14, 22, 13, 14, 17, 6, 15, 8, 15, 300, 18, 17, 14, 13, 300, 23, 16, 16, 20, 24, 14, 18, 22, 17, 7, 14, 24, 13, 10, 17, 18, 16, 15, 19, 14, 14, 13, 20, 16, 14, 20, 12, 19, 16, 13, 13, 16, 11, 15, 300, 13, 14, 21, 16, 13, 19, 15, 15, 58, 15, 22, 17, 13, 39, 21, 14, 25, 16, 13, 9, 14, 10, 14, 11, 13, 17, 15, 16, 16, 29, 19, 18, 16, 16, 14, 13, 14, 14, 14, 13, 18, 15, 17, 13, 16, 15, 28, 16, 18, 14, 18, 17, 18, 29, 14, 22, 17, 20, 14, 13, 15, 19, 15, 14, 15, 13, 300, 14, 14, 13, 17, 19, 14, 14, 14, 17, 17, 21, 15, 16, 14, 12, 16, 13, 20, 18, 13, 15, 17, 17, 16, 14, 21, 15, 13, 14, 18, 41, 18, 16, 14, 33, 18, 19, 14, 18, 16, 13, 19, 8, 20, 17, 21, 13, 13], "policy_red_0_reward": [0.47, 1.4609999999999999, 0.5, -1.0, 1.4609999999999999, -0.001, 1.4609999999999999, -0.5, 1.451, 1.4609999999999999, 0.5, 1.452, 1.431, 0.5, 1.434, 0.499, 1.458, 1.4489999999999998, 1.482, 1.455, -1.0, 1.455, 0.46799999999999997, 1.444, 1.4489999999999998, 0.5, 0.499, 0.46499999999999997, 0.93, 1.452, 1.451, 1.439, 1.427, 1.458, 1.446, 1.4329999999999998, 1.4489999999999998, -1.0, 1.458, 0.498, 1.4609999999999999, -1.0, 1.4489999999999998, 1.4449999999999998, 1.452, -0.502, 1.442, 1.4569999999999999, 1.458, 0.5, 1.438, 1.452, 0.0, 1.44, 1.464, 1.4409999999999998, 1.45, 1.4609999999999999, 1.4609999999999999, 1.451, 0.967, 1.455, 0.471, 1.4609999999999999, 0.5, 1.435, 0.499, 1.4609999999999999, 0.499, 1.455, 1.455, 1.32, 1.4529999999999998, 0.5, 1.4489999999999998, 1.4609999999999999, 1.381, 1.4369999999999998, 0.498, 0.499, 1.451, 0.5, 0.972, 0.5, -0.5, 1.458, -1.001, 0.5, 0.5, -0.002, 1.452, 1.452, 1.411, 1.442, 0.499, 1.452, 1.452, 0.496, 1.4609999999999999, 0.5, 1.458, 1.458, 0.5, 0.0, 0.5, -0.5, 1.4609999999999999, 1.451, 1.455, 1.415, 1.452, 1.4449999999999998, 1.458, 1.444, 0.5, 1.446, 0.91, 0.5, 1.4329999999999998, -0.5, 1.439, 1.458, 1.4609999999999999, 1.455, 1.442, 0.499, 1.4569999999999999, 1.455, 1.4609999999999999, -0.023000000000000013, 0.5, 1.458, 0.5, 0.498, 1.443, 1.458, -0.002, 1.4569999999999999, 1.448, 0.5, 0.5, 1.454, 1.452, 1.458, 1.464, 1.452, 0.498, 1.439, 1.443, 0.5, 0.5, 1.4489999999999998, 1.4489999999999998, 1.452, 1.458, 1.4369999999999998, 1.455, 1.4609999999999999, 1.458, 1.4449999999999998, -0.002, 1.4449999999999998, 1.452, 1.458, 0.5, 1.4449999999999998, 1.442, 1.458, -0.002, 1.452, 0.499, -0.5009999999999999, 1.476, 1.44, 1.4489999999999998, 1.436, 0.499, 0.5], "policy_blue_0_reward": [0.474, 0.5, 1.454, 0.975, 0.499, 1.446, 0.499, 1.479, 0.0, 0.499, 1.458, 0.499, -0.002, 1.458, 0.495, 1.4609999999999999, 0.499, -0.001, -1.0, 0.499, 1.476, -0.001, -0.025000000000000015, 0.499, -0.001, 1.458, 1.4609999999999999, -0.03200000000000002, -0.501, 0.499, 0.498, 0.498, 0.498, 0.0, 0.498, 0.5, 0.5, 1.479, 0.5, 1.423, 0.499, 0.969, -0.501, 0.498, 0.499, 0.953, -0.002, 0.5, 0.5, 1.4609999999999999, -0.001, 0.5, 1.458, 0.0, -0.5, 0.498, 0.498, 0.499, 0.499, 0.5, -1.0, 0.499, 0.46299999999999997, 0.0, 1.458, 0.5, 1.452, 0.498, 1.442, 0.5, 0.497, 0.495, -0.502, 1.4329999999999998, 0.5, 0.5, 0.498, 0.498, 1.4569999999999999, 1.424, 0.496, 1.4609999999999999, -1.001, 1.458, 1.468, 0.499, 0.966, 1.4609999999999999, 1.4489999999999998, 1.455, 0.499, 0.5, -0.503, 0.5, 1.443, -0.002, 0.5, 1.458, 0.498, 1.458, 0.0, 0.498, 1.4609999999999999, 1.446, 1.454, 0.948, 0.498, 0.499, 0.0, 0.498, 0.5, 0.499, 0.5, 0.499, 1.4489999999999998, 0.497, -1.001, 1.458, 0.498, 1.448, 0.497, 0.5, 0.5, 0.499, 0.499, 1.454, 0.499, 0.0, 0.499, 0.47, 1.458, 0.5, 1.4609999999999999, 1.4489999999999998, 0.5, 0.5, 1.458, 0.5, 0.499, 1.4489999999999998, 1.436, 0.498, -0.001, 0.498, -0.5, 0.498, 1.4609999999999999, 0.5, 0.5, 1.4609999999999999, 1.455, -0.001, 0.498, 0.499, 0.5, 0.5, 0.499, 0.5, 0.5, 0.499, 1.374, -0.002, 0.5, 0.5, 1.395, 0.499, 0.5, 0.499, 1.446, 0.499, 1.4609999999999999, 1.443, -0.501, 0.498, 0.5, 0.496, 1.4609999999999999, 1.4609999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.433142818098597, "mean_inference_ms": 7.4482675200837845, "mean_action_processing_ms": 0.38939535966736427, "mean_env_wait_ms": 0.5226086578779358, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.12803325492344544, "StateBufferConnector_ms": 0.008314580060123058, "ViewRequirementAgentConnector_ms": 0.19191302610247324}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.09099999999999997, "episode_reward_mean": 1.6709269662921347, "episode_len_mean": 24.39325842696629, "episodes_this_iter": 178, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.001}, "policy_reward_max": {"red_0": 1.482, "blue_0": 1.479}, "policy_reward_mean": {"red_0": 1.0131235955056181, "blue_0": 0.6578033707865169}, "hist_stats": {"episode_reward": [0.944, 1.9609999999999999, 1.954, -0.02499999999999991, 1.96, 1.4449999999999998, 1.96, 0.979, 1.451, 1.96, 1.958, 1.951, 1.429, 1.958, 1.9289999999999998, 1.96, 1.9569999999999999, 1.448, 0.482, 1.954, 0.476, 1.454, 0.44299999999999995, 1.943, 1.448, 1.958, 1.96, 0.43299999999999994, 0.42900000000000005, 1.951, 1.9489999999999998, 1.9369999999999998, 1.9249999999999998, 1.458, 1.944, 1.9329999999999998, 1.9489999999999998, 0.479, 1.958, 1.9209999999999998, 1.96, -0.030999999999999917, 0.948, 1.943, 1.951, 0.45099999999999996, 1.44, 1.9569999999999999, 1.958, 1.9609999999999999, 1.4369999999999998, 1.952, 1.458, 1.44, 0.964, 1.939, 1.948, 1.96, 1.96, 1.951, -0.03300000000000003, 1.954, 0.9339999999999999, 1.4609999999999999, 1.958, 1.935, 1.951, 1.959, 1.9409999999999998, 1.955, 1.952, 1.815, 0.9510000000000001, 1.9329999999999998, 1.9489999999999998, 1.9609999999999999, 1.879, 1.935, 1.955, 1.923, 1.947, 1.9609999999999999, -0.028999999999999915, 1.958, 0.968, 1.9569999999999999, -0.03500000000000003, 1.9609999999999999, 1.9489999999999998, 1.4529999999999998, 1.951, 1.952, 0.9079999999999999, 1.942, 1.942, 1.45, 1.952, 1.954, 1.959, 1.958, 1.458, 1.956, 1.9609999999999999, 1.446, 1.954, 0.44799999999999995, 1.959, 1.95, 1.455, 1.913, 1.952, 1.944, 1.958, 1.943, 1.9489999999999998, 1.943, -0.09099999999999997, 1.958, 1.931, 0.948, 1.936, 1.958, 1.9609999999999999, 1.954, 1.9409999999999998, 1.9529999999999998, 1.956, 1.455, 1.96, 0.44699999999999995, 1.958, 1.958, 1.9609999999999999, 1.947, 1.943, 1.958, 1.456, 1.9569999999999999, 1.947, 1.9489999999999998, 1.936, 1.952, 1.451, 1.956, 0.964, 1.95, 1.959, 1.939, 1.943, 1.9609999999999999, 1.955, 1.448, 1.947, 1.951, 1.958, 1.9369999999999998, 1.9540000000000002, 1.9609999999999999, 1.958, 1.944, 1.3719999999999999, 1.443, 1.952, 1.958, 1.895, 1.944, 1.942, 1.9569999999999999, 1.444, 1.951, 1.96, 0.9420000000000001, 0.9750000000000001, 1.938, 1.9489999999999998, 1.932, 1.96, 1.9609999999999999], "episode_lengths": [300, 13, 15, 8, 13, 17, 13, 7, 16, 13, 14, 16, 23, 14, 22, 13, 14, 17, 6, 15, 8, 15, 300, 18, 17, 14, 13, 300, 23, 16, 16, 20, 24, 14, 18, 22, 17, 7, 14, 24, 13, 10, 17, 18, 16, 15, 19, 14, 14, 13, 20, 16, 14, 20, 12, 19, 16, 13, 13, 16, 11, 15, 300, 13, 14, 21, 16, 13, 19, 15, 15, 58, 15, 22, 17, 13, 39, 21, 14, 25, 16, 13, 9, 14, 10, 14, 11, 13, 17, 15, 16, 16, 29, 19, 18, 16, 16, 14, 13, 14, 14, 14, 13, 18, 15, 17, 13, 16, 15, 28, 16, 18, 14, 18, 17, 18, 29, 14, 22, 17, 20, 14, 13, 15, 19, 15, 14, 15, 13, 300, 14, 14, 13, 17, 19, 14, 14, 14, 17, 17, 21, 15, 16, 14, 12, 16, 13, 20, 18, 13, 15, 17, 17, 16, 14, 21, 15, 13, 14, 18, 41, 18, 16, 14, 33, 18, 19, 14, 18, 16, 13, 19, 8, 20, 17, 21, 13, 13], "policy_red_0_reward": [0.47, 1.4609999999999999, 0.5, -1.0, 1.4609999999999999, -0.001, 1.4609999999999999, -0.5, 1.451, 1.4609999999999999, 0.5, 1.452, 1.431, 0.5, 1.434, 0.499, 1.458, 1.4489999999999998, 1.482, 1.455, -1.0, 1.455, 0.46799999999999997, 1.444, 1.4489999999999998, 0.5, 0.499, 0.46499999999999997, 0.93, 1.452, 1.451, 1.439, 1.427, 1.458, 1.446, 1.4329999999999998, 1.4489999999999998, -1.0, 1.458, 0.498, 1.4609999999999999, -1.0, 1.4489999999999998, 1.4449999999999998, 1.452, -0.502, 1.442, 1.4569999999999999, 1.458, 0.5, 1.438, 1.452, 0.0, 1.44, 1.464, 1.4409999999999998, 1.45, 1.4609999999999999, 1.4609999999999999, 1.451, 0.967, 1.455, 0.471, 1.4609999999999999, 0.5, 1.435, 0.499, 1.4609999999999999, 0.499, 1.455, 1.455, 1.32, 1.4529999999999998, 0.5, 1.4489999999999998, 1.4609999999999999, 1.381, 1.4369999999999998, 0.498, 0.499, 1.451, 0.5, 0.972, 0.5, -0.5, 1.458, -1.001, 0.5, 0.5, -0.002, 1.452, 1.452, 1.411, 1.442, 0.499, 1.452, 1.452, 0.496, 1.4609999999999999, 0.5, 1.458, 1.458, 0.5, 0.0, 0.5, -0.5, 1.4609999999999999, 1.451, 1.455, 1.415, 1.452, 1.4449999999999998, 1.458, 1.444, 0.5, 1.446, 0.91, 0.5, 1.4329999999999998, -0.5, 1.439, 1.458, 1.4609999999999999, 1.455, 1.442, 0.499, 1.4569999999999999, 1.455, 1.4609999999999999, -0.023000000000000013, 0.5, 1.458, 0.5, 0.498, 1.443, 1.458, -0.002, 1.4569999999999999, 1.448, 0.5, 0.5, 1.454, 1.452, 1.458, 1.464, 1.452, 0.498, 1.439, 1.443, 0.5, 0.5, 1.4489999999999998, 1.4489999999999998, 1.452, 1.458, 1.4369999999999998, 1.455, 1.4609999999999999, 1.458, 1.4449999999999998, -0.002, 1.4449999999999998, 1.452, 1.458, 0.5, 1.4449999999999998, 1.442, 1.458, -0.002, 1.452, 0.499, -0.5009999999999999, 1.476, 1.44, 1.4489999999999998, 1.436, 0.499, 0.5], "policy_blue_0_reward": [0.474, 0.5, 1.454, 0.975, 0.499, 1.446, 0.499, 1.479, 0.0, 0.499, 1.458, 0.499, -0.002, 1.458, 0.495, 1.4609999999999999, 0.499, -0.001, -1.0, 0.499, 1.476, -0.001, -0.025000000000000015, 0.499, -0.001, 1.458, 1.4609999999999999, -0.03200000000000002, -0.501, 0.499, 0.498, 0.498, 0.498, 0.0, 0.498, 0.5, 0.5, 1.479, 0.5, 1.423, 0.499, 0.969, -0.501, 0.498, 0.499, 0.953, -0.002, 0.5, 0.5, 1.4609999999999999, -0.001, 0.5, 1.458, 0.0, -0.5, 0.498, 0.498, 0.499, 0.499, 0.5, -1.0, 0.499, 0.46299999999999997, 0.0, 1.458, 0.5, 1.452, 0.498, 1.442, 0.5, 0.497, 0.495, -0.502, 1.4329999999999998, 0.5, 0.5, 0.498, 0.498, 1.4569999999999999, 1.424, 0.496, 1.4609999999999999, -1.001, 1.458, 1.468, 0.499, 0.966, 1.4609999999999999, 1.4489999999999998, 1.455, 0.499, 0.5, -0.503, 0.5, 1.443, -0.002, 0.5, 1.458, 0.498, 1.458, 0.0, 0.498, 1.4609999999999999, 1.446, 1.454, 0.948, 0.498, 0.499, 0.0, 0.498, 0.5, 0.499, 0.5, 0.499, 1.4489999999999998, 0.497, -1.001, 1.458, 0.498, 1.448, 0.497, 0.5, 0.5, 0.499, 0.499, 1.454, 0.499, 0.0, 0.499, 0.47, 1.458, 0.5, 1.4609999999999999, 1.4489999999999998, 0.5, 0.5, 1.458, 0.5, 0.499, 1.4489999999999998, 1.436, 0.498, -0.001, 0.498, -0.5, 0.498, 1.4609999999999999, 0.5, 0.5, 1.4609999999999999, 1.455, -0.001, 0.498, 0.499, 0.5, 0.5, 0.499, 0.5, 0.5, 0.499, 1.374, -0.002, 0.5, 0.5, 1.395, 0.499, 0.5, 0.499, 1.446, 0.499, 1.4609999999999999, 1.443, -0.501, 0.498, 0.5, 0.496, 1.4609999999999999, 1.4609999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.433142818098597, "mean_inference_ms": 7.4482675200837845, "mean_action_processing_ms": 0.38939535966736427, "mean_env_wait_ms": 0.5226086578779358, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.12803325492344544, "StateBufferConnector_ms": 0.008314580060123058, "ViewRequirementAgentConnector_ms": 0.19191302610247324}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1112000, "num_agent_steps_trained": 1112000, "num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 155.3601688880437, "num_env_steps_trained_throughput_per_sec": 155.3601688880437, "timesteps_total": 556000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1112000, "timers": {"training_iteration_time_ms": 28421.914, "sample_time_ms": 4009.315, "learn_time_ms": 24385.565, "learn_throughput": 164.031, "synch_weights_time_ms": 25.558}, "counters": {"num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_agent_steps_sampled": 1112000, "num_agent_steps_trained": 1112000}, "done": false, "episodes_total": 12443, "training_iteration": 139, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-10-45", "timestamp": 1694841045, "time_this_iter_s": 25.766571044921875, "time_total_s": 4316.7947289943695, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a34a710>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4316.7947289943695, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 23.77105263157895, "ram_util_percent": 56.47105263157893}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6170212765957447, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0425531914893617, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02127659574468085, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.0425531914893617, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.28368794326241137, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.02127659574468085, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.0425531914893617, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02127659574468085, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.46238213527637223, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.029581397049090203, "policy_loss": -0.05914185246898948, "vf_loss": 0.023099631552274028, "vf_explained_var": 0.786821704544127, "kl": 0.008341982596543375, "entropy": 0.9934391984095176, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 133920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4034753693267703, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0343902018328663, "policy_loss": -0.06503709038394542, "vf_loss": 0.025666079560566383, "vf_explained_var": 0.6551657736301422, "kl": 0.008369694913584485, "entropy": 1.2533623211085796, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 133920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.039000000000000035, "episode_reward_mean": 1.7369078014184398, "episode_len_mean": 27.25531914893617, "episode_media": {}, "episodes_this_iter": 141, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.001}, "policy_reward_max": {"red_0": 1.478, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 1.0432198581560281, "blue_0": 0.6936879432624113}, "custom_metrics": {"red_0/door_open_done_mean": 0.6170212765957447, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0425531914893617, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02127659574468085, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.0425531914893617, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.28368794326241137, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.02127659574468085, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.0425531914893617, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02127659574468085, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.96, 1.944, 1.9609999999999999, 1.93, 1.941, 1.9569999999999999, 1.9449999999999998, 1.9569999999999999, 1.952, 1.46, 1.95, 1.9609999999999999, 1.399, 1.947, 1.429, 1.9609999999999999, 1.9609999999999999, 1.952, 1.955, 1.959, 1.96, 1.954, 1.96, 1.951, 1.951, 1.45, 1.8940000000000001, 1.947, -0.039000000000000035, 1.9569999999999999, 0.9529999999999998, 1.9569999999999999, 1.434, 0.472, 1.954, 0.951, 1.9569999999999999, 1.951, 1.947, 1.9609999999999999, 1.9569999999999999, 1.946, 1.939, -0.030999999999999917, 0.46399999999999997, 1.9489999999999998, 1.9609999999999999, 1.854, 1.3940000000000001, 1.958, 1.955, 0.9319999999999999, 1.955, 1.434, 1.9609999999999999, 1.954, 1.935, 1.948, 1.96, 1.929, 1.952, 1.46, 1.938, 1.955, 1.95, 1.4569999999999999, 1.9609999999999999, 1.451, 1.43, 1.959, 1.943, 1.9569999999999999, 1.946, 1.96, 1.454, 1.958, 1.452, 1.9609999999999999, 1.4529999999999998, 1.923, 1.934, 1.939, 1.923, 1.9609999999999999, 1.952, 0.978, 1.956, 1.9409999999999998, 1.96, 1.927, 1.958, 1.9569999999999999, 1.447, 1.456, 1.9609999999999999, 1.958, 1.954, 1.948, 1.958, 1.9489999999999998, 1.4529999999999998, 1.443, 1.942, 1.901, 1.9369999999999998, 1.8639999999999999, 1.428, 0.9329999999999999, 1.9609999999999999, 1.9609999999999999, 0.476, 0.9259999999999999, 1.947, 1.946, 1.959, 1.939, 1.943, 1.689, 0.943, 1.955, 1.95, 1.9529999999999998, 1.454, 1.939, 1.46, 1.958, 1.9609999999999999, 0.46499999999999986, 1.4609999999999999, 1.951, 1.95, 1.948, 1.956, 1.943, 1.959, 1.946, 1.946, 0.4630000000000001, 1.946, 1.8940000000000001, 1.9609999999999999], "episode_lengths": [13, 18, 13, 22, 19, 14, 18, 14, 16, 13, 16, 13, 33, 17, 23, 13, 13, 15, 15, 13, 13, 15, 13, 16, 16, 16, 32, 17, 13, 14, 15, 14, 21, 9, 15, 300, 14, 16, 17, 13, 14, 17, 20, 10, 11, 16, 13, 46, 34, 14, 14, 300, 15, 22, 13, 15, 21, 17, 13, 23, 16, 13, 20, 14, 16, 14, 13, 16, 22, 13, 19, 14, 17, 13, 15, 14, 14, 13, 15, 25, 22, 19, 25, 13, 15, 7, 14, 19, 13, 23, 14, 14, 17, 14, 13, 14, 15, 16, 13, 17, 15, 18, 18, 31, 19, 41, 22, 300, 13, 13, 8, 300, 17, 18, 13, 20, 19, 98, 300, 15, 16, 15, 15, 19, 13, 14, 13, 11, 13, 16, 16, 17, 14, 18, 13, 18, 18, 12, 18, 32, 13], "policy_red_0_reward": [0.499, 1.446, 0.5, 1.432, 1.443, 1.458, 1.4449999999999998, 1.458, 1.452, -0.001, 1.452, 1.4609999999999999, -0.001, 1.4489999999999998, 0.0, 0.5, 1.4609999999999999, 1.455, 1.455, 1.4609999999999999, 0.499, 1.454, 1.4609999999999999, 0.499, 1.452, 1.452, 1.401, 1.4489999999999998, 0.961, 1.4569999999999999, 1.455, 0.499, -0.001, -1.0, 1.455, 0.479, 1.4569999999999999, 1.452, 1.4489999999999998, 1.4609999999999999, 1.4569999999999999, 1.447, 1.44, -1.0, 0.967, 1.451, 1.4609999999999999, 1.357, 1.397, 1.458, 1.4569999999999999, 0.46799999999999997, 1.455, 1.434, 0.5, 0.499, 0.499, 1.448, 0.499, 1.4300000000000002, 0.5, 1.4609999999999999, 0.499, 1.458, 1.452, 1.458, 1.4609999999999999, 1.452, 1.434, 0.498, 0.5, 1.458, 1.448, 1.4609999999999999, -0.001, 1.458, -0.005, 0.5, 1.455, 1.424, 1.434, 1.4409999999999998, 1.425, 0.5, 1.454, 1.478, 1.4569999999999999, 0.499, 0.499, 1.4300000000000002, 0.5, 1.4569999999999999, 1.4489999999999998, -0.001, 1.4609999999999999, 0.5, 1.454, 1.451, 1.4609999999999999, 1.4489999999999998, 1.455, -0.002, 1.444, 0.495, 1.442, 0.491, -0.003, 0.45799999999999996, 1.4609999999999999, 1.4609999999999999, -1.0, 0.46699999999999997, 1.4489999999999998, 1.446, 0.498, 1.44, 1.443, 0.49, 0.487, 0.5, 1.452, 0.499, -0.001, 0.499, 1.4609999999999999, 1.458, 1.4609999999999999, 0.966, 0.0, 1.452, 1.452, 1.4489999999999998, 0.498, 0.498, 1.4609999999999999, 1.446, 1.446, 1.464, 1.446, 1.395, 1.4609999999999999], "policy_blue_0_reward": [1.4609999999999999, 0.498, 1.4609999999999999, 0.498, 0.498, 0.499, 0.5, 0.499, 0.5, 1.4609999999999999, 0.498, 0.5, 1.4, 0.498, 1.429, 1.4609999999999999, 0.5, 0.497, 0.5, 0.498, 1.4609999999999999, 0.5, 0.499, 1.452, 0.499, -0.002, 0.493, 0.498, -1.0, 0.5, -0.502, 1.458, 1.435, 1.472, 0.499, 0.472, 0.5, 0.499, 0.498, 0.5, 0.5, 0.499, 0.499, 0.969, -0.503, 0.498, 0.5, 0.497, -0.003, 0.5, 0.498, 0.46399999999999997, 0.5, 0.0, 1.4609999999999999, 1.455, 1.436, 0.5, 1.4609999999999999, 0.499, 1.452, -0.001, 1.439, 0.497, 0.498, -0.001, 0.5, -0.001, -0.004, 1.4609999999999999, 1.443, 0.499, 0.498, 0.499, 1.455, 0.5, 1.4569999999999999, 1.4609999999999999, -0.002, 0.499, 0.5, 0.498, 0.498, 1.4609999999999999, 0.498, -0.5, 0.499, 1.442, 1.4609999999999999, 0.497, 1.458, 0.5, -0.002, 1.4569999999999999, 0.5, 1.458, 0.5, 0.497, 0.497, 0.5, -0.002, 1.4449999999999998, 0.498, 1.4060000000000001, 0.495, 1.373, 1.431, 0.475, 0.5, 0.5, 1.476, 0.45899999999999996, 0.498, 0.5, 1.4609999999999999, 0.499, 0.5, 1.1989999999999998, 0.45599999999999996, 1.455, 0.498, 1.454, 1.455, 1.44, -0.001, 0.5, 0.5, -0.501, 1.4609999999999999, 0.499, 0.498, 0.499, 1.458, 1.4449999999999998, 0.498, 0.5, 0.5, -1.001, 0.5, 0.499, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4297296125654135, "mean_inference_ms": 7.452222673028236, "mean_action_processing_ms": 0.390447310814525, "mean_env_wait_ms": 0.522319326737374, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1222459982472954, "StateBufferConnector_ms": 0.0083514984617842, "ViewRequirementAgentConnector_ms": 0.16318694919559126}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.039000000000000035, "episode_reward_mean": 1.7369078014184398, "episode_len_mean": 27.25531914893617, "episodes_this_iter": 141, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.001}, "policy_reward_max": {"red_0": 1.478, "blue_0": 1.476}, "policy_reward_mean": {"red_0": 1.0432198581560281, "blue_0": 0.6936879432624113}, "hist_stats": {"episode_reward": [1.96, 1.944, 1.9609999999999999, 1.93, 1.941, 1.9569999999999999, 1.9449999999999998, 1.9569999999999999, 1.952, 1.46, 1.95, 1.9609999999999999, 1.399, 1.947, 1.429, 1.9609999999999999, 1.9609999999999999, 1.952, 1.955, 1.959, 1.96, 1.954, 1.96, 1.951, 1.951, 1.45, 1.8940000000000001, 1.947, -0.039000000000000035, 1.9569999999999999, 0.9529999999999998, 1.9569999999999999, 1.434, 0.472, 1.954, 0.951, 1.9569999999999999, 1.951, 1.947, 1.9609999999999999, 1.9569999999999999, 1.946, 1.939, -0.030999999999999917, 0.46399999999999997, 1.9489999999999998, 1.9609999999999999, 1.854, 1.3940000000000001, 1.958, 1.955, 0.9319999999999999, 1.955, 1.434, 1.9609999999999999, 1.954, 1.935, 1.948, 1.96, 1.929, 1.952, 1.46, 1.938, 1.955, 1.95, 1.4569999999999999, 1.9609999999999999, 1.451, 1.43, 1.959, 1.943, 1.9569999999999999, 1.946, 1.96, 1.454, 1.958, 1.452, 1.9609999999999999, 1.4529999999999998, 1.923, 1.934, 1.939, 1.923, 1.9609999999999999, 1.952, 0.978, 1.956, 1.9409999999999998, 1.96, 1.927, 1.958, 1.9569999999999999, 1.447, 1.456, 1.9609999999999999, 1.958, 1.954, 1.948, 1.958, 1.9489999999999998, 1.4529999999999998, 1.443, 1.942, 1.901, 1.9369999999999998, 1.8639999999999999, 1.428, 0.9329999999999999, 1.9609999999999999, 1.9609999999999999, 0.476, 0.9259999999999999, 1.947, 1.946, 1.959, 1.939, 1.943, 1.689, 0.943, 1.955, 1.95, 1.9529999999999998, 1.454, 1.939, 1.46, 1.958, 1.9609999999999999, 0.46499999999999986, 1.4609999999999999, 1.951, 1.95, 1.948, 1.956, 1.943, 1.959, 1.946, 1.946, 0.4630000000000001, 1.946, 1.8940000000000001, 1.9609999999999999], "episode_lengths": [13, 18, 13, 22, 19, 14, 18, 14, 16, 13, 16, 13, 33, 17, 23, 13, 13, 15, 15, 13, 13, 15, 13, 16, 16, 16, 32, 17, 13, 14, 15, 14, 21, 9, 15, 300, 14, 16, 17, 13, 14, 17, 20, 10, 11, 16, 13, 46, 34, 14, 14, 300, 15, 22, 13, 15, 21, 17, 13, 23, 16, 13, 20, 14, 16, 14, 13, 16, 22, 13, 19, 14, 17, 13, 15, 14, 14, 13, 15, 25, 22, 19, 25, 13, 15, 7, 14, 19, 13, 23, 14, 14, 17, 14, 13, 14, 15, 16, 13, 17, 15, 18, 18, 31, 19, 41, 22, 300, 13, 13, 8, 300, 17, 18, 13, 20, 19, 98, 300, 15, 16, 15, 15, 19, 13, 14, 13, 11, 13, 16, 16, 17, 14, 18, 13, 18, 18, 12, 18, 32, 13], "policy_red_0_reward": [0.499, 1.446, 0.5, 1.432, 1.443, 1.458, 1.4449999999999998, 1.458, 1.452, -0.001, 1.452, 1.4609999999999999, -0.001, 1.4489999999999998, 0.0, 0.5, 1.4609999999999999, 1.455, 1.455, 1.4609999999999999, 0.499, 1.454, 1.4609999999999999, 0.499, 1.452, 1.452, 1.401, 1.4489999999999998, 0.961, 1.4569999999999999, 1.455, 0.499, -0.001, -1.0, 1.455, 0.479, 1.4569999999999999, 1.452, 1.4489999999999998, 1.4609999999999999, 1.4569999999999999, 1.447, 1.44, -1.0, 0.967, 1.451, 1.4609999999999999, 1.357, 1.397, 1.458, 1.4569999999999999, 0.46799999999999997, 1.455, 1.434, 0.5, 0.499, 0.499, 1.448, 0.499, 1.4300000000000002, 0.5, 1.4609999999999999, 0.499, 1.458, 1.452, 1.458, 1.4609999999999999, 1.452, 1.434, 0.498, 0.5, 1.458, 1.448, 1.4609999999999999, -0.001, 1.458, -0.005, 0.5, 1.455, 1.424, 1.434, 1.4409999999999998, 1.425, 0.5, 1.454, 1.478, 1.4569999999999999, 0.499, 0.499, 1.4300000000000002, 0.5, 1.4569999999999999, 1.4489999999999998, -0.001, 1.4609999999999999, 0.5, 1.454, 1.451, 1.4609999999999999, 1.4489999999999998, 1.455, -0.002, 1.444, 0.495, 1.442, 0.491, -0.003, 0.45799999999999996, 1.4609999999999999, 1.4609999999999999, -1.0, 0.46699999999999997, 1.4489999999999998, 1.446, 0.498, 1.44, 1.443, 0.49, 0.487, 0.5, 1.452, 0.499, -0.001, 0.499, 1.4609999999999999, 1.458, 1.4609999999999999, 0.966, 0.0, 1.452, 1.452, 1.4489999999999998, 0.498, 0.498, 1.4609999999999999, 1.446, 1.446, 1.464, 1.446, 1.395, 1.4609999999999999], "policy_blue_0_reward": [1.4609999999999999, 0.498, 1.4609999999999999, 0.498, 0.498, 0.499, 0.5, 0.499, 0.5, 1.4609999999999999, 0.498, 0.5, 1.4, 0.498, 1.429, 1.4609999999999999, 0.5, 0.497, 0.5, 0.498, 1.4609999999999999, 0.5, 0.499, 1.452, 0.499, -0.002, 0.493, 0.498, -1.0, 0.5, -0.502, 1.458, 1.435, 1.472, 0.499, 0.472, 0.5, 0.499, 0.498, 0.5, 0.5, 0.499, 0.499, 0.969, -0.503, 0.498, 0.5, 0.497, -0.003, 0.5, 0.498, 0.46399999999999997, 0.5, 0.0, 1.4609999999999999, 1.455, 1.436, 0.5, 1.4609999999999999, 0.499, 1.452, -0.001, 1.439, 0.497, 0.498, -0.001, 0.5, -0.001, -0.004, 1.4609999999999999, 1.443, 0.499, 0.498, 0.499, 1.455, 0.5, 1.4569999999999999, 1.4609999999999999, -0.002, 0.499, 0.5, 0.498, 0.498, 1.4609999999999999, 0.498, -0.5, 0.499, 1.442, 1.4609999999999999, 0.497, 1.458, 0.5, -0.002, 1.4569999999999999, 0.5, 1.458, 0.5, 0.497, 0.497, 0.5, -0.002, 1.4449999999999998, 0.498, 1.4060000000000001, 0.495, 1.373, 1.431, 0.475, 0.5, 0.5, 1.476, 0.45899999999999996, 0.498, 0.5, 1.4609999999999999, 0.499, 0.5, 1.1989999999999998, 0.45599999999999996, 1.455, 0.498, 1.454, 1.455, 1.44, -0.001, 0.5, 0.5, -0.501, 1.4609999999999999, 0.499, 0.498, 0.499, 1.458, 1.4449999999999998, 0.498, 0.5, 0.5, -1.001, 0.5, 0.499, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4297296125654135, "mean_inference_ms": 7.452222673028236, "mean_action_processing_ms": 0.390447310814525, "mean_env_wait_ms": 0.522319326737374, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.1222459982472954, "StateBufferConnector_ms": 0.0083514984617842, "ViewRequirementAgentConnector_ms": 0.16318694919559126}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 151.26562127422366, "num_env_steps_trained_throughput_per_sec": 151.26562127422366, "timesteps_total": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 28032.329, "sample_time_ms": 3960.354, "learn_time_ms": 24045.119, "learn_throughput": 166.354, "synch_weights_time_ms": 25.433}, "counters": {"num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "episodes_total": 12584, "training_iteration": 140, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-11-12", "timestamp": 1694841072, "time_this_iter_s": 26.461636066436768, "time_total_s": 4343.256365060806, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219b45e0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4343.256365060806, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 24.394871794871793, "ram_util_percent": 57.02051282051283}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6329787234042553, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.10106382978723404, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.031914893617021274, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.10106382978723404, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.21808510638297873, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.031914893617021274, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.10106382978723404, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.031914893617021274, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4394574177140991, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.0316751344910396, "policy_loss": -0.06977789116887531, "vf_loss": 0.03600288740320442, "vf_explained_var": 0.713151995278895, "kl": 0.009193447199645866, "entropy": 0.8425092896446585, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 134880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4613854145165533, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03757320272561628, "policy_loss": -0.07983597407195096, "vf_loss": 0.04143131927315456, "vf_explained_var": 0.5880838251983126, "kl": 0.009973914898478181, "entropy": 1.1747132167220116, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 134880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_agent_steps_sampled": 1128000, "num_agent_steps_trained": 1128000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.05600000000000005, "episode_reward_mean": 1.6232446808510637, "episode_len_mean": 21.345744680851062, "episode_media": {}, "episodes_this_iter": 188, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.475}, "policy_reward_mean": {"red_0": 1.0952127659574469, "blue_0": 0.5280319148936171}, "custom_metrics": {"red_0/door_open_done_mean": 0.6329787234042553, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.10106382978723404, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.031914893617021274, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.10106382978723404, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.21808510638297873, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.031914893617021274, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.10106382978723404, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.031914893617021274, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.943, 1.9609999999999999, 1.959, 1.955, 1.42, 1.454, 1.958, 1.955, 1.958, 0.948, 1.96, 1.9609999999999999, 0.474, 1.958, 1.947, 0.46599999999999997, 1.446, 1.9609999999999999, 1.447, 1.456, 1.9569999999999999, 0.9489999999999998, 1.9449999999999998, 1.458, 1.452, 1.9489999999999998, 1.939, 1.9449999999999998, 1.96, 1.94, 0.9359999999999999, 1.9369999999999998, 0.44099999999999995, 1.4609999999999999, 1.456, 1.948, 1.951, 1.9609999999999999, 1.94, 1.451, 1.912, 1.948, 0.4770000000000001, 1.954, 1.9489999999999998, 1.942, 1.959, 1.44, 1.452, 1.958, 1.92, 1.954, 1.454, 1.95, 1.9489999999999998, 1.946, 1.958, 0.962, 1.951, 0.951, 1.951, 1.4289999999999998, 1.956, 1.955, 1.447, -0.031000000000000028, 1.955, 1.427, 1.9369999999999998, 1.9609999999999999, 1.9449999999999998, 1.933, -0.050000000000000044, 1.9609999999999999, 1.939, 1.9489999999999998, 1.439, 1.955, 1.959, 1.9489999999999998, 1.943, 1.958, 0.46499999999999986, 1.9569999999999999, 1.9569999999999999, 1.889, 1.443, 1.955, 0.958, 1.9569999999999999, 1.956, 1.451, 1.452, 0.944, 1.44, 1.96, 1.94, 1.9569999999999999, 1.954, 1.955, 1.9489999999999998, 1.923, 1.938, 1.956, 0.474, 0.45500000000000007, 1.95, 1.952, 1.9569999999999999, 0.952, 1.9529999999999998, 1.9, 1.4609999999999999, 1.903, 1.4369999999999998, 0.43099999999999994, 1.946, 1.942, 1.442, 1.912, 1.4569999999999999, 1.46, 1.9220000000000002, 1.958, 1.936, 1.9489999999999998, 1.947, 1.895, 1.955, 1.955, 1.924, 1.452, 1.363, 1.958, 1.9449999999999998, -0.028000000000000025, 1.947, 1.96, 1.959, 1.955, 1.858, 1.955, 0.45999999999999996, 1.458, -0.05600000000000005, 1.958, 1.952, 0.9449999999999998, 1.456, 1.958, 1.956, 1.4609999999999999, 1.447, 1.958, 1.9609999999999999, 0.4169999999999999, 1.447, -0.04400000000000004, 1.9569999999999999, 1.956, 1.413, 1.46, 1.4569999999999999, 1.865, 1.4609999999999999, 1.9529999999999998, 1.96, 1.9609999999999999, 1.94, 1.96, 1.96, 1.9260000000000002, 1.458, 1.947, 0.941, 1.9489999999999998, 1.955, 1.4489999999999998, 1.456, -0.018000000000000016, 1.429, 1.917, -0.03699999999999992, 1.954, 1.958, 1.439, 1.951, 1.938], "episode_lengths": [300, 13, 13, 15, 26, 15, 14, 15, 14, 17, 13, 13, 8, 14, 17, 11, 18, 13, 17, 14, 14, 16, 18, 14, 16, 16, 19, 18, 13, 20, 21, 20, 19, 13, 14, 17, 16, 13, 19, 16, 27, 17, 7, 15, 17, 19, 13, 20, 16, 14, 26, 15, 15, 16, 16, 17, 14, 12, 16, 16, 16, 22, 14, 15, 17, 10, 15, 23, 20, 13, 18, 21, 16, 13, 19, 16, 19, 15, 13, 16, 18, 14, 11, 14, 14, 36, 18, 15, 14, 14, 14, 16, 16, 18, 20, 13, 20, 14, 15, 15, 16, 25, 20, 14, 8, 14, 16, 16, 14, 15, 14, 32, 13, 32, 20, 22, 17, 19, 19, 28, 14, 13, 25, 14, 21, 17, 17, 33, 15, 15, 25, 15, 45, 14, 18, 9, 17, 13, 13, 15, 45, 15, 13, 14, 17, 14, 16, 17, 14, 14, 14, 13, 16, 14, 13, 300, 17, 13, 14, 14, 27, 13, 13, 43, 13, 15, 13, 13, 20, 13, 13, 23, 14, 17, 300, 17, 15, 16, 14, 6, 22, 27, 12, 15, 14, 20, 16, 20], "policy_red_0_reward": [0.47, 0.5, 1.4609999999999999, 1.455, 1.4220000000000002, 1.455, 1.458, 0.5, 1.458, 1.448, 0.499, 1.4609999999999999, -1.001, 0.5, 0.499, 1.467, 1.446, 1.4609999999999999, -0.001, 1.4569999999999999, 0.5, 1.45, 1.4449999999999998, 1.458, 0.0, 1.451, 1.443, 0.499, 1.4609999999999999, 1.44, -0.501, 1.44, -1.0, 1.4609999999999999, 1.458, 1.4489999999999998, 1.452, 1.4609999999999999, 1.443, -0.001, 1.416, 1.4489999999999998, 1.479, 1.455, 1.4489999999999998, 1.442, 1.4609999999999999, 0.0, 1.452, 1.458, 1.421, 1.454, -0.001, 0.499, 1.451, 0.499, 0.5, 1.464, 1.452, -0.5, 1.452, 1.432, 0.499, 0.5, 1.4489999999999998, 0.97, 1.455, 1.429, 0.499, 1.4609999999999999, 1.446, 1.4369999999999998, 0.951, 1.4609999999999999, 1.443, 1.451, 1.4409999999999998, 1.455, 1.4609999999999999, 0.497, 0.498, 0.5, 1.467, 1.458, 1.458, 1.391, 0.0, 1.455, 1.458, 1.4569999999999999, 1.4569999999999999, 1.452, 1.452, 1.4449999999999998, 1.44, 1.4609999999999999, 1.44, 1.4569999999999999, 1.455, 1.455, 1.451, 1.425, 0.499, 1.4569999999999999, 1.476, 0.957, 1.452, 0.5, 1.458, 1.452, 1.458, 1.4, 1.4609999999999999, 1.404, -0.002, -1.002, 1.4489999999999998, 1.442, 1.443, 1.413, -0.001, 1.4609999999999999, 1.424, 0.5, 1.4369999999999998, 1.4489999999999998, 1.448, 1.3980000000000001, 1.455, 0.5, 1.425, 1.455, -0.001, 1.458, 1.446, 0.973, 1.4489999999999998, 0.499, 1.4609999999999999, 1.455, 1.363, 1.455, 0.961, 1.458, 0.946, 0.5, 0.5, 1.447, -0.001, 0.5, 1.4569999999999999, 1.4609999999999999, 1.452, 1.458, 1.4609999999999999, -0.03300000000000002, 1.448, 0.959, 1.458, 1.458, -0.001, 1.4609999999999999, 1.4609999999999999, 0.497, 1.4609999999999999, 0.499, 1.4609999999999999, 1.4609999999999999, 1.44, 1.4609999999999999, 1.4609999999999999, 1.431, 1.458, 0.499, 0.47, 1.4489999999999998, 1.455, -0.001, -0.002, 0.982, 1.431, 1.419, -1.0, 1.455, 0.5, 1.44, 1.452, 1.439], "policy_blue_0_reward": [0.473, 1.4609999999999999, 0.498, 0.5, -0.002, -0.001, 0.5, 1.455, 0.5, -0.5, 1.4609999999999999, 0.5, 1.475, 1.458, 1.448, -1.001, 0.0, 0.5, 1.448, -0.001, 1.4569999999999999, -0.501, 0.5, 0.0, 1.452, 0.498, 0.496, 1.446, 0.499, 0.5, 1.4369999999999998, 0.497, 1.4409999999999998, 0.0, -0.002, 0.499, 0.499, 0.5, 0.497, 1.452, 0.496, 0.499, -1.0019999999999998, 0.499, 0.5, 0.5, 0.498, 1.44, 0.0, 0.5, 0.499, 0.5, 1.455, 1.451, 0.498, 1.447, 1.458, -0.502, 0.499, 1.451, 0.499, -0.003, 1.4569999999999999, 1.455, -0.002, -1.001, 0.5, -0.002, 1.438, 0.5, 0.499, 0.496, -1.001, 0.5, 0.496, 0.498, -0.002, 0.5, 0.498, 1.452, 1.4449999999999998, 1.458, -1.002, 0.499, 0.499, 0.498, 1.443, 0.5, -0.5, 0.5, 0.499, -0.001, 0.0, -0.501, 0.0, 0.499, 0.5, 0.5, 0.499, 0.5, 0.498, 0.498, 1.439, 0.499, -1.002, -0.502, 0.498, 1.452, 0.499, -0.5, 0.495, 0.5, 0.0, 0.499, 1.439, 1.4329999999999998, 0.497, 0.5, -0.001, 0.499, 1.458, -0.001, 0.498, 1.458, 0.499, 0.5, 0.499, 0.497, 0.5, 1.455, 0.499, -0.003, 1.3639999999999999, 0.5, 0.499, -1.001, 0.498, 1.4609999999999999, 0.498, 0.5, 0.495, 0.5, -0.501, 0.0, -1.002, 1.458, 1.452, -0.502, 1.4569999999999999, 1.458, 0.499, 0.0, -0.005, 0.5, 0.5, 0.44999999999999996, -0.001, -1.003, 0.499, 0.498, 1.4140000000000001, -0.001, -0.004, 1.3679999999999999, 0.0, 1.454, 0.499, 0.5, 0.5, 0.499, 0.499, 0.495, 0.0, 1.448, 0.471, 0.5, 0.5, 1.45, 1.458, -1.0, -0.002, 0.498, 0.963, 0.499, 1.458, -0.001, 0.499, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4306508487002374, "mean_inference_ms": 7.435269210707949, "mean_action_processing_ms": 0.38920053735868543, "mean_env_wait_ms": 0.5220682185994939, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15801914194796948, "StateBufferConnector_ms": 0.00925850360951525, "ViewRequirementAgentConnector_ms": 0.18830990537684014}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.05600000000000005, "episode_reward_mean": 1.6232446808510637, "episode_len_mean": 21.345744680851062, "episodes_this_iter": 188, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.003}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.475}, "policy_reward_mean": {"red_0": 1.0952127659574469, "blue_0": 0.5280319148936171}, "hist_stats": {"episode_reward": [0.943, 1.9609999999999999, 1.959, 1.955, 1.42, 1.454, 1.958, 1.955, 1.958, 0.948, 1.96, 1.9609999999999999, 0.474, 1.958, 1.947, 0.46599999999999997, 1.446, 1.9609999999999999, 1.447, 1.456, 1.9569999999999999, 0.9489999999999998, 1.9449999999999998, 1.458, 1.452, 1.9489999999999998, 1.939, 1.9449999999999998, 1.96, 1.94, 0.9359999999999999, 1.9369999999999998, 0.44099999999999995, 1.4609999999999999, 1.456, 1.948, 1.951, 1.9609999999999999, 1.94, 1.451, 1.912, 1.948, 0.4770000000000001, 1.954, 1.9489999999999998, 1.942, 1.959, 1.44, 1.452, 1.958, 1.92, 1.954, 1.454, 1.95, 1.9489999999999998, 1.946, 1.958, 0.962, 1.951, 0.951, 1.951, 1.4289999999999998, 1.956, 1.955, 1.447, -0.031000000000000028, 1.955, 1.427, 1.9369999999999998, 1.9609999999999999, 1.9449999999999998, 1.933, -0.050000000000000044, 1.9609999999999999, 1.939, 1.9489999999999998, 1.439, 1.955, 1.959, 1.9489999999999998, 1.943, 1.958, 0.46499999999999986, 1.9569999999999999, 1.9569999999999999, 1.889, 1.443, 1.955, 0.958, 1.9569999999999999, 1.956, 1.451, 1.452, 0.944, 1.44, 1.96, 1.94, 1.9569999999999999, 1.954, 1.955, 1.9489999999999998, 1.923, 1.938, 1.956, 0.474, 0.45500000000000007, 1.95, 1.952, 1.9569999999999999, 0.952, 1.9529999999999998, 1.9, 1.4609999999999999, 1.903, 1.4369999999999998, 0.43099999999999994, 1.946, 1.942, 1.442, 1.912, 1.4569999999999999, 1.46, 1.9220000000000002, 1.958, 1.936, 1.9489999999999998, 1.947, 1.895, 1.955, 1.955, 1.924, 1.452, 1.363, 1.958, 1.9449999999999998, -0.028000000000000025, 1.947, 1.96, 1.959, 1.955, 1.858, 1.955, 0.45999999999999996, 1.458, -0.05600000000000005, 1.958, 1.952, 0.9449999999999998, 1.456, 1.958, 1.956, 1.4609999999999999, 1.447, 1.958, 1.9609999999999999, 0.4169999999999999, 1.447, -0.04400000000000004, 1.9569999999999999, 1.956, 1.413, 1.46, 1.4569999999999999, 1.865, 1.4609999999999999, 1.9529999999999998, 1.96, 1.9609999999999999, 1.94, 1.96, 1.96, 1.9260000000000002, 1.458, 1.947, 0.941, 1.9489999999999998, 1.955, 1.4489999999999998, 1.456, -0.018000000000000016, 1.429, 1.917, -0.03699999999999992, 1.954, 1.958, 1.439, 1.951, 1.938], "episode_lengths": [300, 13, 13, 15, 26, 15, 14, 15, 14, 17, 13, 13, 8, 14, 17, 11, 18, 13, 17, 14, 14, 16, 18, 14, 16, 16, 19, 18, 13, 20, 21, 20, 19, 13, 14, 17, 16, 13, 19, 16, 27, 17, 7, 15, 17, 19, 13, 20, 16, 14, 26, 15, 15, 16, 16, 17, 14, 12, 16, 16, 16, 22, 14, 15, 17, 10, 15, 23, 20, 13, 18, 21, 16, 13, 19, 16, 19, 15, 13, 16, 18, 14, 11, 14, 14, 36, 18, 15, 14, 14, 14, 16, 16, 18, 20, 13, 20, 14, 15, 15, 16, 25, 20, 14, 8, 14, 16, 16, 14, 15, 14, 32, 13, 32, 20, 22, 17, 19, 19, 28, 14, 13, 25, 14, 21, 17, 17, 33, 15, 15, 25, 15, 45, 14, 18, 9, 17, 13, 13, 15, 45, 15, 13, 14, 17, 14, 16, 17, 14, 14, 14, 13, 16, 14, 13, 300, 17, 13, 14, 14, 27, 13, 13, 43, 13, 15, 13, 13, 20, 13, 13, 23, 14, 17, 300, 17, 15, 16, 14, 6, 22, 27, 12, 15, 14, 20, 16, 20], "policy_red_0_reward": [0.47, 0.5, 1.4609999999999999, 1.455, 1.4220000000000002, 1.455, 1.458, 0.5, 1.458, 1.448, 0.499, 1.4609999999999999, -1.001, 0.5, 0.499, 1.467, 1.446, 1.4609999999999999, -0.001, 1.4569999999999999, 0.5, 1.45, 1.4449999999999998, 1.458, 0.0, 1.451, 1.443, 0.499, 1.4609999999999999, 1.44, -0.501, 1.44, -1.0, 1.4609999999999999, 1.458, 1.4489999999999998, 1.452, 1.4609999999999999, 1.443, -0.001, 1.416, 1.4489999999999998, 1.479, 1.455, 1.4489999999999998, 1.442, 1.4609999999999999, 0.0, 1.452, 1.458, 1.421, 1.454, -0.001, 0.499, 1.451, 0.499, 0.5, 1.464, 1.452, -0.5, 1.452, 1.432, 0.499, 0.5, 1.4489999999999998, 0.97, 1.455, 1.429, 0.499, 1.4609999999999999, 1.446, 1.4369999999999998, 0.951, 1.4609999999999999, 1.443, 1.451, 1.4409999999999998, 1.455, 1.4609999999999999, 0.497, 0.498, 0.5, 1.467, 1.458, 1.458, 1.391, 0.0, 1.455, 1.458, 1.4569999999999999, 1.4569999999999999, 1.452, 1.452, 1.4449999999999998, 1.44, 1.4609999999999999, 1.44, 1.4569999999999999, 1.455, 1.455, 1.451, 1.425, 0.499, 1.4569999999999999, 1.476, 0.957, 1.452, 0.5, 1.458, 1.452, 1.458, 1.4, 1.4609999999999999, 1.404, -0.002, -1.002, 1.4489999999999998, 1.442, 1.443, 1.413, -0.001, 1.4609999999999999, 1.424, 0.5, 1.4369999999999998, 1.4489999999999998, 1.448, 1.3980000000000001, 1.455, 0.5, 1.425, 1.455, -0.001, 1.458, 1.446, 0.973, 1.4489999999999998, 0.499, 1.4609999999999999, 1.455, 1.363, 1.455, 0.961, 1.458, 0.946, 0.5, 0.5, 1.447, -0.001, 0.5, 1.4569999999999999, 1.4609999999999999, 1.452, 1.458, 1.4609999999999999, -0.03300000000000002, 1.448, 0.959, 1.458, 1.458, -0.001, 1.4609999999999999, 1.4609999999999999, 0.497, 1.4609999999999999, 0.499, 1.4609999999999999, 1.4609999999999999, 1.44, 1.4609999999999999, 1.4609999999999999, 1.431, 1.458, 0.499, 0.47, 1.4489999999999998, 1.455, -0.001, -0.002, 0.982, 1.431, 1.419, -1.0, 1.455, 0.5, 1.44, 1.452, 1.439], "policy_blue_0_reward": [0.473, 1.4609999999999999, 0.498, 0.5, -0.002, -0.001, 0.5, 1.455, 0.5, -0.5, 1.4609999999999999, 0.5, 1.475, 1.458, 1.448, -1.001, 0.0, 0.5, 1.448, -0.001, 1.4569999999999999, -0.501, 0.5, 0.0, 1.452, 0.498, 0.496, 1.446, 0.499, 0.5, 1.4369999999999998, 0.497, 1.4409999999999998, 0.0, -0.002, 0.499, 0.499, 0.5, 0.497, 1.452, 0.496, 0.499, -1.0019999999999998, 0.499, 0.5, 0.5, 0.498, 1.44, 0.0, 0.5, 0.499, 0.5, 1.455, 1.451, 0.498, 1.447, 1.458, -0.502, 0.499, 1.451, 0.499, -0.003, 1.4569999999999999, 1.455, -0.002, -1.001, 0.5, -0.002, 1.438, 0.5, 0.499, 0.496, -1.001, 0.5, 0.496, 0.498, -0.002, 0.5, 0.498, 1.452, 1.4449999999999998, 1.458, -1.002, 0.499, 0.499, 0.498, 1.443, 0.5, -0.5, 0.5, 0.499, -0.001, 0.0, -0.501, 0.0, 0.499, 0.5, 0.5, 0.499, 0.5, 0.498, 0.498, 1.439, 0.499, -1.002, -0.502, 0.498, 1.452, 0.499, -0.5, 0.495, 0.5, 0.0, 0.499, 1.439, 1.4329999999999998, 0.497, 0.5, -0.001, 0.499, 1.458, -0.001, 0.498, 1.458, 0.499, 0.5, 0.499, 0.497, 0.5, 1.455, 0.499, -0.003, 1.3639999999999999, 0.5, 0.499, -1.001, 0.498, 1.4609999999999999, 0.498, 0.5, 0.495, 0.5, -0.501, 0.0, -1.002, 1.458, 1.452, -0.502, 1.4569999999999999, 1.458, 0.499, 0.0, -0.005, 0.5, 0.5, 0.44999999999999996, -0.001, -1.003, 0.499, 0.498, 1.4140000000000001, -0.001, -0.004, 1.3679999999999999, 0.0, 1.454, 0.499, 0.5, 0.5, 0.499, 0.499, 0.495, 0.0, 1.448, 0.471, 0.5, 0.5, 1.45, 1.458, -1.0, -0.002, 0.498, 0.963, 0.499, 1.458, -0.001, 0.499, 0.499]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4306508487002374, "mean_inference_ms": 7.435269210707949, "mean_action_processing_ms": 0.38920053735868543, "mean_env_wait_ms": 0.5220682185994939, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.15801914194796948, "StateBufferConnector_ms": 0.00925850360951525, "ViewRequirementAgentConnector_ms": 0.18830990537684014}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1128000, "num_agent_steps_trained": 1128000, "num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 144.17157084595337, "num_env_steps_trained_throughput_per_sec": 144.17157084595337, "timesteps_total": 564000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1128000, "timers": {"training_iteration_time_ms": 27204.126, "sample_time_ms": 3898.512, "learn_time_ms": 23279.161, "learn_throughput": 171.827, "synch_weights_time_ms": 25.091}, "counters": {"num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_agent_steps_sampled": 1128000, "num_agent_steps_trained": 1128000}, "done": false, "episodes_total": 12772, "training_iteration": 141, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-11-41", "timestamp": 1694841101, "time_this_iter_s": 27.76459574699402, "time_total_s": 4371.0209608078, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a34b370>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4371.0209608078, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 33.6925, "ram_util_percent": 57.464999999999996}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6044776119402985, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.07462686567164178, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.029850746268656716, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.07462686567164178, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.2537313432835821, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.029850746268656716, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.07462686567164178, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.029850746268656716, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.384350759194543, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03297842744505033, "policy_loss": -0.06004174977788353, "vf_loss": 0.022714336943075373, "vf_explained_var": 0.7911220042034983, "kl": 0.007362216031876038, "entropy": 1.065894193574786, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 135840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.42482579989979663, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.036945730533625466, "policy_loss": -0.06753820054436802, "vf_loss": 0.028049634750641417, "vf_explained_var": 0.6038568257043759, "kl": 0.007850502666831967, "entropy": 1.3167741746952137, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 135840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.041000000000000036, "episode_reward_mean": 1.672268656716418, "episode_len_mean": 27.23134328358209, "episode_media": {}, "episodes_this_iter": 134, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.482, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 1.0774179104477613, "blue_0": 0.5948507462686566}, "custom_metrics": {"red_0/door_open_done_mean": 0.6044776119402985, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.07462686567164178, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.029850746268656716, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.07462686567164178, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.2537313432835821, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.029850746268656716, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.07462686567164178, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.029850746268656716, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.936, 1.959, 1.956, 1.954, 1.96, 0.44799999999999995, 1.926, 0.44299999999999995, 1.9569999999999999, 1.456, 1.944, 1.936, 1.448, 1.9540000000000002, 0.9349999999999999, 1.42, 0.96, 1.954, 1.452, 1.947, 1.366, 1.951, 1.4489999999999998, 1.916, 1.919, 1.955, 1.96, 0.9689999999999999, 1.4609999999999999, 1.4609999999999999, 1.958, 1.9529999999999998, 1.958, 1.434, 1.956, 1.9569999999999999, 1.956, 1.954, 1.948, 1.9609999999999999, 1.95, 1.952, 1.448, 1.46, 1.4609999999999999, 0.958, 1.206, 1.458, 1.454, 1.944, 1.952, 1.431, 1.9609999999999999, 0.46599999999999997, 1.959, 1.435, -0.041000000000000036, 1.959, 0.973, 1.931, 1.955, 1.95, 1.4529999999999998, 1.96, 1.452, 1.455, 1.96, 1.9489999999999998, 1.951, 0.47299999999999986, 1.952, 1.9609999999999999, 1.9569999999999999, 1.924, 1.96, 1.954, 1.9609999999999999, 0.46799999999999997, 1.452, 1.952, 1.4, 0.45899999999999996, 1.958, 1.909, 1.959, 1.9409999999999998, 1.9569999999999999, 1.955, 1.96, 0.938, 1.9489999999999998, 1.952, 1.442, 1.955, 1.944, 1.958, 1.935, 1.954, 0.482, 1.955, 1.951, 1.9609999999999999, 1.955, 0.9590000000000001, 1.9529999999999998, 1.96, 1.407, 0.9609999999999999, 1.9609999999999999, 1.952, 1.948, 1.958, 1.9609999999999999, 1.958, 1.9529999999999998, 1.9609999999999999, 1.919, 1.9489999999999998, 1.958, 1.9609999999999999, 1.951, 1.957, 1.952, 1.404, 1.9609999999999999, 0.46299999999999997, 1.919, 1.429, 0.9630000000000001, 0.967, 1.958, 1.9409999999999998, 1.95, 1.958], "episode_lengths": [21, 13, 14, 15, 13, 16, 24, 300, 14, 14, 18, 20, 17, 15, 300, 26, 13, 15, 16, 17, 42, 16, 17, 27, 26, 15, 13, 10, 13, 13, 14, 15, 14, 20, 14, 14, 14, 15, 17, 13, 16, 15, 17, 13, 13, 300, 90, 14, 15, 18, 15, 23, 13, 11, 13, 21, 13, 13, 9, 22, 15, 16, 15, 13, 16, 15, 13, 17, 16, 9, 16, 13, 14, 25, 13, 15, 13, 10, 16, 16, 31, 13, 14, 29, 13, 19, 14, 15, 13, 300, 17, 15, 18, 15, 18, 14, 21, 15, 6, 15, 16, 13, 14, 13, 15, 13, 30, 13, 13, 15, 17, 14, 13, 14, 15, 13, 25, 16, 14, 13, 16, 14, 16, 30, 13, 11, 25, 23, 11, 300, 14, 19, 16, 14], "policy_red_0_reward": [0.5, 1.4609999999999999, 1.458, 1.455, 1.4609999999999999, 0.95, 1.428, -0.02000000000000001, 1.458, 1.4569999999999999, 0.499, 1.44, 1.4489999999999998, 1.455, 0.46599999999999997, 1.4220000000000002, -0.5, 0.5, 1.452, 0.499, 1.369, 1.452, 1.4489999999999998, 0.5, 1.419, 1.455, 1.4609999999999999, 1.47, 1.4609999999999999, 1.4609999999999999, 1.458, 0.5, 0.5, 1.439, 1.458, 0.499, 1.458, 0.5, 0.5, 1.4609999999999999, 1.45, 1.4529999999999998, 1.4489999999999998, 1.4609999999999999, 1.4609999999999999, 0.486, -0.010000000000000002, 0.0, 1.455, 1.4449999999999998, 0.498, 1.431, 0.5, 1.466, 1.4609999999999999, 1.436, 0.96, 1.4609999999999999, -0.5, 0.5, 1.455, 0.499, -0.001, 0.499, 0.0, 1.455, 1.4609999999999999, 1.4489999999999998, 0.499, 0.973, 1.452, 1.4609999999999999, 1.458, 0.5, 0.499, 1.455, 1.4609999999999999, 1.47, 1.452, 1.452, 1.4060000000000001, -0.5, 0.5, 1.4100000000000001, 1.4609999999999999, 1.442, 1.458, 1.455, 1.4609999999999999, 0.46499999999999997, 0.5, 1.455, -0.002, 1.455, 1.4449999999999998, 0.5, 0.499, 1.455, 1.482, 1.455, 1.452, 0.5, 1.458, 1.459, 1.455, 1.4609999999999999, 1.4100000000000001, 1.4609999999999999, 1.4609999999999999, 0.498, 1.4489999999999998, 1.458, 0.5, 0.5, 1.455, 1.4609999999999999, 1.423, 1.452, 0.5, 1.4609999999999999, 0.5, 1.458, 1.452, 1.408, 0.5, -1.002, 1.423, 1.431, 1.4649999999999999, 0.48, 1.458, 1.443, 1.452, 1.458], "policy_blue_0_reward": [1.436, 0.498, 0.498, 0.499, 0.499, -0.502, 0.498, 0.46299999999999997, 0.499, -0.001, 1.4449999999999998, 0.496, -0.001, 0.499, 0.469, -0.002, 1.46, 1.454, 0.0, 1.448, -0.003, 0.499, 0.0, 1.416, 0.5, 0.5, 0.499, -0.501, 0.0, 0.0, 0.5, 1.4529999999999998, 1.458, -0.005, 0.498, 1.458, 0.498, 1.454, 1.448, 0.5, 0.5, 0.499, -0.001, -0.001, 0.0, 0.472, 1.216, 1.458, -0.001, 0.499, 1.454, 0.0, 1.4609999999999999, -1.0, 0.498, -0.001, -1.001, 0.498, 1.4729999999999999, 1.431, 0.5, 1.451, 1.454, 1.4609999999999999, 1.452, 0.0, 0.499, 0.5, 1.452, -0.5, 0.5, 0.5, 0.499, 1.424, 1.4609999999999999, 0.499, 0.5, -1.002, 0.0, 0.5, -0.006, 0.959, 1.458, 0.499, 0.498, 0.499, 0.499, 0.5, 0.499, 0.473, 1.4489999999999998, 0.497, 1.444, 0.5, 0.499, 1.458, 1.436, 0.499, -1.0, 0.5, 0.499, 1.4609999999999999, 0.497, -0.5, 0.498, 0.499, -0.003, -0.5, 0.5, 1.454, 0.499, 0.5, 1.4609999999999999, 1.458, 0.498, 0.5, 0.496, 0.497, 1.458, 0.5, 1.451, 0.499, 0.5, -0.004, 1.4609999999999999, 1.4649999999999999, 0.496, -0.002, -0.502, 0.487, 0.5, 0.498, 0.498, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4305748850915676, "mean_inference_ms": 7.422275417273513, "mean_action_processing_ms": 0.3881738797096327, "mean_env_wait_ms": 0.5216286189844304, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.12242847414159064, "StateBufferConnector_ms": 0.008115483753716768, "ViewRequirementAgentConnector_ms": 0.1580806810464432}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.041000000000000036, "episode_reward_mean": 1.672268656716418, "episode_len_mean": 27.23134328358209, "episodes_this_iter": 134, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.002}, "policy_reward_max": {"red_0": 1.482, "blue_0": 1.4729999999999999}, "policy_reward_mean": {"red_0": 1.0774179104477613, "blue_0": 0.5948507462686566}, "hist_stats": {"episode_reward": [1.936, 1.959, 1.956, 1.954, 1.96, 0.44799999999999995, 1.926, 0.44299999999999995, 1.9569999999999999, 1.456, 1.944, 1.936, 1.448, 1.9540000000000002, 0.9349999999999999, 1.42, 0.96, 1.954, 1.452, 1.947, 1.366, 1.951, 1.4489999999999998, 1.916, 1.919, 1.955, 1.96, 0.9689999999999999, 1.4609999999999999, 1.4609999999999999, 1.958, 1.9529999999999998, 1.958, 1.434, 1.956, 1.9569999999999999, 1.956, 1.954, 1.948, 1.9609999999999999, 1.95, 1.952, 1.448, 1.46, 1.4609999999999999, 0.958, 1.206, 1.458, 1.454, 1.944, 1.952, 1.431, 1.9609999999999999, 0.46599999999999997, 1.959, 1.435, -0.041000000000000036, 1.959, 0.973, 1.931, 1.955, 1.95, 1.4529999999999998, 1.96, 1.452, 1.455, 1.96, 1.9489999999999998, 1.951, 0.47299999999999986, 1.952, 1.9609999999999999, 1.9569999999999999, 1.924, 1.96, 1.954, 1.9609999999999999, 0.46799999999999997, 1.452, 1.952, 1.4, 0.45899999999999996, 1.958, 1.909, 1.959, 1.9409999999999998, 1.9569999999999999, 1.955, 1.96, 0.938, 1.9489999999999998, 1.952, 1.442, 1.955, 1.944, 1.958, 1.935, 1.954, 0.482, 1.955, 1.951, 1.9609999999999999, 1.955, 0.9590000000000001, 1.9529999999999998, 1.96, 1.407, 0.9609999999999999, 1.9609999999999999, 1.952, 1.948, 1.958, 1.9609999999999999, 1.958, 1.9529999999999998, 1.9609999999999999, 1.919, 1.9489999999999998, 1.958, 1.9609999999999999, 1.951, 1.957, 1.952, 1.404, 1.9609999999999999, 0.46299999999999997, 1.919, 1.429, 0.9630000000000001, 0.967, 1.958, 1.9409999999999998, 1.95, 1.958], "episode_lengths": [21, 13, 14, 15, 13, 16, 24, 300, 14, 14, 18, 20, 17, 15, 300, 26, 13, 15, 16, 17, 42, 16, 17, 27, 26, 15, 13, 10, 13, 13, 14, 15, 14, 20, 14, 14, 14, 15, 17, 13, 16, 15, 17, 13, 13, 300, 90, 14, 15, 18, 15, 23, 13, 11, 13, 21, 13, 13, 9, 22, 15, 16, 15, 13, 16, 15, 13, 17, 16, 9, 16, 13, 14, 25, 13, 15, 13, 10, 16, 16, 31, 13, 14, 29, 13, 19, 14, 15, 13, 300, 17, 15, 18, 15, 18, 14, 21, 15, 6, 15, 16, 13, 14, 13, 15, 13, 30, 13, 13, 15, 17, 14, 13, 14, 15, 13, 25, 16, 14, 13, 16, 14, 16, 30, 13, 11, 25, 23, 11, 300, 14, 19, 16, 14], "policy_red_0_reward": [0.5, 1.4609999999999999, 1.458, 1.455, 1.4609999999999999, 0.95, 1.428, -0.02000000000000001, 1.458, 1.4569999999999999, 0.499, 1.44, 1.4489999999999998, 1.455, 0.46599999999999997, 1.4220000000000002, -0.5, 0.5, 1.452, 0.499, 1.369, 1.452, 1.4489999999999998, 0.5, 1.419, 1.455, 1.4609999999999999, 1.47, 1.4609999999999999, 1.4609999999999999, 1.458, 0.5, 0.5, 1.439, 1.458, 0.499, 1.458, 0.5, 0.5, 1.4609999999999999, 1.45, 1.4529999999999998, 1.4489999999999998, 1.4609999999999999, 1.4609999999999999, 0.486, -0.010000000000000002, 0.0, 1.455, 1.4449999999999998, 0.498, 1.431, 0.5, 1.466, 1.4609999999999999, 1.436, 0.96, 1.4609999999999999, -0.5, 0.5, 1.455, 0.499, -0.001, 0.499, 0.0, 1.455, 1.4609999999999999, 1.4489999999999998, 0.499, 0.973, 1.452, 1.4609999999999999, 1.458, 0.5, 0.499, 1.455, 1.4609999999999999, 1.47, 1.452, 1.452, 1.4060000000000001, -0.5, 0.5, 1.4100000000000001, 1.4609999999999999, 1.442, 1.458, 1.455, 1.4609999999999999, 0.46499999999999997, 0.5, 1.455, -0.002, 1.455, 1.4449999999999998, 0.5, 0.499, 1.455, 1.482, 1.455, 1.452, 0.5, 1.458, 1.459, 1.455, 1.4609999999999999, 1.4100000000000001, 1.4609999999999999, 1.4609999999999999, 0.498, 1.4489999999999998, 1.458, 0.5, 0.5, 1.455, 1.4609999999999999, 1.423, 1.452, 0.5, 1.4609999999999999, 0.5, 1.458, 1.452, 1.408, 0.5, -1.002, 1.423, 1.431, 1.4649999999999999, 0.48, 1.458, 1.443, 1.452, 1.458], "policy_blue_0_reward": [1.436, 0.498, 0.498, 0.499, 0.499, -0.502, 0.498, 0.46299999999999997, 0.499, -0.001, 1.4449999999999998, 0.496, -0.001, 0.499, 0.469, -0.002, 1.46, 1.454, 0.0, 1.448, -0.003, 0.499, 0.0, 1.416, 0.5, 0.5, 0.499, -0.501, 0.0, 0.0, 0.5, 1.4529999999999998, 1.458, -0.005, 0.498, 1.458, 0.498, 1.454, 1.448, 0.5, 0.5, 0.499, -0.001, -0.001, 0.0, 0.472, 1.216, 1.458, -0.001, 0.499, 1.454, 0.0, 1.4609999999999999, -1.0, 0.498, -0.001, -1.001, 0.498, 1.4729999999999999, 1.431, 0.5, 1.451, 1.454, 1.4609999999999999, 1.452, 0.0, 0.499, 0.5, 1.452, -0.5, 0.5, 0.5, 0.499, 1.424, 1.4609999999999999, 0.499, 0.5, -1.002, 0.0, 0.5, -0.006, 0.959, 1.458, 0.499, 0.498, 0.499, 0.499, 0.5, 0.499, 0.473, 1.4489999999999998, 0.497, 1.444, 0.5, 0.499, 1.458, 1.436, 0.499, -1.0, 0.5, 0.499, 1.4609999999999999, 0.497, -0.5, 0.498, 0.499, -0.003, -0.5, 0.5, 1.454, 0.499, 0.5, 1.4609999999999999, 1.458, 0.498, 0.5, 0.496, 0.497, 1.458, 0.5, 1.451, 0.499, 0.5, -0.004, 1.4609999999999999, 1.4649999999999999, 0.496, -0.002, -0.502, 0.487, 0.5, 0.498, 0.498, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4305748850915676, "mean_inference_ms": 7.422275417273513, "mean_action_processing_ms": 0.3881738797096327, "mean_env_wait_ms": 0.5216286189844304, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.12242847414159064, "StateBufferConnector_ms": 0.008115483753716768, "ViewRequirementAgentConnector_ms": 0.1580806810464432}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 157.24010752959262, "num_env_steps_trained_throughput_per_sec": 157.24010752959262, "timesteps_total": 568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 26316.284, "sample_time_ms": 3800.952, "learn_time_ms": 22488.704, "learn_throughput": 177.867, "synch_weights_time_ms": 25.255}, "counters": {"num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "episodes_total": 12906, "training_iteration": 142, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-12-07", "timestamp": 1694841127, "time_this_iter_s": 25.456987142562866, "time_total_s": 4396.477947950363, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219b5990>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4396.477947950363, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 22.528947368421054, "ram_util_percent": 56.62894736842105}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.5947712418300654, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.09803921568627451, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.013071895424836602, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.09803921568627451, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.26143790849673204, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.013071895424836602, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.09803921568627451, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.013071895424836602, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4605748749648531, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.027418591508467215, "policy_loss": -0.05758011699896694, "vf_loss": 0.024542659306219624, "vf_explained_var": 0.7743275712554654, "kl": 0.008280410938092094, "entropy": 0.9736159075051546, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 136800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43225810358611244, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.03725454087737792, "policy_loss": -0.07192233153570365, "vf_loss": 0.030928908728916817, "vf_explained_var": 0.6539136217907071, "kl": 0.008962457705422366, "entropy": 1.21426260980467, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 136800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_agent_steps_sampled": 1144000, "num_agent_steps_trained": 1144000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.08399999999999996, "episode_reward_mean": 1.6719084967320261, "episode_len_mean": 26.45098039215686, "episode_media": {}, "episodes_this_iter": 153, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.007}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.472}, "policy_reward_mean": {"red_0": 1.0988169934640521, "blue_0": 0.5730915032679738}, "custom_metrics": {"red_0/door_open_done_mean": 0.5947712418300654, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.09803921568627451, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.013071895424836602, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.09803921568627451, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.26143790849673204, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.013071895424836602, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.09803921568627451, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.013071895424836602, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9329999999999999, 1.9609999999999999, 1.951, 1.96, 1.447, 1.9369999999999998, 1.9609999999999999, 1.958, 1.46, 1.46, 1.955, 1.9220000000000002, 1.9489999999999998, 1.4449999999999998, 1.9609999999999999, 1.936, 0.976, 1.951, 1.945, 1.927, 1.958, 1.958, 1.954, 1.943, 1.952, 1.9609999999999999, 0.939, 1.952, 1.94, 1.9409999999999998, 1.955, 0.948, 0.45599999999999996, 1.952, 1.919, 1.9609999999999999, 1.958, 1.959, 1.935, 1.956, 1.9449999999999998, 1.851, 1.958, 1.959, 1.96, 1.954, 1.46, 1.917, -0.05800000000000005, 1.45, 1.943, 1.958, 0.43999999999999995, 0.942, 1.9609999999999999, 1.9569999999999999, 1.959, 1.795, 1.948, 1.952, 1.951, 1.4489999999999998, 1.4489999999999998, 1.942, 1.959, 1.9609999999999999, 1.958, 1.9609999999999999, 1.951, 1.942, 1.458, 1.95, 1.405, 1.952, 0.952, 1.94, 1.947, 0.9569999999999999, 1.9529999999999998, 1.955, 1.9489999999999998, 1.932, 1.4489999999999998, 1.9489999999999998, 0.976, 1.96, 1.954, 1.9409999999999998, 1.451, 1.9489999999999998, 0.9460000000000002, -0.04500000000000004, 0.42799999999999994, 0.46099999999999997, 1.942, 1.9489999999999998, 0.471, 1.9609999999999999, 1.45, 1.9609999999999999, 1.943, 1.935, 0.9279999999999999, 1.46, 1.96, 1.948, 1.926, 1.9529999999999998, 1.954, 1.958, 1.9609999999999999, 1.94, 0.954, 1.9529999999999998, 1.947, 1.901, 1.9609999999999999, 1.9329999999999998, 1.455, 1.92, 1.9609999999999999, 0.851, 0.44799999999999995, 1.954, 1.954, 1.4569999999999999, 0.46399999999999997, 1.456, 1.9489999999999998, 1.954, 1.4249999999999998, 1.9569999999999999, 1.448, 1.926, 1.46, 1.9569999999999999, 1.955, 1.935, 1.927, 1.944, 1.452, 1.954, 1.455, 1.4489999999999998, 1.938, -0.08399999999999996, 1.954, 1.434, 1.9529999999999998, 1.443, 1.415, 1.448, 1.95], "episode_lengths": [300, 13, 15, 13, 17, 20, 13, 13, 13, 13, 15, 25, 17, 18, 13, 21, 8, 16, 15, 24, 14, 14, 15, 18, 15, 13, 300, 16, 19, 19, 15, 17, 14, 15, 27, 13, 14, 13, 20, 14, 18, 49, 14, 13, 13, 15, 13, 26, 17, 16, 19, 14, 300, 300, 13, 14, 13, 63, 17, 16, 16, 16, 17, 19, 13, 13, 14, 13, 16, 19, 14, 16, 30, 16, 16, 19, 17, 14, 15, 15, 17, 21, 16, 17, 8, 13, 15, 19, 16, 17, 17, 15, 300, 12, 19, 16, 9, 13, 16, 13, 19, 21, 22, 13, 13, 17, 24, 15, 15, 14, 13, 19, 15, 15, 17, 33, 13, 22, 15, 26, 13, 48, 16, 15, 15, 14, 12, 14, 17, 15, 24, 14, 16, 24, 13, 14, 15, 21, 24, 18, 15, 15, 15, 16, 20, 27, 15, 21, 15, 18, 27, 17, 16], "policy_red_0_reward": [0.46299999999999997, 0.5, 1.454, 0.499, 1.4489999999999998, 1.439, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.455, 1.423, 1.4489999999999998, 1.4449999999999998, 1.4609999999999999, 1.436, 1.476, 1.452, 1.455, 1.427, 0.5, 1.458, 0.5, 0.498, 1.455, 0.5, 0.45799999999999996, 1.452, 1.442, 1.443, 0.5, 1.4489999999999998, 1.4569999999999999, 0.499, 1.419, 0.5, 0.5, 1.4609999999999999, 1.438, 0.499, 0.5, 1.3519999999999999, 0.5, 1.4609999999999999, 0.499, 0.5, -0.001, 0.498, 0.949, 1.45, 0.5, 1.458, -0.03100000000000002, 0.476, 0.5, 1.458, 1.4609999999999999, 1.305, 1.4489999999999998, 1.452, 1.452, -0.001, 1.4489999999999998, 0.5, 1.4609999999999999, 1.4609999999999999, 1.458, 1.4609999999999999, 0.5, 1.443, 1.458, 0.498, 1.409, 1.452, 1.452, 1.442, 1.4489999999999998, 1.458, 1.454, 1.455, 1.4489999999999998, 1.4369999999999998, 1.452, 1.4489999999999998, 1.476, 0.499, 1.455, 1.4409999999999998, 1.451, 1.4489999999999998, 1.448, 0.955, -0.02900000000000002, -0.501, 1.442, 1.452, -1.001, 1.4609999999999999, 1.451, 1.4609999999999999, 1.443, 0.498, 1.4329999999999998, 1.4609999999999999, 0.499, 1.4489999999999998, 0.499, 1.454, 1.455, 0.5, 1.4609999999999999, 1.443, 1.454, 1.455, 0.5, 1.401, 1.4609999999999999, 1.434, 1.455, 1.4220000000000002, 1.4609999999999999, 1.354, 1.451, 1.455, 1.455, -0.001, 1.464, 1.4569999999999999, 1.4489999999999998, 1.454, -0.002, 1.458, -0.002, 0.499, -0.001, 1.458, 1.455, 1.435, 1.428, 1.4449999999999998, 1.455, 0.5, 1.455, 1.452, 0.499, 0.916, 0.5, 1.436, 0.498, 1.4449999999999998, 1.417, -0.001, 0.499], "policy_blue_0_reward": [0.47, 1.4609999999999999, 0.497, 1.4609999999999999, -0.002, 0.498, 0.5, 0.497, -0.001, -0.001, 0.5, 0.499, 0.5, 0.0, 0.5, 0.5, -0.5, 0.499, 0.49, 0.5, 1.458, 0.5, 1.454, 1.4449999999999998, 0.497, 1.4609999999999999, 0.481, 0.5, 0.498, 0.498, 1.455, -0.501, -1.001, 1.4529999999999998, 0.5, 1.4609999999999999, 1.458, 0.498, 0.497, 1.4569999999999999, 1.4449999999999998, 0.499, 1.458, 0.498, 1.4609999999999999, 1.454, 1.4609999999999999, 1.419, -1.007, 0.0, 1.443, 0.5, 0.471, 0.46599999999999997, 1.4609999999999999, 0.499, 0.498, 0.49, 0.499, 0.5, 0.499, 1.45, 0.0, 1.442, 0.498, 0.5, 0.5, 0.5, 1.451, 0.499, 0.0, 1.452, -0.004, 0.5, -0.5, 0.498, 0.498, -0.501, 0.499, 0.5, 0.5, 0.495, -0.003, 0.5, -0.5, 1.4609999999999999, 0.499, 0.5, 0.0, 0.5, -0.5019999999999999, -1.0, 0.45699999999999996, 0.962, 0.5, 0.497, 1.472, 0.5, -0.001, 0.5, 0.5, 1.4369999999999998, -0.505, -0.001, 1.4609999999999999, 0.499, 1.427, 0.499, 0.499, 1.458, 0.5, 0.497, -0.5, 0.498, 1.447, 0.5, 0.5, 0.499, 0.0, 0.498, 0.5, -0.503, -1.003, 0.499, 0.499, 1.458, -1.0, -0.001, 0.5, 0.5, 1.427, 0.499, 1.45, 1.427, 1.4609999999999999, 0.499, 0.5, 0.5, 0.499, 0.499, -0.003, 1.454, 0.0, -0.003, 1.439, -1.0, 1.454, -0.002, 1.455, -0.002, -0.002, 1.4489999999999998, 1.451]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4287919171808405, "mean_inference_ms": 7.426321889248868, "mean_action_processing_ms": 0.38830956775887693, "mean_env_wait_ms": 0.5219377426902215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.12480386721542458, "StateBufferConnector_ms": 0.00827740999608258, "ViewRequirementAgentConnector_ms": 0.16467275183185254}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.08399999999999996, "episode_reward_mean": 1.6719084967320261, "episode_len_mean": 26.45098039215686, "episodes_this_iter": 153, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.007}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.472}, "policy_reward_mean": {"red_0": 1.0988169934640521, "blue_0": 0.5730915032679738}, "hist_stats": {"episode_reward": [0.9329999999999999, 1.9609999999999999, 1.951, 1.96, 1.447, 1.9369999999999998, 1.9609999999999999, 1.958, 1.46, 1.46, 1.955, 1.9220000000000002, 1.9489999999999998, 1.4449999999999998, 1.9609999999999999, 1.936, 0.976, 1.951, 1.945, 1.927, 1.958, 1.958, 1.954, 1.943, 1.952, 1.9609999999999999, 0.939, 1.952, 1.94, 1.9409999999999998, 1.955, 0.948, 0.45599999999999996, 1.952, 1.919, 1.9609999999999999, 1.958, 1.959, 1.935, 1.956, 1.9449999999999998, 1.851, 1.958, 1.959, 1.96, 1.954, 1.46, 1.917, -0.05800000000000005, 1.45, 1.943, 1.958, 0.43999999999999995, 0.942, 1.9609999999999999, 1.9569999999999999, 1.959, 1.795, 1.948, 1.952, 1.951, 1.4489999999999998, 1.4489999999999998, 1.942, 1.959, 1.9609999999999999, 1.958, 1.9609999999999999, 1.951, 1.942, 1.458, 1.95, 1.405, 1.952, 0.952, 1.94, 1.947, 0.9569999999999999, 1.9529999999999998, 1.955, 1.9489999999999998, 1.932, 1.4489999999999998, 1.9489999999999998, 0.976, 1.96, 1.954, 1.9409999999999998, 1.451, 1.9489999999999998, 0.9460000000000002, -0.04500000000000004, 0.42799999999999994, 0.46099999999999997, 1.942, 1.9489999999999998, 0.471, 1.9609999999999999, 1.45, 1.9609999999999999, 1.943, 1.935, 0.9279999999999999, 1.46, 1.96, 1.948, 1.926, 1.9529999999999998, 1.954, 1.958, 1.9609999999999999, 1.94, 0.954, 1.9529999999999998, 1.947, 1.901, 1.9609999999999999, 1.9329999999999998, 1.455, 1.92, 1.9609999999999999, 0.851, 0.44799999999999995, 1.954, 1.954, 1.4569999999999999, 0.46399999999999997, 1.456, 1.9489999999999998, 1.954, 1.4249999999999998, 1.9569999999999999, 1.448, 1.926, 1.46, 1.9569999999999999, 1.955, 1.935, 1.927, 1.944, 1.452, 1.954, 1.455, 1.4489999999999998, 1.938, -0.08399999999999996, 1.954, 1.434, 1.9529999999999998, 1.443, 1.415, 1.448, 1.95], "episode_lengths": [300, 13, 15, 13, 17, 20, 13, 13, 13, 13, 15, 25, 17, 18, 13, 21, 8, 16, 15, 24, 14, 14, 15, 18, 15, 13, 300, 16, 19, 19, 15, 17, 14, 15, 27, 13, 14, 13, 20, 14, 18, 49, 14, 13, 13, 15, 13, 26, 17, 16, 19, 14, 300, 300, 13, 14, 13, 63, 17, 16, 16, 16, 17, 19, 13, 13, 14, 13, 16, 19, 14, 16, 30, 16, 16, 19, 17, 14, 15, 15, 17, 21, 16, 17, 8, 13, 15, 19, 16, 17, 17, 15, 300, 12, 19, 16, 9, 13, 16, 13, 19, 21, 22, 13, 13, 17, 24, 15, 15, 14, 13, 19, 15, 15, 17, 33, 13, 22, 15, 26, 13, 48, 16, 15, 15, 14, 12, 14, 17, 15, 24, 14, 16, 24, 13, 14, 15, 21, 24, 18, 15, 15, 15, 16, 20, 27, 15, 21, 15, 18, 27, 17, 16], "policy_red_0_reward": [0.46299999999999997, 0.5, 1.454, 0.499, 1.4489999999999998, 1.439, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.455, 1.423, 1.4489999999999998, 1.4449999999999998, 1.4609999999999999, 1.436, 1.476, 1.452, 1.455, 1.427, 0.5, 1.458, 0.5, 0.498, 1.455, 0.5, 0.45799999999999996, 1.452, 1.442, 1.443, 0.5, 1.4489999999999998, 1.4569999999999999, 0.499, 1.419, 0.5, 0.5, 1.4609999999999999, 1.438, 0.499, 0.5, 1.3519999999999999, 0.5, 1.4609999999999999, 0.499, 0.5, -0.001, 0.498, 0.949, 1.45, 0.5, 1.458, -0.03100000000000002, 0.476, 0.5, 1.458, 1.4609999999999999, 1.305, 1.4489999999999998, 1.452, 1.452, -0.001, 1.4489999999999998, 0.5, 1.4609999999999999, 1.4609999999999999, 1.458, 1.4609999999999999, 0.5, 1.443, 1.458, 0.498, 1.409, 1.452, 1.452, 1.442, 1.4489999999999998, 1.458, 1.454, 1.455, 1.4489999999999998, 1.4369999999999998, 1.452, 1.4489999999999998, 1.476, 0.499, 1.455, 1.4409999999999998, 1.451, 1.4489999999999998, 1.448, 0.955, -0.02900000000000002, -0.501, 1.442, 1.452, -1.001, 1.4609999999999999, 1.451, 1.4609999999999999, 1.443, 0.498, 1.4329999999999998, 1.4609999999999999, 0.499, 1.4489999999999998, 0.499, 1.454, 1.455, 0.5, 1.4609999999999999, 1.443, 1.454, 1.455, 0.5, 1.401, 1.4609999999999999, 1.434, 1.455, 1.4220000000000002, 1.4609999999999999, 1.354, 1.451, 1.455, 1.455, -0.001, 1.464, 1.4569999999999999, 1.4489999999999998, 1.454, -0.002, 1.458, -0.002, 0.499, -0.001, 1.458, 1.455, 1.435, 1.428, 1.4449999999999998, 1.455, 0.5, 1.455, 1.452, 0.499, 0.916, 0.5, 1.436, 0.498, 1.4449999999999998, 1.417, -0.001, 0.499], "policy_blue_0_reward": [0.47, 1.4609999999999999, 0.497, 1.4609999999999999, -0.002, 0.498, 0.5, 0.497, -0.001, -0.001, 0.5, 0.499, 0.5, 0.0, 0.5, 0.5, -0.5, 0.499, 0.49, 0.5, 1.458, 0.5, 1.454, 1.4449999999999998, 0.497, 1.4609999999999999, 0.481, 0.5, 0.498, 0.498, 1.455, -0.501, -1.001, 1.4529999999999998, 0.5, 1.4609999999999999, 1.458, 0.498, 0.497, 1.4569999999999999, 1.4449999999999998, 0.499, 1.458, 0.498, 1.4609999999999999, 1.454, 1.4609999999999999, 1.419, -1.007, 0.0, 1.443, 0.5, 0.471, 0.46599999999999997, 1.4609999999999999, 0.499, 0.498, 0.49, 0.499, 0.5, 0.499, 1.45, 0.0, 1.442, 0.498, 0.5, 0.5, 0.5, 1.451, 0.499, 0.0, 1.452, -0.004, 0.5, -0.5, 0.498, 0.498, -0.501, 0.499, 0.5, 0.5, 0.495, -0.003, 0.5, -0.5, 1.4609999999999999, 0.499, 0.5, 0.0, 0.5, -0.5019999999999999, -1.0, 0.45699999999999996, 0.962, 0.5, 0.497, 1.472, 0.5, -0.001, 0.5, 0.5, 1.4369999999999998, -0.505, -0.001, 1.4609999999999999, 0.499, 1.427, 0.499, 0.499, 1.458, 0.5, 0.497, -0.5, 0.498, 1.447, 0.5, 0.5, 0.499, 0.0, 0.498, 0.5, -0.503, -1.003, 0.499, 0.499, 1.458, -1.0, -0.001, 0.5, 0.5, 1.427, 0.499, 1.45, 1.427, 1.4609999999999999, 0.499, 0.5, 0.5, 0.499, 0.499, -0.003, 1.454, 0.0, -0.003, 1.439, -1.0, 1.454, -0.002, 1.455, -0.002, -0.002, 1.4489999999999998, 1.451]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4287919171808405, "mean_inference_ms": 7.426321889248868, "mean_action_processing_ms": 0.38830956775887693, "mean_env_wait_ms": 0.5219377426902215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.12480386721542458, "StateBufferConnector_ms": 0.00827740999608258, "ViewRequirementAgentConnector_ms": 0.16467275183185254}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1144000, "num_agent_steps_trained": 1144000, "num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 156.49995495915218, "num_env_steps_trained_throughput_per_sec": 156.49995495915218, "timesteps_total": 572000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1144000, "timers": {"training_iteration_time_ms": 26047.893, "sample_time_ms": 3720.153, "learn_time_ms": 22301.066, "learn_throughput": 179.364, "synch_weights_time_ms": 25.291}, "counters": {"num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_agent_steps_sampled": 1144000, "num_agent_steps_trained": 1144000}, "done": false, "episodes_total": 13059, "training_iteration": 143, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-12-34", "timestamp": 1694841154, "time_this_iter_s": 25.57812809944153, "time_total_s": 4422.056076049805, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb5a3481f0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4422.056076049805, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 22.354054054054057, "ram_util_percent": 56.540540540540526}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.6291390728476821, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.052980132450331126, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.026490066225165563, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.052980132450331126, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.26490066225165565, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.026490066225165563, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.052980132450331126, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.026490066225165563, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4290363573624442, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.02686894589617926, "policy_loss": -0.05622520148220549, "vf_loss": 0.02643383130004319, "vf_explained_var": 0.7712529207890232, "kl": 0.007514385759850484, "entropy": 0.9793706239511569, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 137760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "blue_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4775878745596856, "cur_kl_coeff": 2.2781249999999997, "cur_lr": 0.0010000000000000005, "total_loss": -0.026379380897075557, "policy_loss": -0.06160401578866489, "vf_loss": 0.03183929763132862, "vf_explained_var": 0.5975420612841844, "kl": 0.00897934095599307, "entropy": 1.1510754745453595, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 137760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06500000000000004, "episode_reward_mean": 1.7176887417218543, "episode_len_mean": 25.880794701986755, "episode_media": {}, "episodes_this_iter": 151, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.001}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 1.0644701986754967, "blue_0": 0.6532185430463577}, "custom_metrics": {"red_0/door_open_done_mean": 0.6291390728476821, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.052980132450331126, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.026490066225165563, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.052980132450331126, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.26490066225165565, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.026490066225165563, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.052980132450331126, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.026490066225165563, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.927, 1.9609999999999999, 1.9609999999999999, 1.408, 0.974, 1.954, 1.96, 1.943, 1.952, 1.454, 1.958, 1.9609999999999999, 1.451, 1.9609999999999999, 1.948, 1.958, 1.952, 1.4489999999999998, -0.027000000000000024, 1.9609999999999999, 1.9489999999999998, 1.944, 1.954, 1.9260000000000002, 1.956, 0.6429999999999999, 1.324, 1.439, 1.955, 1.955, 1.9529999999999998, 1.955, 1.96, 1.9569999999999999, 1.907, 1.958, 1.944, 1.96, 1.952, 1.944, 1.9569999999999999, 1.951, 1.9609999999999999, 1.9489999999999998, 1.9609999999999999, 1.955, 1.958, 1.95, 1.96, 0.43999999999999995, 1.9409999999999998, 1.9449999999999998, 1.955, 1.95, 1.931, 1.955, -0.025999999999999912, 1.9609999999999999, -0.02499999999999991, 1.948, 1.9609999999999999, 1.958, 1.954, 1.389, -0.040000000000000036, 0.398, 1.9369999999999998, 1.955, 1.4529999999999998, 1.9609999999999999, 1.9609999999999999, 1.96, 1.943, 1.9609999999999999, 1.958, 0.476, 0.9649999999999999, 1.938, 1.9569999999999999, 1.435, 1.9569999999999999, 1.439, 1.955, 1.9609999999999999, 1.928, 1.95, 1.955, -0.06500000000000004, 1.96, 1.954, 1.391, 1.956, 1.943, 1.96, 0.9510000000000001, 1.9609999999999999, 1.9609999999999999, 1.877, 1.952, 1.958, 1.9569999999999999, 0.43699999999999994, 1.952, 1.96, 1.958, 1.947, 1.9609999999999999, 1.953, 1.9409999999999998, 1.954, 1.955, 0.95, 1.954, 1.954, 1.938, 1.4489999999999998, 1.4329999999999998, 1.9609999999999999, 1.955, 1.9609999999999999, 1.9529999999999998, -0.03400000000000003, 1.9130000000000003, 1.908, 1.9609999999999999, 1.948, 1.958, 1.958, 1.9609999999999999, 1.954, 1.95, 1.9529999999999998, 1.913, 1.951, 1.9609999999999999, 1.939, 0.903, 1.939, 1.948, 1.951, 1.9609999999999999, 1.454, 1.9569999999999999, 1.952, 1.952, 1.4289999999999998, 1.459, -0.052999999999999936, 1.942, 1.948, 1.3900000000000001], "episode_lengths": [24, 13, 13, 30, 8, 15, 13, 19, 15, 15, 14, 13, 16, 13, 17, 14, 16, 17, 9, 13, 17, 18, 15, 23, 14, 270, 56, 20, 15, 15, 15, 14, 13, 14, 29, 14, 18, 13, 16, 18, 14, 16, 13, 17, 13, 15, 14, 16, 13, 300, 19, 17, 15, 16, 22, 15, 8, 13, 8, 16, 13, 14, 15, 36, 13, 32, 20, 15, 15, 13, 13, 13, 18, 13, 14, 8, 11, 20, 14, 21, 14, 19, 15, 13, 23, 16, 15, 300, 13, 15, 35, 14, 18, 13, 16, 13, 13, 40, 16, 14, 14, 300, 15, 13, 14, 17, 13, 15, 19, 15, 15, 300, 15, 15, 20, 16, 21, 13, 15, 13, 15, 11, 27, 30, 13, 17, 14, 14, 13, 15, 16, 15, 28, 16, 13, 19, 28, 20, 17, 16, 13, 15, 14, 16, 16, 21, 13, 16, 18, 17, 34], "policy_red_0_reward": [1.428, 0.5, 1.4609999999999999, 1.408, 1.476, 1.455, 1.4609999999999999, 1.443, 0.498, 0.0, 1.458, 0.5, 0.0, 1.4609999999999999, 1.448, 0.5, 1.452, 1.4489999999999998, -1.0, 1.4609999999999999, 0.5, 1.4449999999999998, 1.455, 1.431, 1.458, 0.6589999999999999, 1.33, 1.44, 1.455, 1.455, 0.499, 1.458, 0.499, 1.4569999999999999, 1.408, 1.458, 1.4449999999999998, 0.499, 1.452, 1.4449999999999998, 1.458, 1.452, 0.5, 1.4489999999999998, 1.4609999999999999, 1.455, 0.5, 1.451, 1.4609999999999999, -0.04100000000000003, 1.442, 1.448, 1.455, 1.451, 0.498, 0.5, 0.975, 1.4609999999999999, -1.001, 1.452, 0.5, 1.458, 1.455, 1.391, 0.96, -0.505, 1.438, 1.455, 1.454, 0.5, 0.5, 1.4609999999999999, 1.444, 1.4609999999999999, 0.5, 0.976, 1.4649999999999999, 1.44, 1.458, 1.4369999999999998, 1.4569999999999999, -0.004, 1.455, 0.5, 1.4300000000000002, 1.452, 1.455, -0.03000000000000002, 1.4609999999999999, 0.499, -0.002, 1.458, 1.4449999999999998, 0.499, 1.451, 0.5, 1.4609999999999999, 1.379, 1.452, 0.5, 1.4569999999999999, 0.46099999999999997, 1.455, 1.4609999999999999, 1.458, 0.499, 1.4609999999999999, 1.455, 0.498, 0.499, 1.455, 0.483, 1.455, 0.5, 0.499, 1.451, 1.436, 1.4609999999999999, 1.455, 0.5, 1.455, 0.967, 1.416, 1.408, 1.4609999999999999, 0.499, 0.5, 0.5, 0.5, 1.455, 0.499, 1.455, 1.415, 1.451, 1.4609999999999999, 0.499, 1.408, 1.44, 1.448, 0.499, 1.4609999999999999, 1.455, 1.458, 1.452, 1.452, 1.4369999999999998, -0.002, -1.003, 1.446, 1.4489999999999998, -0.005], "policy_blue_0_reward": [0.499, 1.4609999999999999, 0.5, 0.0, -0.502, 0.499, 0.499, 0.5, 1.454, 1.454, 0.5, 1.4609999999999999, 1.451, 0.5, 0.5, 1.458, 0.5, 0.0, 0.973, 0.5, 1.4489999999999998, 0.499, 0.499, 0.495, 0.498, -0.016000000000000007, -0.006, -0.001, 0.5, 0.5, 1.454, 0.497, 1.4609999999999999, 0.5, 0.499, 0.5, 0.499, 1.4609999999999999, 0.5, 0.499, 0.499, 0.499, 1.4609999999999999, 0.5, 0.5, 0.5, 1.458, 0.499, 0.499, 0.481, 0.499, 0.497, 0.5, 0.499, 1.4329999999999998, 1.455, -1.001, 0.5, 0.976, 0.496, 1.4609999999999999, 0.5, 0.499, -0.002, -1.0, 0.903, 0.499, 0.5, -0.001, 1.4609999999999999, 1.4609999999999999, 0.499, 0.499, 0.5, 1.458, -0.5, -0.5, 0.498, 0.499, -0.002, 0.5, 1.443, 0.5, 1.4609999999999999, 0.498, 0.498, 0.5, -0.035000000000000024, 0.499, 1.455, 1.393, 0.498, 0.498, 1.4609999999999999, -0.5, 1.4609999999999999, 0.5, 0.498, 0.5, 1.458, 0.5, -0.024000000000000014, 0.497, 0.499, 0.5, 1.448, 0.5, 0.498, 1.443, 1.455, 0.5, 0.46699999999999997, 0.499, 1.454, 1.439, -0.002, -0.003, 0.5, 0.5, 1.4609999999999999, 0.498, -1.001, 0.497, 0.5, 0.5, 1.4489999999999998, 1.458, 1.458, 1.4609999999999999, 0.499, 1.451, 0.498, 0.498, 0.5, 0.5, 1.44, -0.505, 0.499, 0.5, 1.452, 0.5, -0.001, 0.499, 0.5, 0.5, -0.008, 1.4609999999999999, 0.95, 0.496, 0.499, 1.395]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4277950195528293, "mean_inference_ms": 7.42531025826673, "mean_action_processing_ms": 0.3878053017160027, "mean_env_wait_ms": 0.5204883661597591, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13047377794783638, "StateBufferConnector_ms": 0.011034280259088175, "ViewRequirementAgentConnector_ms": 0.17052178351294917}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.06500000000000004, "episode_reward_mean": 1.7176887417218543, "episode_len_mean": 25.880794701986755, "episodes_this_iter": 151, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.001}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.4609999999999999}, "policy_reward_mean": {"red_0": 1.0644701986754967, "blue_0": 0.6532185430463577}, "hist_stats": {"episode_reward": [1.927, 1.9609999999999999, 1.9609999999999999, 1.408, 0.974, 1.954, 1.96, 1.943, 1.952, 1.454, 1.958, 1.9609999999999999, 1.451, 1.9609999999999999, 1.948, 1.958, 1.952, 1.4489999999999998, -0.027000000000000024, 1.9609999999999999, 1.9489999999999998, 1.944, 1.954, 1.9260000000000002, 1.956, 0.6429999999999999, 1.324, 1.439, 1.955, 1.955, 1.9529999999999998, 1.955, 1.96, 1.9569999999999999, 1.907, 1.958, 1.944, 1.96, 1.952, 1.944, 1.9569999999999999, 1.951, 1.9609999999999999, 1.9489999999999998, 1.9609999999999999, 1.955, 1.958, 1.95, 1.96, 0.43999999999999995, 1.9409999999999998, 1.9449999999999998, 1.955, 1.95, 1.931, 1.955, -0.025999999999999912, 1.9609999999999999, -0.02499999999999991, 1.948, 1.9609999999999999, 1.958, 1.954, 1.389, -0.040000000000000036, 0.398, 1.9369999999999998, 1.955, 1.4529999999999998, 1.9609999999999999, 1.9609999999999999, 1.96, 1.943, 1.9609999999999999, 1.958, 0.476, 0.9649999999999999, 1.938, 1.9569999999999999, 1.435, 1.9569999999999999, 1.439, 1.955, 1.9609999999999999, 1.928, 1.95, 1.955, -0.06500000000000004, 1.96, 1.954, 1.391, 1.956, 1.943, 1.96, 0.9510000000000001, 1.9609999999999999, 1.9609999999999999, 1.877, 1.952, 1.958, 1.9569999999999999, 0.43699999999999994, 1.952, 1.96, 1.958, 1.947, 1.9609999999999999, 1.953, 1.9409999999999998, 1.954, 1.955, 0.95, 1.954, 1.954, 1.938, 1.4489999999999998, 1.4329999999999998, 1.9609999999999999, 1.955, 1.9609999999999999, 1.9529999999999998, -0.03400000000000003, 1.9130000000000003, 1.908, 1.9609999999999999, 1.948, 1.958, 1.958, 1.9609999999999999, 1.954, 1.95, 1.9529999999999998, 1.913, 1.951, 1.9609999999999999, 1.939, 0.903, 1.939, 1.948, 1.951, 1.9609999999999999, 1.454, 1.9569999999999999, 1.952, 1.952, 1.4289999999999998, 1.459, -0.052999999999999936, 1.942, 1.948, 1.3900000000000001], "episode_lengths": [24, 13, 13, 30, 8, 15, 13, 19, 15, 15, 14, 13, 16, 13, 17, 14, 16, 17, 9, 13, 17, 18, 15, 23, 14, 270, 56, 20, 15, 15, 15, 14, 13, 14, 29, 14, 18, 13, 16, 18, 14, 16, 13, 17, 13, 15, 14, 16, 13, 300, 19, 17, 15, 16, 22, 15, 8, 13, 8, 16, 13, 14, 15, 36, 13, 32, 20, 15, 15, 13, 13, 13, 18, 13, 14, 8, 11, 20, 14, 21, 14, 19, 15, 13, 23, 16, 15, 300, 13, 15, 35, 14, 18, 13, 16, 13, 13, 40, 16, 14, 14, 300, 15, 13, 14, 17, 13, 15, 19, 15, 15, 300, 15, 15, 20, 16, 21, 13, 15, 13, 15, 11, 27, 30, 13, 17, 14, 14, 13, 15, 16, 15, 28, 16, 13, 19, 28, 20, 17, 16, 13, 15, 14, 16, 16, 21, 13, 16, 18, 17, 34], "policy_red_0_reward": [1.428, 0.5, 1.4609999999999999, 1.408, 1.476, 1.455, 1.4609999999999999, 1.443, 0.498, 0.0, 1.458, 0.5, 0.0, 1.4609999999999999, 1.448, 0.5, 1.452, 1.4489999999999998, -1.0, 1.4609999999999999, 0.5, 1.4449999999999998, 1.455, 1.431, 1.458, 0.6589999999999999, 1.33, 1.44, 1.455, 1.455, 0.499, 1.458, 0.499, 1.4569999999999999, 1.408, 1.458, 1.4449999999999998, 0.499, 1.452, 1.4449999999999998, 1.458, 1.452, 0.5, 1.4489999999999998, 1.4609999999999999, 1.455, 0.5, 1.451, 1.4609999999999999, -0.04100000000000003, 1.442, 1.448, 1.455, 1.451, 0.498, 0.5, 0.975, 1.4609999999999999, -1.001, 1.452, 0.5, 1.458, 1.455, 1.391, 0.96, -0.505, 1.438, 1.455, 1.454, 0.5, 0.5, 1.4609999999999999, 1.444, 1.4609999999999999, 0.5, 0.976, 1.4649999999999999, 1.44, 1.458, 1.4369999999999998, 1.4569999999999999, -0.004, 1.455, 0.5, 1.4300000000000002, 1.452, 1.455, -0.03000000000000002, 1.4609999999999999, 0.499, -0.002, 1.458, 1.4449999999999998, 0.499, 1.451, 0.5, 1.4609999999999999, 1.379, 1.452, 0.5, 1.4569999999999999, 0.46099999999999997, 1.455, 1.4609999999999999, 1.458, 0.499, 1.4609999999999999, 1.455, 0.498, 0.499, 1.455, 0.483, 1.455, 0.5, 0.499, 1.451, 1.436, 1.4609999999999999, 1.455, 0.5, 1.455, 0.967, 1.416, 1.408, 1.4609999999999999, 0.499, 0.5, 0.5, 0.5, 1.455, 0.499, 1.455, 1.415, 1.451, 1.4609999999999999, 0.499, 1.408, 1.44, 1.448, 0.499, 1.4609999999999999, 1.455, 1.458, 1.452, 1.452, 1.4369999999999998, -0.002, -1.003, 1.446, 1.4489999999999998, -0.005], "policy_blue_0_reward": [0.499, 1.4609999999999999, 0.5, 0.0, -0.502, 0.499, 0.499, 0.5, 1.454, 1.454, 0.5, 1.4609999999999999, 1.451, 0.5, 0.5, 1.458, 0.5, 0.0, 0.973, 0.5, 1.4489999999999998, 0.499, 0.499, 0.495, 0.498, -0.016000000000000007, -0.006, -0.001, 0.5, 0.5, 1.454, 0.497, 1.4609999999999999, 0.5, 0.499, 0.5, 0.499, 1.4609999999999999, 0.5, 0.499, 0.499, 0.499, 1.4609999999999999, 0.5, 0.5, 0.5, 1.458, 0.499, 0.499, 0.481, 0.499, 0.497, 0.5, 0.499, 1.4329999999999998, 1.455, -1.001, 0.5, 0.976, 0.496, 1.4609999999999999, 0.5, 0.499, -0.002, -1.0, 0.903, 0.499, 0.5, -0.001, 1.4609999999999999, 1.4609999999999999, 0.499, 0.499, 0.5, 1.458, -0.5, -0.5, 0.498, 0.499, -0.002, 0.5, 1.443, 0.5, 1.4609999999999999, 0.498, 0.498, 0.5, -0.035000000000000024, 0.499, 1.455, 1.393, 0.498, 0.498, 1.4609999999999999, -0.5, 1.4609999999999999, 0.5, 0.498, 0.5, 1.458, 0.5, -0.024000000000000014, 0.497, 0.499, 0.5, 1.448, 0.5, 0.498, 1.443, 1.455, 0.5, 0.46699999999999997, 0.499, 1.454, 1.439, -0.002, -0.003, 0.5, 0.5, 1.4609999999999999, 0.498, -1.001, 0.497, 0.5, 0.5, 1.4489999999999998, 1.458, 1.458, 1.4609999999999999, 0.499, 1.451, 0.498, 0.498, 0.5, 0.5, 1.44, -0.505, 0.499, 0.5, 1.452, 0.5, -0.001, 0.499, 0.5, 0.5, -0.008, 1.4609999999999999, 0.95, 0.496, 0.499, 1.395]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4277950195528293, "mean_inference_ms": 7.42531025826673, "mean_action_processing_ms": 0.3878053017160027, "mean_env_wait_ms": 0.5204883661597591, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.13047377794783638, "StateBufferConnector_ms": 0.011034280259088175, "ViewRequirementAgentConnector_ms": 0.17052178351294917}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 154.97812099581117, "num_env_steps_trained_throughput_per_sec": 154.97812099581117, "timesteps_total": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 26037.345, "sample_time_ms": 3716.187, "learn_time_ms": 22294.643, "learn_throughput": 179.415, "synch_weights_time_ms": 25.139}, "counters": {"num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "episodes_total": 13210, "training_iteration": 144, "trial_id": "fbd9b_00000", "date": "2023-09-16_01-13-00", "timestamp": 1694841180, "time_this_iter_s": 25.829031944274902, "time_total_s": 4447.88510799408, "pid": 34353, "hostname": "str-mac-2615", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.9, "lr": 0.001, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 1, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x7fbb219b7520>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4447.88510799408, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 20.673684210526318, "ram_util_percent": 57.21315789473685}}
