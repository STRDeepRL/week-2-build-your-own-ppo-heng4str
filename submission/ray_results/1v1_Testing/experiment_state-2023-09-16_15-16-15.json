{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"PPO\",\n  \"trial_id\": \"819b8_00000\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/Users/zla0368/Documents/RL/RL_Class/code/test_hw/week-2-build-your-own-ppo-heng4str/submission/ray_results/1v1_Testing\",\n  \"_orig_experiment_dir_name\": \"1v1_Testing\",\n  \"_local_experiment_path\": \"/Users/zla0368/Documents/RL/RL_Class/code/test_hw/week-2-build-your-own-ppo-heng4str/submission/ray_results/1v1_Testing\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"num_gpus\": 0,\n    \"num_cpus_per_worker\": 1,\n    \"num_gpus_per_worker\": 0,\n    \"_fake_gpus\": false,\n    \"num_learner_workers\": 0,\n    \"num_gpus_per_learner_worker\": 0,\n    \"num_cpus_per_learner_worker\": 1,\n    \"local_gpu_idx\": 0,\n    \"custom_resources_per_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"eager_tracing\": false,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"env\": \"MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1\",\n    \"env_config\": {\n      \"size\": 8,\n      \"allow_agent_overlap\": false,\n      \"has_obsticle\": false,\n      \"death_match\": true,\n      \"teams\": {\n        \"red\": 1,\n        \"blue\": 1\n      },\n      \"agents\": 2,\n      \"training_scheme\": \"DTDE\",\n      \"reward_schemes\": {\n        \"red_0\": {\n          \"eliminated_opponent_sparse_reward\": 0.5,\n          \"key_pickup_sparse_reward\": 0.5,\n          \"ball_pickup_dense_reward\": 0.5,\n          \"dense_reward_discount_factor\": {\n            \"ball_carrying_discount_factor\": 0.9\n          },\n          \"invalid_pickup_dense_penalty\": 0.001\n        },\n        \"blue_0\": {\n          \"eliminated_opponent_sparse_reward\": 0.5,\n          \"key_pickup_sparse_reward\": 0.5,\n          \"ball_pickup_dense_reward\": 0.5,\n          \"dense_reward_discount_factor\": {\n            \"ball_carrying_discount_factor\": 0.9\n          },\n          \"invalid_pickup_dense_penalty\": 0.001\n        }\n      },\n      \"randomization\": true,\n      \"max_steps\": 300\n    },\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"env_task_fn\": null,\n    \"render_env\": false,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"disable_env_checking\": false,\n    \"is_atari\": null,\n    \"auto_wrap_old_gym_envs\": true,\n    \"num_envs_per_worker\": 1,\n    \"sample_collector\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n    },\n    \"sample_async\": false,\n    \"enable_connectors\": true,\n    \"rollout_fragment_length\": \"auto\",\n    \"batch_mode\": \"truncate_episodes\",\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"validate_workers_after_construction\": true,\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"synchronize_filters\": true,\n    \"compress_observations\": false,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"gamma\": 0.99,\n    \"lr\": 0.001,\n    \"lr_schedule\": null,\n    \"grad_clip\": null,\n    \"grad_clip_by\": \"global_norm\",\n    \"train_batch_size\": 4000,\n    \"model\": {\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"fcnet_hiddens\": [\n        64,\n        64\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"conv_filters\": [\n        [\n          16,\n          [\n            3,\n            3\n          ],\n          1\n        ],\n        [\n          32,\n          [\n            3,\n            3\n          ],\n          1\n        ],\n        [\n          64,\n          [\n            3,\n            3\n          ],\n          1\n        ]\n      ],\n      \"conv_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"free_log_std\": false,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": false,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059529000000000000008c166d756c7469677269642e726c6c69622e6d6f64656c73948c0a546f7263684d6f64656c9493942e\"\n      },\n      \"custom_model_config\": {\n        \"teams\": {\n          \"red\": 1,\n          \"blue\": 1\n        },\n        \"training_scheme\": \"DTDE\"\n      },\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"encoder_latent_dim\": null,\n      \"always_check_shapes\": false,\n      \"lstm_use_prev_action_reward\": -1,\n      \"_use_default_native_models\": -1\n    },\n    \"optimizer\": {},\n    \"max_requests_in_flight_per_sampler_worker\": 2,\n    \"_learner_class\": null,\n    \"_enable_learner_api\": false,\n    \"explore\": true,\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"policy_states_are_swappable\": false,\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": null,\n    \"evaluation_duration\": 10,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 180.0,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_config\": null,\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_workers\": 0,\n    \"always_attach_evaluation_results\": false,\n    \"enable_async_evaluation\": false,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 100,\n    \"min_time_s_per_iteration\": null,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 0,\n    \"export_native_model_files\": false,\n    \"checkpoint_trainable_policies_only\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": 1,\n    \"worker_cls\": null,\n    \"ignore_worker_failures\": false,\n    \"recreate_failed_workers\": false,\n    \"max_num_worker_restarts\": 1000,\n    \"delay_between_worker_restarts_s\": 60.0,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_worker_failures_tolerance\": 100,\n    \"worker_health_probe_timeout_s\": 60,\n    \"worker_restore_timeout_s\": 1800,\n    \"rl_module_spec\": null,\n    \"_enable_rl_module_api\": false,\n    \"_AlgorithmConfig__prior_exploration_config\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_execution_plan_api\": true,\n    \"_disable_initialize_loss_from_dummy_batch\": false,\n    \"simple_optimizer\": -1,\n    \"replay_sequence_length\": null,\n    \"horizon\": -1,\n    \"soft_horizon\": -1,\n    \"no_done_at_end\": -1,\n    \"use_critic\": true,\n    \"use_gae\": true,\n    \"kl_coeff\": 0.2,\n    \"sgd_minibatch_size\": 128,\n    \"num_sgd_iter\": 30,\n    \"shuffle_sequences\": true,\n    \"vf_loss_coeff\": 0.5,\n    \"entropy_coeff\": 0.001,\n    \"entropy_coeff_schedule\": null,\n    \"clip_param\": 0.3,\n    \"vf_clip_param\": 10.0,\n    \"kl_target\": 0.01,\n    \"vf_share_layers\": -1,\n    \"lambda\": 0.99,\n    \"input\": \"sampler\",\n    \"multiagent\": {\n      \"policies\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059516000000000000008f94288c06626c75655f30948c057265645f3094902e\"\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059504030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b034b014b5f43047c005300944e8594298c086167656e745f6964948c0461726773948c066b77617267739487948c772f55736572732f7a6c61303336382f446f63756d656e74732f524c2f524c5f436c6173732f636f64652f746573745f68772f7765656b2d322d6275696c642d796f75722d6f776e2d70706f2d68656e67347374722f6d756c7469677269642f7574696c732f747261696e696e675f7574696c69732e7079948c083c6c616d6264613e944bd043020400942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6d756c7469677269642e7574696c73948c085f5f6e616d655f5f948c1f6d756c7469677269642e7574696c732e747261696e696e675f7574696c6973948c085f5f66696c655f5f948c772f55736572732f7a6c61303336382f446f63756d656e74732f524c2f524c5f436c6173732f636f64652f746573745f68772f7765656b2d322d6275696c642d796f75722d6f776e2d70706f2d68656e67347374722f6d756c7469677269642f7574696c732f747261696e696e675f7574696c69732e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c22616c676f726974686d5f636f6e6669672e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n      },\n      \"policies_to_train\": null,\n      \"policy_map_capacity\": 100,\n      \"policy_map_cache\": -1,\n      \"count_steps_by\": \"env_steps\",\n      \"observation_fn\": null\n    },\n    \"callbacks\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005953b000000000000008c1f6d756c7469677269642e7574696c732e747261696e696e675f7574696c6973948c134576616c756174696f6e43616c6c6261636b739493942e\"\n    },\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\",\n    \"num_cpus_for_driver\": 1,\n    \"num_workers\": 10\n  },\n  \"_Trial__unresolved_config\": {\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"num_gpus\": 0,\n    \"num_cpus_per_worker\": 1,\n    \"num_gpus_per_worker\": 0,\n    \"_fake_gpus\": false,\n    \"num_learner_workers\": 0,\n    \"num_gpus_per_learner_worker\": 0,\n    \"num_cpus_per_learner_worker\": 1,\n    \"local_gpu_idx\": 0,\n    \"custom_resources_per_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"eager_tracing\": false,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"env\": \"MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1\",\n    \"env_config\": {\n      \"size\": 8,\n      \"allow_agent_overlap\": false,\n      \"has_obsticle\": false,\n      \"death_match\": true,\n      \"teams\": {\n        \"red\": 1,\n        \"blue\": 1\n      },\n      \"agents\": 2,\n      \"training_scheme\": \"DTDE\",\n      \"reward_schemes\": {\n        \"red_0\": {\n          \"eliminated_opponent_sparse_reward\": 0.5,\n          \"key_pickup_sparse_reward\": 0.5,\n          \"ball_pickup_dense_reward\": 0.5,\n          \"dense_reward_discount_factor\": {\n            \"ball_carrying_discount_factor\": 0.9\n          },\n          \"invalid_pickup_dense_penalty\": 0.001\n        },\n        \"blue_0\": {\n          \"eliminated_opponent_sparse_reward\": 0.5,\n          \"key_pickup_sparse_reward\": 0.5,\n          \"ball_pickup_dense_reward\": 0.5,\n          \"dense_reward_discount_factor\": {\n            \"ball_carrying_discount_factor\": 0.9\n          },\n          \"invalid_pickup_dense_penalty\": 0.001\n        }\n      },\n      \"randomization\": true,\n      \"max_steps\": 300\n    },\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"env_task_fn\": null,\n    \"render_env\": false,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"disable_env_checking\": false,\n    \"is_atari\": null,\n    \"auto_wrap_old_gym_envs\": true,\n    \"num_envs_per_worker\": 1,\n    \"sample_collector\": [\n      \"__ref_ph\",\n      \"f176708f\"\n    ],\n    \"sample_async\": false,\n    \"enable_connectors\": true,\n    \"rollout_fragment_length\": \"auto\",\n    \"batch_mode\": \"truncate_episodes\",\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"validate_workers_after_construction\": true,\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"synchronize_filters\": true,\n    \"compress_observations\": false,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"gamma\": 0.99,\n    \"lr\": 0.001,\n    \"lr_schedule\": null,\n    \"grad_clip\": null,\n    \"grad_clip_by\": \"global_norm\",\n    \"train_batch_size\": 4000,\n    \"model\": {\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"fcnet_hiddens\": [\n        64,\n        64\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"conv_filters\": [\n        [\n          16,\n          [\n            3,\n            3\n          ],\n          1\n        ],\n        [\n          32,\n          [\n            3,\n            3\n          ],\n          1\n        ],\n        [\n          64,\n          [\n            3,\n            3\n          ],\n          1\n        ]\n      ],\n      \"conv_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"free_log_std\": false,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": false,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": [\n        \"__ref_ph\",\n        \"a8054fec\"\n      ],\n      \"custom_model_config\": {\n        \"teams\": {\n          \"red\": 1,\n          \"blue\": 1\n        },\n        \"training_scheme\": \"DTDE\"\n      },\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"encoder_latent_dim\": null,\n      \"always_check_shapes\": false,\n      \"lstm_use_prev_action_reward\": -1,\n      \"_use_default_native_models\": -1\n    },\n    \"optimizer\": {},\n    \"max_requests_in_flight_per_sampler_worker\": 2,\n    \"_learner_class\": null,\n    \"_enable_learner_api\": false,\n    \"explore\": true,\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"policy_states_are_swappable\": false,\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": null,\n    \"evaluation_duration\": 10,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 180.0,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_config\": null,\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_workers\": 0,\n    \"always_attach_evaluation_results\": false,\n    \"enable_async_evaluation\": false,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 100,\n    \"min_time_s_per_iteration\": null,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 0,\n    \"export_native_model_files\": false,\n    \"checkpoint_trainable_policies_only\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": 1,\n    \"worker_cls\": null,\n    \"ignore_worker_failures\": false,\n    \"recreate_failed_workers\": false,\n    \"max_num_worker_restarts\": 1000,\n    \"delay_between_worker_restarts_s\": 60.0,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_worker_failures_tolerance\": 100,\n    \"worker_health_probe_timeout_s\": 60,\n    \"worker_restore_timeout_s\": 1800,\n    \"rl_module_spec\": null,\n    \"_enable_rl_module_api\": false,\n    \"_AlgorithmConfig__prior_exploration_config\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_execution_plan_api\": true,\n    \"_disable_initialize_loss_from_dummy_batch\": false,\n    \"simple_optimizer\": -1,\n    \"replay_sequence_length\": null,\n    \"horizon\": -1,\n    \"soft_horizon\": -1,\n    \"no_done_at_end\": -1,\n    \"use_critic\": true,\n    \"use_gae\": true,\n    \"kl_coeff\": 0.2,\n    \"sgd_minibatch_size\": 128,\n    \"num_sgd_iter\": 30,\n    \"shuffle_sequences\": true,\n    \"vf_loss_coeff\": 0.5,\n    \"entropy_coeff\": 0.001,\n    \"entropy_coeff_schedule\": null,\n    \"clip_param\": 0.3,\n    \"vf_clip_param\": 10.0,\n    \"kl_target\": 0.01,\n    \"vf_share_layers\": -1,\n    \"lambda\": 0.99,\n    \"input\": \"sampler\",\n    \"multiagent\": {\n      \"policies\": [\n        \"__ref_ph\",\n        \"e262b846\"\n      ],\n      \"policy_mapping_fn\": [\n        \"__ref_ph\",\n        \"e2d0a7df\"\n      ],\n      \"policies_to_train\": null,\n      \"policy_map_capacity\": 100,\n      \"policy_map_cache\": -1,\n      \"count_steps_by\": \"env_steps\",\n      \"observation_fn\": null\n    },\n    \"callbacks\": [\n      \"__ref_ph\",\n      \"8913b504\"\n    ],\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\",\n    \"num_cpus_for_driver\": 1,\n    \"num_workers\": 10\n  },\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {\n    \"timesteps_total\": 1000000.0\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"80059537010000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d948c0343505594473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff000000000000073658c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"custom_metrics\": {\n      \"red_0/door_open_done_mean\": 0.0,\n      \"red_0/door_open_done_min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"red_0/door_open_done_max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"red_0/eliminated_opponents_done_mean\": 0.28,\n      \"red_0/eliminated_opponents_done_min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"red_0/eliminated_opponents_done_max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"red_0/got_eliminated_done_mean\": 0.34,\n      \"red_0/got_eliminated_done_min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"red_0/got_eliminated_done_max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"red_0/eliminated_opponent_num_mean\": 0.28,\n      \"red_0/eliminated_opponent_num_min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"red_0/eliminated_opponent_num_max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"blue_0/door_open_done_mean\": 0.02,\n      \"blue_0/door_open_done_min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"blue_0/door_open_done_max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"blue_0/eliminated_opponents_done_mean\": 0.34,\n      \"blue_0/eliminated_opponents_done_min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"blue_0/eliminated_opponents_done_max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"blue_0/got_eliminated_done_mean\": 0.28,\n      \"blue_0/got_eliminated_done_min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"blue_0/got_eliminated_done_max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"blue_0/eliminated_opponent_num_mean\": 0.34,\n      \"blue_0/eliminated_opponent_num_min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"blue_0/eliminated_opponent_num_max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      }\n    },\n    \"episode_media\": {},\n    \"info\": {\n      \"learner\": {\n        \"red_0\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.437308070063591,\n            \"cur_kl_coeff\": 0.4500000000000001,\n            \"cur_lr\": 0.0010000000000000005,\n            \"total_loss\": -0.07581120758113684,\n            \"policy_loss\": -0.10054700752856055,\n            \"vf_loss\": 0.024202158497064374,\n            \"vf_explained_var\": 0.5301477359607816,\n            \"kl\": 0.03221447709393853,\n            \"entropy\": 1.8617937531322242,\n            \"entropy_coeff\": 0.0010000000000000005\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 125.0,\n          \"num_grad_updates_lifetime\": 2400.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 479.5\n        },\n        \"blue_0\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.4425927648010353,\n            \"cur_kl_coeff\": 0.4500000000000001,\n            \"cur_lr\": 0.0010000000000000005,\n            \"total_loss\": -0.07579281032764508,\n            \"policy_loss\": -0.10116938730546583,\n            \"vf_loss\": 0.02557258692201382,\n            \"vf_explained_var\": 0.5349774211024244,\n            \"kl\": 0.03211901438317401,\n            \"entropy\": 1.8632729317992927,\n            \"entropy_coeff\": 0.0010000000000000005\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 125.0,\n          \"num_grad_updates_lifetime\": 2400.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 479.5\n        }\n      },\n      \"num_env_steps_sampled\": 12000,\n      \"num_env_steps_trained\": 12000,\n      \"num_agent_steps_sampled\": 24000,\n      \"num_agent_steps_trained\": 24000\n    },\n    \"sampler_results\": {\n      \"episode_reward_max\": 1.321,\n      \"episode_reward_min\": -0.9890000000000001,\n      \"episode_reward_mean\": -0.032540000000000034,\n      \"episode_len_mean\": 211.44,\n      \"episode_media\": {},\n      \"episodes_this_iter\": 20,\n      \"policy_reward_min\": {\n        \"red_0\": -1.047,\n        \"blue_0\": -1.042\n      },\n      \"policy_reward_max\": {\n        \"red_0\": 0.9359999999999999,\n        \"blue_0\": 1.267\n      },\n      \"policy_reward_mean\": {\n        \"red_0\": -0.10322,\n        \"blue_0\": 0.07067999999999999\n      },\n      \"custom_metrics\": {\n        \"red_0/door_open_done_mean\": 0.0,\n        \"red_0/door_open_done_min\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n        },\n        \"red_0/door_open_done_max\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n        },\n        \"red_0/eliminated_opponents_done_mean\": 0.28,\n        \"red_0/eliminated_opponents_done_min\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n        },\n        \"red_0/eliminated_opponents_done_max\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n        },\n        \"red_0/got_eliminated_done_mean\": 0.34,\n        \"red_0/got_eliminated_done_min\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n        },\n        \"red_0/got_eliminated_done_max\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n        },\n        \"red_0/eliminated_opponent_num_mean\": 0.28,\n        \"red_0/eliminated_opponent_num_min\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n        },\n        \"red_0/eliminated_opponent_num_max\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n        },\n        \"blue_0/door_open_done_mean\": 0.02,\n        \"blue_0/door_open_done_min\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n        },\n        \"blue_0/door_open_done_max\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n        },\n        \"blue_0/eliminated_opponents_done_mean\": 0.34,\n        \"blue_0/eliminated_opponents_done_min\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n        },\n        \"blue_0/eliminated_opponents_done_max\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n        },\n        \"blue_0/got_eliminated_done_mean\": 0.28,\n        \"blue_0/got_eliminated_done_min\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n        },\n        \"blue_0/got_eliminated_done_max\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n        },\n        \"blue_0/eliminated_opponent_num_mean\": 0.34,\n        \"blue_0/eliminated_opponent_num_min\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n        },\n        \"blue_0/eliminated_opponent_num_max\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n        }\n      },\n      \"hist_stats\": {\n        \"episode_reward\": [\n          0.4159999999999999,\n          -0.3450000000000001,\n          0.4169999999999999,\n          -0.3560000000000001,\n          -0.45299999999999996,\n          -0.33299999999999996,\n          0.07599999999999996,\n          -0.22699999999999998,\n          -0.44499999999999984,\n          -0.07300000000000006,\n          -0.08900000000000007,\n          -0.366,\n          -0.3579999999999999,\n          -0.49,\n          -0.06500000000000006,\n          -0.07500000000000005,\n          -0.18200000000000005,\n          0.4059999999999999,\n          -0.19800000000000006,\n          -0.08200000000000006,\n          0.4069999999999999,\n          -0.07800000000000007,\n          0.9089999999999999,\n          -0.7140000000000001,\n          0.9349999999999999,\n          -0.4760000000000001,\n          0.4109999999999999,\n          -0.9109999999999999,\n          -0.9890000000000001,\n          0.4009999999999999,\n          0.1509999999999998,\n          0.254,\n          1.321,\n          -0.22999999999999987,\n          0.3979999999999999,\n          -0.2220000000000001,\n          -0.7840000000000001,\n          -0.09100000000000007,\n          0.9239999999999999,\n          0.9149999999999999,\n          -0.134,\n          -0.21700000000000008,\n          -0.11100000000000008,\n          -0.08100000000000006,\n          -0.22899999999999987,\n          0.136,\n          0.4129999999999999,\n          -0.026000000000000134,\n          -0.5249999999999999,\n          -0.5619999999999999\n        ],\n        \"episode_lengths\": [\n          300,\n          257,\n          300,\n          260,\n          140,\n          103,\n          278,\n          221,\n          136,\n          174,\n          300,\n          110,\n          109,\n          150,\n          20,\n          300,\n          55,\n          300,\n          212,\n          300,\n          300,\n          24,\n          300,\n          216,\n          300,\n          146,\n          300,\n          277,\n          295,\n          300,\n          257,\n          74,\n          206,\n          71,\n          300,\n          215,\n          240,\n          300,\n          300,\n          300,\n          193,\n          67,\n          300,\n          300,\n          70,\n          110,\n          300,\n          159,\n          156,\n          171\n        ],\n        \"policy_red_0_reward\": [\n          -0.04400000000000003,\n          -0.537,\n          0.46099999999999997,\n          0.18599999999999994,\n          -1.016,\n          -1.016,\n          -0.547,\n          -1.027,\n          -1.018,\n          0.45099999999999996,\n          -0.04300000000000003,\n          0.651,\n          -1.012,\n          0.533,\n          0.9359999999999999,\n          -0.04000000000000003,\n          0.829,\n          -0.04400000000000003,\n          0.844,\n          -0.03400000000000002,\n          -0.04200000000000003,\n          -1.003,\n          0.45399999999999996,\n          0.32699999999999996,\n          0.469,\n          0.5469999999999999,\n          -0.05300000000000004,\n          -1.0419999999999998,\n          -1.047,\n          -0.05400000000000004,\n          0.6839999999999999,\n          -1.013,\n          0.473,\n          -1.006,\n          0.44199999999999995,\n          -1.034,\n          0.2479999999999999,\n          -0.035000000000000024,\n          0.46199999999999997,\n          0.45499999999999996,\n          -1.027,\n          0.7939999999999999,\n          -0.05200000000000004,\n          -0.04300000000000003,\n          -1.009,\n          -0.514,\n          -0.03300000000000002,\n          0.4969999999999999,\n          0.502,\n          -1.021\n        ],\n        \"policy_blue_0_reward\": [\n          0.45999999999999996,\n          0.19199999999999995,\n          -0.04400000000000003,\n          -0.542,\n          0.563,\n          0.683,\n          0.623,\n          0.7999999999999999,\n          0.5730000000000001,\n          -0.524,\n          -0.046000000000000034,\n          -1.017,\n          0.654,\n          -1.023,\n          -1.001,\n          -0.035000000000000024,\n          -1.011,\n          0.44999999999999996,\n          -1.042,\n          -0.048000000000000036,\n          0.44899999999999995,\n          0.9249999999999999,\n          0.45499999999999996,\n          -1.041,\n          0.46599999999999997,\n          -1.023,\n          0.46399999999999997,\n          0.1309999999999999,\n          0.05799999999999995,\n          0.45499999999999996,\n          -0.533,\n          1.267,\n          0.848,\n          0.776,\n          -0.04400000000000003,\n          0.8119999999999999,\n          -1.032,\n          -0.05600000000000004,\n          0.46199999999999997,\n          0.45999999999999996,\n          0.893,\n          -1.011,\n          -0.059000000000000045,\n          -0.03800000000000003,\n          0.78,\n          0.65,\n          0.44599999999999995,\n          -0.523,\n          -1.027,\n          0.45899999999999996\n        ]\n      },\n      \"sampler_perf\": {\n        \"mean_raw_obs_processing_ms\": 1.5414225792133833,\n        \"mean_inference_ms\": 9.065971449481063,\n        \"mean_action_processing_ms\": 0.4941359974552478,\n        \"mean_env_wait_ms\": 0.5719965869146272,\n        \"mean_env_render_ms\": 0.0\n      },\n      \"num_faulty_episodes\": 0,\n      \"connector_metrics\": {\n        \"ObsPreprocessorConnector_ms\": 0.1568434238433838,\n        \"StateBufferConnector_ms\": 0.014375686645507812,\n        \"ViewRequirementAgentConnector_ms\": 0.23423051834106445\n      }\n    },\n    \"episode_reward_max\": 1.321,\n    \"episode_reward_min\": -0.9890000000000001,\n    \"episode_reward_mean\": -0.032540000000000034,\n    \"episode_len_mean\": 211.44,\n    \"episodes_this_iter\": 20,\n    \"policy_reward_min\": {\n      \"red_0\": -1.047,\n      \"blue_0\": -1.042\n    },\n    \"policy_reward_max\": {\n      \"red_0\": 0.9359999999999999,\n      \"blue_0\": 1.267\n    },\n    \"policy_reward_mean\": {\n      \"red_0\": -0.10322,\n      \"blue_0\": 0.07067999999999999\n    },\n    \"hist_stats\": {\n      \"episode_reward\": [\n        0.4159999999999999,\n        -0.3450000000000001,\n        0.4169999999999999,\n        -0.3560000000000001,\n        -0.45299999999999996,\n        -0.33299999999999996,\n        0.07599999999999996,\n        -0.22699999999999998,\n        -0.44499999999999984,\n        -0.07300000000000006,\n        -0.08900000000000007,\n        -0.366,\n        -0.3579999999999999,\n        -0.49,\n        -0.06500000000000006,\n        -0.07500000000000005,\n        -0.18200000000000005,\n        0.4059999999999999,\n        -0.19800000000000006,\n        -0.08200000000000006,\n        0.4069999999999999,\n        -0.07800000000000007,\n        0.9089999999999999,\n        -0.7140000000000001,\n        0.9349999999999999,\n        -0.4760000000000001,\n        0.4109999999999999,\n        -0.9109999999999999,\n        -0.9890000000000001,\n        0.4009999999999999,\n        0.1509999999999998,\n        0.254,\n        1.321,\n        -0.22999999999999987,\n        0.3979999999999999,\n        -0.2220000000000001,\n        -0.7840000000000001,\n        -0.09100000000000007,\n        0.9239999999999999,\n        0.9149999999999999,\n        -0.134,\n        -0.21700000000000008,\n        -0.11100000000000008,\n        -0.08100000000000006,\n        -0.22899999999999987,\n        0.136,\n        0.4129999999999999,\n        -0.026000000000000134,\n        -0.5249999999999999,\n        -0.5619999999999999\n      ],\n      \"episode_lengths\": [\n        300,\n        257,\n        300,\n        260,\n        140,\n        103,\n        278,\n        221,\n        136,\n        174,\n        300,\n        110,\n        109,\n        150,\n        20,\n        300,\n        55,\n        300,\n        212,\n        300,\n        300,\n        24,\n        300,\n        216,\n        300,\n        146,\n        300,\n        277,\n        295,\n        300,\n        257,\n        74,\n        206,\n        71,\n        300,\n        215,\n        240,\n        300,\n        300,\n        300,\n        193,\n        67,\n        300,\n        300,\n        70,\n        110,\n        300,\n        159,\n        156,\n        171\n      ],\n      \"policy_red_0_reward\": [\n        -0.04400000000000003,\n        -0.537,\n        0.46099999999999997,\n        0.18599999999999994,\n        -1.016,\n        -1.016,\n        -0.547,\n        -1.027,\n        -1.018,\n        0.45099999999999996,\n        -0.04300000000000003,\n        0.651,\n        -1.012,\n        0.533,\n        0.9359999999999999,\n        -0.04000000000000003,\n        0.829,\n        -0.04400000000000003,\n        0.844,\n        -0.03400000000000002,\n        -0.04200000000000003,\n        -1.003,\n        0.45399999999999996,\n        0.32699999999999996,\n        0.469,\n        0.5469999999999999,\n        -0.05300000000000004,\n        -1.0419999999999998,\n        -1.047,\n        -0.05400000000000004,\n        0.6839999999999999,\n        -1.013,\n        0.473,\n        -1.006,\n        0.44199999999999995,\n        -1.034,\n        0.2479999999999999,\n        -0.035000000000000024,\n        0.46199999999999997,\n        0.45499999999999996,\n        -1.027,\n        0.7939999999999999,\n        -0.05200000000000004,\n        -0.04300000000000003,\n        -1.009,\n        -0.514,\n        -0.03300000000000002,\n        0.4969999999999999,\n        0.502,\n        -1.021\n      ],\n      \"policy_blue_0_reward\": [\n        0.45999999999999996,\n        0.19199999999999995,\n        -0.04400000000000003,\n        -0.542,\n        0.563,\n        0.683,\n        0.623,\n        0.7999999999999999,\n        0.5730000000000001,\n        -0.524,\n        -0.046000000000000034,\n        -1.017,\n        0.654,\n        -1.023,\n        -1.001,\n        -0.035000000000000024,\n        -1.011,\n        0.44999999999999996,\n        -1.042,\n        -0.048000000000000036,\n        0.44899999999999995,\n        0.9249999999999999,\n        0.45499999999999996,\n        -1.041,\n        0.46599999999999997,\n        -1.023,\n        0.46399999999999997,\n        0.1309999999999999,\n        0.05799999999999995,\n        0.45499999999999996,\n        -0.533,\n        1.267,\n        0.848,\n        0.776,\n        -0.04400000000000003,\n        0.8119999999999999,\n        -1.032,\n        -0.05600000000000004,\n        0.46199999999999997,\n        0.45999999999999996,\n        0.893,\n        -1.011,\n        -0.059000000000000045,\n        -0.03800000000000003,\n        0.78,\n        0.65,\n        0.44599999999999995,\n        -0.523,\n        -1.027,\n        0.45899999999999996\n      ]\n    },\n    \"sampler_perf\": {\n      \"mean_raw_obs_processing_ms\": 1.5414225792133833,\n      \"mean_inference_ms\": 9.065971449481063,\n      \"mean_action_processing_ms\": 0.4941359974552478,\n      \"mean_env_wait_ms\": 0.5719965869146272,\n      \"mean_env_render_ms\": 0.0\n    },\n    \"num_faulty_episodes\": 0,\n    \"connector_metrics\": {\n      \"ObsPreprocessorConnector_ms\": 0.1568434238433838,\n      \"StateBufferConnector_ms\": 0.014375686645507812,\n      \"ViewRequirementAgentConnector_ms\": 0.23423051834106445\n    },\n    \"num_healthy_workers\": 10,\n    \"num_in_flight_async_reqs\": 0,\n    \"num_remote_worker_restarts\": 0,\n    \"num_agent_steps_sampled\": 24000,\n    \"num_agent_steps_trained\": 24000,\n    \"num_env_steps_sampled\": 12000,\n    \"num_env_steps_trained\": 12000,\n    \"num_env_steps_sampled_this_iter\": 4000,\n    \"num_env_steps_trained_this_iter\": 4000,\n    \"num_env_steps_sampled_throughput_per_sec\": 144.98388069970426,\n    \"num_env_steps_trained_throughput_per_sec\": 144.98388069970426,\n    \"timesteps_total\": 12000,\n    \"num_steps_trained_this_iter\": 4000,\n    \"agent_timesteps_total\": 24000,\n    \"timers\": {\n      \"training_iteration_time_ms\": 29118.374,\n      \"sample_time_ms\": 4715.284,\n      \"learn_time_ms\": 24363.803,\n      \"learn_throughput\": 164.178,\n      \"synch_weights_time_ms\": 37.74\n    },\n    \"counters\": {\n      \"num_env_steps_sampled\": 12000,\n      \"num_env_steps_trained\": 12000,\n      \"num_agent_steps_sampled\": 24000,\n      \"num_agent_steps_trained\": 24000\n    },\n    \"done\": false,\n    \"episodes_total\": 50,\n    \"training_iteration\": 3,\n    \"trial_id\": \"819b8_00000\",\n    \"date\": \"2023-09-16_15-18-09\",\n    \"timestamp\": 1694891889,\n    \"time_this_iter_s\": 27.60136604309082,\n    \"time_total_s\": 87.3975031375885,\n    \"pid\": 59406,\n    \"hostname\": \"str-mac-2615\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"extra_python_environs_for_driver\": {},\n      \"extra_python_environs_for_worker\": {},\n      \"num_gpus\": 0,\n      \"num_cpus_per_worker\": 1,\n      \"num_gpus_per_worker\": 0,\n      \"_fake_gpus\": false,\n      \"num_learner_workers\": 0,\n      \"num_gpus_per_learner_worker\": 0,\n      \"num_cpus_per_learner_worker\": 1,\n      \"local_gpu_idx\": 0,\n      \"custom_resources_per_worker\": {},\n      \"placement_strategy\": \"PACK\",\n      \"eager_tracing\": false,\n      \"eager_max_retraces\": 20,\n      \"tf_session_args\": {\n        \"intra_op_parallelism_threads\": 2,\n        \"inter_op_parallelism_threads\": 2,\n        \"gpu_options\": {\n          \"allow_growth\": true\n        },\n        \"log_device_placement\": false,\n        \"device_count\": {\n          \"CPU\": 1\n        },\n        \"allow_soft_placement\": true\n      },\n      \"local_tf_session_args\": {\n        \"intra_op_parallelism_threads\": 8,\n        \"inter_op_parallelism_threads\": 8\n      },\n      \"env\": \"MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1\",\n      \"env_config\": {\n        \"size\": 8,\n        \"allow_agent_overlap\": false,\n        \"has_obsticle\": false,\n        \"death_match\": true,\n        \"teams\": {\n          \"red\": 1,\n          \"blue\": 1\n        },\n        \"agents\": 2,\n        \"training_scheme\": \"DTDE\",\n        \"reward_schemes\": {\n          \"red_0\": {\n            \"eliminated_opponent_sparse_reward\": 0.5,\n            \"key_pickup_sparse_reward\": 0.5,\n            \"ball_pickup_dense_reward\": 0.5,\n            \"dense_reward_discount_factor\": {\n              \"ball_carrying_discount_factor\": 0.9\n            },\n            \"invalid_pickup_dense_penalty\": 0.001\n          },\n          \"blue_0\": {\n            \"eliminated_opponent_sparse_reward\": 0.5,\n            \"key_pickup_sparse_reward\": 0.5,\n            \"ball_pickup_dense_reward\": 0.5,\n            \"dense_reward_discount_factor\": {\n              \"ball_carrying_discount_factor\": 0.9\n            },\n            \"invalid_pickup_dense_penalty\": 0.001\n          }\n        },\n        \"randomization\": true,\n        \"max_steps\": 300\n      },\n      \"observation_space\": null,\n      \"action_space\": null,\n      \"env_task_fn\": null,\n      \"render_env\": false,\n      \"clip_rewards\": null,\n      \"normalize_actions\": true,\n      \"clip_actions\": false,\n      \"disable_env_checking\": false,\n      \"is_atari\": false,\n      \"auto_wrap_old_gym_envs\": true,\n      \"num_envs_per_worker\": 1,\n      \"sample_collector\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n      },\n      \"sample_async\": false,\n      \"enable_connectors\": true,\n      \"rollout_fragment_length\": \"auto\",\n      \"batch_mode\": \"truncate_episodes\",\n      \"remote_worker_envs\": false,\n      \"remote_env_batch_wait_ms\": 0,\n      \"validate_workers_after_construction\": true,\n      \"preprocessor_pref\": \"deepmind\",\n      \"observation_filter\": \"NoFilter\",\n      \"synchronize_filters\": true,\n      \"compress_observations\": false,\n      \"enable_tf1_exec_eagerly\": false,\n      \"sampler_perf_stats_ema_coef\": null,\n      \"gamma\": 0.99,\n      \"lr\": 0.001,\n      \"lr_schedule\": null,\n      \"grad_clip\": null,\n      \"grad_clip_by\": \"global_norm\",\n      \"train_batch_size\": 4000,\n      \"model\": {\n        \"_disable_preprocessor_api\": false,\n        \"_disable_action_flattening\": false,\n        \"fcnet_hiddens\": [\n          64,\n          64\n        ],\n        \"fcnet_activation\": \"tanh\",\n        \"conv_filters\": [\n          [\n            16,\n            [\n              3,\n              3\n            ],\n            1\n          ],\n          [\n            32,\n            [\n              3,\n              3\n            ],\n            1\n          ],\n          [\n            64,\n            [\n              3,\n              3\n            ],\n            1\n          ]\n        ],\n        \"conv_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": \"relu\",\n        \"free_log_std\": false,\n        \"no_final_linear\": false,\n        \"vf_share_layers\": false,\n        \"use_lstm\": false,\n        \"max_seq_len\": 20,\n        \"lstm_cell_size\": 256,\n        \"lstm_use_prev_action\": false,\n        \"lstm_use_prev_reward\": false,\n        \"_time_major\": false,\n        \"use_attention\": false,\n        \"attention_num_transformer_units\": 1,\n        \"attention_dim\": 64,\n        \"attention_num_heads\": 1,\n        \"attention_head_dim\": 32,\n        \"attention_memory_inference\": 50,\n        \"attention_memory_training\": 50,\n        \"attention_position_wise_mlp_dim\": 32,\n        \"attention_init_gru_gate_bias\": 2.0,\n        \"attention_use_n_prev_actions\": 0,\n        \"attention_use_n_prev_rewards\": 0,\n        \"framestack\": true,\n        \"dim\": 84,\n        \"grayscale\": false,\n        \"zero_mean\": true,\n        \"custom_model\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059529000000000000008c166d756c7469677269642e726c6c69622e6d6f64656c73948c0a546f7263684d6f64656c9493942e\"\n        },\n        \"custom_model_config\": {\n          \"teams\": {\n            \"red\": 1,\n            \"blue\": 1\n          },\n          \"training_scheme\": \"DTDE\"\n        },\n        \"custom_action_dist\": null,\n        \"custom_preprocessor\": null,\n        \"encoder_latent_dim\": null,\n        \"always_check_shapes\": false,\n        \"lstm_use_prev_action_reward\": -1,\n        \"_use_default_native_models\": -1\n      },\n      \"optimizer\": {},\n      \"max_requests_in_flight_per_sampler_worker\": 2,\n      \"_learner_class\": null,\n      \"_enable_learner_api\": false,\n      \"explore\": true,\n      \"exploration_config\": {\n        \"type\": \"StochasticSampling\"\n      },\n      \"policy_states_are_swappable\": false,\n      \"input_config\": {},\n      \"actions_in_input_normalized\": false,\n      \"postprocess_inputs\": false,\n      \"shuffle_buffer_size\": 0,\n      \"output\": null,\n      \"output_config\": {},\n      \"output_compress_columns\": [\n        \"obs\",\n        \"new_obs\"\n      ],\n      \"output_max_file_size\": 67108864,\n      \"offline_sampling\": false,\n      \"evaluation_interval\": null,\n      \"evaluation_duration\": 10,\n      \"evaluation_duration_unit\": \"episodes\",\n      \"evaluation_sample_timeout_s\": 180.0,\n      \"evaluation_parallel_to_training\": false,\n      \"evaluation_config\": null,\n      \"off_policy_estimation_methods\": {},\n      \"ope_split_batch_by_episode\": true,\n      \"evaluation_num_workers\": 0,\n      \"always_attach_evaluation_results\": false,\n      \"enable_async_evaluation\": false,\n      \"in_evaluation\": false,\n      \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n      \"keep_per_episode_custom_metrics\": false,\n      \"metrics_episode_collection_timeout_s\": 60.0,\n      \"metrics_num_episodes_for_smoothing\": 100,\n      \"min_time_s_per_iteration\": null,\n      \"min_train_timesteps_per_iteration\": 0,\n      \"min_sample_timesteps_per_iteration\": 0,\n      \"export_native_model_files\": false,\n      \"checkpoint_trainable_policies_only\": false,\n      \"logger_creator\": null,\n      \"logger_config\": null,\n      \"log_level\": \"WARN\",\n      \"log_sys_usage\": true,\n      \"fake_sampler\": false,\n      \"seed\": 1,\n      \"worker_cls\": null,\n      \"ignore_worker_failures\": false,\n      \"recreate_failed_workers\": false,\n      \"max_num_worker_restarts\": 1000,\n      \"delay_between_worker_restarts_s\": 60.0,\n      \"restart_failed_sub_environments\": false,\n      \"num_consecutive_worker_failures_tolerance\": 100,\n      \"worker_health_probe_timeout_s\": 60,\n      \"worker_restore_timeout_s\": 1800,\n      \"rl_module_spec\": null,\n      \"_enable_rl_module_api\": false,\n      \"_AlgorithmConfig__prior_exploration_config\": null,\n      \"_tf_policy_handles_more_than_one_loss\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"_disable_execution_plan_api\": true,\n      \"_disable_initialize_loss_from_dummy_batch\": false,\n      \"simple_optimizer\": true,\n      \"replay_sequence_length\": null,\n      \"horizon\": -1,\n      \"soft_horizon\": -1,\n      \"no_done_at_end\": -1,\n      \"use_critic\": true,\n      \"use_gae\": true,\n      \"kl_coeff\": 0.2,\n      \"sgd_minibatch_size\": 128,\n      \"num_sgd_iter\": 30,\n      \"shuffle_sequences\": true,\n      \"vf_loss_coeff\": 0.5,\n      \"entropy_coeff\": 0.001,\n      \"entropy_coeff_schedule\": null,\n      \"clip_param\": 0.3,\n      \"vf_clip_param\": 10.0,\n      \"kl_target\": 0.01,\n      \"vf_share_layers\": -1,\n      \"__stdout_file__\": null,\n      \"__stderr_file__\": null,\n      \"lambda\": 0.99,\n      \"input\": \"sampler\",\n      \"multiagent\": {\n        \"policies\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059516000000000000008f94288c06626c75655f30948c057265645f3094902e\"\n        },\n        \"policy_mapping_fn\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059504030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b034b014b5f43047c005300944e8594298c086167656e745f6964948c0461726773948c066b77617267739487948c772f55736572732f7a6c61303336382f446f63756d656e74732f524c2f524c5f436c6173732f636f64652f746573745f68772f7765656b2d322d6275696c642d796f75722d6f776e2d70706f2d68656e67347374722f6d756c7469677269642f7574696c732f747261696e696e675f7574696c69732e7079948c083c6c616d6264613e944bd043020400942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6d756c7469677269642e7574696c73948c085f5f6e616d655f5f948c1f6d756c7469677269642e7574696c732e747261696e696e675f7574696c6973948c085f5f66696c655f5f948c772f55736572732f7a6c61303336382f446f63756d656e74732f524c2f524c5f436c6173732f636f64652f746573745f68772f7765656b2d322d6275696c642d796f75722d6f776e2d70706f2d68656e67347374722f6d756c7469677269642f7574696c732f747261696e696e675f7574696c69732e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c22616c676f726974686d5f636f6e6669672e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n        },\n        \"policies_to_train\": null,\n        \"policy_map_capacity\": 100,\n        \"policy_map_cache\": -1,\n        \"count_steps_by\": \"env_steps\",\n        \"observation_fn\": null\n      },\n      \"callbacks\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c1f6d756c7469677269642e7574696c732e747261696e696e675f7574696c6973948c134576616c756174696f6e43616c6c6261636b739493942e\"\n      },\n      \"create_env_on_driver\": false,\n      \"custom_eval_function\": null,\n      \"framework\": \"torch\",\n      \"num_cpus_for_driver\": 1,\n      \"num_workers\": 10\n    },\n    \"time_since_restore\": 87.3975031375885,\n    \"iterations_since_restore\": 3,\n    \"perf\": {\n      \"cpu_util_percent\": 27.04390243902439,\n      \"ram_util_percent\": 58.0609756097561\n    },\n    \"experiment_tag\": \"0\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1694891890.1301692,\n  \"metric_analysis\": {\n    \"episode_reward_max\": {\n      \"max\": 1.321,\n      \"min\": 0.4169999999999999,\n      \"avg\": 0.891,\n      \"last\": 1.321,\n      \"last-5-avg\": 0.891,\n      \"last-10-avg\": 0.891\n    },\n    \"episode_reward_min\": {\n      \"max\": -0.49,\n      \"min\": -0.9890000000000001,\n      \"avg\": -0.8226666666666667,\n      \"last\": -0.9890000000000001,\n      \"last-5-avg\": -0.8226666666666667,\n      \"last-10-avg\": -0.8226666666666667\n    },\n    \"episode_reward_mean\": {\n      \"max\": -0.032540000000000034,\n      \"min\": -0.17341176470588238,\n      \"avg\": -0.10117281045751636,\n      \"last\": -0.032540000000000034,\n      \"last-5-avg\": -0.10117281045751636,\n      \"last-10-avg\": -0.10117281045751636\n    },\n    \"episode_len_mean\": {\n      \"max\": 216.1,\n      \"min\": 189.0,\n      \"avg\": 205.51333333333332,\n      \"last\": 211.44,\n      \"last-5-avg\": 205.51333333333332,\n      \"last-10-avg\": 205.51333333333332\n    },\n    \"episodes_this_iter\": {\n      \"max\": 20,\n      \"min\": 13,\n      \"avg\": 16.666666666666664,\n      \"last\": 20,\n      \"last-5-avg\": 16.666666666666668,\n      \"last-10-avg\": 16.666666666666668\n    },\n    \"num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_healthy_workers\": {\n      \"max\": 10,\n      \"min\": 10,\n      \"avg\": 10.0,\n      \"last\": 10,\n      \"last-5-avg\": 10.0,\n      \"last-10-avg\": 10.0\n    },\n    \"num_in_flight_async_reqs\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_remote_worker_restarts\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_agent_steps_sampled\": {\n      \"max\": 24000,\n      \"min\": 8000,\n      \"avg\": 16000.0,\n      \"last\": 24000,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 16000.0\n    },\n    \"num_agent_steps_trained\": {\n      \"max\": 24000,\n      \"min\": 8000,\n      \"avg\": 16000.0,\n      \"last\": 24000,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 16000.0\n    },\n    \"num_env_steps_sampled\": {\n      \"max\": 12000,\n      \"min\": 4000,\n      \"avg\": 8000.0,\n      \"last\": 12000,\n      \"last-5-avg\": 8000.0,\n      \"last-10-avg\": 8000.0\n    },\n    \"num_env_steps_trained\": {\n      \"max\": 12000,\n      \"min\": 4000,\n      \"avg\": 8000.0,\n      \"last\": 12000,\n      \"last-5-avg\": 8000.0,\n      \"last-10-avg\": 8000.0\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000.0,\n      \"last\": 4000,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000.0,\n      \"last\": 4000,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"num_env_steps_sampled_throughput_per_sec\": {\n      \"max\": 144.98388069970426,\n      \"min\": 133.6887142710614,\n      \"avg\": 137.5650809403661,\n      \"last\": 144.98388069970426,\n      \"last-5-avg\": 137.5650809403661,\n      \"last-10-avg\": 137.5650809403661\n    },\n    \"num_env_steps_trained_throughput_per_sec\": {\n      \"max\": 144.98388069970426,\n      \"min\": 133.6887142710614,\n      \"avg\": 137.5650809403661,\n      \"last\": 144.98388069970426,\n      \"last-5-avg\": 137.5650809403661,\n      \"last-10-avg\": 137.5650809403661\n    },\n    \"timesteps_total\": {\n      \"max\": 12000,\n      \"min\": 4000,\n      \"avg\": 8000.0,\n      \"last\": 12000,\n      \"last-5-avg\": 8000.0,\n      \"last-10-avg\": 8000.0\n    },\n    \"num_steps_trained_this_iter\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000.0,\n      \"last\": 4000,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"agent_timesteps_total\": {\n      \"max\": 24000,\n      \"min\": 8000,\n      \"avg\": 16000.0,\n      \"last\": 24000,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 16000.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"episodes_total\": {\n      \"max\": 50,\n      \"min\": 17,\n      \"avg\": 32.33333333333333,\n      \"last\": 50,\n      \"last-5-avg\": 32.333333333333336,\n      \"last-10-avg\": 32.333333333333336\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 29.929951190948486,\n      \"min\": 27.60136604309082,\n      \"avg\": 29.13250104586283,\n      \"last\": 27.60136604309082,\n      \"last-5-avg\": 29.132501045862835,\n      \"last-10-avg\": 29.132501045862835\n    },\n    \"time_total_s\": {\n      \"max\": 87.3975031375885,\n      \"min\": 29.866185903549194,\n      \"avg\": 59.01994204521179,\n      \"last\": 87.3975031375885,\n      \"last-5-avg\": 59.01994204521179,\n      \"last-10-avg\": 59.01994204521179\n    },\n    \"time_since_restore\": {\n      \"max\": 87.3975031375885,\n      \"min\": 29.866185903549194,\n      \"avg\": 59.01994204521179,\n      \"last\": 87.3975031375885,\n      \"last-5-avg\": 59.01994204521179,\n      \"last-10-avg\": 59.01994204521179\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"custom_metrics/red_0/door_open_done_mean\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"custom_metrics/red_0/door_open_done_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"custom_metrics/red_0/door_open_done_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"custom_metrics/red_0/eliminated_opponents_done_mean\": {\n      \"max\": 0.35294117647058826,\n      \"min\": 0.28,\n      \"avg\": 0.31098039215686274,\n      \"last\": 0.28,\n      \"last-5-avg\": 0.31098039215686274,\n      \"last-10-avg\": 0.31098039215686274\n    },\n    \"custom_metrics/red_0/eliminated_opponents_done_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"custom_metrics/red_0/eliminated_opponents_done_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"custom_metrics/red_0/got_eliminated_done_mean\": {\n      \"max\": 0.4117647058823529,\n      \"min\": 0.3333333333333333,\n      \"avg\": 0.36169934640522877,\n      \"last\": 0.34,\n      \"last-5-avg\": 0.36169934640522877,\n      \"last-10-avg\": 0.36169934640522877\n    },\n    \"custom_metrics/red_0/got_eliminated_done_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"custom_metrics/red_0/got_eliminated_done_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"custom_metrics/red_0/eliminated_opponent_num_mean\": {\n      \"max\": 0.35294117647058826,\n      \"min\": 0.28,\n      \"avg\": 0.31098039215686274,\n      \"last\": 0.28,\n      \"last-5-avg\": 0.31098039215686274,\n      \"last-10-avg\": 0.31098039215686274\n    },\n    \"custom_metrics/red_0/eliminated_opponent_num_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"custom_metrics/red_0/eliminated_opponent_num_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"custom_metrics/blue_0/door_open_done_mean\": {\n      \"max\": 0.02,\n      \"min\": 0.0,\n      \"avg\": 0.006666666666666666,\n      \"last\": 0.02,\n      \"last-5-avg\": 0.006666666666666667,\n      \"last-10-avg\": 0.006666666666666667\n    },\n    \"custom_metrics/blue_0/door_open_done_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"custom_metrics/blue_0/door_open_done_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.3333333333333333,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"custom_metrics/blue_0/eliminated_opponents_done_mean\": {\n      \"max\": 0.4117647058823529,\n      \"min\": 0.3333333333333333,\n      \"avg\": 0.36169934640522877,\n      \"last\": 0.34,\n      \"last-5-avg\": 0.36169934640522877,\n      \"last-10-avg\": 0.36169934640522877\n    },\n    \"custom_metrics/blue_0/eliminated_opponents_done_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"custom_metrics/blue_0/eliminated_opponents_done_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"custom_metrics/blue_0/got_eliminated_done_mean\": {\n      \"max\": 0.35294117647058826,\n      \"min\": 0.28,\n      \"avg\": 0.31098039215686274,\n      \"last\": 0.28,\n      \"last-5-avg\": 0.31098039215686274,\n      \"last-10-avg\": 0.31098039215686274\n    },\n    \"custom_metrics/blue_0/got_eliminated_done_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"custom_metrics/blue_0/got_eliminated_done_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"custom_metrics/blue_0/eliminated_opponent_num_mean\": {\n      \"max\": 0.4117647058823529,\n      \"min\": 0.3333333333333333,\n      \"avg\": 0.36169934640522877,\n      \"last\": 0.34,\n      \"last-5-avg\": 0.36169934640522877,\n      \"last-10-avg\": 0.36169934640522877\n    },\n    \"custom_metrics/blue_0/eliminated_opponent_num_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"custom_metrics/blue_0/eliminated_opponent_num_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"info/num_env_steps_sampled\": {\n      \"max\": 12000,\n      \"min\": 4000,\n      \"avg\": 8000.0,\n      \"last\": 12000,\n      \"last-5-avg\": 8000.0,\n      \"last-10-avg\": 8000.0\n    },\n    \"info/num_env_steps_trained\": {\n      \"max\": 12000,\n      \"min\": 4000,\n      \"avg\": 8000.0,\n      \"last\": 12000,\n      \"last-5-avg\": 8000.0,\n      \"last-10-avg\": 8000.0\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"max\": 24000,\n      \"min\": 8000,\n      \"avg\": 16000.0,\n      \"last\": 24000,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 16000.0\n    },\n    \"info/num_agent_steps_trained\": {\n      \"max\": 24000,\n      \"min\": 8000,\n      \"avg\": 16000.0,\n      \"last\": 24000,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 16000.0\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"max\": 1.321,\n      \"min\": 0.4169999999999999,\n      \"avg\": 0.891,\n      \"last\": 1.321,\n      \"last-5-avg\": 0.891,\n      \"last-10-avg\": 0.891\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"max\": -0.49,\n      \"min\": -0.9890000000000001,\n      \"avg\": -0.8226666666666667,\n      \"last\": -0.9890000000000001,\n      \"last-5-avg\": -0.8226666666666667,\n      \"last-10-avg\": -0.8226666666666667\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"max\": -0.032540000000000034,\n      \"min\": -0.17341176470588238,\n      \"avg\": -0.10117281045751636,\n      \"last\": -0.032540000000000034,\n      \"last-5-avg\": -0.10117281045751636,\n      \"last-10-avg\": -0.10117281045751636\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"max\": 216.1,\n      \"min\": 189.0,\n      \"avg\": 205.51333333333332,\n      \"last\": 211.44,\n      \"last-5-avg\": 205.51333333333332,\n      \"last-10-avg\": 205.51333333333332\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"max\": 20,\n      \"min\": 13,\n      \"avg\": 16.666666666666664,\n      \"last\": 20,\n      \"last-5-avg\": 16.666666666666668,\n      \"last-10-avg\": 16.666666666666668\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"policy_reward_min/red_0\": {\n      \"max\": -1.027,\n      \"min\": -1.047,\n      \"avg\": -1.040333333333333,\n      \"last\": -1.047,\n      \"last-5-avg\": -1.040333333333333,\n      \"last-10-avg\": -1.040333333333333\n    },\n    \"policy_reward_min/blue_0\": {\n      \"max\": -1.023,\n      \"min\": -1.042,\n      \"avg\": -1.0356666666666667,\n      \"last\": -1.042,\n      \"last-5-avg\": -1.0356666666666667,\n      \"last-10-avg\": -1.0356666666666667\n    },\n    \"policy_reward_max/red_0\": {\n      \"max\": 0.9359999999999999,\n      \"min\": 0.9359999999999999,\n      \"avg\": 0.9359999999999999,\n      \"last\": 0.9359999999999999,\n      \"last-5-avg\": 0.9359999999999999,\n      \"last-10-avg\": 0.9359999999999999\n    },\n    \"policy_reward_max/blue_0\": {\n      \"max\": 1.267,\n      \"min\": 0.7999999999999999,\n      \"avg\": 0.9973333333333333,\n      \"last\": 1.267,\n      \"last-5-avg\": 0.9973333333333333,\n      \"last-10-avg\": 0.9973333333333333\n    },\n    \"policy_reward_mean/red_0\": {\n      \"max\": -0.09769999999999998,\n      \"min\": -0.1325294117647059,\n      \"avg\": -0.11114980392156862,\n      \"last\": -0.10322,\n      \"last-5-avg\": -0.11114980392156863,\n      \"last-10-avg\": -0.11114980392156863\n    },\n    \"policy_reward_mean/blue_0\": {\n      \"max\": 0.07067999999999999,\n      \"min\": -0.04088235294117646,\n      \"avg\": 0.009976993464052286,\n      \"last\": 0.07067999999999999,\n      \"last-5-avg\": 0.009976993464052286,\n      \"last-10-avg\": 0.009976993464052286\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.5414225792133833,\n      \"min\": 1.3866886918419212,\n      \"avg\": 1.4869068014749633,\n      \"last\": 1.5414225792133833,\n      \"last-5-avg\": 1.4869068014749633,\n      \"last-10-avg\": 1.4869068014749633\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"max\": 9.18377288726761,\n      \"min\": 8.556343408489186,\n      \"avg\": 8.935362581745952,\n      \"last\": 9.065971449481063,\n      \"last-5-avg\": 8.935362581745954,\n      \"last-10-avg\": 8.935362581745954\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.4941359974552478,\n      \"min\": 0.45521878000052074,\n      \"avg\": 0.4794685396680227,\n      \"last\": 0.4941359974552478,\n      \"last-5-avg\": 0.4794685396680227,\n      \"last-10-avg\": 0.4794685396680227\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"max\": 0.5719965869146272,\n      \"min\": 0.5206204901627122,\n      \"avg\": 0.5540077404186861,\n      \"last\": 0.5719965869146272,\n      \"last-5-avg\": 0.5540077404186862,\n      \"last-10-avg\": 0.5540077404186862\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"connector_metrics/ObsPreprocessorConnector_ms\": {\n      \"max\": 0.17139514287312826,\n      \"min\": 0.1568434238433838,\n      \"avg\": 0.16379566597782708,\n      \"last\": 0.1568434238433838,\n      \"last-5-avg\": 0.1637956659778271,\n      \"last-10-avg\": 0.1637956659778271\n    },\n    \"connector_metrics/StateBufferConnector_ms\": {\n      \"max\": 0.018004179000854492,\n      \"min\": 0.010263919830322266,\n      \"avg\": 0.014214595158894856,\n      \"last\": 0.014375686645507812,\n      \"last-5-avg\": 0.014214595158894857,\n      \"last-10-avg\": 0.014214595158894857\n    },\n    \"connector_metrics/ViewRequirementAgentConnector_ms\": {\n      \"max\": 0.2793121337890625,\n      \"min\": 0.1898982945610495,\n      \"avg\": 0.23448031556372545,\n      \"last\": 0.23423051834106445,\n      \"last-5-avg\": 0.23448031556372548,\n      \"last-10-avg\": 0.23448031556372548\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"max\": 29882.939,\n      \"min\": 29118.374,\n      \"avg\": 29615.656666666666,\n      \"last\": 29118.374,\n      \"last-5-avg\": 29615.656666666666,\n      \"last-10-avg\": 29615.656666666666\n    },\n    \"timers/sample_time_ms\": {\n      \"max\": 5275.403,\n      \"min\": 4510.193,\n      \"avg\": 4833.626666666667,\n      \"last\": 4715.284,\n      \"last-5-avg\": 4833.626666666667,\n      \"last-10-avg\": 4833.626666666667\n    },\n    \"timers/learn_time_ms\": {\n      \"max\": 25271.818,\n      \"min\": 24363.803,\n      \"avg\": 24732.626999999997,\n      \"last\": 24363.803,\n      \"last-5-avg\": 24732.626999999997,\n      \"last-10-avg\": 24732.626999999997\n    },\n    \"timers/learn_throughput\": {\n      \"max\": 164.178,\n      \"min\": 158.279,\n      \"avg\": 161.76933333333332,\n      \"last\": 164.178,\n      \"last-5-avg\": 161.76933333333332,\n      \"last-10-avg\": 161.76933333333332\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"max\": 61.657,\n      \"min\": 37.74,\n      \"avg\": 47.65533333333333,\n      \"last\": 37.74,\n      \"last-5-avg\": 47.65533333333334,\n      \"last-10-avg\": 47.65533333333334\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"max\": 12000,\n      \"min\": 4000,\n      \"avg\": 8000.0,\n      \"last\": 12000,\n      \"last-5-avg\": 8000.0,\n      \"last-10-avg\": 8000.0\n    },\n    \"counters/num_env_steps_trained\": {\n      \"max\": 12000,\n      \"min\": 4000,\n      \"avg\": 8000.0,\n      \"last\": 12000,\n      \"last-5-avg\": 8000.0,\n      \"last-10-avg\": 8000.0\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"max\": 24000,\n      \"min\": 8000,\n      \"avg\": 16000.0,\n      \"last\": 24000,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 16000.0\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"max\": 24000,\n      \"min\": 8000,\n      \"avg\": 16000.0,\n      \"last\": 24000,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 16000.0\n    },\n    \"perf/cpu_util_percent\": {\n      \"max\": 35.60666666666667,\n      \"min\": 27.04390243902439,\n      \"avg\": 32.25625030795762,\n      \"last\": 27.04390243902439,\n      \"last-5-avg\": 32.25625030795762,\n      \"last-10-avg\": 32.25625030795762\n    },\n    \"perf/ram_util_percent\": {\n      \"max\": 58.11818181818182,\n      \"min\": 58.0609756097561,\n      \"avg\": 58.08120062412745,\n      \"last\": 58.0609756097561,\n      \"last-5-avg\": 58.081200624127455,\n      \"last-10-avg\": 58.081200624127455\n    },\n    \"sampler_results/policy_reward_min/red_0\": {\n      \"max\": -1.027,\n      \"min\": -1.047,\n      \"avg\": -1.040333333333333,\n      \"last\": -1.047,\n      \"last-5-avg\": -1.040333333333333,\n      \"last-10-avg\": -1.040333333333333\n    },\n    \"sampler_results/policy_reward_min/blue_0\": {\n      \"max\": -1.023,\n      \"min\": -1.042,\n      \"avg\": -1.0356666666666667,\n      \"last\": -1.042,\n      \"last-5-avg\": -1.0356666666666667,\n      \"last-10-avg\": -1.0356666666666667\n    },\n    \"sampler_results/policy_reward_max/red_0\": {\n      \"max\": 0.9359999999999999,\n      \"min\": 0.9359999999999999,\n      \"avg\": 0.9359999999999999,\n      \"last\": 0.9359999999999999,\n      \"last-5-avg\": 0.9359999999999999,\n      \"last-10-avg\": 0.9359999999999999\n    },\n    \"sampler_results/policy_reward_max/blue_0\": {\n      \"max\": 1.267,\n      \"min\": 0.7999999999999999,\n      \"avg\": 0.9973333333333333,\n      \"last\": 1.267,\n      \"last-5-avg\": 0.9973333333333333,\n      \"last-10-avg\": 0.9973333333333333\n    },\n    \"sampler_results/policy_reward_mean/red_0\": {\n      \"max\": -0.09769999999999998,\n      \"min\": -0.1325294117647059,\n      \"avg\": -0.11114980392156862,\n      \"last\": -0.10322,\n      \"last-5-avg\": -0.11114980392156863,\n      \"last-10-avg\": -0.11114980392156863\n    },\n    \"sampler_results/policy_reward_mean/blue_0\": {\n      \"max\": 0.07067999999999999,\n      \"min\": -0.04088235294117646,\n      \"avg\": 0.009976993464052286,\n      \"last\": 0.07067999999999999,\n      \"last-5-avg\": 0.009976993464052286,\n      \"last-10-avg\": 0.009976993464052286\n    },\n    \"sampler_results/custom_metrics/red_0/door_open_done_mean\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/custom_metrics/red_0/door_open_done_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/custom_metrics/red_0/door_open_done_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/custom_metrics/red_0/eliminated_opponents_done_mean\": {\n      \"max\": 0.35294117647058826,\n      \"min\": 0.28,\n      \"avg\": 0.31098039215686274,\n      \"last\": 0.28,\n      \"last-5-avg\": 0.31098039215686274,\n      \"last-10-avg\": 0.31098039215686274\n    },\n    \"sampler_results/custom_metrics/red_0/eliminated_opponents_done_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/custom_metrics/red_0/eliminated_opponents_done_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"sampler_results/custom_metrics/red_0/got_eliminated_done_mean\": {\n      \"max\": 0.4117647058823529,\n      \"min\": 0.3333333333333333,\n      \"avg\": 0.36169934640522877,\n      \"last\": 0.34,\n      \"last-5-avg\": 0.36169934640522877,\n      \"last-10-avg\": 0.36169934640522877\n    },\n    \"sampler_results/custom_metrics/red_0/got_eliminated_done_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/custom_metrics/red_0/got_eliminated_done_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"sampler_results/custom_metrics/red_0/eliminated_opponent_num_mean\": {\n      \"max\": 0.35294117647058826,\n      \"min\": 0.28,\n      \"avg\": 0.31098039215686274,\n      \"last\": 0.28,\n      \"last-5-avg\": 0.31098039215686274,\n      \"last-10-avg\": 0.31098039215686274\n    },\n    \"sampler_results/custom_metrics/red_0/eliminated_opponent_num_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/custom_metrics/red_0/eliminated_opponent_num_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"sampler_results/custom_metrics/blue_0/door_open_done_mean\": {\n      \"max\": 0.02,\n      \"min\": 0.0,\n      \"avg\": 0.006666666666666666,\n      \"last\": 0.02,\n      \"last-5-avg\": 0.006666666666666667,\n      \"last-10-avg\": 0.006666666666666667\n    },\n    \"sampler_results/custom_metrics/blue_0/door_open_done_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/custom_metrics/blue_0/door_open_done_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.3333333333333333,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"sampler_results/custom_metrics/blue_0/eliminated_opponents_done_mean\": {\n      \"max\": 0.4117647058823529,\n      \"min\": 0.3333333333333333,\n      \"avg\": 0.36169934640522877,\n      \"last\": 0.34,\n      \"last-5-avg\": 0.36169934640522877,\n      \"last-10-avg\": 0.36169934640522877\n    },\n    \"sampler_results/custom_metrics/blue_0/eliminated_opponents_done_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/custom_metrics/blue_0/eliminated_opponents_done_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"sampler_results/custom_metrics/blue_0/got_eliminated_done_mean\": {\n      \"max\": 0.35294117647058826,\n      \"min\": 0.28,\n      \"avg\": 0.31098039215686274,\n      \"last\": 0.28,\n      \"last-5-avg\": 0.31098039215686274,\n      \"last-10-avg\": 0.31098039215686274\n    },\n    \"sampler_results/custom_metrics/blue_0/got_eliminated_done_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/custom_metrics/blue_0/got_eliminated_done_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"sampler_results/custom_metrics/blue_0/eliminated_opponent_num_mean\": {\n      \"max\": 0.4117647058823529,\n      \"min\": 0.3333333333333333,\n      \"avg\": 0.36169934640522877,\n      \"last\": 0.34,\n      \"last-5-avg\": 0.36169934640522877,\n      \"last-10-avg\": 0.36169934640522877\n    },\n    \"sampler_results/custom_metrics/blue_0/eliminated_opponent_num_min\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"avg\": 0.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452942e\"\n      },\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/custom_metrics/blue_0/eliminated_opponent_num_max\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059569000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.5414225792133833,\n      \"min\": 1.3866886918419212,\n      \"avg\": 1.4869068014749633,\n      \"last\": 1.5414225792133833,\n      \"last-5-avg\": 1.4869068014749633,\n      \"last-10-avg\": 1.4869068014749633\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"max\": 9.18377288726761,\n      \"min\": 8.556343408489186,\n      \"avg\": 8.935362581745952,\n      \"last\": 9.065971449481063,\n      \"last-5-avg\": 8.935362581745954,\n      \"last-10-avg\": 8.935362581745954\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.4941359974552478,\n      \"min\": 0.45521878000052074,\n      \"avg\": 0.4794685396680227,\n      \"last\": 0.4941359974552478,\n      \"last-5-avg\": 0.4794685396680227,\n      \"last-10-avg\": 0.4794685396680227\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"max\": 0.5719965869146272,\n      \"min\": 0.5206204901627122,\n      \"avg\": 0.5540077404186861,\n      \"last\": 0.5719965869146272,\n      \"last-5-avg\": 0.5540077404186862,\n      \"last-10-avg\": 0.5540077404186862\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/connector_metrics/ObsPreprocessorConnector_ms\": {\n      \"max\": 0.17139514287312826,\n      \"min\": 0.1568434238433838,\n      \"avg\": 0.16379566597782708,\n      \"last\": 0.1568434238433838,\n      \"last-5-avg\": 0.1637956659778271,\n      \"last-10-avg\": 0.1637956659778271\n    },\n    \"sampler_results/connector_metrics/StateBufferConnector_ms\": {\n      \"max\": 0.018004179000854492,\n      \"min\": 0.010263919830322266,\n      \"avg\": 0.014214595158894856,\n      \"last\": 0.014375686645507812,\n      \"last-5-avg\": 0.014214595158894857,\n      \"last-10-avg\": 0.014214595158894857\n    },\n    \"sampler_results/connector_metrics/ViewRequirementAgentConnector_ms\": {\n      \"max\": 0.2793121337890625,\n      \"min\": 0.1898982945610495,\n      \"avg\": 0.23448031556372545,\n      \"last\": 0.23423051834106445,\n      \"last-5-avg\": 0.23448031556372548,\n      \"last-10-avg\": 0.23448031556372548\n    },\n    \"info/learner/red_0/num_agent_steps_trained\": {\n      \"max\": 125.0,\n      \"min\": 125.0,\n      \"avg\": 125.0,\n      \"last\": 125.0,\n      \"last-5-avg\": 125.0,\n      \"last-10-avg\": 125.0\n    },\n    \"info/learner/red_0/num_grad_updates_lifetime\": {\n      \"max\": 2400.5,\n      \"min\": 480.5,\n      \"avg\": 1440.5,\n      \"last\": 2400.5,\n      \"last-5-avg\": 1440.5,\n      \"last-10-avg\": 1440.5\n    },\n    \"info/learner/red_0/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 479.5,\n      \"min\": 479.5,\n      \"avg\": 479.5,\n      \"last\": 479.5,\n      \"last-5-avg\": 479.5,\n      \"last-10-avg\": 479.5\n    },\n    \"info/learner/blue_0/num_agent_steps_trained\": {\n      \"max\": 125.0,\n      \"min\": 125.0,\n      \"avg\": 125.0,\n      \"last\": 125.0,\n      \"last-5-avg\": 125.0,\n      \"last-10-avg\": 125.0\n    },\n    \"info/learner/blue_0/num_grad_updates_lifetime\": {\n      \"max\": 2400.5,\n      \"min\": 480.5,\n      \"avg\": 1440.5,\n      \"last\": 2400.5,\n      \"last-5-avg\": 1440.5,\n      \"last-10-avg\": 1440.5\n    },\n    \"info/learner/blue_0/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 479.5,\n      \"min\": 479.5,\n      \"avg\": 479.5,\n      \"last\": 479.5,\n      \"last-5-avg\": 479.5,\n      \"last-10-avg\": 479.5\n    },\n    \"info/learner/red_0/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/red_0/learner_stats/grad_gnorm\": {\n      \"max\": 0.437308070063591,\n      \"min\": 0.34983984266097345,\n      \"avg\": 0.38589320685197076,\n      \"last\": 0.437308070063591,\n      \"last-5-avg\": 0.38589320685197076,\n      \"last-10-avg\": 0.38589320685197076\n    },\n    \"info/learner/red_0/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.4500000000000001,\n      \"min\": 0.20000000000000004,\n      \"avg\": 0.3166666666666667,\n      \"last\": 0.4500000000000001,\n      \"last-5-avg\": 0.3166666666666667,\n      \"last-10-avg\": 0.3166666666666667\n    },\n    \"info/learner/red_0/learner_stats/cur_lr\": {\n      \"max\": 0.0010000000000000005,\n      \"min\": 0.0010000000000000005,\n      \"avg\": 0.0010000000000000005,\n      \"last\": 0.0010000000000000005,\n      \"last-5-avg\": 0.0010000000000000005,\n      \"last-10-avg\": 0.0010000000000000005\n    },\n    \"info/learner/red_0/learner_stats/total_loss\": {\n      \"max\": -0.042020888272115066,\n      \"min\": -0.08523126503860112,\n      \"avg\": -0.067687786963951,\n      \"last\": -0.07581120758113684,\n      \"last-5-avg\": -0.067687786963951,\n      \"last-10-avg\": -0.067687786963951\n    },\n    \"info/learner/red_0/learner_stats/policy_loss\": {\n      \"max\": -0.06172999760092353,\n      \"min\": -0.10054700752856055,\n      \"avg\": -0.08756975927268891,\n      \"last\": -0.10054700752856055,\n      \"last-5-avg\": -0.08756975927268891,\n      \"last-10-avg\": -0.08756975927268891\n    },\n    \"info/learner/red_0/learner_stats/vf_loss\": {\n      \"max\": 0.03195619317411911,\n      \"min\": 0.013300029859237839,\n      \"avg\": 0.02315279384347377,\n      \"last\": 0.024202158497064374,\n      \"last-5-avg\": 0.02315279384347377,\n      \"last-10-avg\": 0.02315279384347377\n    },\n    \"info/learner/red_0/learner_stats/vf_explained_var\": {\n      \"max\": 0.5669182925174634,\n      \"min\": 0.4641108589246869,\n      \"avg\": 0.5203922958009772,\n      \"last\": 0.5301477359607816,\n      \"last-5-avg\": 0.5203922958009773,\n      \"last-10-avg\": 0.5203922958009773\n    },\n    \"info/learner/red_0/learner_stats/kl\": {\n      \"max\": 0.034794901214634896,\n      \"min\": 0.028241681610078024,\n      \"avg\": 0.031750353306217144,\n      \"last\": 0.03221447709393853,\n      \"last-5-avg\": 0.03175035330621715,\n      \"last-10-avg\": 0.03175035330621715\n    },\n    \"info/learner/red_0/learner_stats/entropy\": {\n      \"max\": 1.9173234197000661,\n      \"min\": 1.8617937531322242,\n      \"avg\": 1.8888649517049392,\n      \"last\": 1.8617937531322242,\n      \"last-5-avg\": 1.8888649517049394,\n      \"last-10-avg\": 1.8888649517049394\n    },\n    \"info/learner/red_0/learner_stats/entropy_coeff\": {\n      \"max\": 0.0010000000000000005,\n      \"min\": 0.0010000000000000005,\n      \"avg\": 0.0010000000000000005,\n      \"last\": 0.0010000000000000005,\n      \"last-5-avg\": 0.0010000000000000005,\n      \"last-10-avg\": 0.0010000000000000005\n    },\n    \"info/learner/blue_0/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/blue_0/learner_stats/grad_gnorm\": {\n      \"max\": 0.4425927648010353,\n      \"min\": 0.341019624316444,\n      \"avg\": 0.39494671769336687,\n      \"last\": 0.4425927648010353,\n      \"last-5-avg\": 0.3949467176933669,\n      \"last-10-avg\": 0.3949467176933669\n    },\n    \"info/learner/blue_0/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.4500000000000001,\n      \"min\": 0.20000000000000004,\n      \"avg\": 0.3166666666666667,\n      \"last\": 0.4500000000000001,\n      \"last-5-avg\": 0.3166666666666667,\n      \"last-10-avg\": 0.3166666666666667\n    },\n    \"info/learner/blue_0/learner_stats/cur_lr\": {\n      \"max\": 0.0010000000000000005,\n      \"min\": 0.0010000000000000005,\n      \"avg\": 0.0010000000000000005,\n      \"last\": 0.0010000000000000005,\n      \"last-5-avg\": 0.0010000000000000005,\n      \"last-10-avg\": 0.0010000000000000005\n    },\n    \"info/learner/blue_0/learner_stats/total_loss\": {\n      \"max\": -0.05784769923933102,\n      \"min\": -0.08198436268576188,\n      \"avg\": -0.07187495741757932,\n      \"last\": -0.07579281032764508,\n      \"last-5-avg\": -0.07187495741757932,\n      \"last-10-avg\": -0.07187495741757932\n    },\n    \"info/learner/blue_0/learner_stats/policy_loss\": {\n      \"max\": -0.07545501335165075,\n      \"min\": -0.10116938730546583,\n      \"avg\": -0.09165412844991401,\n      \"last\": -0.10116938730546583,\n      \"last-5-avg\": -0.09165412844991401,\n      \"last-10-avg\": -0.09165412844991401\n    },\n    \"info/learner/blue_0/learner_stats/vf_loss\": {\n      \"max\": 0.026107774430905315,\n      \"min\": 0.015014183438324835,\n      \"avg\": 0.022231514930414656,\n      \"last\": 0.02557258692201382,\n      \"last-5-avg\": 0.022231514930414656,\n      \"last-10-avg\": 0.022231514930414656\n    },\n    \"info/learner/blue_0/learner_stats/vf_explained_var\": {\n      \"max\": 0.5917474298427502,\n      \"min\": 0.5284363742296895,\n      \"avg\": 0.5517204083916214,\n      \"last\": 0.5349774211024244,\n      \"last-5-avg\": 0.5517204083916214,\n      \"last-10-avg\": 0.5517204083916214\n    },\n    \"info/learner/blue_0/learner_stats/kl\": {\n      \"max\": 0.03575939857125992,\n      \"min\": 0.03211901438317401,\n      \"avg\": 0.03340425979160131,\n      \"last\": 0.03211901438317401,\n      \"last-5-avg\": 0.03340425979160131,\n      \"last-10-avg\": 0.03340425979160131\n    },\n    \"info/learner/blue_0/learner_stats/entropy\": {\n      \"max\": 1.9134464843819539,\n      \"min\": 1.8632729317992927,\n      \"avg\": 1.8860028506153157,\n      \"last\": 1.8632729317992927,\n      \"last-5-avg\": 1.8860028506153157,\n      \"last-10-avg\": 1.8860028506153157\n    },\n    \"info/learner/blue_0/learner_stats/entropy_coeff\": {\n      \"max\": 0.0010000000000000005,\n      \"min\": 0.0010000000000000005,\n      \"avg\": 0.0010000000000000005,\n      \"last\": 0.0010000000000000005,\n      \"last-5-avg\": 0.0010000000000000005,\n      \"last-10-avg\": 0.0010000000000000005\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdab020c49ba5e2473fedeb851eb851eb473ff522d0e5604189652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdab020c49ba5e2473fedeb851eb851eb473ff522d0e5604189652e\"\n      }\n    },\n    \"episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847bfdf5c28f5c28f5c47bfefa5e353f7ceda47bfefa5e353f7ceda652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bfdf5c28f5c28f5c47bfefa5e353f7ceda47bfefa5e353f7ceda652e\"\n      }\n    },\n    \"episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800a313515b32c6bf94869452946807680d43085a58830a21fab8bf94869452946807680d430883a99f3715a9a0bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800a313515b32c6bf94869452946807680d43085a58830a21fab8bf94869452946807680d430883a99f3715a9a0bf9486945294652e\"\n      }\n    },\n    \"episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000a0674094869452946807680d43083333333333036b4094869452946807680d4308ae47e17a146e6a409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000a0674094869452946807680d43083333333333036b4094869452946807680d4308ae47e17a146e6a409486945294652e\"\n      }\n    },\n    \"episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b114b0d4b14652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b114b0d4b14652e\"\n      }\n    },\n    \"num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"num_healthy_workers\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0a4b0a4b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0a4b0a4b0a652e\"\n      }\n    },\n    \"num_in_flight_async_reqs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"num_remote_worker_restarts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d401f4d803e4dc05d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d401f4d803e4dc05d652e\"\n      }\n    },\n    \"num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d401f4d803e4dc05d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d401f4d803e4dc05d652e\"\n      }\n    },\n    \"num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284da00f4d401f4de02e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284da00f4d401f4de02e652e\"\n      }\n    },\n    \"num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284da00f4d401f4de02e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284da00f4d401f4de02e652e\"\n      }\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284da00f4da00f4da00f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284da00f4da00f4da00f652e\"\n      }\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284da00f4da00f4da00f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284da00f4da00f4da00f652e\"\n      }\n    },\n    \"num_env_steps_sampled_throughput_per_sec\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474060c0b987fc101b474060b609f282cfe94740621f7bf3608ca7652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474060c0b987fc101b474060b609f282cfe94740621f7bf3608ca7652e\"\n      }\n    },\n    \"num_env_steps_trained_throughput_per_sec\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474060c0b987fc101b474060b609f282cfe94740621f7bf3608ca7652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474060c0b987fc101b474060b609f282cfe94740621f7bf3608ca7652e\"\n      }\n    },\n    \"timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284da00f4d401f4de02e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284da00f4d401f4de02e652e\"\n      }\n    },\n    \"num_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284da00f4da00f4da00f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284da00f4da00f4da00f652e\"\n      }\n    },\n    \"agent_timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d401f4d803e4dc05d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d401f4d803e4dc05d652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898989652e\"\n      }\n    },\n    \"episodes_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b114b1e4b32652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b114b1e4b32652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403dddbe5c00000047403dee114800000047403b99f320000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403dddbe5c00000047403dee114800000047403b99f320000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403dddbe5c00000047404de5e7d2000000474055d970b1000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403dddbe5c00000047404de5e7d2000000474055d970b1000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403dddbe5c00000047404de5e7d2000000474055d970b1000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403dddbe5c00000047404de5e7d2000000474055d970b1000000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"custom_metrics/red_0/door_open_done_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/red_0/door_open_done_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/red_0/door_open_done_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/red_0/eliminated_opponents_done_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308979696969696d63f94869452946807680d4308333333333333d33f94869452946807680d4308ec51b81e85ebd13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308979696969696d63f94869452946807680d4308333333333333d33f94869452946807680d4308ec51b81e85ebd13f9486945294652e\"\n      }\n    },\n    \"custom_metrics/red_0/eliminated_opponents_done_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/red_0/eliminated_opponents_done_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/red_0/got_eliminated_done_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a5a5ada3f94869452946807680d4308555555555555d53f94869452946807680d4308c3f5285c8fc2d53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a5a5ada3f94869452946807680d4308555555555555d53f94869452946807680d4308c3f5285c8fc2d53f9486945294652e\"\n      }\n    },\n    \"custom_metrics/red_0/got_eliminated_done_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/red_0/got_eliminated_done_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/red_0/eliminated_opponent_num_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308979696969696d63f94869452946807680d4308333333333333d33f94869452946807680d4308ec51b81e85ebd13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308979696969696d63f94869452946807680d4308333333333333d33f94869452946807680d4308ec51b81e85ebd13f9486945294652e\"\n      }\n    },\n    \"custom_metrics/red_0/eliminated_opponent_num_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/red_0/eliminated_opponent_num_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/blue_0/door_open_done_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d43087b14ae47e17a943f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d43087b14ae47e17a943f9486945294652e\"\n      }\n    },\n    \"custom_metrics/blue_0/door_open_done_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/blue_0/door_open_done_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/blue_0/eliminated_opponents_done_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a5a5ada3f94869452946807680d4308555555555555d53f94869452946807680d4308c3f5285c8fc2d53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a5a5ada3f94869452946807680d4308555555555555d53f94869452946807680d4308c3f5285c8fc2d53f9486945294652e\"\n      }\n    },\n    \"custom_metrics/blue_0/eliminated_opponents_done_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/blue_0/eliminated_opponents_done_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/blue_0/got_eliminated_done_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308979696969696d63f94869452946807680d4308333333333333d33f94869452946807680d4308ec51b81e85ebd13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308979696969696d63f94869452946807680d4308333333333333d33f94869452946807680d4308ec51b81e85ebd13f9486945294652e\"\n      }\n    },\n    \"custom_metrics/blue_0/got_eliminated_done_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/blue_0/got_eliminated_done_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/blue_0/eliminated_opponent_num_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a5a5ada3f94869452946807680d4308555555555555d53f94869452946807680d4308c3f5285c8fc2d53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a5a5ada3f94869452946807680d4308555555555555d53f94869452946807680d4308c3f5285c8fc2d53f9486945294652e\"\n      }\n    },\n    \"custom_metrics/blue_0/eliminated_opponent_num_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"custom_metrics/blue_0/eliminated_opponent_num_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"info/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284da00f4d401f4de02e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284da00f4d401f4de02e652e\"\n      }\n    },\n    \"info/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284da00f4d401f4de02e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284da00f4d401f4de02e652e\"\n      }\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d401f4d803e4dc05d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d401f4d803e4dc05d652e\"\n      }\n    },\n    \"info/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d401f4d803e4dc05d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d401f4d803e4dc05d652e\"\n      }\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdab020c49ba5e2473fedeb851eb851eb473ff522d0e5604189652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdab020c49ba5e2473fedeb851eb851eb473ff522d0e5604189652e\"\n      }\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847bfdf5c28f5c28f5c47bfefa5e353f7ceda47bfefa5e353f7ceda652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bfdf5c28f5c28f5c47bfefa5e353f7ceda47bfefa5e353f7ceda652e\"\n      }\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800a313515b32c6bf94869452946807680d43085a58830a21fab8bf94869452946807680d430883a99f3715a9a0bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800a313515b32c6bf94869452946807680d43085a58830a21fab8bf94869452946807680d430883a99f3715a9a0bf9486945294652e\"\n      }\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000a0674094869452946807680d43083333333333036b4094869452946807680d4308ae47e17a146e6a409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000a0674094869452946807680d43083333333333036b4094869452946807680d4308ae47e17a146e6a409486945294652e\"\n      }\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b114b0d4b14652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b114b0d4b14652e\"\n      }\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"policy_reward_min/red_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083bdf4f8d976ef0bf94869452946807680d43088d976e1283c0f0bf94869452946807680d43088d976e1283c0f0bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083bdf4f8d976ef0bf94869452946807680d43088d976e1283c0f0bf94869452946807680d43088d976e1283c0f0bf9486945294652e\"\n      }\n    },\n    \"policy_reward_min/blue_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430891ed7c3f355ef0bf94869452946807680d430879e9263108acf0bf94869452946807680d430879e9263108acf0bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430891ed7c3f355ef0bf94869452946807680d430879e9263108acf0bf94869452946807680d430879e9263108acf0bf9486945294652e\"\n      }\n    },\n    \"policy_reward_max/red_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c0caa145b6f3ed3f94869452946807680d4308c0caa145b6f3ed3f94869452946807680d4308c0caa145b6f3ed3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c0caa145b6f3ed3f94869452946807680d4308c0caa145b6f3ed3f94869452946807680d4308c0caa145b6f3ed3f9486945294652e\"\n      }\n    },\n    \"policy_reward_max/blue_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999e93f94869452946807680d4308999999999999ed3f94869452946807680d43081283c0caa145f43f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999e93f94869452946807680d4308999999999999ed3f94869452946807680d43081283c0caa145f43f9486945294652e\"\n      }\n    },\n    \"policy_reward_mean/red_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c4cda448b9f6c0bf94869452946807680d430816b7d100de02b9bf94869452946807680d4308ea094b3ca06cbabf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c4cda448b9f6c0bf94869452946807680d430816b7d100de02b9bf94869452946807680d4308ea094b3ca06cbabf9486945294652e\"\n      }\n    },\n    \"policy_reward_mean/blue_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ed54bb2188eea4bf94869452946807680d43088980bd9cec79213f94869452946807680d43082a357ba01518b23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ed54bb2188eea4bf94869452946807680d43088980bd9cec79213f94869452946807680d43082a357ba01518b23f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ed1a537be02ff63f94869452946807680d4308ecf895279185f83f94869452946807680d43086699f0b8aaa9f83f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ed1a537be02ff63f94869452946807680d4308ecf895279185f83f94869452946807680d43086699f0b8aaa9f83f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c99c110bd91c214094869452946807680d43086969d97a175e224094869452946807680d430855fb8302c72122409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c99c110bd91c214094869452946807680d43086969d97a175e224094869452946807680d430855fb8302c72122409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f42428f34d22dd3f94869452946807680d430899ffa1e69b4cdf3f94869452946807680d4308292f3697ec9fdf3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f42428f34d22dd3f94869452946807680d430899ffa1e69b4cdf3f94869452946807680d4308292f3697ec9fdf3f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f70a5c4deca8e03f94869452946807680d43082d73ec3b9338e23f94869452946807680d43082d1a47c9cb4de23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f70a5c4deca8e03f94869452946807680d43082d73ec3b9338e23f94869452946807680d43082d1a47c9cb4de23f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"connector_metrics/ObsPreprocessorConnector_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083c3c3c3c0ce2c43f94869452946807680d4308abaaaaaa46f0c53f94869452946807680d4308000000007213c43f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083c3c3c3c0ce2c43f94869452946807680d4308abaaaaaa46f0c53f94869452946807680d4308000000007213c43f9486945294652e\"\n      }\n    },\n    \"connector_metrics/StateBufferConnector_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000004005853f94869452946807680d430800000000b06f923f94869452946807680d43080000000000718d3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000004005853f94869452946807680d430800000000b06f923f94869452946807680d43080000000000718d3f9486945294652e\"\n      }\n    },\n    \"connector_metrics/ViewRequirementAgentConnector_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a964ec83f94869452946807680d43080000000040e0d13f94869452946807680d43080000000044fbcd3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a964ec83f94869452946807680d43080000000040e0d13f94869452946807680d43080000000044fbcd3f9486945294652e\"\n      }\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740dd256a0c49ba5e4740dd2ebc189374bc4740dc6f97ef9db22d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740dd256a0c49ba5e4740dd2ebc189374bc4740dc6f97ef9db22d652e\"\n      }\n    },\n    \"timers/sample_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b19e316872b0214740b49b672b020c4a4740b26b48b4395810652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b19e316872b0214740b49b672b020c4a4740b26b48b4395810652e\"\n      }\n    },\n    \"timers/learn_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740d8adf45a1cac084740d7fc90a3d70a3d4740d7caf3645a1cac652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740d8adf45a1cac084740d7fc90a3d70a3d4740d7caf3645a1cac652e\"\n      }\n    },\n    \"timers/learn_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474063c8ed916872b04740645b3b645a1cac47406485b22d0e5604652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474063c8ed916872b04740645b3b645a1cac47406485b22d0e5604652e\"\n      }\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404ed4189374bc6a474045c8d4fdf3b646474042deb851eb851f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404ed4189374bc6a474045c8d4fdf3b646474042deb851eb851f652e\"\n      }\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284da00f4d401f4de02e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284da00f4d401f4de02e652e\"\n      }\n    },\n    \"counters/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284da00f4d401f4de02e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284da00f4d401f4de02e652e\"\n      }\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d401f4d803e4dc05d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d401f4d803e4dc05d652e\"\n      }\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d401f4d803e4dc05d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d401f4d803e4dc05d652e\"\n      }\n    },\n    \"perf/cpu_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084f09f294200f414094869452946807680d43080e74da40a7cd414094869452946807680d43080bd3b3303d0b3b409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084f09f294200f414094869452946807680d43080e74da40a7cd414094869452946807680d43080bd3b3303d0b3b409486945294652e\"\n      }\n    },\n    \"perf/ram_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084f09f294200f4d4094869452946807680d43081ea62eb73f084d4094869452946807680d4308c8e07c0cce074d409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084f09f294200f4d4094869452946807680d43081ea62eb73f084d4094869452946807680d4308c8e07c0cce074d409486945294652e\"\n      }\n    },\n    \"sampler_results/policy_reward_min/red_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083bdf4f8d976ef0bf94869452946807680d43088d976e1283c0f0bf94869452946807680d43088d976e1283c0f0bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083bdf4f8d976ef0bf94869452946807680d43088d976e1283c0f0bf94869452946807680d43088d976e1283c0f0bf9486945294652e\"\n      }\n    },\n    \"sampler_results/policy_reward_min/blue_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430891ed7c3f355ef0bf94869452946807680d430879e9263108acf0bf94869452946807680d430879e9263108acf0bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430891ed7c3f355ef0bf94869452946807680d430879e9263108acf0bf94869452946807680d430879e9263108acf0bf9486945294652e\"\n      }\n    },\n    \"sampler_results/policy_reward_max/red_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c0caa145b6f3ed3f94869452946807680d4308c0caa145b6f3ed3f94869452946807680d4308c0caa145b6f3ed3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c0caa145b6f3ed3f94869452946807680d4308c0caa145b6f3ed3f94869452946807680d4308c0caa145b6f3ed3f9486945294652e\"\n      }\n    },\n    \"sampler_results/policy_reward_max/blue_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999e93f94869452946807680d4308999999999999ed3f94869452946807680d43081283c0caa145f43f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999e93f94869452946807680d4308999999999999ed3f94869452946807680d43081283c0caa145f43f9486945294652e\"\n      }\n    },\n    \"sampler_results/policy_reward_mean/red_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c4cda448b9f6c0bf94869452946807680d430816b7d100de02b9bf94869452946807680d4308ea094b3ca06cbabf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c4cda448b9f6c0bf94869452946807680d430816b7d100de02b9bf94869452946807680d4308ea094b3ca06cbabf9486945294652e\"\n      }\n    },\n    \"sampler_results/policy_reward_mean/blue_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ed54bb2188eea4bf94869452946807680d43088980bd9cec79213f94869452946807680d43082a357ba01518b23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ed54bb2188eea4bf94869452946807680d43088980bd9cec79213f94869452946807680d43082a357ba01518b23f9486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/red_0/door_open_done_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/red_0/door_open_done_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/red_0/door_open_done_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/red_0/eliminated_opponents_done_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308979696969696d63f94869452946807680d4308333333333333d33f94869452946807680d4308ec51b81e85ebd13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308979696969696d63f94869452946807680d4308333333333333d33f94869452946807680d4308ec51b81e85ebd13f9486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/red_0/eliminated_opponents_done_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/red_0/eliminated_opponents_done_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/red_0/got_eliminated_done_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a5a5ada3f94869452946807680d4308555555555555d53f94869452946807680d4308c3f5285c8fc2d53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a5a5ada3f94869452946807680d4308555555555555d53f94869452946807680d4308c3f5285c8fc2d53f9486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/red_0/got_eliminated_done_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/red_0/got_eliminated_done_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/red_0/eliminated_opponent_num_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308979696969696d63f94869452946807680d4308333333333333d33f94869452946807680d4308ec51b81e85ebd13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308979696969696d63f94869452946807680d4308333333333333d33f94869452946807680d4308ec51b81e85ebd13f9486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/red_0/eliminated_opponent_num_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/red_0/eliminated_opponent_num_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/blue_0/door_open_done_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d43087b14ae47e17a943f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d43087b14ae47e17a943f9486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/blue_0/door_open_done_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/blue_0/door_open_done_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/blue_0/eliminated_opponents_done_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a5a5ada3f94869452946807680d4308555555555555d53f94869452946807680d4308c3f5285c8fc2d53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a5a5ada3f94869452946807680d4308555555555555d53f94869452946807680d4308c3f5285c8fc2d53f9486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/blue_0/eliminated_opponents_done_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/blue_0/eliminated_opponents_done_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/blue_0/got_eliminated_done_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308979696969696d63f94869452946807680d4308333333333333d33f94869452946807680d4308ec51b81e85ebd13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308979696969696d63f94869452946807680d4308333333333333d33f94869452946807680d4308ec51b81e85ebd13f9486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/blue_0/got_eliminated_done_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/blue_0/got_eliminated_done_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/blue_0/eliminated_opponent_num_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a5a5ada3f94869452946807680d4308555555555555d53f94869452946807680d4308c3f5285c8fc2d53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a5a5ada3f94869452946807680d4308555555555555d53f94869452946807680d4308c3f5285c8fc2d53f9486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/blue_0/eliminated_opponent_num_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/custom_metrics/blue_0/eliminated_opponent_num_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308010000000000000094869452946807680d4308010000000000000094869452946807680d430801000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ed1a537be02ff63f94869452946807680d4308ecf895279185f83f94869452946807680d43086699f0b8aaa9f83f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ed1a537be02ff63f94869452946807680d4308ecf895279185f83f94869452946807680d43086699f0b8aaa9f83f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c99c110bd91c214094869452946807680d43086969d97a175e224094869452946807680d430855fb8302c72122409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c99c110bd91c214094869452946807680d43086969d97a175e224094869452946807680d430855fb8302c72122409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f42428f34d22dd3f94869452946807680d430899ffa1e69b4cdf3f94869452946807680d4308292f3697ec9fdf3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f42428f34d22dd3f94869452946807680d430899ffa1e69b4cdf3f94869452946807680d4308292f3697ec9fdf3f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f70a5c4deca8e03f94869452946807680d43082d73ec3b9338e23f94869452946807680d43082d1a47c9cb4de23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f70a5c4deca8e03f94869452946807680d43082d73ec3b9338e23f94869452946807680d43082d1a47c9cb4de23f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/connector_metrics/ObsPreprocessorConnector_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083c3c3c3c0ce2c43f94869452946807680d4308abaaaaaa46f0c53f94869452946807680d4308000000007213c43f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083c3c3c3c0ce2c43f94869452946807680d4308abaaaaaa46f0c53f94869452946807680d4308000000007213c43f9486945294652e\"\n      }\n    },\n    \"sampler_results/connector_metrics/StateBufferConnector_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000004005853f94869452946807680d430800000000b06f923f94869452946807680d43080000000000718d3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000004005853f94869452946807680d430800000000b06f923f94869452946807680d43080000000000718d3f9486945294652e\"\n      }\n    },\n    \"sampler_results/connector_metrics/ViewRequirementAgentConnector_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a964ec83f94869452946807680d43080000000040e0d13f94869452946807680d43080000000044fbcd3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a5a5a5a964ec83f94869452946807680d43080000000040e0d13f94869452946807680d43080000000044fbcd3f9486945294652e\"\n      }\n    },\n    \"info/learner/red_0/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000405f4094869452946807680d43080000000000405f4094869452946807680d43080000000000405f409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000405f4094869452946807680d43080000000000405f4094869452946807680d43080000000000405f409486945294652e\"\n      }\n    },\n    \"info/learner/red_0/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000087e4094869452946807680d4308000000000082964094869452946807680d43080000000000c1a2409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000087e4094869452946807680d4308000000000082964094869452946807680d43080000000000c1a2409486945294652e\"\n      }\n    },\n    \"info/learner/red_0/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000f87d4094869452946807680d43080000000000f87d4094869452946807680d43080000000000f87d409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000f87d4094869452946807680d43080000000000f87d4094869452946807680d43080000000000f87d409486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000405f4094869452946807680d43080000000000405f4094869452946807680d43080000000000405f409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000405f4094869452946807680d43080000000000405f4094869452946807680d43080000000000405f409486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000087e4094869452946807680d4308000000000082964094869452946807680d43080000000000c1a2409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000087e4094869452946807680d4308000000000082964094869452946807680d43080000000000c1a2409486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000f87d4094869452946807680d43080000000000f87d4094869452946807680d43080000000000f87d409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000f87d4094869452946807680d43080000000000f87d4094869452946807680d43080000000000f87d409486945294652e\"\n      }\n    },\n    \"info/learner/red_0/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/learner/red_0/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084444c4a6c663d63f94869452946807680d43081111d19fcab6d73f94869452946807680d4308cdccccfcdafcdb3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084444c4a6c663d63f94869452946807680d43081111d19fcab6d73f94869452946807680d4308cdccccfcdafcdb3f9486945294652e\"\n      }\n    },\n    \"info/learner/red_0/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089b9999999999c93f94869452946807680d4308323333333333d33f94869452946807680d4308cfccccccccccdc3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089b9999999999c93f94869452946807680d4308323333333333d33f94869452946807680d4308cfccccccccccdc3f9486945294652e\"\n      }\n    },\n    \"info/learner/red_0/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f9486945294652e\"\n      }\n    },\n    \"info/learner/red_0/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085555c109c383a5bf94869452946807680d43080000f057b7d1b5bf94869452946807680d430833333b015d68b3bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085555c109c383a5bf94869452946807680d43080000f057b7d1b5bf94869452946807680d430833333b015d68b3bf9486945294652e\"\n      }\n    },\n    \"info/learner/red_0/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99c101139bafbf94869452946807680d43081111a9eeedb5b9bf94869452946807680d4308bcbb0bdd72bdb9bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99c101139bafbf94869452946807680d43081111a9eeedb5b9bf94869452946807680d4308bcbb0bdd72bdb9bf9486945294652e\"\n      }\n    },\n    \"info/learner/red_0/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc2ce98f5ca03f94869452946807680d4308000040ca0b3d8b3f94869452946807680d43083333f35c73c8983f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc2ce98f5ca03f94869452946807680d4308000040ca0b3d8b3f94869452946807680d43083333f35c73c8983f9486945294652e\"\n      }\n    },\n    \"info/learner/red_0/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833333308feb3dd3f94869452946807680d4308bcbbbbd43124e23f94869452946807680d430800008062f8f6e03f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833333308feb3dd3f94869452946807680d4308bcbbbbd43124e23f94869452946807680d430800008062f8f6e03f9486945294652e\"\n      }\n    },\n    \"info/learner/red_0/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e5e9982b63eb9c3f94869452946807680d4308de9d9125a3d0a13f94869452946807680d43089e04277b6a7ea03f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e5e9982b63eb9c3f94869452946807680d4308de9d9125a3d0a13f94869452946807680d43089e04277b6a7ea03f9486945294652e\"\n      }\n    },\n    \"info/learner/red_0/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308777777525badfe3f94869452946807680d4308555555cc1b33fe3f94869452946807680d43089a99193fe8c9fd3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308777777525badfe3f94869452946807680d4308555555cc1b33fe3f94869452946807680d43089a99193fe8c9fd3f9486945294652e\"\n      }\n    },\n    \"info/learner/red_0/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f9486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308efee6ef943d3d53f94869452946807680d4308dedd1d37b7add93f94869452946807680d43081111919a7053dc3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308efee6ef943d3d53f94869452946807680d4308dedd1d37b7add93f94869452946807680d43081111919a7053dc3f9486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089b9999999999c93f94869452946807680d4308323333333333d33f94869452946807680d4308cfccccccccccdc3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089b9999999999c93f94869452946807680d4308323333333333d33f94869452946807680d4308cfccccccccccdc3f9486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f9486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087777c3b0369eadbf94869452946807680d4308cdcc845cedfcb4bf94869452946807680d43081111a1592867b3bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087777c3b0369eadbf94869452946807680d4308cdcc845cedfcb4bf94869452946807680d43081111a1592867b3bf9486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082222aa0e0551b3bf94869452946807680d43089a99359cad2cb9bf94869452946807680d43085555d5a93ce6b9bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082222aa0e0551b3bf94869452946807680d43089a99359cad2cb9bf94869452946807680d43085555d5a93ce6b9bf9486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430889886815ffbb9a3f94869452946807680d43080000c096c1bf8e3f94869452946807680d430844440442b32f9a3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430889886815ffbb9a3f94869452946807680d43080000c096c1bf8e3f94869452946807680d430844440442b32f9a3f9486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308abaa2a66f3e8e03f94869452946807680d43085555554e98efe23f94869452946807680d43087777f7f7881ee13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308abaa2a66f3e8e03f94869452946807680d43085555554e98efe23f94869452946807680d43087777f7f7881ee13f9486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308efee9f4c218ea03f94869452946807680d4308e7c0c64e0e4fa23f94869452946807680d43084202b648e771a03f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308efee9f4c218ea03f94869452946807680d4308e7c0c64e0e4fa23f94869452946807680d43084202b648e771a03f9486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081111910f7a9dfe3f94869452946807680d4308000000a3c219fe3f94869452946807680d43089a991947f7cffd3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081111910f7a9dfe3f94869452946807680d4308000000a3c219fe3f94869452946807680d43089a991947f7cffd3f9486945294652e\"\n      }\n    },\n    \"info/learner/blue_0/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595b0000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f94869452946807680d4308fea9f1d24d62503f9486945294652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1694891798.8564942,\n  \"relative_logdir\": \"PPO_MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1_819b8_00000_0_2023-09-16_15-16-15\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"1v1_Testing\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b0a8c11636865636b706f696e745f61745f656e6494888c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b0a8c11636865636b706f696e745f61745f656e6494888c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}"
  ],
  "runner_data": {
    "_earliest_stopping_actor": Infinity,
    "_actor_cleanup_timeout": 600,
    "_actor_force_cleanup_timeout": 10,
    "_reuse_actors": false,
    "_chdir_to_trial_dir": true,
    "_buffer_length": 1,
    "_buffer_min_time_s": 0.0,
    "_buffer_max_time_s": 100.0,
    "_max_pending_trials": 16,
    "_metric": null,
    "_total_time": 87.3975031375885,
    "_iteration": 1138,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_start_time": 1694891775.530537,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2023-09-16_15-16-15",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595ec000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b0a8c11636865636b706f696e745f61745f656e6494888c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e"
    },
    "_resumed": false,
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1694891775.530537,
    "timestamp": -Infinity
  }
}